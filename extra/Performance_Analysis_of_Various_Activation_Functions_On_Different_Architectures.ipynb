{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Performance_Analysis_of_Various_Activation_Functions_On_Different_Architectures.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63b136ada7b548f8992005ab2785594c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10bff533a2d8460fabd5e22a6c2b535b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77f598a333164e36bfd69b840ef02a5d",
              "IPY_MODEL_28e765d70b7747038b1a154fcbeecd84"
            ]
          }
        },
        "10bff533a2d8460fabd5e22a6c2b535b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77f598a333164e36bfd69b840ef02a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2de45a4dda154ecd85a1912225953aa2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39282c0d5cbd4fdcbec93b6531f727c7"
          }
        },
        "28e765d70b7747038b1a154fcbeecd84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85cc406f3b774be5a3a6e9e85ae92df6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:08&lt;00:00, 1111991.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7332ea6f55944a80a196b733b2bfe2aa"
          }
        },
        "2de45a4dda154ecd85a1912225953aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39282c0d5cbd4fdcbec93b6531f727c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85cc406f3b774be5a3a6e9e85ae92df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7332ea6f55944a80a196b733b2bfe2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37e28283e4e64a7daf7e654b0cbf1371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b3588aac1ac427a8b0352f4775fab5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c44fa0b70fe34579897db12d6da7adff",
              "IPY_MODEL_3bb5b77e2f1e4208a80b8e9030779fa6"
            ]
          }
        },
        "6b3588aac1ac427a8b0352f4775fab5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c44fa0b70fe34579897db12d6da7adff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb3d074b73c4495392bd9e9966e75a51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce0f5add97dd45af8aeceede72e8c2c9"
          }
        },
        "3bb5b77e2f1e4208a80b8e9030779fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab054489fa734d71be31e88fced66ff1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:04&lt;00:00, 7935.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f307bcb40eaa4d2b8282ea91f5786957"
          }
        },
        "cb3d074b73c4495392bd9e9966e75a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce0f5add97dd45af8aeceede72e8c2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab054489fa734d71be31e88fced66ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f307bcb40eaa4d2b8282ea91f5786957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de5df5e6c9b34d1ca80ef89873878c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9db455e059de4ee6bbb9064c1c9d201f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb4c2aeaa275408e9e17112b2eeb4bba",
              "IPY_MODEL_42bac99f2f3e4deea68c81d114d26bc5"
            ]
          }
        },
        "9db455e059de4ee6bbb9064c1c9d201f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb4c2aeaa275408e9e17112b2eeb4bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a62ebce15c7487c9b725c1d1bce9341",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98010965f25244458a34e650bf79f1a2"
          }
        },
        "42bac99f2f3e4deea68c81d114d26bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e38aa2010a6a4eb48e1acbecde4b3ffe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:03&lt;00:00, 488398.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44935cd9e75c4bf8a55e418037a439e9"
          }
        },
        "3a62ebce15c7487c9b725c1d1bce9341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98010965f25244458a34e650bf79f1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e38aa2010a6a4eb48e1acbecde4b3ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44935cd9e75c4bf8a55e418037a439e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09bbcc53fffe4d8f87491ce4c282a689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c02727b1ab384b2899e9c716e50236e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0534168353384a70934b963455f78697",
              "IPY_MODEL_7c8eae18db7a4c33ba5bd60dcdc24877"
            ]
          }
        },
        "c02727b1ab384b2899e9c716e50236e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0534168353384a70934b963455f78697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef4c3e21b8c2455d9d32b98b9889730f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcbe021324114370b72f60f8e1bd25b7"
          }
        },
        "7c8eae18db7a4c33ba5bd60dcdc24877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b65cbbf88203419a9411bc2a9987288f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:01&lt;00:00, 7293.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51848de9becb4732810de3098bff7425"
          }
        },
        "ef4c3e21b8c2455d9d32b98b9889730f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcbe021324114370b72f60f8e1bd25b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b65cbbf88203419a9411bc2a9987288f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51848de9becb4732810de3098bff7425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT3EWy9YEnOC",
        "colab_type": "text"
      },
      "source": [
        "Name: Sree Lakshmi Addepalli\n",
        "\n",
        "\n",
        "Email: sla410@nyu.edu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HU1MOA6-sZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQf1g-dnDHrQ",
        "colab_type": "code",
        "outputId": "e25bdeb3-d46a-4ca4-e183-68152ed25f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349,
          "referenced_widgets": [
            "63b136ada7b548f8992005ab2785594c",
            "10bff533a2d8460fabd5e22a6c2b535b",
            "77f598a333164e36bfd69b840ef02a5d",
            "28e765d70b7747038b1a154fcbeecd84",
            "2de45a4dda154ecd85a1912225953aa2",
            "39282c0d5cbd4fdcbec93b6531f727c7",
            "85cc406f3b774be5a3a6e9e85ae92df6",
            "7332ea6f55944a80a196b733b2bfe2aa",
            "37e28283e4e64a7daf7e654b0cbf1371",
            "6b3588aac1ac427a8b0352f4775fab5d",
            "c44fa0b70fe34579897db12d6da7adff",
            "3bb5b77e2f1e4208a80b8e9030779fa6",
            "cb3d074b73c4495392bd9e9966e75a51",
            "ce0f5add97dd45af8aeceede72e8c2c9",
            "ab054489fa734d71be31e88fced66ff1",
            "f307bcb40eaa4d2b8282ea91f5786957",
            "de5df5e6c9b34d1ca80ef89873878c1f",
            "9db455e059de4ee6bbb9064c1c9d201f",
            "cb4c2aeaa275408e9e17112b2eeb4bba",
            "42bac99f2f3e4deea68c81d114d26bc5",
            "3a62ebce15c7487c9b725c1d1bce9341",
            "98010965f25244458a34e650bf79f1a2",
            "e38aa2010a6a4eb48e1acbecde4b3ffe",
            "44935cd9e75c4bf8a55e418037a439e9",
            "09bbcc53fffe4d8f87491ce4c282a689",
            "c02727b1ab384b2899e9c716e50236e4",
            "0534168353384a70934b963455f78697",
            "7c8eae18db7a4c33ba5bd60dcdc24877",
            "ef4c3e21b8c2455d9d32b98b9889730f",
            "bcbe021324114370b72f60f8e1bd25b7",
            "b65cbbf88203419a9411bc2a9987288f",
            "51848de9becb4732810de3098bff7425"
          ]
        }
      },
      "source": [
        "input_size  = 28*28   # images are 28x28 pixels\n",
        "output_size = 10      # there are 10 classes\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=1000, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63b136ada7b548f8992005ab2785594c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37e28283e4e64a7daf7e654b0cbf1371",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de5df5e6c9b34d1ca80ef89873878c1f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09bbcc53fffe4d8f87491ce4c282a689",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC0wCyx-iCa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWG5PEX7pP76",
        "colab_type": "code",
        "outputId": "c7e73058-0302-4b24-f8af-56b6c15c71e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# show some images\n",
        "plt.figure(figsize=(16, 6))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    image, _ = train_loader.dataset.__getitem__(i)\n",
        "    plt.imshow(image.squeeze().numpy())\n",
        "    plt.axis('off');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAFUCAYAAACTLZkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 1152x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU1iFbY3iN-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to count number of parameters\n",
        "def get_n_params(model):\n",
        "    np=0\n",
        "    for p in list(model.parameters()):\n",
        "        print(p.size())\n",
        "        np += p.nelement()\n",
        "    return np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsIQnmd0E7BP",
        "colab_type": "text"
      },
      "source": [
        "## List of activation functions used:\n",
        "\n",
        "- Tanh\n",
        "- ReLu\n",
        "- Sigmoid\n",
        "\n",
        "\n",
        "## Comparison of various activation functions on the following Neural Network Architectures:\n",
        "\n",
        "- MultiLayerPerceptron / FeedForward Neural Network\n",
        "- Convolution Neural Network\n",
        "- Recurrent Neural Network\n",
        "- Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc45g0PnFshC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for multilayer perceptron with Relu activation:\n",
        "\n",
        "class FC2LayerRelu(nn.Module):\n",
        "    def __init__(self, input_size, n_hidden, output_size):\n",
        "        super(FC2LayerRelu, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, n_hidden), \n",
        "            nn.ReLU(), \n",
        "            nn.Linear(n_hidden, n_hidden), \n",
        "            nn.ReLU(), \n",
        "            nn.Linear(n_hidden, output_size), \n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        return self.network(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OddCcijTiRP",
        "colab_type": "code",
        "outputId": "0f26b1fd-b3dd-478f-cec6-dc78ac916995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Defining the classes for multilayer perceptron with Tanh activation:\n",
        "\n",
        "class FC2LayerTanh(nn.Module):\n",
        "    def __init__(self, input_size, n_hidden, output_size):\n",
        "        super(FC2LayerTanh, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, n_hidden), \n",
        "            nn.Tanh(), \n",
        "            nn.Linear(n_hidden, n_hidden), \n",
        "            nn.Tanh(), \n",
        "            nn.Linear(n_hidden, output_size), \n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        return self.network(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU0z61peTioD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for multilayer perceptron with Sigmoid activation:\n",
        "\n",
        "class FC2LayerSigmoid(nn.Module):\n",
        "    def __init__(self, input_size, n_hidden, output_size):\n",
        "        super(FC2LayerSigmoid, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, n_hidden), \n",
        "            nn.Sigmoid(), \n",
        "            nn.Linear(n_hidden, n_hidden), \n",
        "            nn.Sigmoid(), \n",
        "            nn.Linear(n_hidden, output_size), \n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        return self.network(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9skj2U2ELxJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for Convolutional Neural Network with Relu activation function:\n",
        "\n",
        "class CNNRelu(nn.Module):\n",
        "    def __init__(self, input_size, n_feature, output_size):\n",
        "        super(CNNRelu, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        \n",
        "    def forward(self, x, verbose=False):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = x.view(-1, self.n_feature*4*4)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXYne_sLY8Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for Convolutional Neural Network with Tanh activation function:\n",
        "\n",
        "class CNNTanh(nn.Module):\n",
        "    def __init__(self, input_size, n_feature, output_size):\n",
        "        super(CNNTanh, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        \n",
        "    def forward(self, x, verbose=False):\n",
        "        x = self.conv1(x)\n",
        "        x = F.tanh(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.tanh(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = x.view(-1, self.n_feature*4*4)\n",
        "        x = self.fc1(x)\n",
        "        x = F.tanh(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91V-fA4RY8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for Convolutional Neural Network with sigmoid activation function:\n",
        "\n",
        "class CNNSigmoid(nn.Module):\n",
        "    def __init__(self, input_size, n_feature, output_size):\n",
        "        super(CNNSigmoid, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        \n",
        "    def forward(self, x, verbose=False):\n",
        "        x = self.conv1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "        x = x.view(-1, self.n_feature*4*4)\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sM4nArjHLdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for Autoencoders with Tanh activation function:\n",
        "\n",
        "class autoencoderTanh(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoderTanh, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.Tanh(), nn.Linear(64, 12), nn.Tanh(), nn.Linear(12, 3))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 12),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(12, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.Tanh(), nn.Linear(128, 28 * 28), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGgh_aCsHL5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for Autoencoders with Relu activation function:\n",
        "\n",
        "class autoencoderReLu(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoderReLu, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 12),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(12, 64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JWsqyXCHMTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining the classes for Autoencoders with Sigmoid activation function:\n",
        "\n",
        "class autoencoderSigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoderSigmoid, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.Sigmoid(), nn.Linear(64, 12), nn.Sigmoid(), nn.Linear(12, 3))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 12),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(12, 64),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.Sigmoid(), nn.Linear(128, 28 * 28), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbzAI0CMatAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Train and Test module for CNN and MLP\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "def train(epoch, model, perm=torch.arange(0, 784).long()):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        #print(len(data))\n",
        "        #print(len(target))\n",
        "        \n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "        #print(data.shape)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        #print(\"%%%\")\n",
        "        #print(output.shape)\n",
        "        #print(target.shape)\n",
        "        #print(\"%%%\")\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def test(model, perm=torch.arange(0, 784).long()):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p98NZBiQgwpm",
        "colab_type": "code",
        "outputId": "e1d8d498-6561-463e-ae4f-1303f0402809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_hidden = 8 # number of hidden units\n",
        "\n",
        "# Training MLP with Relu Activation\n",
        "\n",
        "model_fnn_relu = FC2LayerRelu(input_size, n_hidden, output_size)\n",
        "model_fnn_relu.to(device)\n",
        "optimizer = optim.SGD(model_fnn_relu.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_fnn_relu)))\n",
        "\n",
        "for epoch in range(0, 10):\n",
        "    train(epoch, model_fnn_relu)\n",
        "    test(model_fnn_relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 784])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8])\n",
            "torch.Size([8])\n",
            "torch.Size([10, 8])\n",
            "torch.Size([10])\n",
            "Number of parameters: 6442\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.386166\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.739565\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.164121\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.912180\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.685729\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.702468\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.374500\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.436413\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.403473\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.547804\n",
            "\n",
            "Test set: Average loss: 0.4639, Accuracy: 8616/10000 (86%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.569574\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.377917\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.415138\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.553593\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.381232\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.275821\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.249208\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.713686\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.447825\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.476394\n",
            "\n",
            "Test set: Average loss: 0.3624, Accuracy: 8951/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.503022\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.351727\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.289401\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.402353\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.441482\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.332227\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.460176\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.273902\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.355909\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.376152\n",
            "\n",
            "Test set: Average loss: 0.3278, Accuracy: 9075/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.135048\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.239668\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.357914\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.420532\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.317722\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.178623\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.433443\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.266840\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.311850\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.267538\n",
            "\n",
            "Test set: Average loss: 0.3062, Accuracy: 9120/10000 (91%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.240613\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.226728\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.137828\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.307221\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.297257\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.349473\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.269227\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.247556\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.287442\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.172249\n",
            "\n",
            "Test set: Average loss: 0.3061, Accuracy: 9093/10000 (91%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.319914\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.151001\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.114451\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.245424\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.309089\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.161615\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.214676\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.512995\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.222277\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.288581\n",
            "\n",
            "Test set: Average loss: 0.2840, Accuracy: 9160/10000 (92%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.250361\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.133728\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.205971\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.366084\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.457255\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.227698\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.426497\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.338983\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.409856\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.132741\n",
            "\n",
            "Test set: Average loss: 0.2911, Accuracy: 9153/10000 (92%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.138333\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.351530\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.292733\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.268591\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.324876\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.208184\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.130116\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.071788\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.141000\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.161024\n",
            "\n",
            "Test set: Average loss: 0.2834, Accuracy: 9135/10000 (91%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.240946\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.345542\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.298830\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.366084\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.345698\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.187768\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.121236\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.192911\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.213867\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.312997\n",
            "\n",
            "Test set: Average loss: 0.2706, Accuracy: 9198/10000 (92%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.257653\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.367118\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.377971\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.244463\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.090759\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.214819\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.124990\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.308964\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.238058\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.297786\n",
            "\n",
            "Test set: Average loss: 0.2636, Accuracy: 9200/10000 (92%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTWbFSP6nOHs",
        "colab_type": "code",
        "outputId": "3fdb038d-183b-4660-c4e5-3f88c331cceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_hidden = 8 # number of hidden units\n",
        "\n",
        "# Training MLP with Tanh Activation\n",
        "\n",
        "model_fnn_tanh = FC2LayerTanh(input_size, n_hidden, output_size)\n",
        "model_fnn_tanh.to(device)\n",
        "optimizer = optim.SGD(model_fnn_tanh.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_fnn_tanh)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_fnn_tanh)\n",
        "    test(model_fnn_tanh)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 784])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8])\n",
            "torch.Size([8])\n",
            "torch.Size([10, 8])\n",
            "torch.Size([10])\n",
            "Number of parameters: 6442\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.310840\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.937800\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.573378\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 1.387727\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 1.359571\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 1.062811\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.892072\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.935538\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.830902\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.781470\n",
            "\n",
            "Test set: Average loss: 0.7027, Accuracy: 8512/10000 (85%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.650554\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.624576\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.542503\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.638803\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.568011\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.549609\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.614062\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.473229\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.560629\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.476315\n",
            "\n",
            "Test set: Average loss: 0.4765, Accuracy: 8836/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.501433\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.513336\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.437603\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.419756\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.507873\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.318201\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.691756\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.445492\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.487859\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.584014\n",
            "\n",
            "Test set: Average loss: 0.4174, Accuracy: 8911/10000 (89%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.356044\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.378985\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.346052\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.412453\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.392518\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.461219\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.407685\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.342402\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.556387\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.263588\n",
            "\n",
            "Test set: Average loss: 0.3890, Accuracy: 8972/10000 (90%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.312158\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.390518\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.386975\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.309492\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.534368\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.319606\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.221269\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.293634\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.268146\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.395213\n",
            "\n",
            "Test set: Average loss: 0.3662, Accuracy: 9000/10000 (90%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.129065\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.378401\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.308010\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.484279\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.477756\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.422480\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.462054\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.480863\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.551052\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.227312\n",
            "\n",
            "Test set: Average loss: 0.3541, Accuracy: 9022/10000 (90%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.390802\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.507170\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.371057\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.312639\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.539620\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.210163\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.300534\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.253971\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.325200\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.467040\n",
            "\n",
            "Test set: Average loss: 0.3455, Accuracy: 9042/10000 (90%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.260855\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.231218\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.314551\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.321195\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.379556\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.416886\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.343712\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.188446\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.379518\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.375813\n",
            "\n",
            "Test set: Average loss: 0.3601, Accuracy: 8996/10000 (90%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.499498\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.217617\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.350074\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.364077\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.161979\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.257348\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.186801\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.331622\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.407147\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.190850\n",
            "\n",
            "Test set: Average loss: 0.3325, Accuracy: 9084/10000 (91%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.150156\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.321389\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.223956\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.392279\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.341694\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.344355\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.320583\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.283231\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.225179\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.309990\n",
            "\n",
            "Test set: Average loss: 0.3326, Accuracy: 9072/10000 (91%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.313315\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.281378\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.434309\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.350844\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.414005\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.267677\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.200304\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.235614\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.460496\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.359246\n",
            "\n",
            "Test set: Average loss: 0.3374, Accuracy: 9050/10000 (90%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.484094\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.157980\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.220749\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.550507\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.352327\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.262737\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.424275\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.380487\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.259989\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.121726\n",
            "\n",
            "Test set: Average loss: 0.3238, Accuracy: 9104/10000 (91%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.184587\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.200462\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.275417\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.293020\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.475267\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.224813\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.422974\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.301185\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.226654\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.251332\n",
            "\n",
            "Test set: Average loss: 0.3173, Accuracy: 9143/10000 (91%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.323242\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.296957\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.209039\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.357638\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.471464\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.385414\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.146019\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.218317\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.220036\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.347586\n",
            "\n",
            "Test set: Average loss: 0.3173, Accuracy: 9125/10000 (91%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.194912\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.133097\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.231324\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.265271\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.387556\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.304818\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.216581\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.311586\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.237298\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.304544\n",
            "\n",
            "Test set: Average loss: 0.3230, Accuracy: 9077/10000 (91%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b594iJaxn7wi",
        "colab_type": "code",
        "outputId": "f394b1c9-449b-4327-ba9f-1b6a6604f37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_hidden = 8 # number of hidden units\n",
        "\n",
        "# Training MLP with Sigmoid Activation\n",
        "\n",
        "model_fnn_sigmoid = FC2LayerSigmoid(input_size, n_hidden, output_size)\n",
        "model_fnn_sigmoid.to(device)\n",
        "optimizer = optim.SGD(model_fnn_sigmoid.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_fnn_sigmoid)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_fnn_sigmoid)\n",
        "    test(model_fnn_sigmoid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 784])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8])\n",
            "torch.Size([8])\n",
            "torch.Size([10, 8])\n",
            "torch.Size([10])\n",
            "Number of parameters: 6442\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.426656\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.305347\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.294896\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.264743\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.277064\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.273560\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.270343\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.259883\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 2.231049\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 2.243030\n",
            "\n",
            "Test set: Average loss: 2.2292, Accuracy: 3428/10000 (34%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.244579\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.209894\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.217648\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.237319\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.154653\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.130236\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.135985\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.091084\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.028627\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.043939\n",
            "\n",
            "Test set: Average loss: 2.0140, Accuracy: 3149/10000 (31%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.032959\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.923090\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.968400\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.899505\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.883461\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.900920\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.878806\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.878310\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.834978\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.818960\n",
            "\n",
            "Test set: Average loss: 1.8048, Accuracy: 4223/10000 (42%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.796800\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.797930\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.809220\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.689506\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.769999\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.647753\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.723317\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.702258\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.607598\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.725472\n",
            "\n",
            "Test set: Average loss: 1.6484, Accuracy: 5807/10000 (58%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.629323\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.630664\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.570066\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.656303\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.518988\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.647091\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.519513\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.479435\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.536620\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.510377\n",
            "\n",
            "Test set: Average loss: 1.4577, Accuracy: 6233/10000 (62%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.418416\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.412736\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.573971\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 1.403021\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.592072\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.347872\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.273992\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.382388\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.377327\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.288588\n",
            "\n",
            "Test set: Average loss: 1.2734, Accuracy: 6573/10000 (66%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.355096\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.306271\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.219943\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.259922\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.282183\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.245088\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.118384\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 1.189084\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.214947\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.200219\n",
            "\n",
            "Test set: Average loss: 1.1219, Accuracy: 7121/10000 (71%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.133503\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.060741\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.087808\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.976164\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.058626\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.040193\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.289984\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.015879\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.963775\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.967629\n",
            "\n",
            "Test set: Average loss: 1.0049, Accuracy: 7640/10000 (76%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.039938\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.905645\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.038977\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.952661\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.900631\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.101092\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.030009\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.805412\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.911825\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.813564\n",
            "\n",
            "Test set: Average loss: 0.9143, Accuracy: 7805/10000 (78%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.856980\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.925680\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.998632\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.785801\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.878531\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.946098\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.789461\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.825744\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.878149\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.863749\n",
            "\n",
            "Test set: Average loss: 0.8395, Accuracy: 7995/10000 (80%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.853936\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.865868\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.821826\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.751012\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.813621\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.727566\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.878159\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.854557\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.846690\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.819144\n",
            "\n",
            "Test set: Average loss: 0.7782, Accuracy: 8143/10000 (81%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.847470\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.764982\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.844141\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.731041\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.662226\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.758182\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.724841\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.803585\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.833235\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.724161\n",
            "\n",
            "Test set: Average loss: 0.7190, Accuracy: 8278/10000 (83%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.667714\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.773871\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.918866\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.742714\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.628642\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.612289\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.664517\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.616281\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.737682\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.494642\n",
            "\n",
            "Test set: Average loss: 0.6660, Accuracy: 8480/10000 (85%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.712282\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.790789\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.589913\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.645157\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.582996\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.588866\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.732199\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.610964\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.922877\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.743102\n",
            "\n",
            "Test set: Average loss: 0.6251, Accuracy: 8569/10000 (86%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.847639\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.695565\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.761246\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.542276\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.546025\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.671143\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.500827\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.572042\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.581754\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.595859\n",
            "\n",
            "Test set: Average loss: 0.5885, Accuracy: 8661/10000 (87%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0HJo6N3oamw",
        "colab_type": "code",
        "outputId": "9bfb0a61-0605-4070-cbf7-31e55b47384f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training settings \n",
        "n_features = 6 # number of feature maps\n",
        "\n",
        "model_cnn_relu = CNNRelu(input_size, n_features, output_size)\n",
        "model_cnn_relu.to(device)\n",
        "optimizer = optim.SGD(model_cnn_relu.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_cnn_relu)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_cnn_relu)\n",
        "    test(model_cnn_relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([6, 6, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([50, 96])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n",
            "Number of parameters: 6422\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.297632\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.082773\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.422694\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.374466\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.239305\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.237707\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.245148\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.105336\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.185915\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.109109\n",
            "\n",
            "Test set: Average loss: 0.1607, Accuracy: 9498/10000 (95%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.150529\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.143387\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.320941\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.179309\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.158617\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.128969\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.096189\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.233709\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.121956\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.262844\n",
            "\n",
            "Test set: Average loss: 0.1085, Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.140361\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.094827\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.073567\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.084043\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.207646\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.058656\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.150257\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.203301\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.147884\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.202322\n",
            "\n",
            "Test set: Average loss: 0.0935, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.061764\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.061379\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.156822\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.027083\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.007049\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.078212\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.076756\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.067667\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.017996\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.118981\n",
            "\n",
            "Test set: Average loss: 0.0727, Accuracy: 9757/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.068030\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.035860\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.042420\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.018273\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.006580\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.035873\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.037439\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.084657\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.074821\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.084395\n",
            "\n",
            "Test set: Average loss: 0.0664, Accuracy: 9791/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.007352\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.062577\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.020940\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.043147\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.080625\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.119694\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.154191\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.059962\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.011832\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.011852\n",
            "\n",
            "Test set: Average loss: 0.0588, Accuracy: 9818/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.098320\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.010304\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.027612\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.086767\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.031406\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.012476\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.133538\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.009349\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.034847\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.034035\n",
            "\n",
            "Test set: Average loss: 0.0550, Accuracy: 9832/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.022634\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.027898\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.074579\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.047636\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.022520\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.026479\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.062131\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.049832\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.018404\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.072395\n",
            "\n",
            "Test set: Average loss: 0.0548, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.122544\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.019727\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.026316\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.083882\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.017212\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.053689\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.011234\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.029396\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.011418\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.115339\n",
            "\n",
            "Test set: Average loss: 0.0505, Accuracy: 9836/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.098967\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.016188\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.031711\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.034788\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.010502\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.057098\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.037809\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.045508\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.014551\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.004863\n",
            "\n",
            "Test set: Average loss: 0.0477, Accuracy: 9831/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.006126\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.028553\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.096049\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.010260\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.053403\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.006910\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.037709\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.009411\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.011247\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.017577\n",
            "\n",
            "Test set: Average loss: 0.0476, Accuracy: 9838/10000 (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.019554\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.076666\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.182268\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.075941\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.054212\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.057112\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.027565\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.090724\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.024681\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.042974\n",
            "\n",
            "Test set: Average loss: 0.0460, Accuracy: 9856/10000 (99%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.014122\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.018352\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.016254\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.025231\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.056215\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.013693\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.008034\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.120768\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.018414\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.025674\n",
            "\n",
            "Test set: Average loss: 0.0435, Accuracy: 9865/10000 (99%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.008537\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.060805\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.037562\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.145921\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.170840\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.011670\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.031608\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.105979\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.013018\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.022657\n",
            "\n",
            "Test set: Average loss: 0.0422, Accuracy: 9859/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.043724\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.002178\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.012211\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.020479\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.029385\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.022169\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.011731\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.016225\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.044247\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.033554\n",
            "\n",
            "Test set: Average loss: 0.0457, Accuracy: 9852/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1nnXG3pss_4",
        "colab_type": "code",
        "outputId": "946b7cb6-81cc-4163-d284-fa2b95dbff7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_cnn_tanh = CNNTanh(input_size, n_features, output_size)\n",
        "model_cnn_tanh.to(device)\n",
        "optimizer = optim.SGD(model_cnn_tanh.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_cnn_tanh)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_cnn_tanh)\n",
        "    test(model_cnn_tanh)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([6, 6, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([50, 96])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n",
            "Number of parameters: 6422\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.287863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.058550\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.467990\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.933859\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.716314\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.583629\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.483176\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.375110\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.385188\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.297981\n",
            "\n",
            "Test set: Average loss: 0.3502, Accuracy: 9098/10000 (91%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.385027\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.465593\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.360413\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.234203\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.378700\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.280973\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.248648\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.228931\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.164800\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.183629\n",
            "\n",
            "Test set: Average loss: 0.2116, Accuracy: 9417/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.272809\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.207599\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.213754\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.159827\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.244313\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.143998\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.242379\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.185589\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.274149\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.133491\n",
            "\n",
            "Test set: Average loss: 0.1560, Accuracy: 9560/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.149842\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.144111\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.077503\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.087247\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.262181\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.173867\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.088148\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.126913\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.086515\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.261600\n",
            "\n",
            "Test set: Average loss: 0.1261, Accuracy: 9640/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.246466\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.043418\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.065989\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.107361\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.077294\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.091682\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.123599\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.078166\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.056199\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.113917\n",
            "\n",
            "Test set: Average loss: 0.1089, Accuracy: 9686/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.164926\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.119489\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.174960\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.100450\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.164400\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.199646\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.036083\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.111191\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.051080\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.074592\n",
            "\n",
            "Test set: Average loss: 0.0958, Accuracy: 9724/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.082108\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.054204\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.082700\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.084887\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.046101\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.168298\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.142906\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.097838\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.075337\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.297512\n",
            "\n",
            "Test set: Average loss: 0.0874, Accuracy: 9738/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.117511\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.170771\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.184917\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.120346\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.103626\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.042819\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.084470\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.077700\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.041902\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.054045\n",
            "\n",
            "Test set: Average loss: 0.0812, Accuracy: 9752/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.191867\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.055528\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.041733\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.198525\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.095232\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.089510\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.046107\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.021722\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.068614\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.081743\n",
            "\n",
            "Test set: Average loss: 0.0752, Accuracy: 9760/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.054798\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.029280\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.088973\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.123165\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.063647\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.046895\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.114271\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.087259\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.076313\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.083834\n",
            "\n",
            "Test set: Average loss: 0.0717, Accuracy: 9787/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.083095\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.053376\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.037944\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.019422\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.176495\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.038898\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.076514\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.038954\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.131687\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.088083\n",
            "\n",
            "Test set: Average loss: 0.0703, Accuracy: 9779/10000 (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.043697\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.058153\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.058439\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.042124\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.042768\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.104658\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.017119\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.118735\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.042660\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.080593\n",
            "\n",
            "Test set: Average loss: 0.0667, Accuracy: 9788/10000 (98%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.022159\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.024675\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.185105\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.018418\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.033279\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.038923\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.031210\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.030843\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.094510\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.018921\n",
            "\n",
            "Test set: Average loss: 0.0626, Accuracy: 9807/10000 (98%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.042186\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.064674\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.019518\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.049331\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.076643\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.029987\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.012617\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.065723\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.031613\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.043808\n",
            "\n",
            "Test set: Average loss: 0.0617, Accuracy: 9807/10000 (98%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.050722\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.092601\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.081606\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.127578\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.087579\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.062650\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.028100\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.070258\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.043657\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.032878\n",
            "\n",
            "Test set: Average loss: 0.0602, Accuracy: 9800/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gseozqLP8XJY",
        "colab_type": "code",
        "outputId": "81948556-d7c2-433a-c719-f8feaec3bd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_cnn_sigmoid = CNNSigmoid(input_size, n_features, output_size)\n",
        "model_cnn_sigmoid.to(device)\n",
        "optimizer = optim.SGD(model_cnn_sigmoid.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_cnn_sigmoid)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_cnn_sigmoid)\n",
        "    test(model_cnn_sigmoid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([6, 6, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([50, 96])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n",
            "Number of parameters: 6422\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.303092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.294076\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.307382\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.303046\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.305100\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.300410\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.304241\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.297681\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 2.299185\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 2.292947\n",
            "\n",
            "Test set: Average loss: 2.3028, Accuracy: 982/10000 (10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.296388\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.295945\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.311974\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.288855\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.304740\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.304266\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.306136\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.297113\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.292290\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.306994\n",
            "\n",
            "Test set: Average loss: 2.2996, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.288204\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.291840\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.295647\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.310416\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.295842\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.307236\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.300547\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 2.299436\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.291579\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 2.298828\n",
            "\n",
            "Test set: Average loss: 2.2990, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.290349\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 2.287395\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.290568\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 2.294096\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.306814\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.323244\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.295468\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 2.293073\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.298722\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 2.290629\n",
            "\n",
            "Test set: Average loss: 2.2960, Accuracy: 1818/10000 (18%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.294185\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 2.307472\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.294569\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 2.290946\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.284925\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.303623\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.293074\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 2.302496\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.308908\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 2.302517\n",
            "\n",
            "Test set: Average loss: 2.2855, Accuracy: 1743/10000 (17%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.280778\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 2.290852\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.294006\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 2.287712\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.278316\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.272334\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.251789\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 2.266827\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.248439\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 2.258630\n",
            "\n",
            "Test set: Average loss: 2.2369, Accuracy: 3487/10000 (35%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.257745\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 2.226898\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 2.217307\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 2.207716\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 2.152527\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.113807\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 2.080835\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 2.066332\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 2.032929\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.915894\n",
            "\n",
            "Test set: Average loss: 1.9241, Accuracy: 5196/10000 (52%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.059619\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.803331\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.841472\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 1.828867\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.671391\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.485315\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.566029\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.509362\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.506759\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.252642\n",
            "\n",
            "Test set: Average loss: 1.3287, Accuracy: 7030/10000 (70%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.384301\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 1.198314\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.194882\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.208636\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.319724\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.164497\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.105249\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.947463\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.947382\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.888922\n",
            "\n",
            "Test set: Average loss: 0.9056, Accuracy: 7897/10000 (79%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.034169\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.891821\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.900887\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.815094\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.037684\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.850066\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.870214\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.701880\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.690327\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.819223\n",
            "\n",
            "Test set: Average loss: 0.6868, Accuracy: 8227/10000 (82%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.610186\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.625807\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.602623\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.634079\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.590258\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.724711\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.526544\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.415428\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.413425\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.641686\n",
            "\n",
            "Test set: Average loss: 0.5578, Accuracy: 8557/10000 (86%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.519653\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.628652\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.473647\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.501403\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.422666\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.627854\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.423393\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.514839\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.492633\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.674131\n",
            "\n",
            "Test set: Average loss: 0.4698, Accuracy: 8759/10000 (88%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.520477\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.456695\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.371430\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.272120\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.461393\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.351282\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.324596\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.449384\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.403933\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.327095\n",
            "\n",
            "Test set: Average loss: 0.4062, Accuracy: 8925/10000 (89%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.315669\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.406639\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.426290\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.396469\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.261974\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.373466\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.492989\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.331163\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.400869\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.407056\n",
            "\n",
            "Test set: Average loss: 0.3588, Accuracy: 9036/10000 (90%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.519569\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.390023\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.324059\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.301560\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.350699\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.224980\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.292484\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.255969\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.410601\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.379610\n",
            "\n",
            "Test set: Average loss: 0.3231, Accuracy: 9133/10000 (91%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFBVmserKUEo",
        "colab": {}
      },
      "source": [
        "# Define Train and Test module for CNN and MLP\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "def trainAE(epoch, model, perm=torch.arange(0, 784).long()):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        #print(len(data))\n",
        "        #print(len(target))\n",
        "        \n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "        #print(data.shape)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        #print(\"%%%%%\")\n",
        "        #print(target.shape)\n",
        "        #print(output.shape)\n",
        "        #print(\"%%%%%\")\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def testAE(model, perm=torch.arange(0, 784).long()):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # permute pixels\n",
        "        data = data.view(-1, 28*28)\n",
        "        data = data[:, perm]\n",
        "        data = data.view(-1, 1, 28, 28)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Jxe-GTKi3E",
        "colab_type": "code",
        "outputId": "c8dfe4f7-b679-4c1b-f67b-b8ecf2ebc223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_autoencoder_relu = autoencoderReLu()\n",
        "model_autoencoder_relu.to(device)\n",
        "optimizer = optim.SGD(model_autoencoder_relu.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_autoencoder_relu)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_autoencoder_relu)\n",
        "    test(model_autoencoder_relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 784])\n",
            "torch.Size([128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([12, 64])\n",
            "torch.Size([12])\n",
            "torch.Size([3, 12])\n",
            "torch.Size([3])\n",
            "torch.Size([12, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([64, 12])\n",
            "torch.Size([64])\n",
            "torch.Size([128, 64])\n",
            "torch.Size([128])\n",
            "torch.Size([784, 128])\n",
            "torch.Size([784])\n",
            "Number of parameters: 219891\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: -0.045438\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: -0.430359\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: nan\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: nan\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: nan\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: nan\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: nan\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: nan\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: nan\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: nan\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: nan\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: nan\n",
            "\n",
            "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7UwT4V7KkiU",
        "colab_type": "code",
        "outputId": "f6f18e53-49f2-4dbd-fbf8-5ef8b420f2af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_autoencoder_Tanh = autoencoderTanh()\n",
        "model_autoencoder_Tanh.to(device)\n",
        "optimizer = optim.SGD(model_autoencoder_Tanh.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_autoencoder_Tanh)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_autoencoder_Tanh)\n",
        "    test(model_autoencoder_Tanh)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 784])\n",
            "torch.Size([128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([12, 64])\n",
            "torch.Size([12])\n",
            "torch.Size([3, 12])\n",
            "torch.Size([3])\n",
            "torch.Size([12, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([64, 12])\n",
            "torch.Size([64])\n",
            "torch.Size([128, 64])\n",
            "torch.Size([128])\n",
            "torch.Size([784, 128])\n",
            "torch.Size([784])\n",
            "Number of parameters: 219891\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: -0.026073\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: -0.905730\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: -0.974799\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: -0.986994\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: -0.991612\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: -0.993770\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: -0.995120\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: -0.996108\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: -0.996618\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: -0.997185\n",
            "\n",
            "Test set: Average loss: -0.9973, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.997259\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: -0.997569\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: -0.997857\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: -0.998067\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: -0.998262\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: -0.998415\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: -0.998509\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: -0.998635\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: -0.998735\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: -0.998840\n",
            "\n",
            "Test set: Average loss: -0.9988, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: -0.998862\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: -0.998905\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: -0.998951\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: -0.999024\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: -0.999053\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: -0.999107\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: -0.999137\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: -0.999179\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: -0.999227\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: -0.999266\n",
            "\n",
            "Test set: Average loss: -0.9993, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: -0.999290\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: -0.999305\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: -0.999337\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: -0.999358\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: -0.999373\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: -0.999392\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: -0.999415\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: -0.999430\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: -0.999461\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: -0.999470\n",
            "\n",
            "Test set: Average loss: -0.9995, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: -0.999474\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: -0.999499\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: -0.999496\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: -0.999519\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: -0.999522\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: -0.999554\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: -0.999567\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: -0.999571\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: -0.999584\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: -0.999593\n",
            "\n",
            "Test set: Average loss: -0.9996, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: -0.999598\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: -0.999603\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: -0.999614\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: -0.999615\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: -0.999632\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: -0.999640\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: -0.999647\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: -0.999663\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: -0.999660\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: -0.999666\n",
            "\n",
            "Test set: Average loss: -0.9997, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: -0.999674\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: -0.999675\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: -0.999684\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: -0.999687\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: -0.999693\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: -0.999697\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: -0.999708\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: -0.999716\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: -0.999717\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: -0.999717\n",
            "\n",
            "Test set: Average loss: -0.9997, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: -0.999724\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: -0.999727\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: -0.999729\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: -0.999731\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: -0.999737\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: -0.999743\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: -0.999747\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: -0.999751\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: -0.999751\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: -0.999762\n",
            "\n",
            "Test set: Average loss: -0.9998, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: -0.999759\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: -0.999760\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: -0.999765\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: -0.999771\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: -0.999773\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: -0.999776\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: -0.999780\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: -0.999783\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: -0.999786\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: -0.999789\n",
            "\n",
            "Test set: Average loss: -0.9998, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: -0.999788\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: -0.999795\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: -0.999790\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: -0.999796\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: -0.999798\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: -0.999801\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: -0.999804\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: -0.999807\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: -0.999805\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: -0.999812\n",
            "\n",
            "Test set: Average loss: -0.9998, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: -0.999816\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: -0.999814\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: -0.999819\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: -0.999816\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: -0.999822\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: -0.999825\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: -0.999825\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: -0.999826\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: -0.999829\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: -0.999832\n",
            "\n",
            "Test set: Average loss: -0.9998, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: -0.999828\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: -0.999828\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: -0.999835\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: -0.999835\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: -0.999838\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: -0.999839\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: -0.999841\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: -0.999841\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: -0.999843\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: -0.999844\n",
            "\n",
            "Test set: Average loss: -0.9998, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: -0.999845\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: -0.999845\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: -0.999850\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: -0.999853\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: -0.999854\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: -0.999852\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: -0.999854\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: -0.999857\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: -0.999858\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: -0.999858\n",
            "\n",
            "Test set: Average loss: -0.9999, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: -0.999857\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: -0.999862\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: -0.999863\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: -0.999859\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: -0.999864\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: -0.999867\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: -0.999866\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: -0.999870\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: -0.999869\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: -0.999870\n",
            "\n",
            "Test set: Average loss: -0.9999, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: -0.999870\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: -0.999867\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: -0.999871\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: -0.999874\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: -0.999874\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: -0.999875\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: -0.999877\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: -0.999877\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: -0.999878\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: -0.999880\n",
            "\n",
            "Test set: Average loss: -0.9999, Accuracy: 1135/10000 (11%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6edWHxAlKlYs",
        "colab_type": "code",
        "outputId": "8b3c441c-4f70-42f7-abec-ab0bfec87aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_autoencoder_Sigmoid = autoencoderSigmoid()\n",
        "model_autoencoder_Sigmoid.to(device)\n",
        "optimizer = optim.SGD(model_autoencoder_Sigmoid.parameters(), lr=0.01, momentum=0.5)\n",
        "print('Number of parameters: {}'.format(get_n_params(model_autoencoder_Sigmoid)))\n",
        "\n",
        "for epoch in range(0, 15):\n",
        "    train(epoch, model_autoencoder_Sigmoid)\n",
        "    test(model_autoencoder_Sigmoid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 784])\n",
            "torch.Size([128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([12, 64])\n",
            "torch.Size([12])\n",
            "torch.Size([3, 12])\n",
            "torch.Size([3])\n",
            "torch.Size([12, 3])\n",
            "torch.Size([12])\n",
            "torch.Size([64, 12])\n",
            "torch.Size([64])\n",
            "torch.Size([128, 64])\n",
            "torch.Size([128])\n",
            "torch.Size([784, 128])\n",
            "torch.Size([784])\n",
            "Number of parameters: 219891\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: -0.482957\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: -0.802594\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: -0.905563\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: -0.941550\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: -0.958642\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: -0.968609\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: -0.974718\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: -0.978961\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: -0.981877\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: -0.984384\n",
            "\n",
            "Test set: Average loss: -0.9852, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.985205\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: -0.986770\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: -0.988135\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: -0.989301\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: -0.990190\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: -0.991009\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: -0.991574\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: -0.992193\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: -0.992783\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: -0.993275\n",
            "\n",
            "Test set: Average loss: -0.9934, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: -0.993443\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: -0.993818\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: -0.994074\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: -0.994459\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: -0.994691\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: -0.994929\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: -0.995151\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: -0.995378\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: -0.995610\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: -0.995755\n",
            "\n",
            "Test set: Average loss: -0.9958, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: -0.995814\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: -0.996040\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: -0.996166\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: -0.996233\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: -0.996424\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: -0.996499\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: -0.996668\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: -0.996762\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: -0.996852\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: -0.996988\n",
            "\n",
            "Test set: Average loss: -0.9970, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: -0.996983\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: -0.997085\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: -0.997195\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: -0.997219\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: -0.997309\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: -0.997369\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: -0.997460\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: -0.997514\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: -0.997552\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: -0.997640\n",
            "\n",
            "Test set: Average loss: -0.9977, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: -0.997670\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: -0.997749\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: -0.997787\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: -0.997821\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: -0.997889\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: -0.997886\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: -0.997972\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: -0.997998\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: -0.998036\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: -0.998098\n",
            "\n",
            "Test set: Average loss: -0.9981, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: -0.998107\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: -0.998143\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: -0.998173\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: -0.998184\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: -0.998242\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: -0.998271\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: -0.998300\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: -0.998320\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: -0.998354\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: -0.998384\n",
            "\n",
            "Test set: Average loss: -0.9984, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: -0.998409\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: -0.998428\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: -0.998424\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: -0.998480\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: -0.998486\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: -0.998520\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: -0.998542\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: -0.998577\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: -0.998594\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: -0.998617\n",
            "\n",
            "Test set: Average loss: -0.9986, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: -0.998633\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: -0.998649\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: -0.998649\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: -0.998683\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: -0.998714\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: -0.998714\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: -0.998732\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: -0.998741\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: -0.998766\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: -0.998791\n",
            "\n",
            "Test set: Average loss: -0.9988, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: -0.998773\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: -0.998803\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: -0.998826\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: -0.998833\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: -0.998851\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: -0.998854\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: -0.998889\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: -0.998882\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: -0.998893\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: -0.998915\n",
            "\n",
            "Test set: Average loss: -0.9989, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: -0.998929\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: -0.998932\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: -0.998942\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: -0.998963\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: -0.998978\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: -0.998980\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: -0.998977\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: -0.999011\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: -0.999009\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: -0.999023\n",
            "\n",
            "Test set: Average loss: -0.9990, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: -0.999032\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: -0.999034\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: -0.999041\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: -0.999070\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: -0.999073\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: -0.999074\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: -0.999092\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: -0.999096\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: -0.999100\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: -0.999116\n",
            "\n",
            "Test set: Average loss: -0.9991, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: -0.999128\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: -0.999123\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: -0.999149\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: -0.999138\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: -0.999150\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: -0.999149\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: -0.999168\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: -0.999173\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: -0.999178\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: -0.999193\n",
            "\n",
            "Test set: Average loss: -0.9992, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: -0.999190\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: -0.999205\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: -0.999218\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: -0.999223\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: -0.999223\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: -0.999228\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: -0.999231\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: -0.999238\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: -0.999245\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: -0.999262\n",
            "\n",
            "Test set: Average loss: -0.9993, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: -0.999266\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: -0.999270\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: -0.999269\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: -0.999273\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: -0.999281\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: -0.999274\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: -0.999294\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: -0.999299\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: -0.999305\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: -0.999314\n",
            "\n",
            "Test set: Average loss: -0.9993, Accuracy: 1135/10000 (11%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLsCPhtQfv-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-parameters\n",
        "sequence_length = 28*2\n",
        "input_size = 14\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "num_epochs = 15\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocAKnsCLtRII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Device configuration\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
        "seed = 1008\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def train_and_eval(model):\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Train the model\n",
        "  model.train()\n",
        "  total_step = len(train_loader)\n",
        "  for epoch in range(num_epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "          model.vis = False\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          \n",
        "          # # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          \n",
        "          if (i+1) % 100 == 0:\n",
        "              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "  # Test the model\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSd-B8WBteu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recurrent neural network (many-to-one)\n",
        "class RNNRelu(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNNRelu, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='relu')\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.vis = False\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        # Forward propagate RNN\n",
        "        out, _ = self.rnn(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        if self.vis:\n",
        "          x.register_hook(lambda grad: vis_weights(grad))\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wg78mLRJnuwo",
        "colab": {}
      },
      "source": [
        "# Recurrent neural network (many-to-one)\n",
        "class RNNtanh(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNNtanh, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='tanh')\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.vis = False\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        # Forward propagate RNN\n",
        "        out, _ = self.rnn(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        if self.vis:\n",
        "          x.register_hook(lambda grad: vis_weights(grad))\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HdYa6x7ti3O",
        "colab_type": "code",
        "outputId": "ba68a807-6766-4b53-b2b7-1ca88ac69ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnn_model_relu = RNNRelu(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "train_and_eval(rnn_model_relu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/15], Step [100/938], Loss: 1.7319\n",
            "Epoch [1/15], Step [200/938], Loss: 1.5751\n",
            "Epoch [1/15], Step [300/938], Loss: 1.7825\n",
            "Epoch [1/15], Step [400/938], Loss: 1.6285\n",
            "Epoch [1/15], Step [500/938], Loss: 1.5805\n",
            "Epoch [1/15], Step [600/938], Loss: 4.5791\n",
            "Epoch [1/15], Step [700/938], Loss: 2.3156\n",
            "Epoch [1/15], Step [800/938], Loss: 2.2851\n",
            "Epoch [1/15], Step [900/938], Loss: 2.2893\n",
            "Epoch [2/15], Step [100/938], Loss: 2.3019\n",
            "Epoch [2/15], Step [200/938], Loss: 2.2973\n",
            "Epoch [2/15], Step [300/938], Loss: 2.2771\n",
            "Epoch [2/15], Step [400/938], Loss: 2.2921\n",
            "Epoch [2/15], Step [500/938], Loss: 2.2852\n",
            "Epoch [2/15], Step [600/938], Loss: 2.3032\n",
            "Epoch [2/15], Step [700/938], Loss: 2.2939\n",
            "Epoch [2/15], Step [800/938], Loss: 2.3036\n",
            "Epoch [2/15], Step [900/938], Loss: 2.3007\n",
            "Epoch [3/15], Step [100/938], Loss: 2.3032\n",
            "Epoch [3/15], Step [200/938], Loss: 2.3040\n",
            "Epoch [3/15], Step [300/938], Loss: 2.3088\n",
            "Epoch [3/15], Step [400/938], Loss: 2.2994\n",
            "Epoch [3/15], Step [500/938], Loss: 2.3070\n",
            "Epoch [3/15], Step [600/938], Loss: 2.3067\n",
            "Epoch [3/15], Step [700/938], Loss: 2.3067\n",
            "Epoch [3/15], Step [800/938], Loss: 2.3197\n",
            "Epoch [3/15], Step [900/938], Loss: 2.2955\n",
            "Epoch [4/15], Step [100/938], Loss: 2.3124\n",
            "Epoch [4/15], Step [200/938], Loss: 2.3005\n",
            "Epoch [4/15], Step [300/938], Loss: 2.3111\n",
            "Epoch [4/15], Step [400/938], Loss: 2.3015\n",
            "Epoch [4/15], Step [500/938], Loss: 2.3122\n",
            "Epoch [4/15], Step [600/938], Loss: 2.3003\n",
            "Epoch [4/15], Step [700/938], Loss: 2.3025\n",
            "Epoch [4/15], Step [800/938], Loss: 2.2983\n",
            "Epoch [4/15], Step [900/938], Loss: 2.3040\n",
            "Epoch [5/15], Step [100/938], Loss: 2.3067\n",
            "Epoch [5/15], Step [200/938], Loss: 2.3158\n",
            "Epoch [5/15], Step [300/938], Loss: 2.2840\n",
            "Epoch [5/15], Step [400/938], Loss: 2.2909\n",
            "Epoch [5/15], Step [500/938], Loss: 2.3071\n",
            "Epoch [5/15], Step [600/938], Loss: 2.3087\n",
            "Epoch [5/15], Step [700/938], Loss: 2.2995\n",
            "Epoch [5/15], Step [800/938], Loss: 2.2887\n",
            "Epoch [5/15], Step [900/938], Loss: 2.2917\n",
            "Epoch [6/15], Step [100/938], Loss: 2.2965\n",
            "Epoch [6/15], Step [200/938], Loss: 2.3027\n",
            "Epoch [6/15], Step [300/938], Loss: 2.3005\n",
            "Epoch [6/15], Step [400/938], Loss: 2.3068\n",
            "Epoch [6/15], Step [500/938], Loss: 2.3012\n",
            "Epoch [6/15], Step [600/938], Loss: 2.3083\n",
            "Epoch [6/15], Step [700/938], Loss: 2.2912\n",
            "Epoch [6/15], Step [800/938], Loss: 2.2988\n",
            "Epoch [6/15], Step [900/938], Loss: 2.2965\n",
            "Epoch [7/15], Step [100/938], Loss: 2.3041\n",
            "Epoch [7/15], Step [200/938], Loss: 2.3055\n",
            "Epoch [7/15], Step [300/938], Loss: 2.3107\n",
            "Epoch [7/15], Step [400/938], Loss: 2.2885\n",
            "Epoch [7/15], Step [500/938], Loss: 2.2906\n",
            "Epoch [7/15], Step [600/938], Loss: 2.3093\n",
            "Epoch [7/15], Step [700/938], Loss: 2.3042\n",
            "Epoch [7/15], Step [800/938], Loss: 2.3080\n",
            "Epoch [7/15], Step [900/938], Loss: 2.2929\n",
            "Epoch [8/15], Step [100/938], Loss: 2.3114\n",
            "Epoch [8/15], Step [200/938], Loss: 2.3175\n",
            "Epoch [8/15], Step [300/938], Loss: 2.2907\n",
            "Epoch [8/15], Step [400/938], Loss: 2.3132\n",
            "Epoch [8/15], Step [500/938], Loss: 2.3055\n",
            "Epoch [8/15], Step [600/938], Loss: 2.2942\n",
            "Epoch [8/15], Step [700/938], Loss: 2.2933\n",
            "Epoch [8/15], Step [800/938], Loss: 2.3067\n",
            "Epoch [8/15], Step [900/938], Loss: 2.2741\n",
            "Epoch [9/15], Step [100/938], Loss: 2.2934\n",
            "Epoch [9/15], Step [200/938], Loss: 2.2920\n",
            "Epoch [9/15], Step [300/938], Loss: 2.3153\n",
            "Epoch [9/15], Step [400/938], Loss: 2.3201\n",
            "Epoch [9/15], Step [500/938], Loss: 2.2921\n",
            "Epoch [9/15], Step [600/938], Loss: 2.2954\n",
            "Epoch [9/15], Step [700/938], Loss: 2.2961\n",
            "Epoch [9/15], Step [800/938], Loss: 2.3098\n",
            "Epoch [9/15], Step [900/938], Loss: 2.3109\n",
            "Epoch [10/15], Step [100/938], Loss: 2.3090\n",
            "Epoch [10/15], Step [200/938], Loss: 2.3063\n",
            "Epoch [10/15], Step [300/938], Loss: 2.3030\n",
            "Epoch [10/15], Step [400/938], Loss: 2.3002\n",
            "Epoch [10/15], Step [500/938], Loss: 2.2885\n",
            "Epoch [10/15], Step [600/938], Loss: 2.2991\n",
            "Epoch [10/15], Step [700/938], Loss: 2.2980\n",
            "Epoch [10/15], Step [800/938], Loss: 2.3076\n",
            "Epoch [10/15], Step [900/938], Loss: 2.2958\n",
            "Epoch [11/15], Step [100/938], Loss: 2.3003\n",
            "Epoch [11/15], Step [200/938], Loss: 2.3013\n",
            "Epoch [11/15], Step [300/938], Loss: 2.2893\n",
            "Epoch [11/15], Step [400/938], Loss: 2.2882\n",
            "Epoch [11/15], Step [500/938], Loss: 2.2943\n",
            "Epoch [11/15], Step [600/938], Loss: 2.2986\n",
            "Epoch [11/15], Step [700/938], Loss: 2.2959\n",
            "Epoch [11/15], Step [800/938], Loss: 2.2911\n",
            "Epoch [11/15], Step [900/938], Loss: 2.3030\n",
            "Epoch [12/15], Step [100/938], Loss: 2.3014\n",
            "Epoch [12/15], Step [200/938], Loss: 2.2996\n",
            "Epoch [12/15], Step [300/938], Loss: 2.3019\n",
            "Epoch [12/15], Step [400/938], Loss: 2.3160\n",
            "Epoch [12/15], Step [500/938], Loss: 2.3056\n",
            "Epoch [12/15], Step [600/938], Loss: 2.2991\n",
            "Epoch [12/15], Step [700/938], Loss: 2.2944\n",
            "Epoch [12/15], Step [800/938], Loss: 2.3176\n",
            "Epoch [12/15], Step [900/938], Loss: 2.3208\n",
            "Epoch [13/15], Step [100/938], Loss: 2.2981\n",
            "Epoch [13/15], Step [200/938], Loss: 2.3074\n",
            "Epoch [13/15], Step [300/938], Loss: 2.2953\n",
            "Epoch [13/15], Step [400/938], Loss: 2.3110\n",
            "Epoch [13/15], Step [500/938], Loss: 2.3088\n",
            "Epoch [13/15], Step [600/938], Loss: 2.2892\n",
            "Epoch [13/15], Step [700/938], Loss: 2.3126\n",
            "Epoch [13/15], Step [800/938], Loss: 2.2973\n",
            "Epoch [13/15], Step [900/938], Loss: 2.2971\n",
            "Epoch [14/15], Step [100/938], Loss: 2.2871\n",
            "Epoch [14/15], Step [200/938], Loss: 2.3007\n",
            "Epoch [14/15], Step [300/938], Loss: 2.3093\n",
            "Epoch [14/15], Step [400/938], Loss: 2.3071\n",
            "Epoch [14/15], Step [500/938], Loss: 2.2973\n",
            "Epoch [14/15], Step [600/938], Loss: 2.3089\n",
            "Epoch [14/15], Step [700/938], Loss: 2.2900\n",
            "Epoch [14/15], Step [800/938], Loss: 2.2987\n",
            "Epoch [14/15], Step [900/938], Loss: 2.3052\n",
            "Epoch [15/15], Step [100/938], Loss: 2.3046\n",
            "Epoch [15/15], Step [200/938], Loss: 2.3022\n",
            "Epoch [15/15], Step [300/938], Loss: 2.3064\n",
            "Epoch [15/15], Step [400/938], Loss: 2.3046\n",
            "Epoch [15/15], Step [500/938], Loss: 2.3009\n",
            "Epoch [15/15], Step [600/938], Loss: 2.2984\n",
            "Epoch [15/15], Step [700/938], Loss: 2.3018\n",
            "Epoch [15/15], Step [800/938], Loss: 2.3016\n",
            "Epoch [15/15], Step [900/938], Loss: 2.3076\n",
            "Test Accuracy of the model on the 10000 test images: 11.35 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8257fa15-3d6e-46cc-e3f8-205b17ce46c1",
        "id": "tLRDbvoNn6Kd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnn_model_tanh = RNNtanh(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "train_and_eval(rnn_model_tanh)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/15], Step [100/938], Loss: 1.9959\n",
            "Epoch [1/15], Step [200/938], Loss: 1.5925\n",
            "Epoch [1/15], Step [300/938], Loss: 2.3395\n",
            "Epoch [1/15], Step [400/938], Loss: 2.3771\n",
            "Epoch [1/15], Step [500/938], Loss: 2.3896\n",
            "Epoch [1/15], Step [600/938], Loss: 2.4478\n",
            "Epoch [1/15], Step [700/938], Loss: 2.3896\n",
            "Epoch [1/15], Step [800/938], Loss: 2.3629\n",
            "Epoch [1/15], Step [900/938], Loss: 2.3446\n",
            "Epoch [2/15], Step [100/938], Loss: 2.4308\n",
            "Epoch [2/15], Step [200/938], Loss: 2.3620\n",
            "Epoch [2/15], Step [300/938], Loss: 2.3474\n",
            "Epoch [2/15], Step [400/938], Loss: 2.2510\n",
            "Epoch [2/15], Step [500/938], Loss: 2.4069\n",
            "Epoch [2/15], Step [600/938], Loss: 2.3528\n",
            "Epoch [2/15], Step [700/938], Loss: 2.3772\n",
            "Epoch [2/15], Step [800/938], Loss: 2.3515\n",
            "Epoch [2/15], Step [900/938], Loss: 2.4652\n",
            "Epoch [3/15], Step [100/938], Loss: 2.3894\n",
            "Epoch [3/15], Step [200/938], Loss: 2.3639\n",
            "Epoch [3/15], Step [300/938], Loss: 2.4049\n",
            "Epoch [3/15], Step [400/938], Loss: 2.5167\n",
            "Epoch [3/15], Step [500/938], Loss: 2.3924\n",
            "Epoch [3/15], Step [600/938], Loss: 2.3661\n",
            "Epoch [3/15], Step [700/938], Loss: 2.3429\n",
            "Epoch [3/15], Step [800/938], Loss: 2.3660\n",
            "Epoch [3/15], Step [900/938], Loss: 2.3307\n",
            "Epoch [4/15], Step [100/938], Loss: 2.3834\n",
            "Epoch [4/15], Step [200/938], Loss: 2.4145\n",
            "Epoch [4/15], Step [300/938], Loss: 2.3075\n",
            "Epoch [4/15], Step [400/938], Loss: 2.4619\n",
            "Epoch [4/15], Step [500/938], Loss: 2.4013\n",
            "Epoch [4/15], Step [600/938], Loss: 2.3718\n",
            "Epoch [4/15], Step [700/938], Loss: 2.3349\n",
            "Epoch [4/15], Step [800/938], Loss: 2.4637\n",
            "Epoch [4/15], Step [900/938], Loss: 2.3484\n",
            "Epoch [5/15], Step [100/938], Loss: 2.3798\n",
            "Epoch [5/15], Step [200/938], Loss: 2.3957\n",
            "Epoch [5/15], Step [300/938], Loss: 2.3591\n",
            "Epoch [5/15], Step [400/938], Loss: 2.4684\n",
            "Epoch [5/15], Step [500/938], Loss: 2.3987\n",
            "Epoch [5/15], Step [600/938], Loss: 2.3428\n",
            "Epoch [5/15], Step [700/938], Loss: 2.3426\n",
            "Epoch [5/15], Step [800/938], Loss: 2.3300\n",
            "Epoch [5/15], Step [900/938], Loss: 2.3649\n",
            "Epoch [6/15], Step [100/938], Loss: 2.3927\n",
            "Epoch [6/15], Step [200/938], Loss: 2.4670\n",
            "Epoch [6/15], Step [300/938], Loss: 2.3087\n",
            "Epoch [6/15], Step [400/938], Loss: 2.3820\n",
            "Epoch [6/15], Step [500/938], Loss: 2.4141\n",
            "Epoch [6/15], Step [600/938], Loss: 2.3897\n",
            "Epoch [6/15], Step [700/938], Loss: 2.3535\n",
            "Epoch [6/15], Step [800/938], Loss: 2.3862\n",
            "Epoch [6/15], Step [900/938], Loss: 2.3156\n",
            "Epoch [7/15], Step [100/938], Loss: 2.5483\n",
            "Epoch [7/15], Step [200/938], Loss: 2.3741\n",
            "Epoch [7/15], Step [300/938], Loss: 2.5233\n",
            "Epoch [7/15], Step [400/938], Loss: 2.3832\n",
            "Epoch [7/15], Step [500/938], Loss: 2.4000\n",
            "Epoch [7/15], Step [600/938], Loss: 2.3568\n",
            "Epoch [7/15], Step [700/938], Loss: 2.3776\n",
            "Epoch [7/15], Step [800/938], Loss: 2.4154\n",
            "Epoch [7/15], Step [900/938], Loss: 2.3920\n",
            "Epoch [8/15], Step [100/938], Loss: 2.3856\n",
            "Epoch [8/15], Step [200/938], Loss: 2.3597\n",
            "Epoch [8/15], Step [300/938], Loss: 2.3236\n",
            "Epoch [8/15], Step [400/938], Loss: 2.3067\n",
            "Epoch [8/15], Step [500/938], Loss: 2.3651\n",
            "Epoch [8/15], Step [600/938], Loss: 2.4006\n",
            "Epoch [8/15], Step [700/938], Loss: 2.3678\n",
            "Epoch [8/15], Step [800/938], Loss: 2.4279\n",
            "Epoch [8/15], Step [900/938], Loss: 2.2999\n",
            "Epoch [9/15], Step [100/938], Loss: 2.4384\n",
            "Epoch [9/15], Step [200/938], Loss: 2.2911\n",
            "Epoch [9/15], Step [300/938], Loss: 2.4852\n",
            "Epoch [9/15], Step [400/938], Loss: 2.3916\n",
            "Epoch [9/15], Step [500/938], Loss: 2.4017\n",
            "Epoch [9/15], Step [600/938], Loss: 2.3921\n",
            "Epoch [9/15], Step [700/938], Loss: 2.4752\n",
            "Epoch [9/15], Step [800/938], Loss: 2.4778\n",
            "Epoch [9/15], Step [900/938], Loss: 2.3491\n",
            "Epoch [10/15], Step [100/938], Loss: 2.3140\n",
            "Epoch [10/15], Step [200/938], Loss: 2.4477\n",
            "Epoch [10/15], Step [300/938], Loss: 2.3752\n",
            "Epoch [10/15], Step [400/938], Loss: 2.4189\n",
            "Epoch [10/15], Step [500/938], Loss: 2.3555\n",
            "Epoch [10/15], Step [600/938], Loss: 2.4021\n",
            "Epoch [10/15], Step [700/938], Loss: 2.4310\n",
            "Epoch [10/15], Step [800/938], Loss: 2.3437\n",
            "Epoch [10/15], Step [900/938], Loss: 2.4112\n",
            "Epoch [11/15], Step [100/938], Loss: 2.6397\n",
            "Epoch [11/15], Step [200/938], Loss: 2.6041\n",
            "Epoch [11/15], Step [300/938], Loss: 2.3423\n",
            "Epoch [11/15], Step [400/938], Loss: 2.2791\n",
            "Epoch [11/15], Step [500/938], Loss: 2.3503\n",
            "Epoch [11/15], Step [600/938], Loss: 2.4291\n",
            "Epoch [11/15], Step [700/938], Loss: 2.4355\n",
            "Epoch [11/15], Step [800/938], Loss: 2.3208\n",
            "Epoch [11/15], Step [900/938], Loss: 2.3836\n",
            "Epoch [12/15], Step [100/938], Loss: 2.4053\n",
            "Epoch [12/15], Step [200/938], Loss: 2.3057\n",
            "Epoch [12/15], Step [300/938], Loss: 2.3584\n",
            "Epoch [12/15], Step [400/938], Loss: 2.4021\n",
            "Epoch [12/15], Step [500/938], Loss: 2.3977\n",
            "Epoch [12/15], Step [600/938], Loss: 2.6270\n",
            "Epoch [12/15], Step [700/938], Loss: 2.3426\n",
            "Epoch [12/15], Step [800/938], Loss: 2.5082\n",
            "Epoch [12/15], Step [900/938], Loss: 2.4187\n",
            "Epoch [13/15], Step [100/938], Loss: 2.3551\n",
            "Epoch [13/15], Step [200/938], Loss: 2.3862\n",
            "Epoch [13/15], Step [300/938], Loss: 2.3629\n",
            "Epoch [13/15], Step [400/938], Loss: 2.3796\n",
            "Epoch [13/15], Step [500/938], Loss: 2.4835\n",
            "Epoch [13/15], Step [600/938], Loss: 2.3150\n",
            "Epoch [13/15], Step [700/938], Loss: 2.4174\n",
            "Epoch [13/15], Step [800/938], Loss: 2.2987\n",
            "Epoch [13/15], Step [900/938], Loss: 2.4045\n",
            "Epoch [14/15], Step [100/938], Loss: 2.4018\n",
            "Epoch [14/15], Step [200/938], Loss: 2.3613\n",
            "Epoch [14/15], Step [300/938], Loss: 2.3944\n",
            "Epoch [14/15], Step [400/938], Loss: 2.4238\n",
            "Epoch [14/15], Step [500/938], Loss: 2.3475\n",
            "Epoch [14/15], Step [600/938], Loss: 2.4534\n",
            "Epoch [14/15], Step [700/938], Loss: 2.3236\n",
            "Epoch [14/15], Step [800/938], Loss: 2.3469\n",
            "Epoch [14/15], Step [900/938], Loss: 2.3501\n",
            "Epoch [15/15], Step [100/938], Loss: 2.3633\n",
            "Epoch [15/15], Step [200/938], Loss: 2.3817\n",
            "Epoch [15/15], Step [300/938], Loss: 2.3746\n",
            "Epoch [15/15], Step [400/938], Loss: 2.3379\n",
            "Epoch [15/15], Step [500/938], Loss: 2.4138\n",
            "Epoch [15/15], Step [600/938], Loss: 2.3148\n",
            "Epoch [15/15], Step [700/938], Loss: 2.3591\n",
            "Epoch [15/15], Step [800/938], Loss: 2.4266\n",
            "Epoch [15/15], Step [900/938], Loss: 2.4028\n",
            "Test Accuracy of the model on the 10000 test images: 8.92 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s53MK7RC7VP",
        "colab_type": "text"
      },
      "source": [
        "### References:\n",
        "\n",
        "- https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials\n",
        "- https://github.com/unvercanunlu/pytorch-activation-functions-comparison\n",
        "- https://github.com/Atcold/pytorch-Deep-Learning/blob/master/06-convnet.ipynb\n",
        "- https://colab.research.google.com/drive/1KhTmS7NXRY77SQpxAxCp-hW57mjDPwJY#scrollTo=fUNerlYjtsyD"
      ]
    }
  ]
}