---
lang: zh
lang-ref: ch.05
title: 第五周
translation-date: 26 Mar 2020
translator: Shengkun Tang
---

## 讲座A部分

我们以介绍梯度下降算法开始。我们将讨论它的目的以及讨论步长大小在获得解答中所起到的重要作用。然后我们将继续介绍随机梯度下降算法以及它和全批次梯度下降算法比较下的表现。最后我们将讨论动量更新，明确使用动量背后的两条更新规则和目的，以及它对收敛的影响


## 讲座B部分

我们将讨论适用于随机梯度下降的方法，比如RMSprop优化算法和ADAM优化算法。 我们也会讨论归一化层和它们在神经网络训练进程中的作用。 最后，我们将讨论一个神经网络在工业中使核磁共振扫描更快和更有效的例子。


## 动手做

我们将简单复习一下矩阵乘法然后讨论卷积。 我们使用卷积核的关键是通过堆叠和滑动。我们先通过手写推导理解一维卷积，然后使用PyTorch学习卷积核的维度以及一维和二维卷积例子中的输出宽度。更多地，我们使用PyTorch学习自动梯度和自定义梯度是如何运作的。