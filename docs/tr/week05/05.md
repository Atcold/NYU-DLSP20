---
lang-ref: ch.05
title: Hafta 5
lang: tr
translation date: 17 Jul 2020
translator: melikenurm
---


## Bölüm A

Gradient Descent'i tanıtarak başlayacağız. Ardındaki sezgisel yaklaşımı tartışacağız ve adım boyutlarının çözüme ulaşmada nasıl önemli bir rol oynadığından bahsedeceğiz. Ardından SGD'ye ve tam toptan GD'ye(Full batch GD) kıyasla SGD'nin performansına geçiş yapacağız. Son olarak Momentum Güncellemeleri konusunda özellikle iki güncelleme kuralından, momentumun ardındaki sezgisel yaklaşımdan ve momentumun yakınsama üzerindeki etkisinden bahsedeceğiz.


## Bölüm B

SGD için RMSprop ve ADAM gibi adaptif yöntemleri tartışacağız. Ayrıca normalizasyon katmanları ve bunların sinir ağının eğitim sürecine etkileri hakkında konuşacağız. Son olarak,  MRI taramalarını daha hızlı ve daha verimli hale getirmek için endüstride kullanılan gerçek dünyadaki bir sinir ağı örneğini tartışacağız.


## Uygulama

Matris çarpmalarını kısaca gözden geçirip evrişimleri(convolution) tartışacağız. Kilit nokta, çekirdekleri(kernel) istifleyerek ve kaydırarak kullanmamızdır. Önce 1 boyutta evrişimi elle yaparak anlayacağız daha sonra PyTorch'u kullanarak çekirdeklerin boyutunu ve hem 1 hem de 2 boyutta evrişim örneklerinde çıktı genişliğini öğreneceğiz. Ayrıca, PyTorch'u kullanarak otomatik gradyanın ve özel gradyanların nasıl çalıştığını öğreneceğiz.
