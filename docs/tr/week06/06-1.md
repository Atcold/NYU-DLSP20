---
lang-ref: ch.06-1
lang: tr
lecturer: Yann LeCun
title: Evrişimli Ağların Uygulamaları
authors: Shiqing Li, Chenqin Yang, Yakun Wang, Jimin Tan
date: 2 Mar 2020
transator: İrem Demirtaş
translation-date: 23 Jun 2020
---


<!-- ## [Zip Code Recognition](https://www.youtube.com/watch?v=ycbMGyCPzvE&t=43s)

In the previous lecture, we demonstrated that a convolutional network can recognize digits, however, the question remains, how does the model pick each digit and avoid perturbation on neighboring digits. The next step is to detect non/overlapping objects and use the general approach of Non-Maximum Suppression (NMS). Now, given the assumption that the input is a series of non-overlapping digits, the strategy is to train several convolutional networks and using either majority vote or picking the digits corresponding to the highest score generated by the convolutional network. -->

## [Posta Kodu Tanıma](https://www.youtube.com/watch?v=ycbMGyCPzvE&t=43s)

Önceki derste evrişimli ağların nasıl sayıları tanıyabileceğini gösterdik, ancak modelin nasıl her bir sayıyı seçerken yanındaki sayılardan kaynaklanan karışıklığı öğrenebildiği sorusunu cevaplamadık. Bir sonraki adım üst üste gelen/gelmeyen nesneleri saptamak ve genel Maximum Olmayanı Baskılama (Non-Maximum Supression, NMS) yaklaşımını kullanmak. Bu örnekte girdilerin üst üste gelmeyen sayılar olduğu varsayımı göz önüne alındığında, izlenecek strateji birden fazla evrişimsel ağ eğitip çoğunluk oylamasını kullanarak veya evrişimli ağ tarafından üretilen en yüksek skora sahip sayıyı seçmektir.

<!-- ### Recognition with CNN

Here we present the task of recognizing 5 non-overlapping zip codes. The system was not given any instructions on how to separate each digit but knows that is must predict 5 digits. The system (Figure 1) consists of 4 different sized convolutional networks, each producing one set of outputs. The output is represented in matrices. The four output matrices are from models with a different kernel width in the last layer. In each output, there are 10 rows, representing 10 categories from 0 to 9. The larger white square represents a higher score in that category. In these four output blocks, the horizontal sizes of the last kernel layers are 5, 4, 3 and 2 respectively. The size of the kernel decides the width of the model's viewing window on the input, therefore each model is predicting digits based on different window sizes. The model then takes a majority vote and selects the category that corresponds to the highest score in that window. To extract useful information, one should keep in mind that not all combinations of characters are possible, therefore error correction leveraging input restrictions is useful to ensure the outputs are true zip codes.

<center>
<img src="{{site.baseurl}}/images/week06/06-1/O1IN3JD.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Figure 1:</b> Multiple classifiers on zip code recognition
</center>

Now to impose the order of the characters. The trick is to utilize a shortest path algorithm. Since we are given ranges of possible characters and the total number of digits to predict, We can approach this problem by computing the minimum cost of producing digits and transitions between digit. The path has to be continuous from the lower left cell to the upper right cell on the graph, and the path is restricted to only contain movements from left to right and bottom to top. Note that if the same number is repeated next to each other, the algorithm should be able to distinguish there are repeated numbers instead of predicting a single digit. -->

### CNN'lerle Tanıma

Burada üst üste gelmeyen beş haneli posta kodlarını tanıma görevini sunuyoruz. Sisteme her bir haneyi nasıl ayıracağına dair yönergeler verilmemiştir, ama sistem beş hane tahmin etmesi gerektiğini bilmektedir. Fig. 1'de görüldüğü üzere, sistem 4 farklı boyutta, her biri farklı çıktılar üreten evrişimli ağlardan oluşmaktadır. Çıktı matris şeklinde gösterilmektedir. Dört çıktı matrisi son katmanda farklı kernel genişliklerine sahip modellerden gelmektedir. Her bir çıktıda 0'dan 9'a 10 kategoriyi ifade eden 10 satır bulunmaktadır. Daha büyük olan beyaz kare o kategoride daha yüksek bir skoru temsil etmektedir. Bu dört çıktı bloğunda son katman çekirdeklerinin yatay eksendeki boyutları sırasıyla 5, 4, 3, ve 1'dir. Kernel boyutu modelin girdiye baktığı pencerenin genişliğini belirler. Daha sonra model çoğunluk oylaması yöntemini uygulayarak o pencerede en yüksek skora sahip olan kategoriyi seçer. Kullanışlı bilginin çıkarılabilmesi için, tüm karakterlerin tüm kombinasyonlarının olası olduğu ve dolayısıyla çıktıların doğru posta kodları olduğunu garanti altına almak için girdi kısıtlamalarını kullanrak hata düzeltmeleri yapılmasının faydalı olacağı göz önünde bulundurulmalıdır.
 
<center>
<img src="{{site.baseurl}}/images/week06/06-1/O1IN3JD.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Fig 1.</b> Posta kodu tanımada kullanılan birden fazla sınıflandırıcı
</center>

Karakterlerin sırasının nasıl belirlenmesi için püf noktası bir en kısa yol algoritması kullanmaktır. Olası karaklerin aralıklarını ve toplam kaç hane tahmin etmemiz gerektiğini bildiğimizden bu probleme hanelerin ve haneden haneye geçişin minimum maliyetini hesaplayarak yaklaşabiliriz. İzlenecek yol grafikteki sol alt hücreden sağ üst hücreye doğru kesintisiz olmalı ve sağdan sola, yukarıdan aşağıya belirli hareketler içerecek şekilde kısıtlanmalıdır. Eğer aynı sayılar yan yana tekrar edilirse, algoritmanın bu sayıların tek hane tahmin etmektense bunların tekrar eden sayılar olduğunu ayıırt edebilmesi gerektiğine dikkat edin.

<!-- ## [Face detection](https://www.youtube.com/watch?v=ycbMGyCPzvE&t=1241s)

Convolutional neural networks perform well on detection tasks and face detection is no exception. To perform face detection we collect a dataset of images with faces and without faces, on which we train a convolutional net with a window size such as 30 $\times$ 30 pixels and ask the network to tell whether there is a face or not. Once trained, we apply the model to a new image and if there are faces roughly within a 30 $\times$ 30 pixel window, the convolutional net will light up the output at the corresponding locations. However, two problems exist.


- **False Positives**: There are many ways that a patch of an image is not a face. During the training stage, the model may not see all of them (i.e. a fully representative set.). Therefore, the model may suffer from a lot of false positives at test time.

- **Different Face Size:** Not all faces are 30 $\times$ 30 pixels, so faces of differing sizes may not be detected. One way to handle this issue is to generate multi-scale versions of the same image. The original detector will detect faces around 30 $\times$ 30 pixels. If applying a scale on the image of factor $\sqrt 2$, the model will detect faces that were smaller in the original image since what was 30 $\times$ 30 is now 20 $\times$ 20 pixels roughly. To detect bigger faces, we can downsize the image. This process is inexpensive as half of the expense comes from processing the original non-scaled image. The sum of the expenses of all other networks combined is about the same as processing the original non-scaled image. The size of the network is the square of the size of the image on one side, so if you scale down the image by $\sqrt 2$, the network you need to run is smaller by a factor of 2. So the overall cost is $1+1/2+1/4+1/8+1/16…$, which is 2. Performing a multi-scale model only doubles the computational cost. -->

## [Yüz Saptama](https://www.youtube.com/watch?v=ycbMGyCPzvE&t=1241s)

Evrişimli ağlar saptama görevlerinde iyi çalışırlar ve yüz saptama bir istisna değildir. Yüz tanıma gerçekleştirmek için, üzerinde, örneğin 30 $\times$ 30'luk bir pencere boyutuna sahip bir evrişimli ağ eğiteceğimiz ve ağa girdinin yüz içerip içermediğini sorabileceğimiz, yüz içeren ve içermeyen resimlerden oluşan bir verikümesi oluşturmamız gerekir. Eğitildikten sonra modeli yeni bir resme uyguladığımızda, 30 $\times$ 30'luk bir pencerede bir yüz varsa, evrişimli ağ karşılık gelen konumlarda parlayacaktır. Ancak, iki problem vardır.

- **Yanlış Pozitifler**: Resmin bir kısmının bir yüz olmadığı bir çok durum vardır. Eğitim aşamasında model bunların hepsini görmeyebilir (diğer bir deyişle tamamen temsilci bir küme). Bu nedenle model test aşamasında model bir çok yanlış pozitifle karşılaşabilir.

- **Farklı Yüz Boyutları** Tüm yüzzler 30 $\times$ 30 piksel değildir, yani farklı boylardaki yüzler saptanamayabilir. Bunu çözmenin yollarından biri aynı görüntünün çoklu-ölçekli versionlarını oluşturmaktır. Orijinal saptayıcı 30 $\times$ 30 civarı boyuta sahip yüzleri saptar. görüntü $\sqrt 2$ katsayısıyla ölçeklendirilirse, model orijinal görüntüdeki daha küçük yüzleri, 30 $\times$ 30 yaklaşık 20 $\times$ 20 piksele dönüştüğünden tanıyabilecektir. Daha büyük yüzleri tanıyabilmek için görüntü küçültülebilir. Bu işlem masrafın yarısı original, ölçeklenmemiş resmi işlemekten geldiğinden masrafsız bir işlemdir. Tüm diğer ağların masraflarının toplamı neredeyse ölçeklenmemiş resmi işlemekle aynıdır. Ağın boyutu bir taraftaki görüntünün boyutunun karesidir, yani görüntüyü $\sqrt 2$ ile ölçeklerseniz, çalıştırmanız gereken ağ 2 kat daha küçük olur. Tüm masraf $1+1/2+1/4+1/8+1/16…$, yani 2'dir. Çok ölçekli bir model kullanmak hesaplama maliyetini sadece iki katına çıkarır.

<!-- ### A multi-scale face detection system

<center>
<img src="{{site.baseurl}}/images/week06/06-1/8R3v0Dj.png" style="zoom: 30%; background-color:#DCDCDC;"/><br>
<b>Figure 2:</b> Face detection system
</center>

The maps shown in (Figure 3) indicate the scores of face detectors. This face detector recognizes faces that are 20 $\times$ 20 pixels in size. In fine-scale (Scale 3) there are many high scores but are not very definitive. When the scaling factor goes up (Scale 6), we see more clustered white regions. Those white regions represent detected faces. We then apply non-maximum suppression to get the final location of the face.

<center>
<img src="{{site.baseurl}}/images/week06/06-1/CQ8T00O.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Figure 3:</b> Face detector scores for various scaling factors
</center> -->

### Bir Çok Ölçekli Yüz Saptama Sistemi

<center>
<img src="{{site.baseurl}}/images/week06/06-1/8R3v0Dj.png" style="zoom: 30%; background-color:#DCDCDC;"/><br>
<b>Fig. 2.</b> Yüz saptama sistemi
</center>

The maps shown in (Figure 3) indicate the scores of face detectors. This face detector recognizes faces that are 20 $\times$ 20 pixels in size. In fine-scale (Scale 3) there are many high scores but are not very definitive. When the scaling factor goes up (Scale 6), we see more clustered white regions. Those white regions represent detected faces. We then apply non-maximum suppression to get the final location of the face.

Fig. 3'te gösterilen harita yüz saptayıcılarının skorlarını gösterir. Bu yüz saptayıcı 20 $\times$ 20 boyutuna sahip yüzleri saptar. (Ölçek 3 - Scale 3) İnce ölçekte çok fazla yüksek skor varıdr ama bunlar kesin değildir. Ölçek arttığında (Ölçek 6 - Scale 6), daha fazla kümelenmiş beyaz bölgeler görüyoruz. Bu beyaz bölgeler saptanan yüzleri göstermektedir. Yüzün son konumunu elde etmek için maksimum olmayan baskılama uygularız.

<center>
<img src="{{site.baseurl}}/images/week06/06-1/CQ8T00O.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Fig. 3.</b> Farklı ölçek katsayıları için yüz saptama skorları
</center>

<!-- ### Non-maximum suppression

For each high-scoring region, there is probably a face underneath. If more faces are detected very close to the first, it means that only one should be considered correct and the rest are wrong. With non-maximum suppression, we take the highest-scoring of the overlapping bounding boxes and remove the others. The result will be a single bounding box at the optimum location. -->

### Maksimum Olmayan Baskılama

Her yüksek skorlu bölgede büyük olasılıkla bir yüz vardır. Eğer yüzler ilkinin yakınlarında tahmin edilirse, bu sadece birinin dikkate alınması ve kalanların yanlış olduğu anlamına gelir. Maksimum olmayan baskılamayla, üst üste gelen sınırlayıcı kutulardan en yüksek olanı alır ve diğerlerini kaldırırız. Sonuç en uygun konumda tek bir sınırlayıcı kutu olacaktır.

<!-- ### Negative mining

In the last section, we discussed how the model will run into a large number of false positives at test time as there are many ways for objects to appear similar to a face. No training set will include all the non-face objects that look like faces. We can mitigate this problem through negative mining. In negative mining, we create a negative dataset of non-face patches that the model detects as faces. The data is collected by running the model on inputs that are known to contain no faces. Then we retrain the detector using the negative dataset. We can repeat this process to increase the robustness of our model against false positives. -->

### Negatif Madenciliği (Negative Mining)

In the last section, we discussed how the model will run into a large number of false positives at test time as there are many ways for objects to appear similar to a face. No training set will include all the non-face objects that look like faces. We can mitigate this problem through negative mining. In negative mining, we create a negative dataset of non-face patches that the model detects as faces. The data is collected by running the model on inputs that are known to contain no faces. Then we retrain the detector using the negative dataset. We can repeat this process to increase the robustness of our model against false positives.

Son bölümde bir modelin test esnasında, bir nesnenin yüze çok benzer görünmesi için bir çok sebep olduğundan, yüksek sayıda yanlış pozitifle karşılacağını tartıştık. Hiçbir eğitim kümesi yüze benzeyen ama yüz olmayan tüm nesneleri içermeyecektir. Bu problemi negatif madenciliği yöntemiyle azaltabiliriz. Negatif madenciliğinde, modelin yüz olarak saptadığı yüz olmayan parçalardan bir negatif verikümesi oluştururuz. Verikümesi saptayıcıyı yüz içermediği bilinen girdiler üzerinde çalıştırarak oluşturulur. Bu süreci modelimizin yanlış pozitiflere karşı sağlamlığını artırmak için
tekrar edebiliriz.

<!-- ## Semantic segmentation

Semantic segmentation is the task of assigning a category to every pixel in an input image.
 -->

## Semantik Bölütleme

Semantik bölütleme görüntüdeki her bir piksele bir kategori atanması görevidir.

<!-- ### [CNN for Long Range Adaptive Robot Vision](https://www.youtube.com/watch?v=ycbMGyCPzvE&t=1669s)

In this project, the goal was to label regions from input images so that a robot can distinguish between roads and obstacles. In the figure, the green regions are areas the robot can drive on and the red regions are obstacles like tall grass. To train the network for this task, we took a patch from the image and manually label it traversable or not (green or red). We then train the convolutional network on the patches by asking it to predict the color of the patch. Once the system is sufficiently trained, it is applied to the entire image, labeling all the regions of the image as green or red.

<center>
<img src="{{site.baseurl}}/images/week06/06-1/5mM7dTT.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Figure 4:</b> CNN for Long Range Adaptive Robot Vision (DARPA LAGR program 2005-2008)
</center>

There were five categories for prediction: 1) super green, 2) green, 3) purple: obstacle foot line, 4) red obstacle  5) super red: definitely an obstacle.


**Stereo Labels** (Figure 4, Column 2)
 Images are captured by the 4 cameras on the robot, which are grouped into 2 stereo vision pairs. Using the known distances between the stereo pair cameras, the positions of every pixel in 3D space are then estimated by measuring the relative distances between the pixels that appear in both the cameras in a stereo pair. This is the same process our brains use to estimate the distance of the objects that we see. Using the estimated position information, a plane is fit to the ground, and pixels are then labeled as green if they are near the ground and red if they are above it.

* **Limitations & Motivation for ConvNet**: The stereo vision only works up to 10 meters and driving a robot requires long-range vision. A ConvNet however, is capable of detecting objects at much greater distances, if trained correctly.

<center>
<img src="{{site.baseurl}}/images/week06/06-1/rcxY4Lb.png" style="zoom: 100%; background-color:#DCDCDC;"/><br>
<b>Figure 5:</b> Scale-invariant Pyramid of Distance-normalized Images
</center>

* **Served as Model Inputs**: Important pre-processing includes building a scale-invariant pyramid of distance-normalized images (Figure 5). It is similar to what we have done earlier of this lecture when we tried to detect faces of multiple scales.

**Model Outputs** (Figure 4, Column 3)

The model outputs a label for every pixel in the image **up to the horizon**. These are classifier outputs of a multi-scale convolutional network.

* **How the Model Becomes Adaptive**: The robots have continuous access to the stereo labels, allowing the network to re-train, adapting to the new environment it's in. Please note that only the last layer of the network would be re-trained. The previous layers are trained in the lab and fixed.

**System Performance**

When trying to get to a GPS coordinate on the other side of a barrier, the robot "saw" the barrier from far away and planned a route that avoided it. This is thanks to the CNN detecting objects up 50-100m away.

**Limitation**

Back in the 2000s, computation resources were restricted. The robot was able to process around 1 frame per second, which means it would not be able to detect a person that walks in its way for a whole second before being able to react. The solution for this limitation is a **Low-Cost Visual Odometry** model. It is not based on neural networks, has a vision of ~2.5m but reacts quickly. -->

### [CNN for Long Range Adaptive Robot Vision, Uzun Menzilli Uyarlanabilir Robot Görüsü için CNN](https://www.youtube.com/watch?v=ycbMGyCPzvE&t=1669s)

Bu projede amaç, robotun yolları ve engelleri ayırt edebilmesi için girdi görüntülerinden bölgeleri etiketlemekti. Fig. 4'te görüldüğü üzere, yeşil kısımlar robotun ilerleyebileceği alanlar, kırmızı kısımlarsa uzun bitkiler gibi engellerdir. Ağı bu görev için eğitmek için, görüntüden bit parça aldık ve ilerlenebilir olup olmadığını (yeşil ya da kırmızı) elle işaretledik. Sonrasında evrişimli ağa verilen parçanının rengini tahmin etmesini sorarak eğittik. Sistem yeterince eğitildiğinde tüm görüntüye uygulandı ve görüntüdeki tüm kısımları yeşil veya kırmızı olarak etiketledi.

<center>
<img src="{{site.baseurl}}/images/week06/06-1/5mM7dTT.png" style="zoom: 40%; background-color:#DCDCDC;"/><br>
<b>Fig 4.</b> CNN for Long Range Adaptive Robot Vision, Uzun Menzilli Uyarlanabilir Robot Görüsü için CNN (DARPA LAGR program 2005-2008)
</center>

Tahmin edilecek 5 kategori vardı: 1) Parlak yeşil, 2) Yeşil, 3) Mor: Engel hattı, 4) Kırmızı: Engel 5) Parlak kırmızı: Kesinlikle bir engel

**Stereo Etiketler** (Fig 4., Sütun 2)
 Görüntüler robottaki dört kamera tarafından yakalandı ve stereo görü için iki gruba ayrıldı. Stereo kamera çiflerinin arasındaki bilinen uzaklık ve her bir pikselin üç boyutlu uzaydaki pozisyonları stereo çiftteki her iki kamerada da görüntülenen pikseller arasındaki görece uzaklık kullanılarak tüm piksellerin üç boyutlu uzaydaki pozisyonları hesaplandı. Bu süreç beynimizde gördüğümüz cisimlerin uzaklıklarını hesaplamamızı sağlayan süreçle aynıdır. Hesaplanan pozisyon bilgisini kullanarak, yere bir düzlem oturduldu ve pikseller bu düzleme yakınsa yeşil, uzaksa kırmızı olarak işaretlendi.

* **Evrişimli Ağın Motivasyonu ve Sınırları**: Stereo görü sadece 10 metreye kadar çalışır ve robotu ilerletmek uzun menzilli görü gerektirir. Bir evrişimli ağsa, doğru eğitildiğinde, çok daha uzaktaki cisimleri saptayabilir. 

<center>
<img src="{{site.baseurl}}/images/week06/06-1/rcxY4Lb.png" style="zoom: 100%; background-color:#DCDCDC;"/><br>
<b>Fig 5.</b> Uzaklıkla Normalize Edilmiş Görüntülerin Ölçekten Bağımsız Piramidi
</center>

<!-- * **Served as Model Inputs**: Important pre-processing includes building a scale-invariant pyramid of distance-normalized images (Figure 5). It is similar to what we have done earlier of this lecture when we tried to detect faces of multiple scales. -->

* **Modelin Girdileri**: Önemli önişleme adımları uzaklıkla normalize edilmiş görüntülerin ölçekten bağımsız piramidinin oluşturulmasını kapsar (Fig 5). Bu işlem daha önce gördüğümüz çoklu ölçeklerde yüz saptama örneğinde yaptığımız işleme benzerdir.  

<!-- **Model Outputs** (Figure 4, Column 3)

The model outputs a label for every pixel in the image **up to the horizon**. These are classifier outputs of a multi-scale convolutional network. -->

**Modelin Çıktıları** (Figure 4, Column 3)

Model görüntüde ufka kadar her bir pixel için bir etiket üretir. Bunlar çoklu-ölçekli evrişimli ağın sınıflandırıcı çıktılarıdır. 

<!-- * **How the Model Becomes Adaptive**: The robots have continuous access to the stereo labels, allowing the network to re-train, adapting to the new environment it's in. Please note that only the last layer of the network would be re-trained. The previous layers are trained in the lab and fixed. -->

* **Model Nasıl Uyarlanabilir Olur**: Robotlar stereo etiketlere devamlı erişime sahiptir, bu onların tekrar eğitilerek yeni ortamlara uyum sağlayabilmelerini sağlar. Lütfen sadece son katmanın eğitileceğine dikkat edin. Önceki katmanlar laboratuvarda eğitilmiş ve sabit bırakılmıştır.

<!-- **System Performance**

When trying to get to a GPS coordinate on the other side of a barrier, the robot "saw" the barrier from far away and planned a route that avoided it. This is thanks to the CNN detecting objects up 50-100m away. -->

**Sistem Performansı**

Bir bariyerin arkasından GPS koordinatını almaya çalışırken robot bariyerin arkasını uzaktan görüp ondan kaçınacak şekilde yolunu planlamıştır. Bu CNN'in 50-100m uzaktaki nesneleri saptayabilmesi sayesindedir.

<!-- **Limitation**

Back in the 2000s, computation resources were restricted. The robot was able to process around 1 frame per second, which means it would not be able to detect a person that walks in its way for a whole second before being able to react. The solution for this limitation is a **Low-Cost Visual Odometry** model. It is not based on neural networks, has a vision of ~2.5m but reacts quickly. -->

**Sınırlama**

2000'lerde hesaplama kaynakları sınırlıydı. Robot yaklaşık olarak saniyede bir kare işleyebiliyordu ve bu önünde bir insanın yürümesi halinde bunu bir tam saniye geçmeden anlayamayacağı anlamına geliyordu. Bu sınırlama için çözüm **Az-Masraflı Görsel Odometri** modeli bilinir. Bu model sinir ağı tabanlı değildir, ~2.5m görüye sahiptir, ama hızlı tepki verir.

<!-- ### Scene Parsing and Labelling

In this task, the model outputs an object category (buildings, cars, sky, etc.) for every pixel. The architecture is also multi-scale (Figure 6).

<center>
<img src="{{site.baseurl}}/images/week06/06-1/VpVbkl5.jpg" style="zoom: 30%; background-color:#DCDCDC;"/><br>
<b>Figure 6:</b> Multi-scale CNN for scene parsing
</center>

Notice that if we back project one output of the CNN onto the input, it corresponds to an input window of size $46\times46$ on the original image at the bottom of the Laplacian Pyramid. It means we are **using the context of $46\times46$ pixels to decide the category of the central pixel**.

However, sometimes this context size is not enough to determine the category for larger objects. -->

### Görüntü Ayrıştırma (Scene Parsing) ve Etiketleme

In this task, the model outputs an object category (buildings, cars, sky, etc.) for every pixel. The architecture is also multi-scale (Figure 6).

Bu görevde model her bir piksel için bir nesne kategorisi (binalar, arabalar, gökyüzü vb.) üretir. Mimari yine çoklu-ölçeklidir (Fig. 6).

<center>
<img src="{{site.baseurl}}/images/week06/06-1/VpVbkl5.jpg" style="zoom: 30%; background-color:#DCDCDC;"/><br>
<b>Fig. 6.</b> Görüntü ayrıştırma için çoklu-ölçekli CNN
</center>

CNN çıktılarındna birini girdisine yansıtırsak, original görüntünün Laplace piramidinin en altındaki $46\times46$'lık pencereye karşılık geleceğine dikkat edin. Bu $46\times46$'lık piksel bağlamını merkezdeki pikselin kategorisine karar vermek için kullandığımız anlamına gelir.

Ancak, bazen bu bağlam boyutu daha büyük nesnelerin kategorilerini belirlemek için yeterli değildir.

**Çoklu-ölçekli yaklaşım fazladan ölçeklendirilmiş görüntüleri girdi olarak kullanarak daha geniş görü sağlar.** Adımlar aşağıdaki gibidir:
1. Aynı görüntüyü alın, ayrı ayrı 2 ve 4 kat küçültün.
2. Ölçeklenmiş fazladan iki görüntüyü **aynı evrişimli ağa** (aynı ağırlıklar, aynı kerneller) verin ve iki farklı 2. seviye özellik kümesi elde edin.
3. Bu özellikleri orijinal görselin 2. seviye özellikleriyle aynı boyuta sahip olacak şekilde **sık örnekleyin (upsampling)**.
4. Üç (sık örneklenmiş) özellik kümesini üst üste koyarak bir sınıflandırıcıya verin.

Şimdi içeriğin, 1/4'ü yeniden boyutlandırlımış görselden gelen, efektif boyutu, $184\times 184\, (46\times 4=184)$.'tür.

**Performance**: With no post-processing and running frame-by-frame, the model runs very fast even on standard hardware. It has a rather small size of training data (2k~3k), but the results are still record-breaking.

**Performans**: Hiçbir son-işleme olmadan ve kareden-kareye çalıştırılarak, modelimiz standart donanımda bile çok hızlı çalışır. Eğitim verisinin küçük olmasına rağmen (2k~3k) rekor kıran sonuçlar elde edilmiştir.
