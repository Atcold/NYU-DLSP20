---
lang-ref: ch.02
title: Week 2
lang: tr
translator: İrem Demirtaş
tranlation-date: 06 Sep 2020
---


<!-- ## Lecture part A

We start by understanding what parametrised models are and then discuss what a loss function is. We then look at Gradient-based methods and how it's used in the backpropagation algorithm in a traditional neural network. We conclude this section by learning how to implement a neural network in PyTorch followed by a discussion on a more generalized form of backpropagation.


## Lecture part B

We begin with a concrete example of backpropagation and discuss the dimensions of Jacobian matrices. We then look at various basic neural net modules and compute their gradients, followed by a brief discussion on softmax and logsoftmax. The other topic of discussion in this part is Practical Tricks for backpropagation.


## Practicum

We give a brief introduction to supervised learning using artificial neural networks. We expound on the problem formulation and conventions of data used to train these networks. We also discuss how to train a neural network for multi class classification, and how to perform inference once the network is trained. -->

## Bölüm A

Parametrik modellerin ne olduğunu anlayarak başlıyoruz ve sonrasında kayıp fonksiyonunun ne olduğunu tartışıyoruz. Daha sonra gradyan-temelli metotları ve geleneksel bir sinir ağında geri yayılım algoritmasında nasıl kullanıldıklarını inceliyoruz. Nasıl PyTorch ile bir sinir ağı uygulayabileceğimizi öğrenip geri yayılımın genelleştirilmiş bir halini tartışarak bu kısmı bitiriyoruz.

## Bölüm B

Daha somut bir geri yayılım örneğiyle başlıyoruz ve Jacobi matrislerin boyutlarını tartışıyoruz. Sonrasonda basit sinir ağı modüllerini inceliyouruz ve gradyanlarını hesaplayıp, softmax ve logsoftmax üzerine kısa bir tartışmaya geçiyoruz. Bu bölümün bir diğer tartışması da geri yayılım için püf noktaları. 


## Uygulama

Yapay sinir ağlarıyla denetimli öğrenime kısa bir giriş yapıyoruz. Problem formülasyonunu ve bahsedilen ağları eğitmek için kullanılan verinin düzenini açıklıyoruz. Çok sınıflı sınıflandırma için bir sinir ağını nasıl eğitebileceğimizi ve eğitilen modelle nasıl çıkarım yapılabileceğini tartışıyoruz.