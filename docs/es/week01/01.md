---
lang: es
lang-ref: ch.01
title: Semana 1
translation-date: 24 Mar 2020
translator: LecJackS
---


## Lección parte A

Discutimos la motivación detrás del aprendizaje profundo. Comenzamos con la historia y la inspiración del mismo. Luego discutimos la historia del reconocimiento de patrones e introducimos el descenso del gradiente y su cálculo por retropropagación. Finalmente, discutimos la representación jerárquica de la corteza visual.


## Lección parte B

Primero discutimos la evolución de las CNN, desde Fukushima a LeCun y hasta AlexNet. Luego discutimos algunas aplicaciones de CNN, como la segmentación de imágenes, vehículos autónomos y análisis de imágenes médicas. Discutimos la naturaleza jerárquica de las redes profundas y los atributos que las hacen ventajosas. Concluimos con una discusión sobre la generación y el aprendizaje de características/representaciones.


## Práctica

Discutimos la motivación para aplicar transformaciones a puntos de datos visualizados en el espacio. Hablamos de álgebra lineal y la aplicación de transformaciones lineales y no lineales. Discutimos el uso de la visualización para comprender la función y los efectos de estas transformaciones. Analizamos ejemplos en Jupyter Notebook y concluimos con una discusión de las funciones representadas por las redes neuronales.
