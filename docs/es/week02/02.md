---
lang: es
lang-ref: ch.02
title: Semana 2
date: 3 February 2020
translation-date: 30 Mar 2020
translator: juanmartinezitm
---

<!--
## Lecture part A

We start by understanding what parametrised models are and then discuss what a loss function is. We then look at Gradient-based methods and how it's used in the backpropagation algorithm in a traditional neural network. We conclude this section by learning how to implement a neural network in PyTorch followed by a discussion on a more generalized form of backpropagation.
-->

## Lectura parte A

Comenzamos entendiendo qué son modelos parametrizados y después discutimos qué es una función de pérdida. Después miramos métodos basados en gradiente y cómo se utilizan en el algoritmo de propagación hacia atrás en una red neuronal tradicional. Concluimos esta sección aprendiendo como implementar una red neuronal en PyTorch seguido de una discusión en una forma más generalizada de propagación hacia atrás.

<!--
## Lecture part B

We begin with a concrete example of backpropagation and discuss the dimensions of Jacobian matrices. We then look at various basic neural net modules and compute their gradients, followed by a brief discussion on softmax and logsoftmax. The other topic of discussion in this part is Practical Tricks for backpropagation.
-->

## Lectura parte B

Comenzamos con un ejemplo concreto de propagación hacia atrás y discutimos la dimensión de matrices Jacobianas. Después miramos varios módulas básicos de redes neuronales y calculamos sus gradientes, siguiendo con una breve discusión de *softmax* y *logsoftmax*. El otro tópico de discusión en esta parte es Trucos prácticos para propagación hacia atrás. 

<!--
## Practicum

We give a brief introduction to supervised learning using artificial neural networks. We expound on the problem formulation and conventions of data used to train these networks. We also discuss how to train a neural network for multi class classification, and how to perform inference once the network is trained.
-->

## Practicum
Damos una breve introducción a aprendizaje supervisado utilizando redes neuronales artificiales. Exponemos la formulación del problema y convenciones de datos utilizandos para entrenar estas redes. También discutimos como entrenar una red neuronal para clasificación multi clase, y como realizar infrerencia una vez que la red se ha entrenado.
