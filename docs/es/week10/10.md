---
lang: es
lang-ref: ch.10
title: Semana 10
translation-date: 3 Sep 2020
translator: ccaballeroh
---


<!--## Lecture part A
-->
## Lección parte A
<!--In this section, we understand the motivation behind Self-Supervised Learning (SSL), define what it is and see some of its applications in NLP and Computer Vision. We understand how pretext tasks aid with SSL and see some example pretext tasks in images, videos and videos with sound. Finally, we try to get an intuition behind the representation learned by pretext tasks.
-->

En esta sección, entendemos la motivación detrás del Aprendizaje Autosupervisado (SSL, por las siglas en inglés de *Self-Supervised Learning*), definimos qué es y vemos algunas de sus aplicaciones en PLN y visión por computadora. Entendemos cómo las tareas de pretexto ayudan con el SSL y vemos algunas tareas de pretexto de ejemplo en imágenes, videos y videos con sonido. Por último, intentamos tener una intuición detrás de la representación aprendida por las tareas de pretexto. 

<!--## Lecture part B
-->
## Lección parte B

<!--In this section, we discuss the shortcomings of pretext tasks, define characteristics that make a good pretrained feature, and how we can achieve this using Clustering and Contrastive Learning. We then learn about ClusterFit, its steps and performance. We further dive into a specific simple framework for Contrastive Learning known as PIRL. We discuss its working as well as its evaluation in different contexts.
-->
En esta sección, discutimos las deficiencias de las tareas de pretexto, definimos qué es lo que hace a una buena característica preentrenada y cómo podemos lograr esto usando agrupamiento (*clustering*) y aprendizaje por contraste (*contrastive learning*). Después aprendemos sobre ClusterFit, sus pasos y desempeño. Profundizamos específicamente en un marco de trabajo simple para el aprendizaje por contraste conocido como PIRL. Discutimos su funcionamiento así como su evaluación en diferentes contextos.

<!--## Practicum
-->
## Práctica

<!--During this week's practicum, we explore the [Truck Backer-Upper](http://neuro.bstu.by/ai/To-dom/My_research/Papers-2.1-done/RL-sparce-reward/9/Ref/truckbackerupper.pdf) (Nguyen & Widrow, '90).
This problem shows how to solve an non-linear control problem using neural networks.
We learn a model of a truck's kinematics, and optimize a controller through this learned model, finding that the controller is able to learn complex behaviors through purely observational data.
-->
Durante la práctica de esta semana, exploramos el [*Truck Backer-Upper*](http://neuro.bstu.by/ai/To-dom/My_research/Papers-2.1-done/RL-sparce-reward/9/Ref/truckbackerupper.pdf) (Nguyen y Widrow, 1990). Este problema muestra cómo resolver un problema de control no lineal usando redes neuronales. Aprendemos un modelo de la cinemática de un camión y optimizamos un controlador a través de este modelo aprendido. Encontramos así que el controlador es capaz de aprender comportamientos complejos a través de datos puramente observacionales.
