---
lang: es
lang-ref: ch.03
title: Semana 3
translation-date: 24 Mar 2020
translator: je-santos
---

<!--
## Lecture part A

We first see a visualization of a 6-layer neural network. Next we begin with the topic of Convolutions and Convolution Neural Networks (CNN). We review several types of parameter transformations in the context of CNNs and introduce the idea of a kernel, which is used to learn features in a hierarchical manner. Thereby allowing us to classify our input data which is the basic idea motivating the use of CNNs.
-->
## Lección parte A

Primero vemos una visualización de una red neuronal de seis capas. A continuación, comenzamos con el tema de convoluciones y de las redes neuronales convolucionales (CNN). Revisamos varios tipos de transformaciones de parámetros e introducimos la noción de *kernel* o núcleo, el cual es usado para aprender características jerárquicamente. Lo que nos permite clasificar nuestros datos de entrada: la idea básica que motiva el uso de las CNN.

<!--
## Lecture part B

We give an introduction on how CNNs have evolved over time. We discuss in detail different CNN architectures, including a modern implementation of LeNet5 to exemplify the task of digit recognition on the MNIST dataset. Based on its design principles, we expand on the advantages of CNNs which allows us to exploit the compositionality, stationarity, and locality features of natural images.
-->

## Lección parte B


Damos una introducción a cómo han evolucionado en el tiempo las CNN. Discutimos a detalle las diferentes arquitecturas de CNN, incluyendo una implementación moderna de LeNet5 para usar como ejemplo el reconocimiento de dígitos del conjunto de datos MNIST. A partir de sus principios de diseño, ahondamos en las ventajas de las CNN que nos permiten aprovechar la composicionalidad, la estacionariedad y la localidad de características en imágenes naturales.


<!--
## Practicum

Properties of natural signals that are most relevant to CNNs are discussed in more detail, namely: Locality, Stationarity, and Compositionality. We explore precisely how a kernel exploits these features through sparsity, weight sharing and the stacking of layers, as well as motivate the concepts of padding and pooling. Finally, a performance comparison between FCN and CNN was done for different data modalities.
-->

## Práctica

 Discutimos a detalle las propiedades de las señales naturales más relevantes para las CNN: composicionalidad, estacionariedad y localidad. Exploramos precisamente cómo es que un *kernel* aprovecha estas características utilizando las cualidades de esparcidad (*sparcity*), reutilización de parámetros (*weight sharing*) y el apilamiento (*stacking*) de capas convolucionales, al igual que las técnicas de relleno (*padding*) y muestreo (*pooling*). Por último, realizamos una comparación de desempeño entre una red densa (*fully connected network*) y una CNN para distintas modalidades de datos.
