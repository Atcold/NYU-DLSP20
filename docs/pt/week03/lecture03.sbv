0:00:04.819,0:00:08.319
Neste caso, temos uma rede que tem uma entrada do lado esquerdo

0:00:08.959,0:00:14.259
Normalmente você tem a entrada no lado inferior ou no lado esquerdo. Eles são rosa em meus slides

0:00:14.260,0:00:17.409
Então, se você tomar notas, faça-as cor-de-rosa. Não, é brincadeira!

0:00:18.400,0:00:23.020
E então temos... Quantas ativações? Quantas camadas ocultas você conta lá?

0:00:23.539,0:00:27.789
Quatro camadas ocultas. Então, no geral, quantas camadas a rede tem aqui?

0:00:28.820,0:00:32.980
Seis, certo? Porque temos quatro camadas ocultas, mais uma de entrada, mais uma de saída

0:00:33.649,0:00:37.568
Então, neste caso, eu tenho dois neurônios por camada, certo?

0:00:37.569,0:00:41.739
Então o que isso significa? Quais são as dimensões das matrizes que estamos usando aqui?

0:00:43.339,0:00:46.119
Dois por dois. Então, o que essa matriz dois por dois faz?

0:00:48.739,0:00:51.998
Vamos! Você tem... Você sabe a resposta para esta pergunta

0:00:53.359,0:00:57.579
Rotação, sim. Depois dimensionar, depois cortar e...

0:00:59.059,0:01:05.469
reflexão. Fantástico, certo? Então, restringimos nossa rede para realizar todas as operações no plano

0:01:05.540,0:01:12.380
Vimos pela primeira vez se eu permitir que a camada oculta tenha uma centena de neurônios de comprimento, podemos...

0:01:12.380,0:01:13.680
Uau tudo bem!

0:01:13.680,0:01:15.680
Podemos facilmente...

0:01:18.079,0:01:20.079
Ai fantástico. O que é isso?

0:01:21.170,0:01:23.170
Estamos assistindo filmes agora. Eu vejo...

0:01:24.409,0:01:29.889
Ver? Fantástico. O que é isso? Mandaloriano é tão legal, não? OK...

0:01:32.479,0:01:39.428
Ok, como é bom esta lição. É mesmo gravado? Ok, não temos ideia

0:01:40.789,0:01:43.719
Certo, me dê um segundo. Ok, então vamos aqui...

0:01:47.810,0:01:49.810
Feito

0:01:50.390,0:01:52.070
Ouvir

0:01:52.070,0:01:53.600
Tudo bem

0:01:53.600,0:01:59.679
Então a gente começou dessa rede aqui, né? Que tinha essa camada intermediária e nós os forçamos a serem

0:02:00.289,0:02:05.229
2 dimensões, certo? De tal forma que todas as transformações são forçadas para estar em um plano

0:02:05.270,0:02:08.319
Então é isso que a rede faz com o nosso plano

0:02:08.319,0:02:14.269
Ele dobra em regiões específicas, certo? E essas dobras são muito abruptas

0:02:14.370,0:02:18.499
Isso porque todas as transformações são realizadas na camada 2d, certo?

0:02:18.500,0:02:22.550
Então esse treinamento me exigiu muito esforço porque o

0:02:23.310,0:02:25.310
otimização é realmente muito difícil

0:02:25.740,0:02:30.769
Sempre que eu tinha uma camada oculta de cem neurônios, isso era muito fácil de treinar

0:02:30.770,0:02:35.299
Este realmente exigiu muito esforço e você tem que me dizer por quê, ok?

0:02:35.400,0:02:39.469
Se você não sabe a resposta agora, é melhor saber a resposta para o semestre

0:02:40.470,0:02:43.370
Então você pode tomar nota de quais são as perguntas para o meio-termo...

0:02:43.980,0:02:49.600
Certo, então esta é a saída final da rede, que também é aquela camada 2d

0:02:50.010,0:02:55.489
para a incorporação, então não tenho não linearidade na minha última camada. E estes são os finais

0:02:56.370,0:03:01.850
regiões de classificação. Então vamos ver o que cada camada faz. Esta é a primeira camada, transformação afim

0:03:01.850,0:03:06.710
então parece que é uma rotação 3d, mas não está certo? É apenas uma rotação 2D

0:03:07.740,0:03:15.600
reflexão, escala e cisalhamento. E então qual é essa parte? Ah, o que aconteceu agora? Você vê?

0:03:17.820,0:03:21.439
Temos como a parte ReLU, que está matando todos os negativos

0:03:22.800,0:03:27.079
lados da rede, certo? Desculpe, todos os lados negativos disso

0:03:28.080,0:03:33.499
espaço, certo? É a segunda transformação afim e aqui você aplica novamente

0:03:34.770,0:03:37.460
o ReLU, você pode ver todos os pontos negativos

0:03:38.220,0:03:41.149
subespaços foram apagados e eles foram definidos como zero

0:03:41.730,0:03:44.509
Então continuamos com uma terceira transformação afim

0:03:45.120,0:03:46.790
Nós ampliamos... está aumentando muito...

0:03:46.790,0:03:54.469
E então você vai ter a camada ReLU que vai matar um desses... todos os três quadrantes, certo?

0:03:54.470,0:03:59.240
Apenas um quadrante sobrevive a cada vez. E então vamos com a quarta transformação afim

0:03:59.790,0:04:06.200
onde está a alongar-se muito porque dado que confinamos toda a transformação a viver neste espaço

0:04:06.210,0:04:12.439
ele realmente precisa esticar e usar toda a energia que puder, certo? Novamente, este é o

0:04:13.170,0:04:18.589
penúltimo. Então temos a última transformação afim, que é a final. E então chegamos finalmente

0:04:19.320,0:04:20.910
linearmente separável

0:04:20.910,0:04:26.359
regiões aqui. Por fim, veremos como cada transformação afim pode ser

0:04:27.240,0:04:31.759
dividido em cada componente. Então, temos a rotação, agora temos o esmagamento, como o zoom

0:04:32.340,0:04:38.539
Então temos rotação, reflexão porque o determinante é menos um, e então temos o viés final

0:04:38.539,0:04:42.769
Você tem a parte positiva da ReLU (Unidade Linear Retificada), novamente rotação

0:04:43.650,0:04:47.209
lançando porque tínhamos um determinante negativo, menos um

0:04:47.849,0:04:49.849
Zoom, rotação

0:04:49.889,0:04:54.258
Mais uma reflexão e depois o viés final. Esta foi a segunda transformação afim

0:04:54.259,0:04:58.609
Então temos aqui a parte positiva novamente. Nós temos a terceira camada então rotação, reflexão

0:05:00.000,0:05:05.629
zoom e então temos... esta é a decomposição SVD, certo? Você deve estar ciente disso, certo?

0:05:05.629,0:05:09.799
Você deveria saber. E então final é a tradução e a terceira

0:05:10.229,0:05:15.589
ReLU, então tivemos a quarta camada, então rotação, reflexão porque o determinante era negativo

0:05:16.169,0:05:18.169
zoom, novamente a outra rotação

0:05:18.599,0:05:21.769
Mais uma vez... reflexão e preconceito

0:05:22.379,0:05:24.559
Finalmente um ReLU e então temos o último...

0:05:25.259,0:05:27.259
a quinta camada. Então rotação

0:05:28.139,0:05:32.059
zoom, não tivemos reflexão porque o determinante foi +1

0:05:32.490,0:05:37.069
Novamente, reflexão neste caso porque o determinante foi negativo e depois finalmente o viés final, certo?

0:05:37.139,0:05:41.478
E foi assim que essa rede, que foi

0:05:42.599,0:05:44.599
apenas feito de

0:05:44.759,0:05:46.759
uma sequência de camadas de

0:05:47.159,0:05:52.218
neurônios que são apenas dois neurônios por camada, está realizando a tarefa de classificação

0:05:54.990,0:05:58.159
E todas essas transformações foram restringidas a ser

0:05:58.680,0:06:03.199
morando no avião. Ok, então isso foi muito difícil de treinar

0:06:03.419,0:06:05.959
Você consegue descobrir por que foi tão difícil treinar?

0:06:06.539,0:06:08.539
O que acontece se o meu...

0:06:09.270,0:06:16.219
se meu viés de uma das quatro camadas afasta meus pontos do quadrante superior direito?

0:06:21.060,0:06:25.519
Exatamente, então se você tem um dos quatro preconceitos colocando meu

0:06:26.189,0:06:28.549
ponto inicial longe do quadrante superior direito

0:06:29.189,0:06:34.039
então os ReLUs estarão matando tudo completamente, e tudo será reduzido a zero

0:06:34.560,0:06:38.399
OK? E aí você não pode fazer mais nada, então

0:06:38.980,0:06:44.129
essa rede aqui foi muito difícil de treinar. Se você apenas torná-lo um pouco mais gordo do que...

0:06:44.320,0:06:48.659
em vez de restringi-lo a ser dois neurônios para cada uma das camadas ocultas

0:06:48.660,0:06:52.230
então é muito mais fácil treinar. Ou você pode fazer uma combinação dos dois, certo?

0:06:52.230,0:06:54.300
Então, em vez de ter apenas uma rede gorda

0:06:54.300,0:07:01.589
você pode ter uma rede menos gorda, mas aí você tem algumas camadas escondidas, ok?

0:07:02.770,0:07:06.659
Então a gordura é quantos neurônios você tem por camada oculta, certo?

0:07:07.810,0:07:11.429
OK. Então a questão é como determinamos a estrutura ou o

0:07:12.730,0:07:15.150
configuração da nossa rede, certo? Como projetamos a rede?

0:07:15.580,0:07:20.550
E a resposta vai ser, isso é o que Yann vai ensinar ao longo do semestre, certo?

0:07:20.550,0:07:27.300
Então mantenha sua atenção alta porque é isso que vamos ensinar aqui

0:07:28.090,0:07:30.840
Essa é uma boa pergunta certo? Não há

0:07:32.410,0:07:34.679
regra matemática, há um monte de experimentos

0:07:35.710,0:07:39.569
evidências empíricas e muitas pessoas estão tentando configurações diferentes

0:07:39.570,0:07:42.000
Encontramos algo que realmente funciona muito bem agora.

0:07:42.100,0:07:46.200
Vamos cobrir essas arquiteturas nas lições a seguir. Outras perguntas?

0:07:48.790,0:07:50.790
Não seja tímido

0:07:51.880,0:07:56.130
Não? Ok, então acho que podemos mudar para a segunda parte da aula

0:07:57.880,0:08:00.630
Ok, então vamos falar sobre redes convolucionais hoje

0:08:02.710,0:08:05.879
Vamos mergulhar de cabeça. Então vou começar com

0:08:06.820,0:08:09.500
algo que é relevante para redes convolucionais, mas não apenas [para eles]

0:08:10.000,0:08:12.500
que é a ideia de transformar os parâmetros de uma rede neural

0:08:12.570,0:08:17.010
Então aqui temos um diagrama que vimos antes, exceto por uma pequena reviravolta

0:08:17.920,0:08:22.300
O diagrama que estamos vendo aqui é que temos uma rede neural G de X e W

0:08:22.360,0:08:27.960
W sendo os parâmetros, X sendo a entrada que faz uma previsão sobre uma saída, e isso entra em uma função de custo

0:08:27.960,0:08:29.500
Já vimos isso antes

0:08:29.500,0:08:34.500
Mas a diferença aqui é que o vetor peso em vez de ser um

0:08:35.830,0:08:39.660
parâmetro que está sendo otimizado, é na verdade a saída de alguma outra função

0:08:40.599,0:08:43.589
possivelmente parametrizado. Neste caso esta função é

0:08:44.320,0:08:50.369
não é uma função parametrizada, ou é uma função parametrizada mas a única entrada é outro parâmetro U, ok?

0:08:50.750,0:08:56.929
Então, o que fizemos aqui é fazer com que os pesos dessa rede neural sejam a função de algo mais elementar...

0:08:57.480,0:08:59.480
alguns parâmetros mais elementares U

0:09:00.420,0:09:02.420
através de uma função e

0:09:02.940,0:09:07.880
você percebe muito rapidamente que o backprop simplesmente funciona lá, certo? Se você voltar a propagar gradientes

0:09:09.210,0:09:15.049
através da função G para obter o gradiente de qualquer função objetivo que estamos minimizando em relação ao

0:09:15.600,0:09:21.290
parâmetros de peso, você pode continuar propagando através da função H aqui para obter os gradientes em relação a U

0:09:22.620,0:09:27.229
Então, no final, você está meio que propagando coisas assim

0:09:30.600,0:09:42.220
Então, quando você está atualizando U, você está multiplicando o Jacobiano da função objetivo em relação aos parâmetros, e então pelo...

0:09:42.750,0:09:46.760
Jacobiano da função H em relação aos seus próprios parâmetros, ok?

0:09:46.760,0:09:50.960
Então você obtém o produto de dois jacobianos aqui, que é exatamente o que você obtém da propagação de volta

0:09:50.960,0:09:54.919
Você não precisa fazer nada no PyTorch para isso. Isso acontecerá automaticamente conforme você define a rede

0:09:59.130,0:10:03.080
E esse é o tipo de atualização que ocorre

0:10:03.840,0:10:10.820
Agora, é claro, W sendo uma função de U através da função H, a mudança em W

0:10:12.390,0:10:16.460
será a mudança em U multiplicada pela Jacobiana de H transposta

0:10:18.090,0:10:24.739
E esse é o tipo de coisa que você obtém aqui, a mudança efetiva no W que você obtém sem atualizar o W

0:10:24.740,0:10:30.260
--você realmente está atualizando U-- é a atualização em U multiplicada pelo jacobiano de H

0:10:30.690,0:10:37.280
E nós tivemos uma transposição aqui. Temos o oposto aí. Esta é uma matriz quadrada

0:10:37.860,0:10:41.720
que é Nw por Nw, que é o número de... a dimensão de W ao quadrado, ok?

0:10:42.360,0:10:44.690
Então essa matriz aqui

0:10:45.780,0:10:47.780
tem tantas linhas quanto

0:10:48.780,0:10:52.369
W tem componentes e então o número de colunas é o número de

0:10:52.560,0:10:57.470
componentes de U. E então esse cara, é claro, é o contrário, então é um Nu por Nw

0:10:57.540,0:11:02.669
Então quando você faz o produto, faça o produto dessas duas matrizes você obtém uma matriz Nw por Nw

0:11:03.670,0:11:05.670
E então você multiplica isso por isso

0:11:06.190,0:11:10.380
Nw vetor e você obtém um vetor Nw que é o que você precisa para atualizar

0:11:11.440,0:11:13.089
os pesos

0:11:13.089,0:11:16.828
Ok, então essa é uma forma geral de transformar o espaço de parâmetros e há

0:11:18.430,0:11:22.979
muitas maneiras de usar isso e uma maneira particular de usá-lo é quando

0:11:23.769,0:11:25.389
H é o que se chama de...

0:11:26.709,0:11:30.089
sobre o que falamos na semana passada, que é um "conector Y"

0:11:30.089,0:11:35.578
Então imagine que a única coisa que H faz é pegar um componente de U e copiá-lo várias vezes

0:11:36.029,0:11:40.000
Para que você tenha o mesmo valor, o mesmo peso replicado na função G

0:11:40.000,0:11:43.379
a função G usamos o mesmo valor várias vezes

0:11:45.639,0:11:47.639
Então isso ficaria assim

0:11:48.339,0:11:50.339
Então vamos imaginar que U é bidimensional

0:11:51.279,0:11:54.448
u1, u2 e então W é quadridimensional, mas

0:11:55.000,0:11:59.969
w1 e w2 são iguais a u1 e w3, w4 são iguais a u2

0:12:01.060,0:12:04.400
Então, basicamente, você só tem dois parâmetros livres

0:12:04.700,0:00:00.000
e quando você está alterando um componente de U alterando dois componentes de W ao mesmo tempo

0:12:08.560,0:12:14.579
de uma forma muito simples. E isso se chama compartilhamento de peso, ok? Quando dois pesos são forçados a serem iguais

0:12:14.579,0:12:19.200
Eles são na verdade iguais a um parâmetro mais elementar que controla tanto

0:12:19.300,0:12:21.419
Isso é compartilhamento de peso e essa é a base da

0:12:21.940,0:12:23.940
um monte de

0:12:24.670,0:12:26.880
idéias... você sabe, redes convolucionais entre outras

0:12:27.730,0:12:31.890
mas você pode pensar nisso como uma forma muito simples de H de U

0:12:33.399,0:12:38.489
Então você não precisa fazer nada para isso no sentido de que quando você tem compartilhamento de peso

0:12:39.100,0:12:45.810
Se você fizer isso explicitamente com um módulo que faz uma conexão Y no caminho de volta, quando os gradientes são propagados de volta

0:12:45.810,0:12:47.800
os gradientes são somados

0:12:47.800,0:12:53.099
então o gradiente de alguma função de custo em relação a u1, por exemplo, será a soma do gradiente de modo que

0:12:53.199,0:12:55.559
função de custo em relação a w1 e w2

0:12:56.860,0:13:02.219
E da mesma forma para o gradiente em relação a u2 seria a soma dos gradientes em relação a w3 e w4, ok?

0:13:02.709,0:13:06.328
Esse é apenas o efeito da retropropagação através dos dois conectores Y

0:13:13.310,0:13:19.119
Ok, aqui está uma visão um pouco mais geral dessa transformação de parâmetros que algumas pessoas chamam de hiperredes

0:13:19.970,0:13:23.350
Assim, uma hiper-rede é uma rede onde

0:13:23.839,0:13:28.299
os pesos de uma rede são calculados como a saída de outra rede

0:13:28.459,0:13:33.969
Ok, então você tem uma rede H que olha a entrada, ela tem seus próprios parâmetros U

0:13:35.569,0:13:37.929
E calcula os pesos de uma segunda rede

0:13:38.959,0:13:44.199
OK? então a vantagem de fazer isso... existem vários nomes para isso

0:13:44.199,0:13:46.508
A ideia é muito antiga, remonta aos anos 80

0:13:46.880,0:13:52.539
pessoas usando o que é chamado de interações multiplicativas, ou rede de três vias, ou unidades sigma-pi e eles são basicamente

0:13:53.600,0:13:59.050
esta ideia -- e esta é talvez uma formulação geral um pouco mais geral dela

0:14:00.949,0:14:02.949
que você tem uma espécie de dinamismo

0:14:04.069,0:14:06.519
Sua função que é definida dinamicamente

0:14:07.310,0:14:09.669
Em G de X e W

0:14:10.459,0:14:14.318
Porque W é realmente uma função complexa da entrada e algum outro parâmetro

0:14:16.189,0:14:17.959
Isto é particularmente

0:14:17.959,0:14:22.419
arquitetura interessante quando o que você está fazendo com o X está transformando-o de algumas maneiras

0:14:23.000,0:14:29.889
Certo? Então você pode pensar em W como sendo os parâmetros dessa transformação, então Y seria uma versão transformada de X

0:14:32.569,0:14:37.809
E o X, quero dizer, a função H basicamente calcula essa transformação

0:14:38.899,0:14:41.739
OK? Mas voltaremos a isso em algumas semanas

0:14:42.829,0:14:46.209
Só queria mencionar isso porque é basicamente uma pequena modificação do

0:14:46.579,0:14:52.869
deste certo? Você só tem mais um fio que vai de X a H, e é assim que você obtém essas hiper-redes

0:14:56.569,0:15:03.129
Ok, então estamos mostrando a ideia de que você pode ter um parâmetro controlando

0:15:06.500,0:15:12.549
vários parâmetros efetivos em outra rede. E uma razão que é útil é

0:15:13.759,0:15:16.779
se você quiser detectar um motivo em uma entrada

0:15:17.300,0:15:20.139
E você quer detectar esse motivo independentemente de onde ele apareça, ok?

0:15:20.689,0:15:27.099
Então digamos que você tenha uma entrada, digamos que é uma sequência, mas pode ser uma imagem, neste caso é uma sequência

0:15:27.100,0:15:28.000
Sequência de vetores, digamos

0:15:28.300,0:15:33.279
E você tem uma rede que pega uma coleção de três desses vetores, três vetores sucessivos

0:15:34.010,0:15:36.339
É esta rede G de X e W e

0:15:37.010,0:15:42.249
ele é treinado para detectar um motivo específico desses três vetores. Talvez isso seja... eu não sei

0:15:42.889,0:15:44.750
o consumo de energia

0:15:44.750,0:15:51.880
Consumo de energia elétrica e, às vezes, você pode querer detectar um sinal ou uma tendência ou algo assim

0:15:52.519,0:15:54.519
Ou talvez seja, você sabe...

0:15:56.120,0:15:58.120
instrumentos financeiros de algum tipo

0:15:59.149,0:16:05.289
Algum tipo de série temporal. Talvez seja um sinal de fala e você queira detectar um som específico que consiste em três

0:16:06.050,0:16:10.899
vetores que definem o tipo de conteúdo de áudio desse sinal de fala

0:16:12.440,0:16:15.709
E então você gostaria de ser capaz de detectar

0:16:15.709,0:16:20.469
se for um sinal de fala e houver um som específico que você precisa detectar para fazer o reconhecimento de fala

0:16:20.470,0:16:22.630
Você pode querer detectar o som

0:16:23.180,0:16:28.690
A vogal P, certo? O som P onde quer que ocorra em uma sequência

0:16:28.690,0:16:31.299
Você quer algum detector que dispare quando o som P for...

0:16:33.589,0:16:41.439
... é pronunciado. E então o que gostaríamos de ter é um detector que você possa deslizar e independentemente de onde esse motivo ocorra

0:16:42.470,0:16:47.500
detectá-lo. Então o que você precisa ter é alguma rede, alguma função parametrizada que...

0:16:48.920,0:16:55.029
Você tem várias cópias dessa função que você pode aplicar a várias regiões na entrada e todas compartilham o mesmo peso

0:16:55.029,0:16:58.600
mas você gostaria de treinar todo esse sistema de ponta a ponta

0:16:58.700,0:17:01.459
Então, por exemplo, digamos...

0:17:01.459,0:17:03.459
Vamos falar um pouco mais sofisticado

0:17:05.569,0:17:07.688
coisa aqui onde você tem...

0:17:11.059,0:17:13.059
Vamos ver...

0:17:14.839,0:17:17.349
Uma palavra-chave que está sendo pronunciada de forma

0:17:18.169,0:17:22.959
o sistema ouve o som e deseja detectar quando uma determinada palavra-chave, uma ativação

0:17:24.079,0:17:28.329
palavra foi pronunciada, certo? Então essa é a Alexa, certo?

0:17:28.459,0:17:32.709
E você diz "Alexa!" e Alexa acorda faz um bong, certo?

0:17:35.260,0:17:40.619
Então, o que você gostaria de ter é uma rede que faça uma janela sobre o som e mantenha

0:17:41.890,0:17:44.189
em segundo plano, detectando

0:17:44.860,0:17:47.219
Mas você gostaria de ser capaz de detectar

0:17:47.220,0:17:52.020
onde quer que o som ocorra dentro do quadro que está sendo observado, ou foi ouvido, devo dizer

0:17:52.300,0:17:56.639
Então você pode ter uma rede como esta onde você tem detectores replicados

0:17:56.640,0:17:59.520
Todos eles compartilham o mesmo peso e, em seguida, a saída que é

0:17:59.520,0:18:03.329
a pontuação para saber se algo foi detectado ou não, vai para uma função max

0:18:04.090,0:18:07.500
OK? E essa é a saída. E a maneira como você treina um sistema como este

0:18:08.290,0:18:10.290
você terá um monte de amostras

0:18:10.780,0:18:14.140
Exemplos de áudio em que a palavra-chave

0:18:14.140,0:18:18.000
foi pronunciada e um monte de amostras de áudio onde a palavra-chave não foi pronunciada

0:18:18.100,0:18:20.249
E então você treina um classificador de 2 classes

0:18:20.470,0:18:24.689
Ligue quando "Alexa" estiver em algum lugar neste quadro, desligue quando não estiver

0:18:25.059,0:18:30.899
Mas ninguém lhe diz onde a palavra "Alexa" ocorre dentro da janela em que você treina o sistema, ok?

0:18:30.900,0:18:35.729
Porque é muito caro para os rotuladores olharem para o sinal de áudio e dizerem exatamente

0:18:35.730,0:18:37.570
É aqui que a palavra "Alexa" está sendo pronunciada

0:18:37.570,0:18:42.720
A única coisa que eles sabem é que dentro deste segmento de alguns segundos, a palavra foi pronunciada em algum lugar

0:18:43.450,0:18:48.390
Ok, então você gostaria de aplicar uma rede como esta que tem esses detectores replicados?

0:18:48.390,0:18:53.429
Você não sabe exatamente onde está, mas você percorre esse máximo e deseja treinar o sistema para...

0:18:53.950,0:18:59.370
Você deseja propagar o gradiente de volta para que ele aprenda a detectar "Alexa" ou qualquer outra coisa ...

0:19:00.040,0:19:01.900
palavra de despertar ocorre

0:19:01.900,0:19:09.540
E então o que acontece é que você tem várias cópias -- cinco cópias neste exemplo

0:19:09.580,0:19:11.580
desta rede e todos compartilham o mesmo peso

0:19:11.710,0:19:16.650
Você pode ver que há apenas um vetor de peso enviando seu valor para cinco

0:19:17.410,0:19:22.559
instâncias da mesma rede e então voltamos a propagar através do

0:19:23.260,0:19:27.689
cinco cópias da rede, você obtém cinco gradientes, então esses gradientes são somados...

0:19:29.679,0:19:34.949
para o parâmetro. Agora, há essa maneira um pouco estranha de implementar no PyTorch e em outros

0:19:35.740,0:19:41.760
Frameworks de Deep Learning, que é que esse acúmulo de gradiente em um único parâmetro é feito implicitamente

0:19:42.550,0:19:46.659
E é uma razão pela qual antes de fazer um backprop no PyTorch, você precisa zerar o gradiente

0:19:47.840,0:19:49.840
Porque há uma espécie de implícito

0:19:50.510,0:19:52.510
acúmulo de gradientes quando você faz retropropagação

0:19:58.640,0:20:02.000
Ok, então aqui está outra situação em que isso seria útil

0:20:02.100,0:20:07.940
E esta é a verdadeira motivação por trás das redes condicionais em primeiro lugar

0:20:07.940,0:20:09.940
Qual é o problema de

0:20:10.850,0:20:15.000
treinar um sistema para reconhecer a forma independentemente da posição

0:20:16.010,0:20:17.960
de onde a forma ocorre

0:20:17.960,0:20:22.059
e se há distorções dessa forma na entrada

0:20:22.850,0:20:28.929
Portanto, este é um tipo muito simples de rede convolucional que foi construída à mão. não foi treinado

0:20:28.929,0:20:30.929
Ele foi projetado à mão

0:20:31.760,0:20:36.200
E é projetado explicitamente para distinguir C's de D's

0:20:36.400,0:20:38.830
Ok, então você pode desenhar um C na entrada

0:20:39.770,0:20:41.770
imagem com resolução muito baixa

0:20:43.880,0:20:48.459
E o que distingue os Cs dos Ds é que os Cs têm pontos finais, certo?

0:20:48.460,0:20:54.610
O curso meio que acaba, e você pode imaginar projetar um detector para isso. Considerando que estes têm cantos

0:20:55.220,0:20:59.679
Então, se você tem um detector de endpoint ou algo que detecta o final de um segmento e

0:21:00.290,0:21:02.290
um detector de canto

0:21:02.330,0:21:06.699
Onde quer que você detecte cantos, é um D e onde quer que você tenha

0:21:07.700,0:21:09.700
segmentos que terminam, é um C

0:21:11.870,0:21:16.989
Então aqui está um exemplo de um C. Você pega o primeiro detector, então o pequeno

0:21:17.750,0:21:19.869
motivo preto e branco aqui no topo

0:21:20.870,0:21:24.640
é um detector de endpoint, ok? Detecta o fim de um

0:21:25.610,0:21:28.059
de um segmento e a forma como este

0:21:28.760,0:21:33.969
é representado aqui é que os pixels pretos aqui...

0:21:35.840,0:21:37.929
Então pense nisso como algum tipo de modelo

0:21:38.990,0:21:43.089
Ok, você vai pegar este modelo e passar sobre a imagem de entrada

0:21:44.510,0:21:51.160
e você vai comparar esse modelo com a pequena imagem que está colocada embaixo, ok?

0:21:51.980,0:21:56.490
E se esses dois corresponderem, a maneira como você determinará se eles correspondem é fazendo um produto escalar

0:21:56.490,0:22:03.930
Então você vai pensar nesses pixels preto e branco como valor de +1 ou -1, digamos +1 para preto e -1 para branco

0:22:05.020,0:22:09.420
E você vai pensar nesses pixels também como sendo +1 para pretos e -1 para branco e

0:22:10.210,0:22:16.800
quando você calcula o produto escalar de uma pequena janela com esse modelo

0:22:17.400,0:22:22.770
Se eles forem semelhantes, você obterá um grande valor positivo. Se eles são diferentes, você vai ter um...

0:22:24.010,0:22:27.629
valor zero ou negativo. Ou um valor menor, ok?

0:22:29.020,0:22:35.489
Então você pega esse pequeno detector aqui e calcula o produto escalar com a primeira janela, segunda janela, terceira janela, etc.

0:22:35.650,0:22:42.660
Você muda um pixel toda vez para cada local e lembra o resultado. E o que você ganha é isso, certo?

0:22:42.660,0:22:43.660
Então isso é...

0:22:43.660,0:22:51.640
Aqui a escala de cinza é uma indicação da correspondência

0:22:51.640,0:22:57.959
que na verdade é o produto escalar entre o vetor formado por esses valores

0:22:58.100,0:23:05.070
E o patch do local correspondente na entrada. Esta imagem aqui é aproximadamente do mesmo tamanho que aquela imagem

0:23:06.250,0:23:08.250
menos efeitos de borda

0:23:08.290,0:23:13.469
E você vê que há um... sempre que a saída estiver escura, há uma correspondência

0:23:14.380,0:23:16.380
Então você vê um jogo aqui

0:23:16.810,0:23:20.249
porque este detector de endpoint aqui corresponde ao

0:23:20.980,0:23:24.810
o ponto final. Você vê uma espécie de correspondência aqui na parte inferior

0:23:25.630,0:23:27.930
E o outro tipo de valores não são tão

0:23:28.750,0:23:32.459
escuro, ok? Não tão forte se você quiser

0:23:33.250,0:23:38.820
Agora, se você limitar esses valores, você define a saída para +1 se estiver acima do limite

0:23:39.520,0:23:41.520
Zero se estiver abaixo do limite

0:23:42.070,0:23:46.499
Você obtém esses mapas aqui, você precisa definir o limite adequadamente, mas o que você obtém é que

0:23:46.500,0:23:50.880
esse carinha aqui detectou uma correspondência nas duas pontas do C, ok?

0:23:52.150,0:23:54.749
Então agora se você pegar este mapa e resumir

0:23:56.050,0:23:58.050
Basta adicionar todos os valores

0:23:58.600,0:24:00.430
Você obtém um número positivo

0:24:00.430,0:24:03.989
Passe isso pelo limiar, e esse é o seu detector C. Não é um detector C muito bom

0:24:03.990,0:24:07.859
Não é um detector muito bom de nada, mas para esses exemplos particulares de C's

0:24:08.429,0:24:10.210
e talvez aqueles D's

0:24:10.210,0:24:16.980
Vai funcionar, vai ser o suficiente. Agora para o D é semelhante, esses outros detectores aqui destinam-se a detectar os cantos do D

0:24:17.679,0:24:24.538
Então, esse cara aqui, esse detector, conforme você passa sobre a entrada, detectará o

0:24:25.659,0:24:29.189
canto superior esquerdo e esse cara detectará o canto inferior direito

0:24:29.649,0:24:33.689
Depois de atingir o limite, você obterá esses dois mapas onde os cantos são detectados

0:24:34.509,0:24:37.019
e então você pode resumir isso e o

0:24:37.360,0:24:44.729
O detector D será ligado. Agora, o que você vê aqui é um exemplo de por que isso é bom porque essa detecção agora é invariante ao deslocamento

0:24:44.730,0:24:49.169
Então, se eu pegar a mesma entrada D aqui, e eu a deslocar por alguns pixels

0:24:50.340,0:24:56.279
E eu corro este detector novamente, ele detectará os motivos onde quer que eles apareçam. A saída será deslocada

0:24:56.379,0:25:01.559
Ok, então isso é chamado de equivariância ao deslocamento. Então a saída dessa rede

0:25:02.590,0:25:10.499
é equivalente a deslocamento, o que significa que, se eu deslocar a entrada, a saída será deslocada, mas de outra forma inalterada. OK? Isso é equivariância

0:25:11.289,0:25:12.909
A invariância seria

0:25:12.909,0:25:17.398
se eu mudar, a saída ficará completamente inalterada, mas aqui está modificada

0:25:17.399,0:25:19.739
Apenas modificou da mesma maneira que a entrada

0:25:23.950,0:25:31.080
E se eu apenas resumir as atividades nos mapas de recursos aqui, não importa onde elas ocorram

0:25:31.809,0:25:34.199
Meu detector D ainda será ativado

0:25:34.929,0:25:38.998
se eu apenas calcular a soma. Então isso é uma espécie de artesanato

0:25:39.700,0:25:47.100
reconhecedor de padrões que usa detectores de recursos locais e, em seguida, resume sua atividade e o que você obtém é uma detecção invariável

0:25:47.710,0:25:52.529
Ok, esta é uma maneira bastante clássica de construir certos tipos de sistemas de reconhecimento de padrões

0:25:53.049,0:25:55.049
Voltando muitos anos

0:25:57.730,0:26:03.929
Mas o truque aqui, o importante é claro, o interessante seria aprender esses templates

0:26:04.809,0:26:10.258
Podemos ver isso apenas como uma rede neural e propagarmos de volta para ela e aprendermos esses modelos?

0:26:11.980,0:26:18.779
Como pesos de uma rede neural? Afinal, estamos usando-os para fazer aquele produto que é uma soma ponderada, então basicamente

0:26:21.710,0:26:29.059
Esta camada aqui para ir da entrada para os chamados mapas de recursos que são somas ponderadas

0:26:29.520,0:26:33.080
é uma operação linear, ok? E sabemos como voltar a propagar através disso

0:26:35.850,0:26:41.750
Teríamos que usar um tipo de limiar suave, um ReLU ou algo assim aqui porque senão não podemos fazer backprop

0:26:43.470,0:26:48.409
Ok, então esta operação aqui de pegar o produto escalar de um monte de coeficientes

0:26:49.380,0:26:53.450
com uma janela de entrada e, em seguida, passando-a, isso é uma convolução

0:26:57.810,0:27:03.409
Ok, então essa é a definição de uma convolução. Na verdade, é o que está lá em cima, então este é o caso unidimensional

0:27:05.400,0:27:07.170
onde imagine que você tem

0:27:10.530,0:27:16.639
Uma entrada Xj, então X indexado pelo j no índice

0:27:20.070,0:27:22.070
Você pega uma janela

0:27:23.310,0:27:26.029
de X em um determinado local i

0:27:27.330,0:27:30.080
Ok, e então você soma

0:27:31.890,0:27:40.340
Você faz uma soma ponderada da janela dos valores X e os multiplica pelos pesos wⱼ's

0:27:41.070,0:27:50.359
Ok, e a soma presumivelmente passa por uma espécie de pequena janela, então j aqui iria de 1 a 5

0:27:51.270,0:27:54.259
Algo assim, que é o caso do pequeno exemplo que mostrei anteriormente

0:27:58.020,0:28:00.950
e isso lhe dá um Yi

0:28:01.770,0:28:05.510
Ok, então pegue a primeira janela de 5 valores de X

0:28:06.630,0:28:13.280
Calcule a soma ponderada com os pesos, que lhe dá Y1. Em seguida, desloque essa janela por 1, calcule a soma ponderada dos

0:28:13.620,0:28:18.320
produto escalar dessa janela pelos Y's, que lhe dá Y2, shift novamente, etc.

0:28:23.040,0:28:26.839
Agora, na prática, quando as pessoas implementam coisas como PyTorch

0:28:26.840,0:28:31.069
há uma confusão entre duas coisas que os matemáticos pensam que são muito diferentes

0:28:31.070,0:28:37.009
mas na verdade são praticamente iguais. É convolução e correlação cruzada. Então, em convolução, a convenção é que o...

0:28:37.979,0:28:44.359
o índice retrocede na janela quando avança nos pesos

0:28:44.359,0:28:49.519
Na correlação cruzada, ambos avançam. No final, é apenas uma convenção, depende de como você se deita...

0:28:51.659,0:28:59.598
organizar os dados e seus pesos. Você pode interpretar isso como uma convolução se ler os pesos de trás para frente, então realmente não faz diferença

0:29:01.259,0:29:06.949
Mas para certas propriedades matemáticas de uma convolução, se você quer que tudo seja consistente, você precisa ter o...

0:29:07.440,0:29:10.849
O j no W com sinal oposto ao j no X

0:29:11.879,0:29:13.879
Então a versão bidimensional disso...

0:29:15.419,0:29:17.419
Se você tem uma imagem X

0:29:17.789,0:29:21.258
que tem dois índices --neste caso i e j

0:29:23.339,0:29:25.909
Você faz uma soma ponderada sobre dois índices k e l

0:29:25.909,0:29:31.368
E então você tem uma janela bidimensional indexada por k e l e calcula o produto escalar

0:29:31.769,0:29:34.008
daquela janela sobre X com o...

0:29:35.099,0:29:39.679
o peso, e isso lhe dá um valor em Yij que é a saída

0:29:43.349,0:29:51.319
Portanto, o vetor W ou a matriz W na versão 2d, há extensões óbvias disso para 3d e 4d, etc.

0:29:52.080,0:29:55.639
É chamado de kernel, é chamado de kernel convolucional, ok?

0:30:00.380,0:30:03.309
Está claro? Tenho certeza que isso é conhecido por muitos de vocês, mas...

0:30:10.909,0:30:13.449
Então, o que vamos fazer com isso é que

0:30:14.750,0:30:18.699
Vamos organizar... construir uma rede como uma sucessão de

0:30:20.120,0:30:23.769
convoluções onde em uma rede neural regular você tem

0:30:25.340,0:30:29.100
alternância de operadores lineares e não linearidade pontual

0:30:29.250,0:30:34.389
Em redes convolucionais, teremos uma alternância de operadores lineares que serão convoluções, então várias convoluções

0:30:34.940,0:30:40.179
Então também não linearidade pontual e haverá um terceiro tipo de operação chamado pooling...

0:30:42.620,0:30:44.620
que na verdade é opcional

0:30:45.470,0:30:50.409
Antes de prosseguir, devo mencionar que existem

0:30:52.220,0:30:56.889
torções que você pode fazer para esta convolução. Então uma torção é o que é chamado de passo

0:30:57.380,0:31:01.239
Assim, um passo em uma convolução consiste em mover a janela

0:31:01.760,0:31:07.509
de uma posição para outra em vez de movê-lo por apenas um valor

0:31:07.940,0:31:13.510
Você o move por dois ou três ou quatro, ok? Isso é chamado de passo de uma convolução

0:31:14.149,0:31:17.138
E então se você tem uma entrada de um certo comprimento e...

0:31:19.700,0:31:26.590
Então, digamos que você tenha uma entrada que é uma espécie de unidimensional e tamanho 100 cem

0:31:27.019,0:31:31.059
E você tem um kernel de convolução de tamanho cinco

0:31:32.330,0:31:34.330
Ok, e você se envolve

0:31:34.909,0:31:38.409
este kernel com a entrada

0:31:39.350,0:31:46.120
E você garante que a janela fique dentro da entrada de tamanho 100

0:31:46.730,0:31:51.639
A saída que você obtém tem 96 saídas, ok? Tem o número de entradas

0:31:52.519,0:31:56.019
menos o tamanho do kernel, que é 5 menos 1

0:31:57.110,0:32:00.610
Ok, isso dá 4. Então você obtém 100 menos 4, que é 96

0:32:02.299,0:32:08.709
Esse é o número de janelas de tamanho 5 que cabem nessa grande entrada de tamanho 100

0:32:11.760,0:32:13.760
Agora, se eu usar este passo...

0:32:13.760,0:32:21.960
Então, o que eu faço agora é pegar minha janela de 5 onde apliquei o kernel e desloco não por um pixel, mas por 2 pixels

0:32:21.960,0:32:24.710
Ou dois valores, digamos. Eles não são necessariamente pixels

0:32:26.310,0:32:31.880
Ok, o número de saídas que vou obter será dividido por dois aproximadamente

0:32:33.570,0:32:36.500
Ok, em vez de 96 eu vou ter

0:32:37.080,0:32:42.949
um pouco menos de 50, 48 ou algo assim. O número não é exato, você pode...

0:32:44.400,0:32:46.400
descobrir isso na sua cabeça

0:32:47.430,0:32:51.470
Muitas vezes, quando as pessoas executam convoluções em redes convolucionais, elas realmente preenchem a convolução

0:32:51.470,0:32:59.089
Então, às vezes, eles gostam de ter a saída do mesmo tamanho que a entrada e, na verdade, deslocam a janela de entrada

0:32:59.490,0:33:02.479
passado o final do vetor assumindo que é preenchido com zeros

0:33:04.230,0:33:06.230
geralmente dos dois lados

0:33:16.110,0:33:19.849
Tem algum efeito no desempenho ou é apenas por conveniência?

0:33:21.480,0:33:25.849
Se isso tem um efeito sobre o desempenho é ruim, ok? Mas é conveniente

0:33:28.350,0:33:30.350
Essa é praticamente a resposta

0:33:32.700,0:33:37.800
A suposição que é ruim é assumir que quando você não tem dados é igual a zero

0:33:38.000,0:33:41.720
Então, quando suas não linearidades são ReLU, não é necessariamente completamente irracional

0:33:43.650,0:33:48.079
Mas às vezes cria efeitos de borda engraçados (efeitos de fronteira)

0:33:51.120,0:33:53.539
Ok, tudo claro até agora?

0:33:54.960,0:33:59.059
Certo. OK. Então, o que vamos construir é um

0:34:01.050,0:34:03.050
rede neural composta por

0:34:03.690,0:34:08.120
convoluções que serão usadas como detectores de recursos, detectores de recursos locais

0:34:09.090,0:34:13.069
seguido por não linearidades, e então vamos empilhar várias camadas dessas

0:34:14.190,0:34:18.169
E a razão para empilhar várias camadas é porque

0:34:19.170,0:34:21.090
Nós queremos construir

0:34:21.090,0:34:25.809
representações hierárquicas do mundo visual dos dados

0:34:26.089,0:34:32.258
Não é... redes convolucionais não são necessariamente aplicadas a imagens. Eles podem ser aplicados à fala e outros sinais

0:34:32.299,0:34:35.619
Eles basicamente podem ser aplicados a qualquer sinal que chegue até você na forma de uma matriz

0:34:36.889,0:34:41.738
E eu vou voltar para as propriedades que este array tem que verificar

0:34:43.789,0:34:45.789
Então o que você quer é...

0:34:46.459,0:34:48.698
Por que você quer construir representações hierárquicas?

0:34:48.699,0:34:54.369
Porque o mundo é composicional - e eu aludi a isso, acho que a primeira palestra se lembra corretamente

0:34:55.069,0:35:03.519
É o fato de que os pixels se reúnem para formar motivos simples, como bordas orientadas

0:35:04.430,0:35:10.839
As arestas orientadas são montadas para formar recursos locais, como cantos e junções em T e ...

0:35:11.539,0:35:14.018
coisas assim... grades, você sabe, e...

0:35:14.719,0:35:19.600
em seguida, esses se reúnem para formar motivos um pouco mais abstratos.

0:35:19.700,0:35:23.559
Então, aqueles se reúnem para formar partes de objetos, e aqueles se reúnem para formar objetos

0:35:23.559,0:35:28.000
Portanto, há uma espécie de hierarquia de composição natural no mundo natural

0:35:28.100,0:35:33.129
E essa hierarquia de composição natural no mundo natural não é apenas por causa de

0:35:34.369,0:35:38.438
percepção --percepção visual-- é verdade em um nível físico, certo?

0:35:41.390,0:35:46.808
Você começa no nível mais baixo da descrição

0:35:47.719,0:35:50.079
Você tem partículas elementares e elas formam...

0:35:50.079,0:35:56.438
eles se aglomeram para formar partículas menos elementares, e se aglomeram para formar átomos, e se aglomeram para formar moléculas, e as moléculas se aglomeram para formar

0:35:57.229,0:36:00.399
materiais e materiais partes de objetos e

0:36:01.130,0:36:03.609
partes de objetos em objetos, e coisas assim, certo?

0:36:04.670,0:36:07.599
Ou macromoléculas ou polímeros, bla bla bla

0:36:08.239,0:36:13.239
E então você tem essa composição natural ou hierarquia, o mundo é construído dessa maneira

0:36:14.719,0:36:19.000
E pode ser por isso que o mundo é compreensível, certo?

0:36:19.100,0:36:22.419
Então há esta famosa citação de Einstein que diz:

0:36:23.329,0:36:26.750
"a coisa mais incompreensível sobre o mundo é que o mundo é compreensível"

0:36:26.800,0:36:30.069
E parece uma conspiração que vivemos em um mundo que somos capazes de compreender

0:36:31.130,0:36:35.019
Mas podemos compreendê-lo porque o mundo é composicional e

0:36:36.970,0:36:38.970
acontece de ser fácil de construir

0:36:39.760,0:36:44.370
cérebros em um mundo composicional que realmente pode interpretar o mundo composicional

0:36:45.580,0:36:47.580
Ainda me parece uma conspiração

0:36:49.660,0:36:51.660
Então, há uma frase famosa de...

0:36:53.650,0:36:54.970
a partir de um...

0:36:54.970,0:37:00.780
Não tão famoso, mas um tanto famoso, de um estatístico de Brown chamado Stuart Geman.

0:37:01.360,0:37:04.799
E ele diz que isso soa como uma conspiração, como mágica

0:37:06.070,0:37:08.070
Mas você sabe...

0:37:08.440,0:37:15.570
Se o mundo não fosse composicional, precisaríamos de ainda mais magia para poder entendê-lo

0:37:17.260,0:37:21.540
A maneira como ele diz isso é: "o mundo é composicional ou existe um Deus"

0:37:25.390,0:37:32.339
Você precisaria apelar para poderes superiores se o mundo não fosse composicional para explicar como podemos entendê-lo

0:37:35.830,0:37:37.830
Ok, então essa ideia de hierarquia

0:37:38.440,0:37:44.520
e a detecção de características locais vem da biologia. Portanto, toda a ideia de redes convolucionais vem da biologia. Tem sido

0:37:45.850,0:37:47.850
tão inspirado pela biologia e

0:37:48.850,0:37:53.399
o que você vê aqui à direita é um diagrama de Simon Thorpe, que é um

0:37:54.160,0:37:56.160
psicofísico e

0:37:56.500,0:38:02.939
fez alguns experimentos relativamente famosos onde mostrou que a maneira como reconhecemos objetos do cotidiano

0:38:03.580,0:38:05.969
parece ser extremamente rápido. Então se você mostrar...

0:38:06.640,0:38:10.409
se você mostrar a imagem de um objeto cotidiano para uma pessoa e

0:38:11.110,0:38:12.730
você pisca

0:38:12.730,0:38:16.649
um deles a cada 100 milissegundos mais ou menos, você percebe que o

0:38:18.070,0:38:23.549
o tempo que leva para uma pessoa identificar em uma longa sequência, se havia um objeto em particular, digamos um tigre

0:38:25.780,0:38:27.640
é cerca de 100 milissegundos

0:38:27.640,0:38:34.769
Portanto, o tempo que o cérebro leva para interpretar uma imagem e reconhecer objetos básicos nelas é de cerca de 100 milissegundos

0:38:35.650,0:38:37.740
Um décimo de segundo, certo?

0:38:39.490,0:38:42.120
E isso é quase o tempo que leva para o

0:38:43.000,0:38:45.000
sinal nervoso para se propagar

0:38:45.700,0:38:47.550
a retina

0:38:47.550,0:38:54.090
onde as imagens são formadas no olho para o que é chamado de LGN (núcleo geniculado lateral)

0:38:54.340,0:38:56.340
que é um pequeno

0:38:56.350,0:39:02.640
pedaço do cérebro que basicamente faz uma espécie de aprimoramento de contraste e ganha controle, e coisas assim

0:39:03.580,0:39:08.789
E então esse sinal vai para a parte de trás do seu cérebro v1. Essa é a área primária do córtex visual

0:39:09.490,0:39:15.600
em humanos e depois v2, que é muito próximo de v1. Há uma dobra que meio que faz a v1 meio que

0:39:17.380,0:39:20.549
bem na frente da v2, e há muitos fios entre eles

0:39:21.580,0:39:28.890
E então v4, e então o córtex temporal inferior, que está do lado aqui e é onde as categorias de objetos são representadas

0:39:28.890,0:39:35.369
Portanto, existem neurônios em seu córtex temporal inferior que representam categorias genéricas de objetos

0:39:38.350,0:39:41.370
E as pessoas fizeram experimentos com isso onde...

0:39:44.320,0:39:51.150
pacientes epilépticos estão no hospital e têm o crânio aberto porque precisam localizar o...

0:39:52.570,0:40:00.200
posição exata da fonte de suas crises de epilepsia

0:40:02.080,0:40:04.650
E porque eles têm eletrodos na superfície do cérebro

0:40:05.770,0:40:11.000
você pode mostrar os filmes e observar se um neurônio específico liga para filmes específicos

0:40:11.100,0:40:14.110
E você mostra a eles um filme com Jennifer Aniston e tem isso

0:40:14.110,0:40:17.900
neurônio que só liga quando Jennifer Aniston está lá, ok?

0:40:18.000,0:40:21.000
Ele não liga para mais nada até onde sabemos, ok?

0:40:21.700,0:40:27.810
Então você parece ter neurônios muito seletivos no córtex temporal inferior que reagem a um pequeno número de categorias

0:40:30.760,0:40:35.669
Há uma piada, uma espécie de piada corrente, na neurociência de um conceito chamado célula avó

0:40:35.670,0:40:40.350
Então este é o único neurônio em seu córtex temporal inferior que liga quando você vê sua avó

0:40:41.050,0:40:45.120
independentemente da posição que ela está vestindo, a que distância, se é uma foto ou não

0:40:46.510,0:40:50.910
Ninguém realmente acredita nesse conceito, o que as pessoas realmente acreditam são representações distribuídas

0:40:50.910,0:40:54.449
Então não existe celular que só liga pra sua avó

0:40:54.970,0:41:00.820
Há essa coleção de células que ligam para várias coisas e servem para representar categorias gerais

0:41:01.100,0:41:04.060
Mas o importante é que eles são invariáveis

0:41:04.700,0:41:06.700
posição, tamanho...

0:41:06.920,0:41:11.080
iluminação, todos os tipos de coisas diferentes e a verdadeira motivação por trás

0:41:11.930,0:41:14.349
redes convolucionais é construir

0:41:15.140,0:41:18.670
redes neurais que são invariantes à transformação irrelevante das entradas

0:41:19.510,0:41:27.070
Você ainda pode reconhecer um C ou D ou sua avó, independentemente da posição e, até certo ponto, da orientação, do estilo etc.

0:41:29.150,0:41:36.790
Então essa ideia de que o sinal leva apenas 100 milissegundos para ir da retina ao córtex temporal inferior

0:41:37.160,0:41:40.330
Parece sugerir que se você contar o atraso

0:41:40.850,0:41:42.850
passar por cada neurônio ou cada

0:41:43.340,0:41:45.489
fase nesse caminho

0:41:46.370,0:41:48.880
Mal há tempo suficiente para alguns picos passarem

0:41:48.880,0:41:55.720
Portanto, não há tempo para computação recorrente complexa, é basicamente um processo feed-forward. é muito rápido

0:41:56.930,0:41:59.980
Ok, e precisamos que seja rápido porque isso é uma questão de sobrevivência para nós

0:41:59.980,0:42:06.159
Há muito... para a maioria dos animais, você precisa ser capaz de reconhecer muito rapidamente o que está acontecendo, particularmente...

0:42:07.850,0:42:12.820
predadores ou presas em movimento rápido para esse assunto

0:42:17.570,0:42:20.830
Então, isso sugere a ideia de que podemos fazer

0:42:21.920,0:42:26.230
talvez possamos criar algum tipo de arquitetura de rede neuronal que seja completamente feed-forward e

0:42:27.110,0:42:29.110
ainda pode fazer o reconhecimento

0:42:30.230,0:42:32.230
O diagrama à direita

0:42:34.430,0:42:39.280
é de Gallent & Van Essen, então este é um tipo de resumo

0:42:39.920,0:42:43.450
diagrama conceitual das duas vias no córtex visual

0:42:43.490,0:42:50.530
Existe a via ventral e a via dorsal. O caminho ventral é basicamente a hierarquia v1, v2, v4, TI

0:42:50.530,0:42:54.999
que é meio que da parte de trás do cérebro, e vai para o fundo e para o lado e

0:42:55.280,0:42:58.179
então o caminho dorsal meio que vai

0:42:59.060,0:43:02.469
pelo topo também em direção ao córtex temporal inferior e

0:43:04.040,0:43:09.619
existe essa ideia de alguma forma que o caminho ventral está lá para dizer o que você está olhando, certo?

0:43:10.290,0:43:12.499
A via dorsal basicamente identifica

0:43:13.200,0:43:15.200
Localizações

0:43:15.390,0:43:17.390
geometria e movimento

0:43:17.460,0:43:25.040
OK? Portanto, há um caminho para o quê, e outro caminho para onde, e isso parece bastante separado no

0:43:25.040,0:43:29.030
córtex visual humano ou primata

0:43:32.610,0:43:34.610
E é claro que há interações entre eles

0:43:39.390,0:43:45.499
Então várias pessoas tiveram a ideia de usar... então de onde vem essa ideia? Há

0:43:46.080,0:43:48.799
trabalho clássico em neurociência do final dos anos 50 início dos anos 60

0:43:49.650,0:43:52.129
Por Hubel & Wiesel, eles estão na foto aqui

0:43:53.190,0:43:57.440
Eles ganharam um Prêmio Nobel por isso, então é um trabalho realmente clássico e o que eles mostraram

0:43:58.290,0:44:01.519
com gatos --basicamente enfiando eletrodos em cérebros de gatos

0:44:02.310,0:44:08.480
é que os neurônios no cérebro do gato --em v1-- detectam...

0:44:09.150,0:44:13.789
são sensíveis apenas a uma pequena área do campo visual e detectam bordas orientadas

0:44:14.970,0:44:17.030
contornos nessa área em particular, ok?

0:44:17.880,0:44:22.160
Assim, a área à qual um neurônio em particular é sensível é chamada de campo receptivo.

0:44:23.700,0:44:27.859
E você pega um neurônio em particular e mostra

0:44:29.070,0:44:35.719
tipo de uma barra orientada que você gira, e em um ponto o neurônio irá disparar

0:44:36.270,0:44:40.640
para um determinado ângulo, e à medida que você se afasta desse ângulo, a ativação do neurônio

0:44:42.690,0:44:50.149
diminui, ok? Então isso é chamado de neurônios seletivos de orientação, e Hubel & Wiesel chamaram de células simples

0:44:51.420,0:44:56.930
Se você mover um pouco a barra, você sai do campo receptivo, aquele neurônio não dispara mais

0:44:57.150,0:45:03.049
não reage a isso. Este poderia ser outro neurônio quase exatamente idêntico a ele, apenas um pouco

0:45:04.830,0:45:09.620
Longe do primeiro que faz exatamente a mesma função. Ele vai reagir a um pouco diferente

0:45:10.380,0:45:12.440
campo receptivo, mas com a mesma orientação

0:45:14.700,0:45:18.889
Então você começa a ter essa ideia de que tem detectores de recursos locais posicionados

0:45:20.220,0:45:23.689
replicado por todo o campo visual, que é basicamente essa ideia de

0:45:24.960,0:45:26.960
convolução, ok?

0:45:27.870,0:45:33.470
Por isso são chamadas de células simples. E então outra ideia que ou descoberta que

0:45:35.100,0:45:40.279
Hubel & Wiesel fizeram é a ideia de células complexas. Então, o que é uma célula complexa é outro tipo de neurônio

0:45:41.100,0:45:45.200
que integra a saída de várias células simples dentro de uma determinada área

0:45:46.170,0:45:50.120
OK? Então eles vão pegar diferentes células simples que todas detectam

0:45:51.180,0:45:54.079
contornos em uma orientação específica, bordas em uma orientação específica

0:45:55.350,0:46:02.240
E calcule um agregado de todas essas ativações. Ele fará um máximo, ou uma soma, ou

0:46:02.760,0:46:08.239
uma soma de quadrados, ou raiz quadrada de soma de quadrados. Algum tipo de função que não depende da ordem dos argumentos

0:46:08.820,0:46:11.630
OK? Digamos max por uma questão de simplicidade

0:46:12.900,0:46:17.839
Então, basicamente, uma célula complexa será ativada se qualquer uma das células simples dentro de sua

0:46:19.740,0:46:22.399
grupo de entrada é ativado

0:46:22.680,0:46:29.480
OK? Assim, essa célula complexa detectará uma borda em uma orientação específica, independentemente de sua posição dentro dessa pequena região

0:46:30.210,0:46:32.210
Então ele constrói um pouco de

0:46:32.460,0:46:34.609
invariância de deslocamento do

0:46:35.250,0:46:40.159
representação que sai das células complexas com relação à pequena variação de posições de

0:46:40.890,0:46:42.890
características na entrada

0:46:46.680,0:46:52.010
Então, um cavalheiro com o nome de Kunihiko Fukushima

0:46:54.420,0:46:56.569
--Nenhuma relação real com a usina nuclear

0:46:58.230,0:47:00.230
No final dos anos 70 início dos anos 80

0:47:00.330,0:47:07.190
experimentou com modelos de computador que meio que implementavam essa ideia de célula simples / célula complexa, e ele teve a ideia de replicar isso

0:47:07.500,0:47:09.500
com várias camadas, então basicamente...

0:47:11.310,0:47:17.810
A arquitetura que ele fez foi muito parecida com a que mostrei anteriormente aqui com esse tipo de artesanato

0:47:18.570,0:47:20.490
detector de recursos

0:47:20.490,0:47:24.559
Alguns desses detectores de recursos em seu modelo foram feitos à mão, mas alguns deles foram aprendidos

0:47:25.230,0:47:30.709
Eles foram aprendidos por um método não supervisionado. Ele não tinha backprop, certo? Backprop não existia

0:47:30.710,0:47:36.770
Quer dizer, existia, mas não era muito popular e as pessoas não o usavam

0:47:38.609,0:47:43.338
Então ele treinou esses filtros basicamente com algo que equivale a um

0:47:44.190,0:47:46.760
tipo de algoritmo de agrupamento um pouco ...

0:47:49.830,0:47:53.569
e separadamente para cada camada. E assim ele faria

0:47:56.609,0:48:02.389
treinar os filtros para a primeira camada, treinar isso com dígitos manuscritos -- ele também tinha um conjunto de dados de dígitos manuscritos

0:48:03.390,0:48:06.470
e, em seguida, alimentar isso para células complexas que

0:48:06.470,0:48:10.820
agrupar a atividade de células simples, e então isso

0:48:11.880,0:48:18.440
formar a entrada para a próxima camada, e repetiria o mesmo algoritmo em execução. Seu modelo de neurônio era muito complicado

0:48:18.440,0:48:19.589
Foi meio que inspirado pela biologia

0:48:19.589,0:48:27.229
Então tinha neurônios inibitórios separados, os outros neurônios só têm pesos positivos e pesos de saída, etc.

0:48:27.839,0:48:29.839
Ele conseguiu fazer essa coisa funcionar

0:48:30.510,0:48:33.800
Não muito bem, mas meio que funcionou

0:48:36.420,0:48:39.170
Então, alguns anos depois

0:48:40.770,0:48:44.509
Eu basicamente me inspirei em arquiteturas semelhantes, mas

0:48:45.780,0:48:51.169
treinou-os supervisionado com backprop, ok? Essa é a gênese das redes convolucionais, se você quiser

0:48:51.750,0:48:53.869
E então independentemente mais ou menos

0:48:57.869,0:49:04.969
O laboratório de Max Riesenhuber e Tony Poggio no MIT meio que redescobriu essa arquitetura também, mas também não usou backprop por algum motivo

0:49:06.060,0:49:08.060
Ele chama isso de H-max

0:49:12.150,0:49:20.039
Este é um tipo de experimento que fiz com redes convolucionais quando estava terminando meu pós-doutorado na Universidade de Toronto em 1988

0:49:20.040,0:49:22.040
Então isso remonta a muito tempo

0:49:22.840,0:49:26.730
E eu estava tentando descobrir, isso funciona melhor em um pequeno conjunto de dados?

0:49:26.730,0:49:27.870
Então, se você tem uma pequena quantidade de dados

0:49:27.870,0:49:31.109
você está tentando se conectar totalmente à rede ou rede linear com apenas uma camada ou

0:49:31.480,0:49:34.529
uma rede com conexões locais, mas sem pesos compartilhados ou compare isso com

0:49:35.170,0:49:39.299
o que ainda não era chamado de rede convolucional, onde você compartilha pesos e conexões locais

0:49:39.400,0:49:42.749
Qual deles funciona melhor? E descobriu-se que em termos de

0:49:43.450,0:49:46.439
capacidade de generalização, que são as curvas no canto inferior esquerdo

0:49:49.270,0:49:52.499
que você vê aqui, a curva superior aqui, é...

0:49:53.500,0:50:00.330
basicamente a arquitetura de rede convolucional bebê treinada com um conjunto de dados muito simples de dígitos manuscritos que foram desenhados com um mouse, certo?

0:50:00.330,0:50:02.490
Não tínhamos como coletar imagens, basicamente

0:50:03.640,0:50:05.640
naquela hora

0:50:05.860,0:50:09.240
E então, se você tiver conexões reais sem pesos compartilhados

0:50:09.240,0:50:12.119
funciona um pouco pior. E então, se você estiver totalmente conectado

0:50:14.470,0:50:22.230
redes funciona pior, e se você tem uma rede linear, não só funciona pior, mas também superajusta, sobre trens

0:50:23.110,0:50:28.410
Então o erro de teste diminui depois de um tempo, e isso foi treinado com 320

0:50:29.410,0:50:35.519
320 amostras de treinamento, o que é muito pequeno. Essas redes tiveram da ordem de

0:50:36.760,0:50:43.170
cinco mil conexões, mil parâmetros. Então isso é um bilhão de vezes menor do que o que fazemos hoje

0:50:43.990,0:50:45.990
Um milhão de vezes eu diria

0:50:47.890,0:50:53.730
E então terminei meu pós-doutorado, fui para a Bell Labs, e a Bell Labs tinha computadores um pouco maiores

0:50:53.730,0:50:57.389
mas o que eles tinham era um conjunto de dados que veio do Serviço Postal

0:50:57.390,0:51:00.629
Então eles tinham códigos postais para envelopes e nós construímos um

0:51:00.730,0:51:05.159
conjunto de dados desses códigos postais e, em seguida, treinou uma rede neural um pouco maior por três semanas

0:51:06.430,0:51:12.749
e obtive resultados muito bons. Portanto, esta rede convolucional não tem separação

0:51:13.960,0:51:15.960
convolução e agrupamento

0:51:16.240,0:51:22.769
Tinha convolução a passos largos, então convoluções onde a janela é deslocada em mais de um pixel. Então isso é...

0:51:23.860,0:51:29.739
Qual é o resultado disso? Então o resultado é que o mapa de saída quando você faz uma convolução onde o passo é

0:51:30.710,0:51:36.369
mais de um, você obtém uma saída cuja resolução é menor que a entrada e vê um exemplo aqui

0:51:36.370,0:51:40.390
Então aqui a entrada é de 16 por 16 pixels. Isso é o que poderíamos pagar

0:51:41.900,0:51:49.029
Os kernels são de 5 por 5, mas são deslocados em 2 pixels a cada vez e, portanto, o

0:51:51.950,0:51:56.919
a saída aqui é menor por causa disso

0:52:11.130,0:52:13.980
OK? E então um ano depois esta era a próxima geração

0:52:14.830,0:52:16.830
rede convolucional. Este tinha separado

0:52:17.680,0:52:19.680
convolução e pooling então...

0:52:20.740,0:52:24.389
Onde está a operação de pooling? Naquela época, a operação de pooling era apenas mais uma

0:52:25.690,0:52:31.829
neurônio exceto que todos os pesos desse neurônio eram iguais, ok? Assim, uma unidade de pooling era basicamente

0:52:32.680,0:52:36.839
uma unidade que calculou uma média de suas entradas

0:52:37.180,0:52:41.730
adicionou um viés e, em seguida, passou para uma não linearidade, que neste caso era uma função tangente hiperbólica

0:52:42.820,0:52:48.450
OK? Todas as não linearidades nesta rede eram tangentes hiperbólicas na época. Isso é o que as pessoas estavam fazendo

0:52:53.200,0:52:55.200
E a operação de agrupamento foi

0:52:56.380,0:52:58.440
realizado por deslocamento

0:52:59.680,0:53:01.710
a janela sobre a qual você calcula o

0:53:02.770,0:53:09.240
o agregado da saída da camada anterior por 2 pixels, ok? Então aqui

0:53:10.090,0:53:13.470
você obtém uma janela de entrada de 32 por 32

0:53:14.470,0:53:20.730
Você envolve isso com filtros que são 5 por 5. Devo mencionar que um kernel de convolução às vezes também é chamado de filtro

0:53:22.540,0:53:25.230
E então o que você tem aqui são

0:53:27.520,0:53:29.520
saídas que são

0:53:30.520,0:53:33.749
Acho que menos 4, então é 28 por 28, ok?

0:53:34.540,0:53:40.380
E então há um pooling que calcula uma média de

0:53:41.530,0:53:44.400
pixels aqui em uma janela de 2 por 2 e

0:53:45.310,0:53:47.310
então muda essa janela por 2

0:53:48.160,0:53:50.160
Então, quantas dessas janelas você tem?

0:53:51.220,0:53:56.279
Já que a imagem é 28 por 28, você divide por 2, é 14 por 14, ok? Então essas imagens

0:53:57.460,0:54:00.359
aqui estão 14 por 14 pixels

0:54:02.050,0:54:05.759
E eles são basicamente metade da resolução da janela anterior

0:54:07.420,0:54:09.420
por causa desse passo

0:54:10.360,0:54:16.470
OK? Agora fica interessante porque o que você quer é que a próxima camada detecte combinações de recursos da camada anterior

0:54:17.200,0:54:19.200
E assim...

0:54:20.200,0:54:22.619
a maneira de fazer isso é... você tem

0:54:23.440,0:54:26.579
diferentes filtros de convolução se aplicam a cada um desses mapas de recursos

0:54:27.730,0:54:29.730
OK?

0:54:29.950,0:54:35.939
E você os soma, soma os resultados dessas quatro circunvoluções e passa o resultado para uma não linearidade e isso lhe dá

0:54:36.910,0:54:42.239
um mapa de características da próxima camada. Então, porque esses filtros são 5 por 5 e aqueles

0:54:43.330,0:54:46.380
as imagens são 14 por 14, esses caras são 10 por 10

0:54:47.290,0:54:49.739
OK? Para não ter efeitos de borda

0:54:52.270,0:54:56.999
Então, cada um desses mapas de recursos -- dos quais há dezesseis se bem me lembro

0:54:59.290,0:55:01.290
usa um conjunto diferente de

0:55:02.860,0:55:04.860
núcleos para...

0:55:06.340,0:55:09.509
convolva as camadas anteriores. Na verdade

0:55:10.630,0:55:13.799
o padrão de conexão entre o mapa de recursos...

0:55:14.650,0:55:18.720
o mapa de feição nesta camada e o mapa de feição na próxima camada não estão cheios

0:55:18.720,0:55:22.349
portanto, nem todo mapa de recursos está conectado a todos os mapas de recursos. Há um esquema particular de

0:55:23.680,0:55:25.950
diferentes combinações de mapa de recursos da camada anterior

0:55:28.030,0:55:33.600
combinando com quatro mapas de recursos na próxima camada. E a razão para fazer isso é apenas para economizar tempo no computador

0:55:34.000,0:55:40.170
Nós simplesmente não podíamos nos dar ao luxo de conectar tudo a tudo. Levaria o dobro do tempo para correr ou mais

0:55:41.890,0:55:48.359
Hoje em dia somos meio que forçados a ter uma conexão completa entre mapas de características em uma rede convolucional

0:55:49.210,0:55:52.289
Devido à maneira como várias convoluções são implementadas em GPUs

0:55:53.440,0:55:55.440
O que é triste

0:55:56.560,0:55:59.789
E então a próxima camada para cima. Então, novamente, esses mapas são 10 por 10

0:55:59.790,0:56:02.729
Esses mapas de recursos são 10 por 10 e a próxima camada acima

0:56:03.970,0:56:06.389
é produzido por agrupamento e subamostragem

0:56:07.330,0:56:09.330
por um fator de 2

0:56:09.370,0:56:11.370
e então esses são 5 por 5

0:56:12.070,0:56:14.880
OK? E então, novamente, há uma convolução de 5 por 5 aqui

0:56:14.880,0:56:18.089
Claro, você não pode mover a janela 5 por 5 sobre uma imagem de 5 por 5

0:56:18.090,0:56:21.120
Parece uma conexão completa, mas na verdade é uma convolução

0:56:22.000,0:56:24.000
OK? Mantenha isso em mente

0:56:24.460,0:56:26.460
Mas você basicamente apenas soma em apenas um local

0:56:27.250,0:56:33.960
E esses mapas de recursos no topo aqui são realmente saídas. E assim você tem um local especial

0:56:33.960,0:56:39.399
OK? Porque você só pode colocar uma janela de 5 por 5 em uma imagem de 5 por 5

0:56:40.460,0:56:45.340
E você tem 10 desses mapas de recursos, cada um correspondendo a uma categoria, então você treina o sistema para classificar

0:56:45.560,0:56:47.619
dígitos de 0 a 9, você tem dez categorias

0:56:59.750,0:57:03.850
Esta é uma pequena animação que peguei emprestada de Andrej Karpathy

0:57:05.570,0:57:08.439
Ele gastou o tempo para construir esta animação real muito legal

0:57:09.470,0:57:16.780
que é para representar várias circunvoluções, certo? Então você tem três mapas de recursos aqui na entrada e você tem seis

0:57:18.650,0:57:21.100
kernels de convolução e dois mapas de recursos na saída

0:57:21.100,0:57:26.709
Então, aqui o primeiro grupo de três mapas de recursos é convoluído com...

0:57:28.520,0:57:31.899
kernels são convolvidos com os três mapas de recursos de entrada para produzir

0:57:32.450,0:57:37.330
o primeiro grupo, o primeiro dos dois mapas de recursos, o verde no topo

0:57:38.390,0:57:40.370
OK?

0:57:40.370,0:57:42.820
E então...

0:57:44.180,0:57:49.000
Ok, então este é o primeiro grupo de três kernels convoluídos com os três mapas de recursos

0:57:49.000,0:57:53.349
E eles produzem o mapa verde no topo, e então você muda para o segundo grupo de

0:57:54.740,0:57:58.479
de núcleos de convolução. Você se envolve com o

0:57:59.180,0:58:04.149
três mapas de recursos de entrada para produzir o mapa na parte inferior. OK? Então isso é

0:58:05.810,0:58:07.810
um exemplo de

0:58:10.070,0:58:17.709
Mapa de n recursos na entrada, mapa de n recursos na saída e N vezes M kernels de convolução para obter todas as combinações

0:58:25.000,0:58:27.000
Aqui está outra animação que fiz há muito tempo

0:58:28.100,0:58:34.419
Isso mostra a rede convolucional depois de ser treinada em ação tentando reconhecer dígitos

0:58:35.330,0:58:38.529
E o que é interessante ver aqui é que você tem

0:58:39.440,0:58:41.440
uma entrada aqui, que é eu acredito

0:58:42.080,0:58:44.590
32 linhas por 64 colunas

0:58:45.770,0:58:52.570
E depois de fazer seis convoluções com seis núcleos de convolução passando por uma tangente hiperbólica não linear após um viés

0:58:52.570,0:58:59.229
você obtém esses mapas de recursos aqui, cada um dos quais é ativado para um tipo diferente de recurso. Assim, por exemplo

0:58:59.990,0:59:01.990
o mapa de recursos no topo aqui

0:59:02.390,0:59:04.690
acende quando há algum tipo de borda horizontal

0:59:07.400,0:59:10.090
Esse cara aqui liga sempre que tem uma borda vertical

0:59:10.940,0:59:15.340
OK? E esses kernels convolucionais foram aprendidos através do backprop, a coisa acabou de ser treinada

0:59:15.980,0:59:20.980
com suporte traseiro. Não definido à mão. Eles são definidos aleatoriamente geralmente

0:59:21.620,0:59:26.769
Então você vê essa noção de equivariância aqui, se eu mudar a imagem de entrada

0:59:27.500,0:59:31.600
as ativações nos mapas de recursos mudam, mas permanecem inalteradas

0:59:32.540,0:59:34.540
Tudo bem?

0:59:34.940,0:59:36.940
Isso é equivariância de deslocamento

0:59:36.950,0:59:38.860
Ok, e então vamos para a operação de pooling

0:59:38.860,0:59:42.519
Portanto, este primeiro mapa de recursos aqui corresponde a uma versão agrupada de

0:59:42.800,0:59:46.149
este primeiro, o segundo para o segundo, o terceiro foi para o terceiro

0:59:46.250,0:59:51.370
e a operação de agrupamento aqui novamente é uma média, depois um viés, depois uma não linearidade semelhante

0:59:52.070,0:59:55.029
E assim, se este mapa muda de

0:59:56.570,0:59:59.499
um pixel este mapa mudará em meio pixel

0:00:01.370,0:00:02.780
OK?

0:00:02.780,0:00:05.259
Então você ainda tem equavariância, mas

0:00:06.260,0:00:11.830
os deslocamentos são reduzidos por um fator de dois, essencialmente

0:00:11.830,0:00:15.850
e então você tem o segundo estágio onde cada um desses mapas aqui é resultado de

0:00:16.160,0:00:23.440
fazendo uma convolução em cada um, ou um subconjunto dos mapas anteriores com kernels diferentes, somando o resultado, passando o resultado por

0:00:24.170,0:00:27.070
um sigmóide, e assim você obtém esse tipo de recursos abstratos

0:00:28.730,0:00:32.889
aqui que são um pouco difíceis de interpretar visualmente, mas ainda é equivalente mudar

0:00:33.860,0:00:40.439
OK? E então, novamente, você faz o agrupamento e a subamostragem. Então o pooling também tem esse passo por um fator de dois

0:00:40.630,0:00:42.580
Então o que você tem aqui são

0:00:42.580,0:00:47.609
nossos mapas, para que esses mapas mudem em um quarto de pixel se a entrada mudar em um pixel

0:00:48.730,0:00:55.290
OK? Então reduzimos a mudança e torna-se... pode tornar-se cada vez mais fácil para as camadas seguintes para interpretar qual é a forma

0:00:55.290,0:00:57.290
porque você troca

0:00:58.540,0:01:00.540
resolução espacial para

0:01:01.030,0:01:05.009
resolução do tipo de recurso. Você aumenta o número de tipos de feição à medida que sobe as camadas

0:01:06.040,0:01:08.879
A resolução espacial diminui devido ao agrupamento e subamostragem

0:01:09.730,0:01:14.459
Mas o número de mapas de recursos aumenta e você torna a representação um pouco mais abstrata

0:01:14.460,0:01:19.290
mas menos sensível a mudanças e distorções. E a próxima camada

0:01:20.740,0:01:25.080
novamente executa convoluções, mas agora o tamanho do kernel de convolução é igual à altura da imagem

0:01:25.080,0:01:27.449
E então o que você ganha é uma única banda

0:01:28.359,0:01:32.219
para este mapa de recursos. Basicamente torna-se unidimensional e

0:01:32.920,0:01:39.750
então agora qualquer deslocamento vertical é basicamente eliminado, certo? Ele se transformou em alguma variação de ativação, mas não é

0:01:40.840,0:01:42.929
Não é mais uma mudança. É algum tipo de

0:01:44.020,0:01:45.910
mais simples --espero

0:01:45.910,0:01:49.020
transformação da entrada. Na verdade, você pode mostrar que é mais simples

0:01:51.160,0:01:53.580
É mais plano em alguns aspectos

0:01:56.650,0:02:00.330
OK? Esse é o tipo de arquitetura de rede convolucional genérica que temos

0:02:01.570,0:02:05.699
Esta é uma versão um pouco mais moderna, onde você tem alguma forma de normalização

0:02:07.450,0:02:09.450
Norma de lote

0:02:10.600,0:02:15.179
Boa norma, tanto faz. Um banco de filtros, essas são as múltiplas convoluções

0:02:16.660,0:02:18.690
No processamento de sinal, eles são chamados de bancos de filtros

0:02:19.840,0:02:27.149
Não linearidade pontual, geralmente um ReLU e, em seguida, algum pooling, geralmente max pooling no mais comum

0:02:28.330,0:02:30.629
implementações de redes convolucionais. Você pode, claro

0:02:30.630,0:02:35.880
imagine outros tipos de pooling. Eu falei sobre a média, mas a versão mais genérica é a norma LP

0:02:36.640,0:02:38.640
qual é...

0:02:38.770,0:02:45.530
pegue todas as entradas através de uma célula complexa, eleve-as a alguma potência e então pegue o...

0:02:45.530,0:02:47.530
Soma-os e depois toma o...

0:02:49.860,0:02:51.860
Eleve isso para 1 sobre o poder

0:02:53.340,0:02:58.489
Sim, isso deve ser uma soma dentro da raiz P-th aqui

0:03:00.870,0:03:02.870
Outra maneira de piscina e novamente

0:03:03.840,0:03:07.759
uma boa operação de pooling é uma operação que é

0:03:07.920,0:03:11.719
invariante a uma permutação da entrada. Dá o mesmo resultado

0:03:12.750,0:03:14.750
independentemente da ordem em que você coloca a entrada

0:03:15.780,0:03:22.670
Aqui está outro exemplo. Falamos sobre essa função antes: 1 sobre b log soma de nossas entradas de e para o bXᵢ

0:03:25.920,0:03:30.649
Exponencial bX. Novamente, esse é um tipo de operação de agregação simétrica que você pode usar

0:03:32.400,0:03:35.539
Então, isso é uma espécie de estágio de uma rede convolucional, e então você pode repetir isso

0:03:36.270,0:03:43.729
Existem várias maneiras de posicionar a normalização. Algumas pessoas colocam após a não linearidade antes do agrupamento

0:03:43.730,0:03:45.730
Você sabe, depende

0:03:46.590,0:03:48.590
Mas é típico

0:03:53.640,0:03:56.569
Então, como você faz isso no PyTorch? há várias maneiras diferentes

0:03:56.570,0:04:02.479
Você pode fazer isso escrevendo explicitamente, escrevendo uma classe. Este é um exemplo de uma classe de rede convolucional

0:04:04.020,0:04:10.520
Em particular aqui onde você faz convoluções, ReLU e pool máximo

0:04:12.600,0:04:17.900
Ok, então o construtor aqui cria camadas convolucionais que possuem parâmetros nelas

0:04:18.810,0:04:24.499
E este tem o que chamamos de camadas totalmente conectadas. Eu odeio isso. OK?

0:04:25.980,0:04:30.919
Então existe essa ideia de alguma forma que a última camada de uma rede convolucional

0:04:32.760,0:04:34.790
Como este, está totalmente conectado porque

0:04:37.320,0:04:42.860
cada unidade nesta camada está conectada a cada unidade naquela camada. Então isso parece uma conexão completa

0:04:44.010,0:04:47.060
Mas é realmente útil pensar nisso como uma convolução

0:04:49.200,0:04:51.060
OK?

0:04:51.060,0:04:56.070
Agora, por razões de eficiência, ou talvez outras razões ruins, eles são chamados

0:04:57.370,0:05:00.959
camadas totalmente conectadas, e usamos a classe linear aqui

0:05:01.120,0:05:05.459
Mas meio que quebra toda a ideia de que sua rede é uma rede convolucional

0:05:06.070,0:05:09.209
Portanto, é muito melhor vê-los como convoluções

0:05:09.760,0:05:14.370
Neste caso, uma por uma convolução que é uma espécie de conceito estranho. OK. Então aqui temos

0:05:15.190,0:05:20.460
quatro camadas, duas camadas convolucionais e duas chamadas camadas totalmente conectadas

0:05:21.790,0:05:23.440
E então a maneira como nós...

0:05:23.440,0:05:29.129
Então, precisamos criá-los no construtor, e a maneira como os usamos na passagem para frente é que

0:05:30.630,0:05:35.310
nós fazemos uma convolução da entrada, e então aplicamos o ReLU, e então fazemos o pool máximo e então nós

0:05:35.710,0:05:38.699
execute a segunda camada e aplique o ReLU e faça o pool máximo novamente

0:05:38.700,0:05:44.280
E então remodelamos a saída porque é uma camada totalmente conectada. Então queremos fazer disso um

0:05:45.190,0:05:47.879
vetor então é isso que o x.view(-1) faz

0:05:48.820,0:05:50.820
E depois aplique um

0:05:51.160,0:05:53.160
ReLU para isso

0:05:53.260,0:05:55.260
E...

0:05:55.510,0:06:00.330
a segunda camada totalmente conectada e, em seguida, aplique um softmax se quisermos fazer a classificação

0:06:00.460,0:06:04.409
E isso é um pouco semelhante à arquitetura que você vê na parte inferior

0:06:04.900,0:06:08.370
Os números podem ser diferentes em termos de mapas de recursos e outras coisas, mas ...

0:06:09.160,0:06:11.160
mas a arquitetura geral é

0:06:12.250,0:06:14.250
praticamente o que estamos falando

0:06:15.640,0:06:17.640
Sim?

0:06:20.530,0:06:22.530
Repita

0:06:24.040,0:06:26.100
Você sabe, o que quer que a descida do gradiente decida

0:06:28.630,0:06:30.630
Podemos olhar para eles, mas

0:06:31.180,0:06:33.180
se você treinar com muito

0:06:33.280,0:06:37.590
exemplos de imagens naturais, o tipo de filtro que você verá na primeira camada

0:06:37.840,0:06:44.999
basicamente acabarão sendo detectores de bordas orientados, muito semelhantes ao que as pessoas, ao que os neurocientistas

0:06:45.340,0:06:49.110
observar no córtex de

0:06:49.210,0:06:50.440
animais

0:06:50.440,0:06:52.440
No córtex visual dos animais

0:06:55.780,0:06:58.469
Eles vão mudar quando você treinar o modelo, esse é o ponto sim

0:07:05.410,0:07:11.160
Ok, então é bem simples. Aqui está outra maneira de defini-los. Isso é... eu acho que é uma espécie de

0:07:12.550,0:07:15.629
maneira desatualizada de fazer isso, certo? Muitas pessoas não fazem mais isso

0:07:17.170,0:07:23.340
mas é uma forma simples. Também existe essa classe no PyTorch chamada nn.Sequential

0:07:24.550,0:07:28.469
É basicamente um container e você continua colocando módulos nele e simplesmente

0:07:29.080,0:07:36.269
automaticamente meio que usá-los como sendo meio conectados em sequência, certo? E então você só tem que ligar

0:07:40.780,0:07:45.269
adiante e ele apenas calculará a coisa certa

0:07:46.360,0:07:50.370
Neste formulário específico aqui, você passa um monte de pares

0:07:50.370,0:07:55.229
É como um dicionário para que você possa dar um nome a cada uma das camadas e depois acessá-las

0:08:08.079,0:08:10.079
É a mesma arquitetura que estávamos falando anteriormente

0:08:18.489,0:08:24.029
Sim, quero dizer que o backprop é automático, certo? Você entendeu

0:08:25.630,0:08:27.630
por padrão você apenas chama

0:08:28.690,0:08:32.040
para trás e sabe como voltar a propagar através dele

0:08:44.000,0:08:49.180
Bem, a classe meio que encapsula tudo em um objeto onde os parâmetros são

0:08:49.250,0:08:51.250
Existe uma forma específica de...

0:08:52.220,0:08:54.220
tirando os parâmetros e

0:08:55.130,0:08:58.420
tipo de alimentá-los para um otimizador

0:08:58.420,0:09:01.330
E assim o otimizador não precisa saber como é sua rede

0:09:01.330,0:09:06.910
Ele apenas sabe que existe uma função e um monte de parâmetros e obtém um gradiente e

0:09:06.910,0:09:08.910
ele não precisa saber como é sua rede

0:09:10.790,0:09:12.879
Sim, você vai ouvir mais sobre isso

0:09:14.840,0:09:16.840
amanhã

0:09:25.610,0:09:33.159
Então aqui está um aspecto muito interessante das redes convolucionais e é uma das razões pelas quais elas se tornaram tão

0:09:33.830,0:09:37.390
sucesso em muitas aplicações. É o fato de

0:09:39.440,0:09:45.280
se você visualizar cada camada em uma rede convolucional como uma convolução, então não há conexões completas, por assim dizer

0:09:47.660,0:09:53.320
você não precisa ter uma entrada de tamanho fixo. Você pode variar o tamanho da entrada e a rede

0:09:54.380,0:09:56.380
variar seu tamanho de acordo

0:09:56.780,0:09:58.780
Porque...

0:09:59.510,0:10:01.510
quando você aplica uma convolução a uma imagem

0:10:02.150,0:10:05.800
você encaixa uma imagem de um certo tamanho, você faz uma convolução com um kernel

0:10:06.620,0:10:11.979
você obtém uma imagem cujo tamanho está relacionado ao tamanho da entrada

0:10:12.140,0:10:15.789
mas você pode alterar o tamanho da entrada e apenas altera o tamanho da saída

0:10:16.760,0:10:20.320
E isso é verdade para todas as operações do tipo convolucional, certo?

0:10:20.320,0:10:25.509
Portanto, se sua rede é composta apenas de convoluções, não importa o tamanho da entrada

0:10:26.180,0:10:31.450
Vai passar pela rede e o tamanho de cada camada mudará de acordo com o tamanho da entrada

0:10:31.580,0:10:34.120
e o tamanho da saída também mudará de acordo

0:10:34.640,0:10:37.329
Então aqui está um pequeno exemplo aqui onde

0:10:38.720,0:10:40.720
Eu quero fazer

0:10:41.300,0:10:45.729
reconhecimento de caligrafia cursiva e é muito difícil porque não sei onde estão as letras

0:10:45.730,0:10:48.700
Então eu não posso simplesmente ter um reconhecedor de caracteres que...

0:10:49.260,0:10:51.980
Refiro-me a um sistema que primeiro cortará o

0:10:52.890,0:10:56.100
palavra em letras

0:10:56.100,0:10:57.720
porque não sei onde estão as letras

0:10:57.720,0:10:59.900
e, em seguida, aplique a rede convolucional a cada uma das letras

0:11:00.210,0:11:05.200
Então, o melhor que posso fazer é pegar a rede convolucional e passá-la sobre a entrada e gravar a saída

0:11:05.850,0:11:11.810
OK? E então você pensaria que para fazer isso você terá que pegar uma rede convolucional como esta que tem uma janela

0:11:12.060,0:11:14.389
grande o suficiente para ver um único caractere

0:11:15.120,0:11:21.050
e então você pega sua imagem de entrada e calcula sua rede convolucional em cada local

0:11:21.660,0:11:27.110
deslocando-o em um pixel ou dois pixels ou quatro pixels ou algo assim, um número pequeno o suficiente de pixels que

0:11:27.630,0:11:30.619
independentemente de onde o caractere ocorre na entrada

0:11:30.620,0:11:35.000
você ainda obterá uma pontuação na saída sempre que precisar reconhecer um

0:11:36.150,0:11:38.989
Mas acontece que será extremamente desperdício

0:11:40.770,0:11:42.770
Porque...

0:11:43.290,0:11:50.179
você estará refazendo o mesmo cálculo várias vezes. E a maneira correta de fazer isso -- e isso é muito importante para entender

0:11:50.880,0:11:56.659
é que você não faz o que acabei de descrever onde você tem uma pequena rede convolucional que você aplica a todas as janelas

0:11:58.050,0:12:00.050
O que você faz é você

0:12:01.230,0:12:07.939
pegue uma entrada grande e aplique as convoluções à imagem de entrada, pois é maior, você obterá uma saída maior

0:12:07.940,0:12:11.270
você aplica a convolução da segunda camada a isso, ou o pooling, seja lá o que for

0:12:11.610,0:12:15.170
Você obterá uma entrada maior novamente, etc.

0:12:15.170,0:12:16.650
todo o caminho até o topo e

0:12:16.650,0:12:20.929
enquanto no design original você estava obtendo apenas uma saída, agora você obterá várias saídas porque

0:12:21.570,0:12:23.570
é uma camada convolucional

0:12:27.990,0:12:29.990
Isso é superimportante porque

0:12:30.600,0:12:35.780
esta maneira de aplicar uma rede convolucional com uma janela deslizante é

0:12:36.870,0:12:40.610
muito, muito mais barato do que recalcular a rede convolucional em cada local

0:12:42.510,0:12:44.510
OK?

0:12:45.150,0:12:51.619
Você não acreditaria em quantas décadas foram necessárias para convencer as pessoas de que isso era uma coisa boa

0:12:58.960,0:13:03.390
Então aqui está um exemplo de como você pode usar isso

0:13:04.090,0:13:09.180
Esta é uma rede convencional que foi treinada em dígitos individuais, 32 por 32. Foi treinada em um MNIST, ok?

0:13:09.760,0:13:11.760
32 por 32 janelas de entrada

0:13:12.400,0:13:15.690
É LeNet 5, então é muito semelhante à arquitetura

0:13:15.690,0:13:20.940
Acabei de mostrar o código para, ok? É treinado em personagens individuais para apenas classificar

0:13:21.970,0:13:26.369
o personagem no centro da imagem. E a maneira como foi treinado foi que havia um pouco de dados

0:13:26.770,0:13:30.359
aumento onde o personagem no centro foi meio que mudou um pouco em vários locais

0:13:31.420,0:13:36.629
mudou de tamanho. E então havia dois outros personagens

0:13:37.420,0:13:39.600
que foram meio que adicionados ao lado para confundir

0:13:40.480,0:13:45.660
em muitas amostras. E então também foi treinado com uma 11ª categoria

0:13:45.660,0:13:50.249
que foi "nenhuma das opções acima" e a maneira como é treinado é ou você mostra uma imagem em branco

0:13:50.410,0:13:54.149
ou você mostra uma imagem onde não há nenhum caractere no centro, mas há caracteres na lateral

0:13:54.940,0:13:59.399
para detectar sempre que estiver entre dois caracteres

0:14:00.520,0:14:02.520
e então você faz essa coisa de

0:14:02.650,0:14:10.970
computando a rede convolucional em cada local na entrada sem realmente deslocá-la, mas apenas aplicando as convoluções à imagem inteira

0:14:11.740,0:14:13.740
E é isso que você ganha

0:14:13.780,0:14:23.220
Então aqui a imagem de entrada é 64 por 32, embora a rede tenha sido treinada em 32 por 32 com esse tipo de exemplo gerado

0:14:24.280,0:14:28.049
E o que você vê é a atividade de algumas das camadas, nem todas estão representadas

0:14:29.410,0:14:32.309
E o que você vê no topo aqui, essas formas engraçadas

0:14:33.520,0:14:37.560
Você vê três e cinco aparecendo e eles são basicamente um

0:14:38.830,0:14:41.850
indicação da categoria vencedora para cada localidade, certo?

0:14:42.670,0:14:47.339
Portanto, as oito saídas que você vê no topo são

0:14:48.520,0:14:50.520
basicamente a saída correspondente a oito

0:14:51.250,0:14:56.790
posições da janela de entrada de 32 por 32 na entrada, deslocadas em 4 pixels a cada vez

0:14:59.530,0:15:05.859
E o que está representado é a categoria vencedora dentro dessa janela e a escala de cinza indica a pontuação, ok?

0:15:07.220,0:15:10.419
Então o que você vê é que há dois detectores detectando os cinco

0:15:11.030,0:15:15.850
até que os três tipos comecem a se sobrepor. E então dois detectores estão detectando os três que meio que se moveram

0:15:18.230,0:15:22.779
porque dentro de uma janela de 32 por 32

0:15:23.390,0:15:29.919
os três aparecem à esquerda dessa janela de 32 por 32 e, em seguida, à direita das outras janelas de 32 por 32 deslocadas por quatro

0:15:29.920,0:15:31.920
e então esses dois detectores detectam

0:15:32.690,0:15:34.690
aquele 3 ou aquele 5

0:15:36.140,0:15:39.890
Então o que você faz é pegar todas essas pontuações aqui no topo e você

0:15:39.890,0:15:43.809
faça um pouco de pós-processamento muito simples e você descobre se é um três e um cinco

0:15:44.630,0:15:46.630
O que é interessante nisso é que

0:15:47.660,0:15:49.899
você não precisa fazer segmentação prévia

0:15:49.900,0:15:51.860
Então, algo que as pessoas tinham que fazer

0:15:51.860,0:15:58.180
antes, em visão computacional, era se você quisesse reconhecer um objeto que você tinha que separar o objeto de seu fundo porque o sistema de reconhecimento

0:15:58.490,0:16:00.490
ficaria confuso com

0:16:00.800,0:16:07.900
o fundo. Mas aqui com esta rede convolucional, ela foi treinada com caracteres sobrepostos e sabe como diferenciá-los

0:16:08.600,0:16:10.809
E por isso não é confundido por caracteres que se sobrepõem

0:16:10.810,0:16:15.729
Eu tenho um monte deles no meu site, a propósito, aquelas animações do início dos anos noventa

0:16:38.450,0:16:41.679
Não, essa era a questão principal. Essa é uma das razões pelas quais

0:16:44.210,0:16:48.040
a visão computacional não estava funcionando muito bem. É porque o próprio problema de

0:16:49.850,0:16:52.539
separação figura/fundo, detectando um objeto

0:16:53.780,0:16:59.530
e reconhecê-lo é o mesmo. Você não pode reconhecer o objeto até segmentá-lo, mas não pode segmentá-lo até reconhecê-lo

0:16:59.840,0:17:05.290
É o mesmo para o reconhecimento de caligrafia cursiva, certo? Você não pode... então aqui está um exemplo

0:17:07.460,0:17:09.460
Temos canetas?

0:17:10.650,0:17:12.650
Não parece que temos canetas né?

0:17:14.969,0:17:21.859
Aqui vamos nós, isso é verdade. Me desculpe... talvez eu deva usar o...

0:17:24.780,0:17:26.780
Se isso funcionar...

0:17:34.500,0:17:36.510
Ah, claro...

0:17:43.409,0:17:45.409
OK...

0:17:52.310,0:17:54.310
Vocês podem ler isso?

0:17:55.670,0:18:01.990
Ok, quero dizer que é uma caligrafia horrível, mas também é porque estou escrevendo na tela. Ok, agora você pode lê-lo?

0:18:08.240,0:18:10.240
Mínimo sim

0:18:11.870,0:18:15.010
Ok, na verdade não há como você segmentar as letras dessa direita

0:18:15.010,0:18:17.439
Quero dizer, isso é meio que um número aleatório de ondas

0:18:17.900,0:18:23.260
Mas apenas o fato de que os dois "I"s são identificados, então basicamente não é ambíguo, pelo menos em inglês

0:18:24.620,0:18:26.620
Então esse é um bom exemplo de

0:18:28.100,0:18:30.340
a interpretação do indivíduo

0:18:31.580,0:18:38.169
objetos dependendo de seu contexto. E o que você precisa é de algum tipo de modelo de linguagem de alto nível para saber quais palavras são possíveis

0:18:38.170,0:18:40.170
Se você não sabe inglês ou similar

0:18:40.670,0:18:44.320
idiomas que têm a mesma palavra, não tem como você ler isso

0:18:45.500,0:18:48.490
A linguagem falada é muito semelhante a esta

0:18:49.700,0:18:53.679
Todos vocês que tiveram a experiência de aprender uma língua estrangeira

0:18:54.470,0:18:56.470
provavelmente teve a experiência de que

0:18:57.110,0:19:04.150
você tem dificuldade em segmentar palavras de um novo idioma e depois reconhecer as palavras porque não tem o vocabulário

0:19:04.850,0:19:09.550
Certo? Então, se eu falar em francês -- se eu começar a falar francês, você não tem ideia de onde estão os limites das palavras]

0:19:09.740,0:19:13.749
Exceto se você fala francês. Então eu falei uma frase, são palavras

0:19:13.750,0:19:17.140
mas você não pode dizer o limite entre as palavras porque basicamente não é

0:19:17.990,0:19:23.800
clara apreensão entre as palavras, a menos que você saiba onde as palavras estão de antemão, certo? Então esse é o problema da segmentação

0:19:23.900,0:19:28.540
Você não pode reconhecer até segmentar, não pode segmentar até reconhecer que precisa fazer as duas coisas ao mesmo tempo

0:19:29.150,0:19:32.379
Os primeiros sistemas de visão computacional tiveram muita dificuldade em fazer isso

0:19:40.870,0:19:46.739
Então é por isso que esse tipo de coisa é um grande progresso, porque você não precisa fazer a segmentação com antecedência, apenas...

0:19:47.679,0:19:52.559
apenas treine seu sistema para ser robusto a objetos sobrepostos e coisas assim. Sim, nas costas!

0:19:55.510,0:19:59.489
Sim, há uma classe de fundo. Então, quando você vê uma resposta em branco

0:20:00.340,0:20:04.410
significa que o sistema diz "nenhuma das opções acima" basicamente, certo? Então foi treinado

0:20:05.590,0:20:07.590
para produzir "nenhuma das anteriores"

0:20:07.690,0:20:11.699
ou quando a entrada está em branco ou quando há um caractere que é muito

0:20:13.420,0:20:17.190
fora do centro ou quando você tem dois personagens

0:20:17.620,0:20:24.029
mas não há nada no centro. Ou quando você tem dois personagens que se sobrepõem, mas não tem um personagem central, certo? Então é...

0:20:24.760,0:20:27.239
tentando detectar limites entre personagens essencialmente

0:20:28.420,0:20:30.420
Aqui está outro exemplo

0:20:31.390,0:20:38.640
Este é um exemplo que mostra que mesmo uma rede convolucional muito simples com apenas dois estágios, certo? convolução, agrupamento, convolução

0:20:38.640,0:20:40.640
pooling e, em seguida, duas camadas de ...

0:20:42.010,0:20:44.010
mais duas camadas depois

0:20:44.770,0:20:47.429
pode resolver o que é chamado de problema de vinculação de recursos

0:20:48.130,0:20:50.130
Assim, neurocientistas visuais e

0:20:50.320,0:20:56.190
as pessoas de visão computacional tinham o problema --era uma espécie de quebra-cabeça-- Como é que

0:20:57.489,0:21:01.289
percebemos os objetos como objetos? Objetos são coleções de recursos

0:21:01.290,0:21:04.229
mas como ligamos todos os recursos de um objeto para formar esse objeto?

0:21:06.460,0:21:09.870
Existe algum tipo de maneira mágica de fazer isso?

0:21:12.520,0:21:16.589
E eles fizeram... psicólogos fizeram experimentos como...

0:21:24.210,0:21:26.210
desenhe isso e depois aquilo

0:21:28.239,0:21:31.349
e você percebe a barra como

0:21:32.469,0:21:39.419
uma única barra porque você está acostumado a barras sendo obstruídas por outros objetos

0:21:39.550,0:21:41.550
e então você apenas assume que é uma oclusão

0:21:44.410,0:21:47.579
E depois há experimentos que descobrem o quanto eu tenho que

0:21:48.430,0:21:52.109
mude as duas barras para me fazer percebê-las como duas barras separadas

0:21:53.980,0:21:56.580
Mas, na verdade, no minuto em que eles se alinham perfeitamente e se você...

0:21:57.250,0:21:59.080
se você fizer isto..

0:21:59.080,0:22:03.809
talvez exatamente idêntico ao que você vê aqui, mas agora você os percebe como dois objetos diferentes

0:22:06.489,0:22:12.929
Então, como parece que estamos resolvendo o problema de vinculação de recursos?

0:22:15.880,0:22:21.450
E o que isso mostra é que você não precisa de nenhum mecanismo específico para isso. Simplesmente acontece

0:22:22.210,0:22:25.919
Se você tiver não linearidades suficientes e treinar com dados suficientes

0:22:26.440,0:22:33.359
então, como efeito colateral, você obtém um sistema que resolve o problema de vinculação de recursos sem nenhum mecanismo específico para isso

0:22:37.510,0:22:40.260
Então aqui você tem duas formas e você move uma única

0:22:43.060,0:22:50.519
curso e vai de um seis e um, para um três, para um cinco e um, para um sete e um três

0:22:53.140,0:22:55.140
etc.

0:23:00.020,0:23:07.480
Certo, boa pergunta. Então a pergunta é: como você distingue entre as duas situações? Temos dois cincos um ao lado do outro e

0:23:08.270,0:23:14.890
o fato de você ter um único cinco sendo detectado por dois quadros diferentes, certo? Dois enquadramentos diferentes desses cinco

0:23:15.470,0:23:17.470
Bem, há isso explícito

0:23:17.660,0:23:20.050
treinando para que quando você tiver dois personagens que

0:23:20.690,0:23:25.029
estão se tocando e nenhum deles está realmente centralizado, você treina o sistema para dizer "nenhuma das opções acima", certo?

0:23:25.030,0:23:29.079
Então sempre vai ter cinco cinco em branco

0:23:30.020,0:23:35.800
Sempre vai ter um em branco, e os dois podem ser muito próximos. Será que você vai te dizer a diferença

0:23:39.170,0:23:41.289
Ok, então para que servem os convnets?

0:24:04.970,0:24:07.599
Então o que você tem que olhar é isso

0:24:11.510,0:24:13.510
Cada camada aqui é uma convolução

0:24:13.610,0:24:15.020
OK?

0:24:15.020,0:24:21.070
Incluindo a última camada, então parece uma conexão completa porque cada unidade na segunda camada vai para a saída

0:24:21.070,0:24:24.460
Mas, na verdade, é uma convolução, só acontece de ser aplicada a um único local

0:24:24.950,0:24:31.300
Então agora imagine que essa camada no topo aqui agora é maior, ok? Que está representado aqui

0:24:32.840,0:24:34.130
OK?

0:24:34.130,0:24:37.779
Agora o tamanho do kernel é o tamanho da imagem que você tinha aqui anteriormente

0:24:37.820,0:24:43.360
Mas agora é uma convolução que tem vários locais, certo? E então o que você obtém são várias saídas

0:24:46.430,0:24:55.100
Isso mesmo, isso mesmo. Cada um deles corresponde a uma classificação em uma janela de entrada de tamanho 32 por 32 no exemplo que mostrei

0:24:55.100,0:25:02.710
E essas janelas são deslocadas em 4 pixels. A razão é que a arquitetura de rede que mostrei

0:25:04.280,0:25:11.739
aqui tem uma convolução com passo um, então juntando com passo dois, convolução com passo um, juntando com passo dois

0:25:13.949,0:25:17.178
E assim o passo geral é quatro, certo?

0:25:18.719,0:25:22.788
E assim, para obter uma nova saída, você precisa deslocar a janela de entrada em quatro

0:25:24.210,0:25:29.509
para obter um desses por causa das duas camadas de pool com ...

0:25:31.170,0:25:35.480
Talvez eu devesse ser um pouco mais explícito sobre isso. Deixe-me desenhar uma imagem, isso seria mais claro

0:25:39.929,0:25:43.848
Então você tem uma entrada

0:25:49.110,0:25:53.749
assim... uma convolução, digamos uma convolução de tamanho três

0:25:57.420,0:25:59.420
OK? Sim com passo um

0:26:01.289,0:26:04.518
Ok, eu não vou desenhar todos eles, então você tem

0:26:05.460,0:26:11.389
agrupando com subamostragem de tamanho dois, então você agrupa mais de 2 e subamostra, o passo é 2, então você muda por dois

0:26:12.389,0:26:14.389
Sem sobreposição

0:26:18.550,0:26:25.060
Ok, então aqui a entrada é deste tamanho -- um dois, três, quatro, cinco, seis, sete, oito

0:26:26.150,0:26:29.049
porque a convolução é de tamanho três, você obtém

0:26:29.840,0:26:31.840
uma saída aqui de tamanho seis e

0:26:32.030,0:26:39.010
então quando você faz o agrupamento com subamostragem com passo dois, você obtém três saídas porque isso divide a saída por dois, ok?

0:26:39.880,0:26:41.880
Deixe-me adicionar outro

0:26:43.130,0:26:45.130
Na verdade dois

0:26:46.790,0:26:48.790
Ok, então agora a saída é dez

0:26:50.030,0:26:51.680
Esse cara tem oito

0:26:51.680,0:26:53.680
Esse cara tem quatro

0:26:54.260,0:26:56.409
Eu posso fazer convoluções agora também

0:26:57.650,0:26:59.650
Digamos três

0:27:01.400,0:27:03.400
só tenho duas saídas

0:27:04.490,0:27:06.490
OK? Ops!

0:27:07.040,0:27:10.820
Hmm não tenho certeza porque não... desenha

0:27:10.820,0:27:13.270
Não quer mais desenhar, isso é interessante

0:27:17.060,0:27:19.060
Ah!

0:27:24.110,0:27:26.380
Ele não reage a cliques, isso é interessante

0:27:34.460,0:27:39.609
Ok, não tenho certeza do que está acontecendo! Oh "xournal" não está respondendo

0:27:41.750,0:27:44.320
Tudo bem, acho que caiu em mim

0:27:46.550,0:27:48.550
Bem, isso é irritante

0:27:53.150,0:27:55.150
Sim, definitivamente caiu

0:28:02.150,0:28:04.150
E, claro, ele esqueceu, então...

0:28:09.860,0:28:12.760
Ok, então temos dez, então oito

0:28:15.230,0:28:20.470
por causa da convolução com três, então temos o agrupamento

0:28:22.520,0:28:24.520
tamanho dois com

0:28:26.120,0:28:28.120
passo dois, então temos quatro

0:28:30.350,0:28:36.970
Então temos convolução com três, então temos dois, ok? E então talvez juntando novamente

0:28:38.450,0:28:42.700
de tamanho dois e subamostrando dois, obtemos um. OK, então...

0:28:44.450,0:28:46.869
dez entradas, oito

0:28:49.370,0:28:53.079
quatro, dois e...

0:28:58.010,0:29:03.339
então um para o pooling. Esta é a convolução três, você está certo

0:29:06.500,0:29:08.500
Isso é dois

0:29:09.140,0:29:11.140
E esses são três

0:29:12.080,0:29:14.080
etc. Certo. Agora, vamos supor

0:29:14.540,0:29:17.860
Eu adiciono algumas unidades aqui

0:29:18.110,0:29:21.010
OK? Então isso vai adicionar, digamos

0:29:21.890,0:29:24.160
quatro unidades aqui, duas unidades aqui

0:29:27.620,0:29:29.620
Então...

0:29:41.190,0:29:42.840
Sim, este é

0:29:42.840,0:29:46.279
assim e assim, então eu tenho quatro e

0:29:47.010,0:29:48.960
tenho outro aqui

0:29:48.960,0:29:52.460
OK? Então agora eu tenho apenas uma saída e adicionando quatro

0:29:53.640,0:29:55.640
quatro entradas aqui

0:29:55.830,0:29:58.249
que não é 14. Eu tenho duas saídas

0:29:59.790,0:30:02.090
Por que quatro? Porque eu tenho 2

0:30:02.970,0:30:04.830
passo de 2

0:30:04.830,0:30:10.939
OK? Portanto, a proporção geral de subamostragem da entrada para a saída é 4, é 2 vezes 2

0:30:13.140,0:30:17.540
Agora isso é 12, e isso é 6, e isso é 4

0:30:20.010,0:30:22.010
Então isso é um...

0:30:22.620,0:30:24.620
demonstração do fato de que

0:30:24.900,0:30:26.900
você pode aumentar o tamanho da entrada

0:30:26.900,0:30:32.330
aumentará o tamanho de cada camada, e se você tiver uma camada com tamanho 1 e for uma camada convolucional

0:30:32.330,0:30:34.330
seu tamanho vai aumentar

0:30:42.870,0:30:44.870
sim

0:30:47.250,0:30:52.760
Alterar o tamanho de uma camada, tipo, verticalmente, horizontalmente? Sim, então vai ter...

0:30:54.390,0:30:57.950
Então, primeiro você tem que treinar para isso, se você quer que o sistema tenha tanta invariância de tamanho

0:30:58.230,0:31:03.860
você tem que treiná-lo com personagens de vários tamanhos. Você pode fazer isso com aumento de dados se seus personagens forem normalizados

0:31:04.740,0:31:06.740
Essa é a primeira coisa. Segunda coisa é...

0:31:08.850,0:31:16.579
redes convolucionais empiricamente simples são apenas invariantes ao tamanho dentro de um fator de... fator bastante pequeno, como você pode aumentar o tamanho por

0:31:17.610,0:31:23.599
talvez 40 por cento ou algo assim. Quero dizer, mude o tamanho cerca de 40% mais/menos 20%, algo assim, certo?

0:31:26.250,0:31:28.250
Além disso...

0:31:28.770,0:31:33.830
você pode ter mais problemas para obter invariância, mas as pessoas treinaram com entrada ...

0:31:33.980,0:31:38.390
Quero dizer objetos de tamanhos que variam muito. Então, a maneira de lidar com isso é

0:31:39.750,0:31:46.430
se você quiser lidar com tamanho variável, é que se você tem uma imagem e não sabe o tamanho dos objetos

0:31:46.950,0:31:50.539
que estão nesta imagem, você aplica sua rede convolucional a essa imagem e

0:31:51.180,0:31:53.979
então você pega a mesma imagem, reduz por um fator de dois

0:31:54.440,0:31:58.179
apenas dimensione a imagem por um fator de dois, execute a mesma rede convolucional nessa nova imagem e

0:31:59.119,0:32:02.949
em seguida, reduza-o por um fator de dois novamente e execute a mesma rede convolucional novamente nessa imagem

0:32:03.800,0:32:08.110
OK? Assim, a primeira rede convolucional será capaz de detectar pequenos objetos dentro da imagem

0:32:08.630,0:32:11.859
Então, digamos que sua rede foi treinada para detectar objetos de tamanho...

0:32:11.860,0:32:16.179
Eu não sei, 20 pixels, como rostos por exemplo, certo? São 20 pixels

0:32:16.789,0:32:20.739
Ele detectará rostos com aproximadamente 20 pixels nesta imagem e

0:32:21.320,0:32:24.309
então, quando você subamostra por um fator de 2 e aplica a mesma rede

0:32:24.309,0:32:31.209
ele detectará rostos com 20 pixels na nova imagem, o que significa que havia 40 pixels na imagem original

0:32:32.179,0:32:37.899
OK? Que a primeira rede não verá porque o rosto seria maior que sua janela de entrada

0:32:39.170,0:32:41.529
E então a próxima rede detectará

0:32:42.139,0:32:44.409
rostos de 80 pixels, etc., certo?

0:32:44.659,0:32:49.089
Então, combinando as pontuações de todos esses, e fazendo algo chamado supressão não máxima

0:32:49.090,0:32:51.090
podemos realmente fazer a detecção e

0:32:51.230,0:32:57.939
localização de objetos. As pessoas usam técnicas consideravelmente mais sofisticadas para detecção agora e para localização, sobre as quais falaremos na próxima semana

0:32:58.429,0:33:00.429
Mas essa é a ideia básica

0:33:00.920,0:33:02.920
Então deixe-me concluir

0:33:03.019,0:33:09.429
Para que servem os convnets? Eles são bons para sinais que chegam até você na forma de uma matriz multidimensional

0:33:10.190,0:33:12.190
Mas essa matriz multidimensional tem

0:33:13.190,0:33:17.500
ter pelo menos duas características. O primeiro é

0:33:18.469,0:33:23.828
há fortes correlações locais entre os valores. Então, se você tirar uma imagem

0:33:24.949,0:33:32.949
imagem aleatória, pegue dois pixels dentro desta imagem, dois pixels que estão próximos. Esses dois pixels provavelmente terão cores muito semelhantes

0:33:33.530,0:33:38.199
Tire uma foto dessa aula, por exemplo, dois pixels na parede têm basicamente a mesma cor

0:33:39.469,0:33:42.069
OK? Parece que há uma tonelada de objetos aqui, mas

0:33:43.280,0:33:49.509
--animar objetos-- mas na verdade principalmente, estatisticamente, os pixels vizinhos são essencialmente da mesma cor

0:33:52.699,0:34:00.129
À medida que você move a distância de dois pixels de distância e calcula as estatísticas de quão semelhantes os pixels são em função da distância

0:34:00.650,0:34:02.650
são cada vez menos parecidos

0:34:03.079,0:34:05.079
Então, o que isso significa? Porque

0:34:06.350,0:34:09.430
pixels próximos provavelmente terão cores semelhantes

0:34:09.560,0:34:14.499
isso significa que quando você pega um pedaço de pixels, digamos cinco por cinco, ou oito por oito ou algo assim

0:34:16.040,0:34:18.040
O tipo de patch que você vai observar

0:34:18.920,0:34:21.159
é muito provável que seja uma espécie de variação suave

0:34:21.830,0:34:23.830
cor ou talvez com uma borda

0:34:24.770,0:34:32.080
Mas entre todas as combinações possíveis de 25 pixels, as que você realmente observa em imagens naturais é um pequeno subconjunto

0:34:34.130,0:34:38.380
O que isso significa é que é vantajoso representar o conteúdo desse patch

0:34:39.440,0:34:46.509
por um vetor com talvez menos de 25 valores que representam o conteúdo desse patch. Existe uma borda, é uniforme?

0:34:46.690,0:34:48.520
Que cor é essa? Você sabe coisas assim, certo?

0:34:48.520,0:34:52.660
E é basicamente isso que as convoluções na primeira camada de uma rede convolucional estão fazendo

0:34:53.900,0:34:58.809
OK. Portanto, se você tiver correlações locais, há uma vantagem em detectar recursos locais

0:34:59.090,0:35:01.659
Isso é o que observamos no cérebro. Isso é o que as redes convolucionais estão fazendo

0:35:03.140,0:35:08.140
Essa ideia de localidade. Se você alimentar uma rede convolucional com pixels permutados

0:35:09.020,0:35:15.070
não será capaz de fazer um bom trabalho em reconhecer suas imagens, mesmo que a permutação seja fixa

0:35:17.030,0:35:19.960
Certo? Uma rede totalmente conectada não se importa

0:35:21.410,0:35:23.410
sobre permutações

0:35:25.700,0:35:28.240
Então a segunda característica é que

0:35:30.050,0:35:34.869
recursos importantes podem aparecer em qualquer lugar da imagem. Então é isso que justifica pesos compartilhados

0:35:35.630,0:35:38.499
OK? A correlação local justifica conexões locais

0:35:39.560,0:35:46.570
O fato de que os recursos podem aparecer em qualquer lugar, que as estatísticas das imagens ou o sinal são uniformes

0:35:47.810,0:35:52.030
significa que você precisa ter detectores de recursos repetidos para cada local

0:35:52.850,0:35:54.850
E é aí que pesos compartilhados

0:35:55.880,0:35:57.880
entre no jogo

0:36:01.990,0:36:06.059
Isso justifica o pooling porque o pooling é se você quiser que a invariância

0:36:06.760,0:36:11.400
variações na localização dessas feições características. E se os objetos que você está tentando reconhecer

0:36:12.340,0:36:16.619
não mude sua natureza meio que distorcida, então você quer agrupar

0:36:21.160,0:36:24.360
Então, as pessoas usaram convnets para coisas de câncer, vídeo de imagem

0:36:25.660,0:36:31.019
texto, fala. Então a fala é realmente bonita... as redes de reconhecimento de fala são muito usadas

0:36:32.260,0:36:34.380
Previsão de séries temporais, você sabe coisas assim

0:36:36.220,0:36:42.030
E você conhece a análise de imagens biomédicas, então se você quiser analisar uma ressonância magnética, por exemplo

0:36:42.030,0:36:44.030
A ressonância magnética ou tomografia computadorizada é uma imagem 3d

0:36:44.950,0:36:49.170
Como humanos, não podemos porque não temos uma boa tecnologia de visualização. Nós não podemos realmente

0:36:49.960,0:36:54.960
apreender ou compreender um volume 3D, uma imagem tridimensional

0:36:55.090,0:36:58.709
Mas um convnet está bem, alimente-o com uma imagem 3d e ele lidará com isso

0:36:59.530,0:37:02.729
Isso é uma grande vantagem porque você não precisa passar por fatias para descobrir

0:37:04.000,0:37:06.030
o objeto na imagem

0:37:10.390,0:37:15.300
E a última coisa aqui embaixo, não sei se vocês sabem onde estão as imagens hiperespectrais

0:37:15.300,0:37:19.139
Então, a imagem hiperespectral é uma imagem onde... a maioria das imagens de cores naturais

0:37:19.140,0:37:22.619
Quero dizer, imagens que você coleta com uma câmera normal, você obtém três componentes de cores

0:37:23.470,0:37:25.390
RGB

0:37:25.390,0:37:28.019
Mas podemos construir câmeras com muito mais

0:37:28.660,0:37:30.660
bandas espectrais do que isso e

0:37:31.510,0:37:34.709
esse é particularmente o caso de imagens de satélite, onde alguns

0:37:36.160,0:37:40.920
câmeras têm muitas bandas espectrais indo do infravermelho ao ultravioleta e

0:37:41.890,0:37:44.610
que fornece muitas informações sobre o que você vê em cada pixel

0:37:45.760,0:37:47.040
Alguns pequenos animais

0:37:47.040,0:37:54.930
que têm cérebros pequenos acham mais fácil processar imagens hiperespectrais de baixa resolução do que imagens de alta resolução com apenas três cores

0:37:55.750,0:38:00.450
Por exemplo, há um tipo específico de camarão, certo? Eles têm aqueles lindos

0:38:01.630,0:38:07.499
olhos e eles têm tipo 17 bandas espectrais ou algo assim, mas resolução super baixa e eles têm um cérebro minúsculo para processá-lo

0:38:09.770,0:38:12.850
Ok, isso é tudo por hoje. Vê você!