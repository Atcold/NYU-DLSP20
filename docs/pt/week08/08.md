---
lang-ref: ch.08
title: Semana 8
lang: pt
translation-date: 28 March 2022
translator: Diogo Santiago
---

## Curso - parte A

Nesta seção, focamos na introdução de métodos contrastantes em modelos baseados em energia (Energy-Based) em diversos aspectos. Primeiro, discutimos as vantagens em aplicar métodos contrastantes em aprendizado auto-supervisionado. Segundo, nós discutimos a arquitetura de autoencoders de remoção de ruídos e suas fraquezas nas tarefas de reconstrução de imagem. Falamos também sobre outros métodos contrastantes, como a divergência contrastante e a divergência contrastante persistente.

## Curso - parte B

Nesta primeira seção, discutimos variáveis latentes regularizadas EBMs em detalhes cobrindo conceitos das versões condicional e incondicional deste modelo. Nós então discutimos os algorítmos ISTA, FISTA e LISTA e vemos exemplos de códigos esparsos e filtros aprendidos pelos encoders convolucionais esparsos. Finalmente falamos sobre Autoencoders Variacionais e diversos detalhes envolvidos.

## Prática

Nesta seção, discutimos um tipo específico de modelo generativo chamado Autoencoder Variacional e comparamos suas funcionalidades e vantagens quanto aos Autoencoders clássicos. Nós exploramos a função objetivo de um VAE (Variational Auto Encode) em detalhes, entendendo como ele suporta certa estrutura no espaço latente. Finalmente, implementamos e treinamos um VAE no dataset MNIST e o utilizamos para gerar novas amostras.