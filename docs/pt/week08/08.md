---
lang-ref: ch.08
title: Semana 8
lang: pt
translation-date: 28 March 2022
translator: Diogo Santiago
---

## Curso - parte A

Nesta seção, nós focamos na introdução de métodos contrastante em modelos baseados em energia(Energy-Based) em diversos aspectos. Primeiro, discutimos as vantagens em aplicar métodos contrastantes em aprendizado auto-supervisionado. Segundo, nós discutimos a arquitetura de autoencoders de remoção de ruídos e suas fraquezas nas tarefas de reconstrução de imagem. Nós também falaomos sobre outros métodos contrastantes, como a divergência contrastante e a persistente divergência contrastante.

## Curso - parte B

Nesta primeira seção, nós discutímos variáveis latentes regularizadas EBMs em detalhes cobrindo conceitos das versões condicional e incondicional deste modelo. Nós então discutímos os algorítmos de ISTA, FISTA e LISTA e vimos exemplos de códigos esparsos e filtros aprendidos pelos encodes convolucionais esparsos. Finalmente nós falamos sobre Auto-Encoders Variacionais e diversos detalhes envolvidos.

## Prática

Nesta seção, nós discutímos um tipo específico de modelo generativo chamado Autoencoder Variacional e comparamos suas funcionalidades e vantagens aos Autoencoders clássicos. Nós exploramos a função objetivo de um VAE(Variational Auto Encode) em detalhes, entendendo como ele supoerta certa estrutura no espaço latente. Finalmente, nós implementamos e treinamos um VAE no dataset MNIST e o utilizamos para gerar novas amostras.