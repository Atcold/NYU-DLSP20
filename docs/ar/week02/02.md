---
lang: ar
lang-ref: ch.02
title: أسبوع 2
---

<!--
## Lecture part A

We start by understanding what parametrised models are and then discuss what a loss function is. We then look at Gradient-based methods and how it's used in the backpropagation algorithm in a traditional neural network. We conclude this section by learning how to implement a neural network in PyTorch followed by a discussion on a more generalized form of backpropagation.
-->

## الجزء أ من المحاضرة

 سنبدأ بفهم ما هي `النماذج ذات العوامل` ثم سنناقش ما هي `دالة الفرق`. بعد ذلك سننظر في الخوارزميات القائمة علي `الإنحدار` وطريقة إستخدامها في خوارزمية `الانتشار الخلفي` علي `شبكة عصبية` تقليدية.
 ثم سننهي هذا الجزئ بتعلم طريقة تنفيذ شبكة عصبية من خلال __ ثم مناقشة .ضيغة اخري من `الانتشار الخلفي` اكثر شمولا من السابقة

<!--
## Lecture part B

We begin with a concrete example of backpropagation and discuss the dimensions of Jacobian matrices. We then look at various basic neural net modules and compute their gradients, followed by a brief discussion on softmax and logsoftmax. The other topic of discussion in this part is Practical Tricks for backpropagation.
-->

## الجزء ب من المحاضرة
سنبدأ بمثال واقعي ل `الانتشار الخلفي` ونناقش ابعاد `مصفوفات جاكوب`. ثم سننظر في عدة أشكال من الشبكات العصبية ونقوم بحساب الانحدار الخاص بهم. ونتابع بمناقشة حول دوال `سوفت-ماكس` و `لوج-ماكس` .  واخيرا نناقش طرق اكثر عملية لحساب `اللإنتشار الخلفي`

<!--
## Practicum

We give a brief introduction to supervised learning using artificial neural networks. We expound on the problem formulation and conventions of data used to train these networks. We also discuss how to train a neural network for multi class classification, and how to perform inference once the network is trained.
-->

## التدريب العملي
سوف نعطي مقدمة موجزة عن `التعليم بالأمثلة` بإستخدام `الشبكات العصبية االإصطناعية` . سنقوم بشرح صياغة المشكلة وصيغ البيانات المتعارف عليها  لتدريب تلك الشبكات. سنناقش ايضا طريقة تدريب تلك الشبكات العصبية لإستخدامها في `التصنيف المتعدد`. وكيفية استخدام هذه الشبكات `للتنبؤ` بعدما يتم `تدريبها`

## مصطلحات
|Parametrised models| النماذج ذات العوامل |
|--|--:|
| loss function | دالة الفرق |
| Gradient | الإنحدار |
|backpropagation|الانتشار الخلفي|
|neural network| شبكة عصبية |
|Jacobian matrices|مصفوفات جاكوب|
| softmax | سوفت-ماكس |
| logsoftmax |  لوج-ماكس|
|supervised learning|التعليم بالأمثلة|
| multi class classification | التصنيف المتعدد |
|inference|التنبؤ|
| training| التدريب |


