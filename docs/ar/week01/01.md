---
lang: ar
lang-ref: ch.01
title: الأسبوع الأول
translation-date: 21 Aug 2020
Translator: Anass Elhoud
---

  
## الجزء الأول من المحاضرة

<!-- We discuss the motivation behind deep learning. We begin with the history and inspiration of deep learning. Then we discuss the history of pattern recognition and introduce gradient descent and its computation by backpropagation. Finally, we discuss the hierarchical representation of the visual cortex.
-->

في هذا الجزء سناقش الدافع وراء التعلم العميق ابتداءً بتاريخ التعلم العميق وإلهامه. كما سنناقش تاريخ التعرف على الأنماط (pattern recognition)، وسنستعرض مقدمة عن خوارزمية الانحدار التدريجي (gradient descent)، وطريقة حسابه عن طريق الإنتشار الخلفي (backpropagation). أخيرًا، سنناقش التمثيل الهرمي للقشرة البصرية.

## الجزء الثاني من المحاضرة

<!--We first discuss the evolution of CNNs, from Fukushima to LeCun to AlexNet. We then discuss some applications of CNN's, such as image segmentation, autonomous vehicles, and medical image analysis. We discuss the hierarchical nature of deep networks and the attributes of deep networks that make them advantageous. We conclude with a discussion of generating and learning features/representations.
-->
في البداية، سنناقش تطور الـ CNN من Fukushima إلى LeCun ثم AlexNet. ثم سنناقش بعدها بعض تطبيقات الشبكات العصبية الالتفافية، مثل تجزئة الصور (image segmentation)، السيارات ذاتية القيادة، وتحليل الصور الطبية. سنذكر أيضًا الطبيعة الهرمية للشبكات العميقة وسماتها التي تجعلها مفيدة. وسننهي هذا الجزء بمناقشة حول إنشاء وتعلم الخواص/التمثيلات.


## التدريب العلمي

<!-- We discuss the motivation for applying transformations to data points visualized in space. We talk about Linear Algebra and the application of linear and non-linear transformations. We discuss the use of visualization to understand the function and effects of these transformations. We walk through examples in a Jupyter Notebook and conclude with a discussion of functions represented by neural networks.
-->

سنناقش الدافع وراء تحويل نقاط البيانات المرئية في الفضاء. سنتحدث عن الجبر الخطي وتطبيق التحويلات الخطية وغير الخطية. كما سنناقش استخدام تصوير البيانات لفهم وظيفة وتأثيرات هذه التحويلات. سنطرح بعض الأمثلة في Jupyter Notebook ونختتم بمناقشة بعض المعادلات التي يمكن تمثيلها باستخدام الشبكات العصبية.
