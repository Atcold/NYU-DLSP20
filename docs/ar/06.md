---
lang-ref: ch.06
title: أسبوع 06
translation date: 1 Sep 2020
translator: Ali elfilali
---

## **الجزء اﻷول من المحاضرة**

ناقشنا ثلاثة تطبيقات للشبكات العصبية الالتفافية. بدأنا بالتعرف على الأرقام وتطبيقها على تحديد الرمز البريدي المكون من 5 أرقام. في تحديد الأهداف (الكائنات)، نتحدث عن كيفية استخدام بنية متعددة المقاييس في إعدادات خوارزمية تحديد الوجه. أخيرًا ، رأينا كيف يتم استخدام الشبكات العصبية الالتفافية  في مهام التجزئة الدلالية مع أمثلة ملموسة في نظام الرؤية الروبوتية وتجزئة الكائن في بيئة مدنية.

## **الجزء الثاني من المحاضرة**

ندرس الشبكات العصبية المتكررة ، مشاكلها والتقنيات الشائعة للتخفيف من هذه المشكلات. نراجع بعد ذلك مجموعة متنوعة من الوحدات التي تم تطويرها لحل مشكلات نموذج الشبكات العصبية المتكررة بانتباه شديد.
و وحدات GRU (وحدة البوابات المتكررة) ، و LSTM (الذاكرة قصيرة المدى المطولة) ، و Seq2Seq.



## تطبيق عملي

ناقشنا هندسة خوارزميات "Vanilla RNN" و LSTM و قارننا الأداء بينهما. ترث LSTM مزايا RNN ، مع تحسين نقاط ضعف RNN من خلال تضمين "خلية ذاكرة" لتخزين المعلومات في الذاكرة لفترات طويلة من الزمن. تتفوق نماذج LSTM بشكل كبير على نماذج RNN.
