---
lang-ref: ch.14
lang: ar
title: الأسبوع 14
translation-date: 13 Sep 2020
translator: Ali elfilali
---


## **الجزء اﻷول من المحاضرة**

في هذا القسم ، ناقشنا التنبؤ المنظم. قدمنا لأول مرة الرسم البياني للعامل القائم على الطاقة والاستدلال الفعال له. ثم قدمنا بعض الأمثلة لرسوم بيانية بسيطة تعتمد على الطاقة بعوامل "ضحلة".  أخيرًا، ناقشنا شبكات المحولات الرسومية (Graph Transformer Net).



## **الجزء الثاني من المحاضرة**

يناقش الجزء الثاني من المحاضرة بشكل أكبر تطبيق أساليب النماذج الرسومية على النماذج القائمة على الطاقة. بعد قضاء بعض الوقت في مقارنة دوال الخسارة المختلفة، نناقش تطبيق خوارزمية Viterbi و خوارزمية إعادة التوجيه إلى شبكات المحولات الرسومية (GTN). ننتقل بعد ذلك إلى مناقشة صياغة لاغرانج للانتشار العكسي ثم الاستدلال المتغير للنماذج القائمة على الطاقة.




## تطبيق عملي

عند تدريب نماذج ذات معلمات (parameters) كثيرة مثل الشبكات العصبية العميقة ، هناك دائما خطر فرط التخصيص (overfitting) لبيانات التدريب. هذا يؤدي إلى خطأ أكبر في التعميم. للمساعدة في تقليل فرط التخصيص، يمكننا إدخال الضبط (regularization) في تدريبنا، مما يؤدي إلى عدم تشجيع حلول معينة لتقليل ملاءمة نماذجنا للضوضاء.

