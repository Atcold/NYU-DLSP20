0:00:01.479,0:00:06.028
Thank you for being here on time I will have only 50 minutes today, so we are going to be trying to

0:00:06.730,0:00:12.599
Squeeze as much as I can without running too much. So there's gonna be like a small agreement between me and you

0:00:13.179,0:00:18.448
every time we start class so the agreement is the following I'm here for

0:00:19.449,0:00:26.848
Trying to communicate to you right so I'm here because I'd like to send a message across every time you don't have

0:00:28.000,0:00:32.549
Idea, what's going on? You think I'm confusing you cannot understand my

0:00:33.130,0:00:38.729
English you know, I have a very strong Italian accent, you know "mamma mia!". No, okay

0:00:39.160,0:00:42.750
Yeah, I make jokes, so don't take every word I say

0:00:43.420,0:00:44.829
as

0:00:44.829,0:00:47.369
Truthful if I'm talking about, you know

0:00:48.399,0:00:52.198
You know being aggressive or whatever. I'm joking. Most likely

0:00:53.079,0:00:57.089
If I'm talking about, you know deep networks and stuff. Usually it's reliable

0:00:58.059,0:01:00.059
Yeah

0:01:00.699,0:01:06.209
Okay, so the point is gonna be like every time you have no idea what's going on just stop me call me:

0:01:06.210,0:01:11.849
"Alf! I've no whatever idea was going on here. Stop, repeat, explain to me again"

0:01:11.890,0:01:15.360
I will explain to you as many times it's required

0:01:16.090,0:01:19.770
If you do not understand something it's almost

0:01:21.580,0:01:28.619
99.9% my fault because I haven't taken an account your background and you know, I'm skipping some steps perhaps because I'm not used to

0:01:29.320,0:01:32.309
You know, maybe this class or your background or whatsoever

0:01:32.590,0:01:40.079
So again, I'm here in order to educate in order to communicate and I can't do that if you don't help me, right?

0:01:40.080,0:01:43.660
So if I ask a question and you understand what I'm saying,

0:01:43.740,0:01:47.820
you should like nod your head because if you're like ...

0:01:48.760,0:01:52.350
Yeah not reacting to my jokes or questions

0:01:52.350,0:01:57.269
Then I have some issues understanding whether you are making any sense of what I'm saying

0:01:58.000,0:02:00.509
If you get distracted, I will try to

0:02:01.240,0:02:04.979
usually I throw chalks. We don't have a chalk here, right?

0:02:06.249,0:02:08.249
I think I can try with markers but

0:02:08.899,0:02:10.899
Maybe not right?

0:02:10.910,0:02:12.910
Just for an undergraduates

0:02:13.160,0:02:17.439
You're grownups. So you should be able to you know, keep yourself awake for the next

0:02:18.049,0:02:22.359
45 minutes more or less do not turn off because if you turn off

0:02:22.670,0:02:28.509
I can't come there and take you and shake you right again. You're not undergraduates anymore. You're grownups

0:02:28.879,0:02:30.999
Some of you are undergraduates, I guess so

0:02:31.670,0:02:34.839
Okay, I figure out where you are if I may come and shake you up

0:02:34.840,0:02:40.599
But for the others you should be able to stay awake for the next 50 minutes. I know it's like late night

0:02:41.020,0:02:44.580
so try not to eat before class so you don't have like *snore*

0:02:44.680,0:02:46.680
You know after dinner

0:02:47.390,0:02:49.539
thingy, whatever so

0:02:52.160,0:02:54.849
Yeah, so don't take me too seriously I'm Italian

0:02:56.510,0:03:00.940
Right so so so inspirational like why are we here?

0:03:01.849,0:03:07.328
To take an A maybe so it's a competitive class right at the end. We're gonna have a competition

0:03:08.720,0:03:12.190
Don't get too scared. We do not only

0:03:13.519,0:03:18.399
Like consider how you're doing well in the final ranking. We also consider,

0:03:19.069,0:03:24.069
How well is your work? Right so sometimes things don't quite work, but you still apply yourselves

0:03:24.069,0:03:28.358
So that's actually what matters nevertheless if you actually win the challenge you may have some

0:03:29.030,0:03:31.569
gifts and presents and something from us

0:03:34.069,0:03:36.069
Yep, that should be it

0:03:36.260,0:03:39.340
also, if you take a very nice grade, you may come and

0:03:40.340,0:03:44.919
you know join the lab perhaps with Yann and so on next semester, so

0:03:45.799,0:03:53.229
Just saying, you know take a nice grade so you can serve later as well. Okay. All right kind of joking

0:03:54.169,0:03:59.349
So neural networks, right? Did we see last time yesterday what neural networks are kind of know?

0:03:59.900,0:04:02.410
So I think we mentioned a few

0:04:02.989,0:04:05.798
applications one of those were classifications

0:04:06.019,0:04:12.939
So let me just give you a small recap about what classification is. So what is classification?

0:04:14.180,0:04:17.889
Let's say I take a picture of these of something right? Let's say I take a picture

0:04:18.519,0:04:21.219
if it is a one megapixel camera

0:04:21.739,0:04:28.568
So how many dimension will be my image? So if I take an image, I can consider my image which is gonna have

0:04:29.389,0:04:32.559
RGB plane and it's gonna be heavy like a thousand

0:04:32.750,0:04:38.229
Pixel in the vertical and one thousand pixels horizontally so you're gonna have overall 1 million pixels

0:04:38.229,0:04:43.658
So one megapixel you have RGB. So how many pixels how many values will you have?

0:04:45.889,0:04:46.840
3 million, right?

0:04:46.840,0:04:47.319
Ok, cool

0:04:47.319,0:04:54.848
So you can think about this image which can be thought as this kind of stack of three layers is one point

0:04:55.280,0:05:02.169
Living in this 3 million dimensional space and this 3 million dimensional space is really really really really large

0:05:02.169,0:05:04.329
right, you can move around and

0:05:05.659,0:05:11.049
Nothing happens, right? So let's say I take a picture of a dog and I have here a picture of a dog (rises right hand)

0:05:11.419,0:05:13.419
Let's say I take a picture of a cat

0:05:14.180,0:05:17.799
Where is gonna be a picture of a cat: here, here, or here (points far away, closer and next to right hand)

0:05:19.009,0:05:20.210
Sorry

0:05:20.210,0:05:26.049
Ok hands up for whose thinks, if this is my cat or dog

0:05:26.419,0:05:29.468
Who thinks the other one is here? (far away)

0:05:31.219,0:05:32.419
Ok

0:05:32.419,0:05:38.559
Maybe you were actually paying attention yesterday who were thinking who thinks the other point is gonna be here (closer). Okay

0:05:39.710,0:05:41.769
Who thinks the other point is gonna be here? (right next to each other)

0:05:43.069,0:05:45.069
Fantastic, ok, so you actually on the right?

0:05:45.500,0:05:49.659
So everything is just in the same damn little spot in the space (closes hand)

0:05:49.659,0:05:55.959
Ok and everything everything it actually makes sense is here. Everything else is just trash and so

0:05:56.539,0:06:01.449
We have to take the space go here take this point and move it here. How do you move point?

0:06:02.599,0:06:04.599
Have you taken linear algebra?

0:06:05.900,0:06:07.729
Yes, no

0:06:07.729,0:06:09.729
Ok about linear algebra

0:06:09.740,0:06:15.069
so as you may know or if you don't, now you do I do have Twitter and

0:06:15.680,0:06:18.310
I'm very annoying person on Twitter because I talk a lot

0:06:19.009,0:06:22.598
So, let's see Twitter. Ok open Twitter

0:06:23.479,0:06:25.279
all right, so

0:06:25.279,0:06:27.309
Here I cannot zoom so

0:06:27.860,0:06:29.770
twitter.com right

0:06:29.770,0:06:34.439
So then you go. Oh, there is no internet. See ha. Let's connect Wi-Fi

0:06:35.590,0:06:37.590
Yes, I'm connecting

0:06:39.490,0:06:41.490
All right, almost there

0:06:44.460,0:06:52.040
Okay, so you want to do a search and you do a linear algebra

0:06:52.500,0:06:56.840
You cannot see anything here. Okay. Damn. Let me zoom here

0:06:58.080,0:07:03.420
Okay, so you go top right, there is the search so you do linear algebra

0:07:04.980,0:07:10.000
Then you do parenthesis from me: "alfcnz", okay

0:07:10.690,0:07:15.570
So here's how you find out what are the questions for the midterm? Right? Just check on Twitter

0:07:15.570,0:07:20.520
I usually yeah leak stuff there. All right. So here you have these

0:07:22.600,0:07:24.600
Actually is very nice, this book

0:07:24.640,0:07:30.809
Introduction to linear algebra by Gilbert Strang so you may want to you know, look up this stuff

0:07:30.810,0:07:32.530
But the other one is this one here

0:07:32.530,0:07:38.610
So you'd like to check the third tweet here where I show you the essence of linear algebra by Grant

0:07:39.550,0:07:44.669
Maybe you know this guy Grant Sanders if you don't know, well, you should know now

0:07:45.460,0:07:50.609
Just check this link, right and this link is going to show you how you move stuff around. Okay?

0:07:51.280,0:07:56.099
Anyhow, it was the first link for today. So how do you move things around in a space?

0:07:56.920,0:08:01.360
For the ones that actually know how linear algebra works

0:08:01.620,0:08:04.960
You just talk it down raise your hands

0:08:06.720,0:08:10.720
Huh, okay matrix multiplication what does it do?

0:08:10.840,0:08:13.020
rotation

0:08:14.160,0:08:18.860
Cant hear. Okay first matrix multiplication is a what kind of variation

0:08:19.860,0:08:23.700
Linear transformation. Okay, what are the linear transformation? one:

0:08:24.000,0:08:26.600
rotation, two:

0:08:29.980,0:08:31.980
You sure

0:08:32.260,0:08:34.830
Stretching okay. Fantastic then, third:

0:08:36.550,0:08:41.409
Stretching, scaling, I guess let's see scaling/stretching is number two, then

0:08:44.000,0:08:48.040
If the determinant is negative, what do you have

0:08:50.460,0:08:53.360
(Alf turn around, showing its back)

0:08:53.380,0:08:57.420
What is it? reflection, third and then one more

0:09:00.560,0:09:02.560
Is it

0:09:03.709,0:09:06.879
Okay, I guess we have three for the moment this should be one more

0:09:06.880,0:09:11.919
Hold on so scaling right? So you have scaling this way (vertical). You have scaling in that way (horizontal)

0:09:12.860,0:09:14.750
Then you have rotation

0:09:14.750,0:09:18.459
Then you have reflection if there when you have reflection

0:09:21.080,0:09:23.480
No no no, identity does nothing, right?

0:09:23.600,0:09:30.580
So okay rotation means the matrix is orthonormal, right? cool second one you have scaling

0:09:30.709,0:09:32.709
When do you have scaling?

0:09:34.459,0:09:35.839
Okay

0:09:35.839,0:09:37.630
Well, I wish you in fantastic

0:09:37.630,0:09:39.700
So we have at the four, right? So we have rotation

0:09:39.700,0:09:43.299
we have zoom in this way you have shearing, right? and then you have the

0:09:43.820,0:09:46.900
Reflection whenever you have the negative determinant

0:09:47.800,0:09:54.680
Cool still I want you to move things around is motion, translation a linear operation?

0:09:59.480,0:10:04.160
No, yes, you can answer you don't have to raise hands

0:10:05.740,0:10:08.780
Adding scalars is adding scaler a linear operation

0:10:10.850,0:10:12.529
Hmm not sure

0:10:12.529,0:10:19.509
Because 0 where is the 0 mapped to, right? only if the 0 is mapped to 0 then you have a linear transformation. Anyhow

0:10:19.510,0:10:24.760
So you have translation which is the fourth one and a fifth operation if you use affine transformations

0:10:24.760,0:10:30.879
So all those nice things you're gonna be fine them there. Ok. So check those things are very useful

0:10:31.130,0:10:35.469
Anyhow, so finally we figure out that if I have everything up here

0:10:35.750,0:10:40.989
We have cat, hippopotamus, dogs and whatever. I want to take them down. I want to

0:10:43.100,0:10:44.120
Translate

0:10:44.120,0:10:49.029
Right. Yes talk to me. No, you don't talk yet. Ok. All right

0:10:49.029,0:10:52.899
So we want to use translation and then you translate this in the 0

0:10:52.900,0:10:56.530
So you have all the things here then how do you separate those things apart?

0:10:59.260,0:11:01.660
So all of them are tall together, how can I (stretches space)

0:11:04.540,0:11:11.100
We mentioned what are the five different- four different transformation that a linear transformation does

0:11:11.740,0:11:14.260
Scaling right? How do you scale things with a

0:11:18.950,0:11:21.280
Diagonal matrix fantastic cool, right, so

0:11:22.310,0:11:29.020
Fantastic. So how do we diagonalize matrices? Ha that is the second question. You can figure out if you check Twitter

0:11:29.540,0:11:33.009
So we open a new page we go Twitter again

0:11:34.370,0:11:42.340
We go on top right should take a note about how to do this stuff. You do SVD parentheses from

0:11:43.610,0:11:50.349
"alfcnz". Okay, cool. Now you go if you go here is like or

0:11:51.680,0:11:57.400
SVD, so this is from also Gilbert, right? So you also like to check these on if you click here

0:11:57.400,0:12:00.999
It's gonna be more information about midterm right last year. Oh

0:12:01.670,0:12:06.039
Okay, you know too much now, okay. Anyhow, so you want to check this stuff out?

0:12:06.710,0:12:10.300
Anyhow, we'll figure out that by using matrices and scalars

0:12:10.300,0:12:17.859
You can move things around and then you can zoom right? And so again, I have things all collapsed here. I can't do anything

0:12:17.860,0:12:19.860
so I take it down with a

0:12:19.940,0:12:26.109
Translation, right? Yes, no? do like that with your head. No you following there?

0:12:27.260,0:12:29.470
Yes, no, okay, it's boring

0:12:30.260,0:12:31.870
No, okay

0:12:31.870,0:12:38.200
Alright, so you take this one, you put it down with translation and then you zoom it right with a matrix perhaps diagonal with some

0:12:38.720,0:12:41.319
Singular values right cool cool. Cool

0:12:42.190,0:12:48.100
And then what so I have this thing zoomed up though. So classification. What is it?

0:12:49.850,0:12:51.850
How do you perform classification now

0:12:56.240,0:12:59.770
You I'd like you'd like to assign labels, but how do you do that?

0:13:01.010,0:13:05.080
So whatever you would like to do is going to be basically moving these points in different regions

0:13:05.630,0:13:06.650
And then you slice them

0:13:06.650,0:13:09.769
Okay, and so this is gonna be part of the next class

0:13:09.769,0:13:12.540
And now I'm just showing you how a neural network does this?

0:13:13.520,0:13:17.020
I hope you're gonna be enjoying this video

0:13:17.660,0:13:20.360
If I find my cursor, okay

0:13:23.940,0:13:25.940
So

0:13:27.480,0:13:29.480
All right, so we start from here

0:13:29.940,0:13:37.340
Full screen, perhaps. All right, so can you see anything? No, how do you turn off the lights? Can someone figure out how to oh

0:13:38.130,0:13:40.130
maybe here

0:13:45.570,0:13:48.919
Yes, no good night, hold on

0:13:50.460,0:13:52.230
All right, good night

0:13:52.230,0:13:53.400
so

0:13:53.400,0:13:55.459
At least then I'd turn it back

0:13:55.460,0:14:02.179
so here we start with these five branches of a spiral and you can see that each point is gonna be basically

0:14:02.700,0:14:06.919
Represented as what how can you represent each of those points without the color?

0:14:10.350,0:14:12.440
Okay, where do these points live

0:14:13.710,0:14:19.549
On a 2d plane, right? So this is a 2d plane this screen here. So each of those points is represented as a

0:14:22.500,0:14:28.820
As a tuple, right, that is representing the X and the Y coordinate, then the color there represents a third dimension

0:14:29.400,0:14:30.960
Where it's going to be basically

0:14:30.960,0:14:36.169
Representing the class to which each of those points belong and here we have five different branches of a spiral

0:14:36.300,0:14:40.070
So this is the input to my network is going to be a bunch of points without

0:14:40.140,0:14:46.910
Colors and then I ask my network to separate the points by color. Okay. Is it clear? What is the task I ask my network?

0:14:48.000,0:14:52.640
You can not raise your hands because I cannot see sh*t, right? *laughs*

0:14:52.920,0:14:56.400
So you have to shout back because I don't see you

0:14:57.490,0:15:02.220
understand right what's going on here if sorry not right now, so we start with this guy here, which is

0:15:03.610,0:15:10.860
Just five branches of a spiral the network doesn't see the colors right now and the network will try to separate the colors apart. So

0:15:11.470,0:15:13.360
This is what my network does

0:15:13.360,0:15:20.130
It takes the space the space space fabric and it performs like a stretching of the space fabric, right?

0:15:20.130,0:15:22.169
how cool does that sound and

0:15:22.990,0:15:25.380
You should do like oh, oh

0:15:26.860,0:15:33.210
See, okay. Yeah, we had to do multiple iterations. I think here this is your first class. It's okay to be shy

0:15:33.820,0:15:35.160
Alright, so this is my network

0:15:35.160,0:15:42.330
Which is basically stretching the space fabric in order to get all those points that are belonging to the same color to the same class

0:15:42.340,0:15:47.009
To be in the same subspace of this final manifold such that

0:15:47.860,0:15:51.900
once we reach convergence, so whenever we reach at the end of this animation you

0:15:52.510,0:15:56.309
Have all your points that belongs to different spirals

0:15:58.660,0:16:00.660
Very separable

0:16:00.940,0:16:07.080
And so now you can just use logistic regression, right or like one versus all whatever regression is called

0:16:08.260,0:16:13.710
Yeah, I don't know. So I mean this is the last matrix is represented by that

0:16:14.470,0:16:22.260
That for five arrows there. So of those five arrows represent a matrix, which is how many rows how many columns

0:16:23.140,0:16:29.219
So what is my output dimension here of this network? What are we trying to infer in this case?

0:16:30.160,0:16:32.819
The classes how many classes do we have?

0:16:33.550,0:16:37.229
five, so the number of rows of this matrix will be

0:16:39.790,0:16:46.710
Five right because they are height of the matrix is they the same dimension where you shoot in two and the width of the matrix?

0:16:46.839,0:16:50.580
Represents the space where you're shooting from right?

0:16:50.580,0:16:53.920
And so what is going to be my width of this matrix?

0:16:54.400,0:16:55.620
Two, right?

0:16:55.620,0:16:58.000
so this matrix is going to be a five times two

0:16:58.000,0:17:01.900
because we are shooting towards five dimensions the five colors over here and then

0:17:01.940,0:17:04.760
And then we have two columns, right?

0:17:04.760,0:17:10.980
So it's gonna be basically the two coordinates of the tip of the arrow and those arrows are just centered in zero

0:17:10.980,0:17:13.940
We're going to talk about more about that intersection

0:17:13.940,0:17:21.540
I guess in later lessons if I actually may manage to make a video about that, but can you see that kind of cute?

0:17:22.340,0:17:24.340
intersection at the center

0:17:24.350,0:17:26.589
Have you ever seen that kind of intersection before?

0:17:28.670,0:17:30.670
Have you ever taken a bath?

0:17:32.540,0:17:38.800
I mean oh, yeah bubbles, right? So whenever you have multiple bubbles touching together, it looks like similar to that

0:17:38.800,0:17:41.840
Perhaps maybe not that I don't know. It looks to me

0:17:41.900,0:17:43.720
Alright, so that was the first Network

0:17:43.720,0:17:44.240
Okay

0:17:44.240,0:17:51.540
and this is how this network work these networks basically take the space fabric and then apply some kind of

0:17:51.860,0:17:57.340
Transformation which is still parametrized by matrices. So I have many many matrices

0:17:57.460,0:17:58.880
then I have

0:17:58.880,0:18:01.020
Nonlinearities, why do I need

0:18:01.100,0:18:08.380
Many matrices or why do I need nonlinearities? Can I turn on the light? Oh, you still like to watch? Okay

0:18:08.660,0:18:11.680
Yeah, otherwise you'll start sleeping

0:18:11.920,0:18:13.920
All right

0:18:14.240,0:18:15.890
So so

0:18:15.890,0:18:21.070
Here it basically this guy here is gonna be a network with two matrices my first matrix maps

0:18:21.260,0:18:23.980
My input which is living in which space?

0:18:25.760,0:18:29.710
Two dimensions to a intermediate layer of 100 dimensions

0:18:30.320,0:18:36.220
So my network architecture is the following so I have my two neurons here.

0:18:37.010,0:18:42.489
I map this one to, one two three, so on here, I have 100

0:18:44.000,0:18:46.000
Then I have some non-linearity

0:18:46.280,0:18:49.149
which is going to be just the positive part and

0:18:50.150,0:18:52.389
then from this guy here, I

0:18:52.910,0:18:54.500
Do something

0:18:54.500,0:18:58.720
Cute or funny or weird? I don't know it depends. So from here I map down to

0:18:59.720,0:19:04.959
Okay, what should I do after let's say this is this is my network. What's gonna be the last layer of this network?

0:19:06.280,0:19:10.860
5 right?, but how many dimension has this screen?

0:19:11.900,0:19:16.880
So, how can I plot there? and don't say PCA

0:19:18.780,0:19:20.780
So I do this one

0:19:24.840,0:19:26.840
Okay

0:19:30.630,0:19:34.340
Such that I can show you there the linear interpolation

0:19:34.340,0:19:37.280
between this point here, which I call embedding in this case

0:19:37.559,0:19:40.129
but just a way I call this stuff right now

0:19:45.020,0:19:47.400
and my input

0:19:51.120,0:19:53.120
Okay

0:19:54.150,0:19:57.949
Alright that's pretty much it so this is my neural network has

0:19:58.559,0:20:00.889
one input layer one hidden layer

0:20:01.500,0:20:08.209
One kind of embedding layer, which does nothing and the output layer. Okay, so it has one hidden and overall

0:20:08.210,0:20:13.970
I count this as three layer neural network, because it is one two, and then this stuff is linear, right?

0:20:14.100,0:20:16.280
so why do we need nonlinearities and

0:20:21.870,0:20:24.140
What can one layer-, okay, he said:

0:20:24.680,0:20:33.220
Without non-linearity it would look like a single layer neural network and a single layer neural network what can it do?

0:20:35.280,0:20:37.280
Scaling,

0:20:37.530,0:20:39.330
Translation,

0:20:39.330,0:20:41.330
Rotation,

0:20:42.030,0:20:44.030
Reflection, and?

0:20:45.200,0:20:51.900
I guess, shearing, right? Okay, so guess what's going to be the next part of this class?

0:20:53.840,0:20:59.680
Let's let's check how one one linear one network with one layer works. Okay questions so far

0:21:00.390,0:21:02.390
Also there in the yeah

0:21:04.650,0:21:10.909
For just displaying stuff on the screen more questions again, don't raise hands you can just talk to me

0:21:14.100,0:21:19.819
Can you hear me the over there is everything okay? Awesome. Alright. Thank you for approval

0:21:26.740,0:21:30.990
So these two points here represent the coordinates of my input points, right

0:21:30.990,0:21:34.559
So this is gonna be my x-coordinate and my y-coordinate of the input space

0:21:35.049,0:21:40.829
This one is going to be my x-coordinate and my y-coordinate of these embedding space which is linearly separable

0:21:42.520,0:21:44.579
Given that I have, you know, I am

0:21:45.100,0:21:52.960
Obtained 100% accuracy with the training we haven't talked about training yet, but does it make any sense the answer what I gave you?

0:21:53.700,0:21:55.700
Okay, yeah

0:22:00.840,0:22:09.040
So this is just a way to visualize five dimensions in two dimensions instead of doing a PCA, I just do a PCA

0:22:11.480,0:22:13.760
Hold on he hasn't finished

0:22:15.820,0:22:21.160
Because I'd like to see what the network output looks like in two dimensions, okay

0:22:24.960,0:22:31.500
Why is that true or is that false you see that next time it doesn't shrink because again those two

0:22:32.380,0:22:37.530
You can see multiply them together, right? It looks like one singular matrix one single matrix

0:22:39.309,0:22:41.309
And actually this works better

0:22:42.160,0:22:46.620
More about this later on in the class actually Yann is going to be talking about this

0:22:48.700,0:22:52.860
Okay, we still have some time all right, so how did I make these animations

0:22:54.700,0:22:56.700
First option: I'm a magician

0:22:57.460,0:23:02.309
Why you're laughing?, it's actually true. But anyhow, I know how to use matplotlib

0:23:03.130,0:23:06.959
I've taken this class three times and I never pass it

0:23:09.010,0:23:11.010
Okay, all of those are three

0:23:11.110,0:23:16.770
All the three are true. I never taken the class. But okay. I mean I've been on the other side

0:23:18.580,0:23:24.780
Yes, so this is not magic, right so this is just visualization using matplotlib free open source code and

0:23:25.600,0:23:27.870
and PyTorch, which is going to be our

0:23:28.960,0:23:31.500
library, which are going to be using for the

0:23:32.230,0:23:35.040
Right in these models. It's very it's very very convenient

0:23:35.710,0:23:40.680
was made by a student of mine back, I guess in 2016, so

0:23:42.010,0:23:48.119
You know be that cool. I'm just kidding. You can be even more cool. All right

0:23:49.420,0:23:51.420
more questions

0:23:52.210,0:23:58.170
No, okay, so now we actually can go to the more concrete part, right, so this was kind of abstract I gave you some

0:23:58.840,0:23:59.980
interesting

0:23:59.980,0:24:07.110
You know delicious I guess appetizer. Let's get on the main course and let's see how you can actually get started. Okay, so

0:24:07.930,0:24:14.639
Everything you're gonna be seen in my classes or in my github repository, which you are gonna be forced to star

0:24:15.340,0:24:16.980
Now I'm just kidding

0:24:16.980,0:24:19.079
But if you don't star it, I will take notice

0:24:21.840,0:24:26.040
All right, github.com/atcold

0:24:26.040,0:24:28.580
so atcold stays for something weird

0:24:28.810,0:24:35.609
So my Italian name is Alfredo, "fredo" can mean "cold" and "al" can mean "at"

0:24:35.920,0:24:39.659
So that "atcold" is gonna be like kind of transliteration of my name

0:24:40.210,0:24:41.950
So atcold

0:24:41.950,0:24:43.950
You go there

0:24:44.770,0:24:46.770
Yet, it's me how cute

0:24:47.170,0:24:53.940
and the first one with one thousand and three hundred stars, and I guess you have two hundred so I should be

0:24:55.210,0:24:56.980
1500 by tonight

0:24:56.980,0:25:02.280
It's not the class repository for the class. Right? And so you're gonna be

0:25:03.340,0:25:05.820
if you don't have so you should have like a

0:25:06.700,0:25:11.220
UNIX, actually no, PyTorch works also on Windows

0:25:11.220,0:25:15.959
I don't use Windows so I have no idea. But if you have a Mac or a

0:25:17.440,0:25:24.779
Linux machine everything works just fine. If you have a Windows it should work as well. I haven't tried

0:25:26.230,0:25:28.440
So how do you access this stuff you go there?

0:25:28.960,0:25:33.420
Here you're gonna have the page website as soon as we actually make it

0:25:33.940,0:25:35.940
we are going to be actually looking at the

0:25:37.679,0:25:39.629
Repo, sorry,

0:25:39.629,0:25:42.108
The notebook number two right now

0:25:42.389,0:25:47.988
If we have time left, we can also check a bit of a more basic introduction to the tensor tutorial

0:25:47.999,0:25:50.329
How many of you have no idea

0:25:50.909,0:25:56.028
what numpy or numpy whatever you want to call it is, hands up. Don't be shy

0:25:57.690,0:25:59.690
So

0:25:59.940,0:26:01.940
I'll change my question now

0:26:02.129,0:26:06.979
Do does everyone here in class know about numpy and has it used before?

0:26:07.109,0:26:10.819
Is it are you gonna be shaking your hand? Just shake your head, right?

0:26:11.129,0:26:18.618
So who is no whatsoever idea what numpy is and how it works and never use Python before you know, it happened

0:26:18.619,0:26:20.619
Don't don't laugh. Okay

0:26:20.759,0:26:26.089
Because if you don't know about that, there is also the zero zero class where you implement things from scratch

0:26:26.090,0:26:28.399
But I guess there's too much back

0:26:28.440,0:26:35.989
So I guess the number one it perhaps is not too worthy going over. We see if we have some time left

0:26:36.680,0:26:41.040
It basically gives you some introduction about how to use basic

0:26:41.880,0:26:45.320
pytorch routines for creating tensors which are basically

0:26:46.200,0:26:48.200
multi-dimensional arrays in numpy.

0:26:48.929,0:26:52.069
And so it creates tensors multiply tensors

0:26:53.549,0:26:55.019
it just

0:26:55.019,0:27:00.199
Initialize create random stuff. So it's it's not that different from numpy again

0:27:00.200,0:27:04.850
We can check them out if we can check this out if we have some time afterwards

0:27:04.919,0:27:08.628
Otherwise, it's gonna be like left as an assignment to go over this

0:27:08.629,0:27:14.779
It should be very easy gentle introduction to how to get started with the API. Ok

0:27:16.379,0:27:18.379
Complaints about this?

0:27:19.109,0:27:21.109
No, wow!

0:27:21.210,0:27:23.329
Are you shy or you're too nice?

0:27:23.970,0:27:25.109
Ok

0:27:25.109,0:27:27.589
You're not laughing. Ok. All right, so

0:27:28.590,0:27:35.509
Ok, I'm joking, but you're not getting the jokes is fine. One more advertisement is typora. This typora thing

0:27:35.509,0:27:37.509
I love it so much is a

0:27:38.309,0:27:41.778
markdown editor where you can write down your

0:27:43.080,0:27:47.500
Notes in latex and markdown, right so you can write for example

0:27:49.240,0:27:54.260
You know, whatever softargmax which is something you're going to be learning about, which I call it this way

0:27:55.060,0:27:58.740
So you can use latex in a markdown file. It looks very good

0:27:59.410,0:28:01.240
for

0:28:01.240,0:28:02.590
example I here I

0:28:02.590,0:28:03.700
annotate

0:28:03.700,0:28:10.980
Articles I I read okay. So this is TYPORA, T Y  P O R A. Okay. That's just you know

0:28:11.620,0:28:14.840
Promotional message I don't get paid so, you know, it's free too, okay

0:28:16.060,0:28:18.450
All right. So, how do we get started there?

0:28:19.750,0:28:21.750
we open the terminal we

0:28:23.380,0:28:28.800
Zoom such that you can see something so we can go for example inside or this is going to be different

0:28:29.920,0:28:32.700
Let's say we go inside that inside that repository

0:28:33.910,0:28:40.920
I go somewhere else which is gonna be my notebooks and then my video something video lessons

0:28:43.750,0:28:48.270
Okay, so you're going to be basically running Conda activate

0:28:49.420,0:28:51.659
deep learning mini course and

0:28:52.480,0:28:54.340
Everything just works

0:28:54.340,0:29:00.419
If you have installed and you have followed the instructions in the readme, okay, so right now if you just type ipython

0:29:03.190,0:29:05.190
Ipython with Python 3.7.6

0:29:06.070,0:29:08.220
will open. You can do import

0:29:09.910,0:29:11.910
Torch for example

0:29:12.070,0:29:17.700
just to see whether everything works and then you can type for example, torch.rand(5)

0:29:18.070,0:29:23.549
and this one is going to be typing creating a tensor with five number

0:29:24.310,0:29:29.249
Which are randomly picked from zero to one uniform distribution, okay

0:29:29.260,0:29:36.330
So this is just to check that everything just works fine. If this works, then we can actually start and playing with the notebooks

0:29:37.240,0:29:41.429
You're not kind of I mean, you can try to follow along in class with the computer

0:29:41.430,0:29:46.379
But I rather I think it's better for you to actually follow what I do here

0:29:47.020,0:29:51.120
you know, I'm a clown I try to engage with you if you isolate yourself with the

0:29:52.000,0:29:56.250
Computer maybe sometimes you may lose some of some of the nuggets I give you

0:29:56.860,0:30:02.609
Anyhow, so it looks like everything works here. So I'm gonna be just opening the Jupyter notebook

0:30:05.710,0:30:09.420
And things are black because I like them this way

0:30:10.480,0:30:16.260
Yeah, black is good. Alright, so we're gonna see this random projection to be starting

0:30:16.929,0:30:18.520
so

0:30:18.520,0:30:20.520
Yeah

0:30:21.160,0:30:23.080
let me go fullscreen

0:30:23.080,0:30:25.620
You should be complaining if you don't see things, right?

0:30:25.620,0:30:30.089
I kind of know what you see what you don't know what you see what you don't see but if you

0:30:30.520,0:30:36.569
Provide feedback live like I can't read anything or can you turn off the light? That would be also useful

0:30:36.570,0:30:38.939
Okay, so do interrupt me to

0:30:39.850,0:30:42.000
Talk to me. Can you see is it okay?

0:30:44.410,0:30:46.410
Yes, no

0:30:46.600,0:30:47.860
Thank you

0:30:47.860,0:30:52.890
All right. Let me turn off that one - all right. Okay, so I do here. I just what I do here

0:30:52.890,0:30:57.150
I'm gonna just import some utilities. I find for plotting stuff

0:30:58.000,0:31:02.579
Then here I just import torch and then from torch I import this nn library

0:31:03.669,0:31:09.839
Which is simply I'm gonna be importing the matrix multiplication and the addition of our vector, okay?

0:31:09.870,0:31:13.319
so matrix multiplication is gonna be a linear operation plus the

0:31:14.049,0:31:17.249
Bias, but plus the translation we have the affine transformation

0:31:17.290,0:31:22.499
Which is the one we were talking about with the five different transformations, and then we're going to be importing

0:31:22.500,0:31:24.719
I guess some ordinary function somewhere

0:31:26.169,0:31:28.919
Moreover I import from matplotlib those

0:31:29.679,0:31:34.829
Things for plotting things. I also important numpy as np.

0:31:37.150,0:31:44.219
Numpy, numpy, I don't know, is it numpy number or numpy with numeric! People complain about that, I don't know?

0:31:44.559,0:31:51.809
Anyhow, so I use some default things and okay. This is the first line torch specific line. So this is gonna be

0:31:52.570,0:31:54.340
device

0:31:54.340,0:31:56.610
equal torch.device

0:31:57.280,0:32:04.499
("cuda=0" if torch.cuda.is_available() otherwise "cpu"). What is this if I am running these

0:32:05.110,0:32:07.890
examples on a machine which has a GPU

0:32:08.679,0:32:12.449
Automatically torch will run on the GPU memory

0:32:12.790,0:32:18.220
So your machine has a CPU which makes only sequential operations one after each other

0:32:18.530,0:32:24.670
Must might be very very very fast, but it's still sequential right? It's like your brain you can only do one thing at a time

0:32:26.030,0:32:30.160
If you try to drive and smoke and funk take a phone call

0:32:31.190,0:32:35.289
Yeah, you might not be here tomorrow so you can only do one thing at a time, right?

0:32:36.530,0:32:42.940
And it's like the CPU of a computer and then you have some local memory, which is the main memory is called RAM random access memory.

0:32:43.460,0:32:48.819
On the other side. If you would like to speed up things you can use something that is much slower

0:32:50.750,0:32:55.119
Which is called GPU so why would you use a GPU which is slower?

0:32:56.360,0:32:59.320
Than a CPU to speed up your computations

0:33:01.610,0:33:08.770
Because although it's very very much slower it can perform many many many more computation at the same time, right?

0:33:08.810,0:33:12.999
So if the CPUs might be like like running very quickly from one side to the other

0:33:13.610,0:33:17.680
It's gonna be beating your GPU so many times but the GPU does

0:33:21.950,0:33:23.840
Okay

0:33:23.840,0:33:29.829
Alright, so the GPU will have a memory which is called device memory, which is which lives on the GPU

0:33:29.830,0:33:32.289
I think right now they are planning to get some

0:33:33.620,0:33:40.340
Access to the main memory of the CPU from the GPU. I think they are working on that. I don't think it's yet out

0:33:41.020,0:33:47.760
Anyhow, if you work on the GPU, you will have to create your tensors in the GPU, yeah, in the GPU memory

0:33:48.920,0:33:52.960
But you don't have to worry about that as long as you specify that thing over there

0:33:53.120,0:33:57.130
at the beginning of your code pytorch will take care and will put your

0:33:57.860,0:34:04.900
Tensors in the right location for you. If you're going to be using a TPU a tensor processing unit from Google similarly

0:34:04.900,0:34:08.860
You're gonna have pytorch putting your tensors in the TPU memory

0:34:08.860,0:34:14.940
Which is close to the actual processing unit there which is going to make your operation, you know computed in a faster way

0:34:15.530,0:34:17.480
so this is a

0:34:17.480,0:34:20.169
Stupid single line, but it's important. Okay

0:34:23.629,0:34:26.529
Again about the Pytorch stuff you won't be

0:34:27.169,0:34:29.169
Tested in the midterm

0:34:29.210,0:34:31.210
Midterm is going to be mostly about math

0:34:31.669,0:34:35.888
This study is going to be essential for actually managing to succeed in the final project

0:34:35.889,0:34:42.819
Okay, so if you are trying to beat others while using CPUs, and they are using GPUs

0:34:42.980,0:34:44.659
You know, good luck

0:34:44.659,0:34:46.429
okay, and

0:34:46.429,0:34:48.429
yeah, I'm ironic but

0:34:49.850,0:34:52.449
You know people tried and

0:34:53.000,0:34:58.060
And then complain and then I don't want complaints. Okay. Alright, so here we create

0:34:58.910,0:35:00.740
1,000 points and

0:35:00.740,0:35:05.139
Actually, I do this one. Okay, so one underscore zero zero zero is the same as one thousand

0:35:05.140,0:35:12.220
But it's better to read and so here I have 1,000 points and my X capital X is gonna be my designed matrix

0:35:12.230,0:35:14.230
It's gonna be having

0:35:14.480,0:35:21.370
1,000 rows and two columns. Okay, and it's sampled from our random and

0:35:22.160,0:35:24.820
Distribution, so if you go here you press shift tab

0:35:25.130,0:35:30.520
You're going to be having this thing opening up and you can click here. You're gonna see what is this stuff, right?

0:35:30.520,0:35:36.429
So randn is gonna be able to turn a tensor filled with random numbers from a normal distribution

0:35:36.530,0:35:42.850
With mean 0 and variance 1 also called the standard normal distribution. Okay. So, how did I open the help?

0:35:42.850,0:35:43.540
Do you know this stuff?

0:35:43.540,0:35:48.550
Have you ever used notebooks before, is the first time you saw this help, you know?

0:35:48.550,0:35:50.550
Some of you may have seen this the first time

0:35:51.950,0:35:58.720
Ok. So, how are these capital X going to be looking like? How are these set of points?

0:35:59.330,0:36:01.959
What what is your expectation for this set of points?

0:36:04.730,0:36:06.730
You're supposed to interact

0:36:11.820,0:36:19.699
Small values near to zero. Okay. So you're going to have a cloud of points. What is going to be the radius of your cloud?

0:36:24.750,0:36:26.750
It's again

0:36:28.230,0:36:29.430
No

0:36:29.430,0:36:31.819
I'm just speaking since I don't like distributions

0:36:31.820,0:36:36.769
I'm gonna have like a bunch of points which are going to be basically somehow circularly distributed

0:36:36.840,0:36:40.160
I'd like to know what is the average radius of this?

0:36:41.010,0:36:43.010
blob

0:36:43.620,0:36:46.009
a half, offers, more or less?

0:36:49.680,0:36:51.680
Zero? average?

0:36:52.710,0:36:57.770
So you have the expectation of the square of the X square, right?

0:36:59.190,0:37:05.840
Square root of the expectation well, whatever like expectation of the square root of the sum of the squares, right?

0:37:07.320,0:37:11.930
Okay. Someone said 1/2, who guess once more, who beats more?

0:37:15.840,0:37:17.400
Say again?

0:37:17.400,0:37:20.749
It's that or 1. So you have the standard deviation is gonna be 1

0:37:21.090,0:37:27.739
So are you gonna get points outside of the standard deviation or not? You know the bell curve right? Where is the one standard deviation?

0:37:28.470,0:37:34.100
Close to the center far away how much larger than the standard deviation is the bell?

0:37:35.970,0:37:37.970
Okay, roughly

0:37:40.350,0:37:44.779
Try to guess just shoot numbers, it's okay. I don't judge you yet

0:37:49.110,0:37:53.749
No you too shy okay, where is my student answer I

0:37:57.150,0:37:59.150
Okay, fine.

0:38:00.120,0:38:02.120
You fine not fine, okay

0:38:03.810,0:38:05.810
There we go

0:38:05.940,0:38:08.840
What is this stuff it's cute I know

0:38:10.830,0:38:15.170
Can you see anything let me should I lower it okay. I just lowered the light whether

0:38:15.810,0:38:18.920
people with the recording are gonna be complaining but

0:38:22.380,0:38:25.969
Okay, still I don't know how to tur n off the first thing so you got get dark

0:38:26.760,0:38:30.080
So what are those red and green arrows there?

0:38:33.780,0:38:36.110
Okay, you can you can guess right I don't bite you

0:38:37.290,0:38:39.350
The axis, fantastic, which axis?

0:38:40.140,0:38:42.469
What is the length of those things? Come on?

0:38:43.770,0:38:48.649
Unit, right? So those are the unit vectors. Why one is red while the other is green?

0:38:52.260,0:38:54.260
Okay, fantastic

0:38:55.080,0:38:57.590
Which one is X which one is Y?

0:39:00.030,0:39:02.330
X is the red one. Why is that because you have?

0:39:03.060,0:39:07.549
RGB, right because you have taken some graphic just before this.

0:39:07.550,0:39:12.529
So R is gonna be always, red is gonna be always the x-axis, green is gonna be always the y-axis.

0:39:12.680,0:39:16.280
Those are unit vectors and therefore this cloud of points spins roughly

0:39:18.390,0:39:22.219
What is the average radius here can you guess more or less

0:39:23.970,0:39:29.929
Three fantastic, that was the  answer. Okay, so you have a cloud of points roughly large three, right?

0:39:31.440,0:39:39.020
Uniformly like circularly distribute, right, sort of all right, cool. So we're gonna run now

0:39:43.890,0:39:51.589
You can try to put like this arrow here one more arrow here one more arrow here you have three arrows there, okay

0:39:52.440,0:39:54.710
More or less. I'm a physicist, right?

0:39:55.830,0:40:01.429
Yeah, later I will be a mathematician. Okay now I'm a mathematician so

0:40:02.400,0:40:07.400
Visualizing linear transformations, see here I compute the SVD singular value decomposition

0:40:08.520,0:40:12.770
Again, there's the video I pointed out before so I'm gonna be multiplying this

0:40:14.280,0:40:19.850
This cloud of point by a matrix, so what does the matrix do to these circular blob?

0:40:22.140,0:40:27.979
Come on, you know this stuff you repeated three times so far. What do you expect to see?

0:40:27.980,0:40:30.409
You have a circle here. What do you expect to see afterwards?

0:40:32.960,0:40:33.780
a

0:40:33.780,0:40:41.300
Potato yes, correct. So first potato and this is a very squished one. So why is he, what's happen here?

0:40:41.300,0:40:43.300
What's happen in the y-direction?

0:40:46.589,0:40:48.589
All right, so how is this matrix?

0:40:51.300,0:40:56.449
It's a cute matrix, is the rotation matrix, is an annoying matrix?

0:41:00.089,0:41:06.409
How are the, what are the singular values look look here, one singular value is almost close to 0, right?

0:41:06.410,0:41:08.410
So this is our almost singular matrix

0:41:09.450,0:41:13.189
So this is what's happening. It's gonna kill one dimension. This one didn't kill it yet

0:41:13.230,0:41:17.810
But basically you have that the dimensions in the diagonal right in the singular value decomposition

0:41:18.660,0:41:24.770
Represent the amount of zooming you have in the different direction and then the first two matrices, the first and the last one

0:41:24.930,0:41:27.020
Represent the rotation that these metrics apply

0:41:28.619,0:41:33.469
This other one has a factor of two in one direction and the 0.6 in the other one

0:41:33.470,0:41:36.139
So you get this stuff here Oh something else. Hold on

0:41:36.270,0:41:43.099
So here you have blue green yellow red, right so R G hold on. No, there is no order here

0:41:43.099,0:41:46.969
We have blue green yellow red and then here you have blue red

0:41:47.609,0:41:50.869
Yellow green. So what's happened here? How's the determinant?

0:41:52.500,0:41:54.500
Negative why is that

0:41:55.170,0:41:57.170
Because you had a

0:41:58.260,0:42:02.359
Reflection that's correct. All right, I'll keep going you can see here different

0:42:03.330,0:42:08.809
Things right? So you have more potatoes here and this is actually zooming a lot. You have 1.3

0:42:09.750,0:42:12.050
This also is kind of zooming a little

0:42:12.960,0:42:14.960
Okay, this one does nothing

0:42:16.050,0:42:21.979
Okay, boring, right, oh, okay what's happen here, how is this matrix?

0:42:24.060,0:42:29.330
It's gonna be singular right almost you can see the one singular value is gonna be 0.03, it's very tiny

0:42:29.330,0:42:34.969
You can see these are the unit vectors. There are very big arrows here means it has squashed down, right?

0:42:34.970,0:42:41.089
The first one is 0.6 the other one is 0.03 so you can basically almost killed a dimension here

0:42:41.910,0:42:44.149
And so on. Okay, so no much

0:42:45.890,0:42:50.980
Stuff anyhow, you can do the same things with Pytorch now, so this can be the first instruction

0:42:50.980,0:42:52.980
You're gonna be seen about Pytorch

0:42:53.720,0:42:56.139
So here I do model is going to be a sequential

0:42:56.390,0:42:57.680
which is basically a

0:42:57.680,0:43:04.779
Container where I can put a few a few modules one after each other and my first module is going to be a nn linear

0:43:04.880,0:43:07.690
Which means what does nn linear means?

0:43:09.289,0:43:10.999
Doesn't mean a linear transformation

0:43:10.999,0:43:12.999
because these people were

0:43:13.039,0:43:18.729
I guess programmers so, you know, they don't know I guess this is an affine transformation

0:43:18.920,0:43:25.029
But actually it's a linear transformation because I said bias equals false. Okay. So this is actually just a matrix multiplication

0:43:25.220,0:43:28.509
So it is a linear transformation. Okay maps to 0 to 0

0:43:29.089,0:43:36.219
Then I do model to device I ship the model to the memory of the GPU and then I remove the gradients

0:43:36.220,0:43:38.220
You're gonna figure out this next week what it is

0:43:39.499,0:43:44.619
I'm gonna bet get here my Y is gonna be the output of the model to which I input the X

0:43:45.680,0:43:50.049
Then I generate my figure and I plot this stuff. So this is to show you that

0:43:51.079,0:43:56.439
You can also get a singular matrix with the Pytorch. How cool is this?

0:43:57.319,0:43:58.579
No, it's boring, right?

0:43:58.579,0:44:04.568
I mean you can see you can multiply data by matrix matrices by using the Pytorch package

0:44:04.569,0:44:06.609
And so we had to create a model

0:44:07.730,0:44:14.409
Sequential container we put inside the linear module. We remove the bias the translation and you get this stuff

0:44:14.420,0:44:16.420
Why did I remove the translation?

0:44:16.549,0:44:24.008
Because otherwise I had to fetch it and it goes outside the screen so I keep it in the center. Okay? All right, so

0:44:25.579,0:44:31.179
Let's have this one. So right now I'm gonna just use the following I just use a matrix

0:44:31.180,0:44:35.739
That is I think I didn't pick curl. No, it's gonna be identity matrix

0:44:36.319,0:44:41.199
Which I scale both items in the diagonal by the same item by the same value

0:44:42.170,0:44:48.129
And then I apply a nonlinear function. So my nonlinear function is gonna be the following. It's a hyperbolic tangent

0:44:48.920,0:44:50.920
which goes to

0:44:50.960,0:44:58.740
Minus 1 roughly when you cross the minus 2.5 here at the bottom and it goes to goes to one

0:45:00.849,0:45:03.629
Roughly whenever you cross the plus 2.5 okay up here

0:45:04.900,0:45:07.260
so this stuff maps what the whole

0:45:08.770,0:45:10.770
Real line to where

0:45:11.800,0:45:13.800
so plus infinity goes to

0:45:14.800,0:45:16.889
one and minus infinity goes to

0:45:17.830,0:45:23.969
Until you reach the linear region, which is roughly minus two point five to two point five

0:45:24.040,0:45:28.499
Why do I mention this name in these numbers? Because sometimes you're gonna put your nose inside

0:45:29.100,0:45:33.320
your model it is not training and you still want to figure out the order of

0:45:33.660,0:45:39.080
Magnitude and you know the rough the number which are kind of associated to the kink of these nonlinearities

0:45:40.560,0:45:46.220
Anyhow, so I just create this one which is very very similar to the thing. I just show you before

0:45:48.250,0:45:50.250
Which has

0:45:50.380,0:45:54.930
Where is it here? So here I have my sequential which is the sequence of

0:45:55.510,0:45:57.629
Operations I use a matrix first

0:45:57.630,0:46:00.720
so this linear two two then I applied the Tanh and

0:46:01.180,0:46:05.700
Then I increased the I think the multiplier for that diagonal matrix

0:46:06.250,0:46:10.919
So that's what you get. So this is my cloud. What do you expect to see of my cloud?

0:46:12.760,0:46:17.369
So what is the range of this cloud we said it's roughly

0:46:18.730,0:46:23.339
It goes from minus 3 to plus 3 right? Where is the kink happening?

0:46:25.990,0:46:27.990
So everything that is

0:46:28.000,0:46:35.879
outside these two point five minus two point five two plus two point five box is going to be mapped to

0:46:36.760,0:46:38.760
one things that are inside

0:46:40.570,0:46:46.679
Stay roughly the same that's correct. So what do you expect to see after this image over here?

0:46:51.730,0:46:57.220
You expect to have inbox your data but what is going to be the size of this box

0:47:02.090,0:47:08.620
Are you sure so the the suggestion was from minus two point five to two point five?

0:47:10.340,0:47:14.350
The box is going to be 2 minus 1 2 plus 1 so minus 1 minus 1

0:47:14.350,0:47:17.140
I mean all the box from minus 1 to plus 1

0:47:17.360,0:47:20.920
But then the points inside are going to be mapped according to the mapping

0:47:20.920,0:47:25.539
We were mentioning before so things from minus two point five to two point five are getting linearly

0:47:26.090,0:47:28.900
Squeezed and then things outside the two point five

0:47:29.870,0:47:32.079
number are going to be squashed down to the

0:47:32.750,0:47:37.929
Basically edge of this box. Okay. Are you ready to see how to box a normal distribution?

0:47:38.660,0:47:40.660
Are you excited?

0:47:41.450,0:47:46.059
Okay, just two people just said that I mean are we excited come on give me some satisfaction

0:47:48.920,0:47:54.670
Okay, you're not playing with me okay, I see I'm trying to be nice to you oh

0:47:56.090,0:48:00.490
Oh, thank you at least that worked, right? So that was first one

0:48:00.590,0:48:08.350
So in this case here, I'll just show you just my identity matrix. I didn't zoom anything and here things are kind of

0:48:09.590,0:48:14.259
What kind of distribution looks this? I mean what what does it look like? Come on? Oh

0:48:15.350,0:48:18.009
It's a uniform kind of between

0:48:19.670,0:48:24.999
Minus 1 to plus 1 fantastic in 2d, what does it happen now if I start zooming a little bit?

0:48:26.930,0:48:33.069
If I start multiplying instead of having identity matrix now, I have the 2x2 matrix or 3x3 or 4x4 5x5

0:48:35.990,0:48:37.990
Say again?

0:48:38.440,0:48:45.700
The points will go further to the edges so you're gonna be seeing this and this and this and

0:48:47.690,0:48:49.690
Finally this huh? Oh, hey

0:48:50.420,0:48:56.710
Cool hah? So what happens here? We met by our cloud. It was like circular into this kind of boxy thing

0:48:56.960,0:49:00.609
How cool is that! Now those little points are very very spread apart

0:49:00.609,0:49:03.459
And so you can actually tell them apart if you are for example

0:49:03.710,0:49:07.210
classifying stuff. Finally in the last minute, then I leave you, let you go

0:49:09.079,0:49:10.640
It's going to be

0:49:10.640,0:49:12.640
using random matrices

0:49:12.799,0:49:16.629
but in this way, so here I'm gonna have my sequential I

0:49:17.510,0:49:19.510
Put like a linear layer

0:49:19.940,0:49:26.679
Which also has the bias terms is affine transformation I go from two to this hidden layer dimension

0:49:26.680,0:49:29.109
Which is going to be five, so I go to two to five

0:49:29.109,0:49:33.068
I applied the ReLU which is simply the positive part operator

0:49:33.109,0:49:38.949
And then I apply another affine transformation that goes to five to two such that I can display them on the screen

0:49:39.049,0:49:43.689
Okay, is it clear what I'm doing, so I create a sequential which is a sequence of modules

0:49:43.690,0:49:44.980
I have three modules

0:49:44.980,0:49:47.109
The first module is a matrix mapping

0:49:47.599,0:49:54.609
Matrix of height five, width two so it shoots towards five dimensions from a two dimensional input space

0:49:54.829,0:50:00.669
There is a bias which is going to be five dimensional. Then you remove you set to zero everything that is negative

0:50:00.670,0:50:03.159
And then you map this five dimensional space

0:50:03.890,0:50:08.619
Whatever down to two dimensions, so you're gonna have a matrix that has two rows and five columns

0:50:08.750,0:50:13.359
And then there is a bias of height like of size two. Okay. Did you follow?

0:50:13.940,0:50:19.179
If you didn't follow you can find in the recording because I'm gonna play press play. Are you ready?

0:50:21.770,0:50:23.889
Mmm, okay some engagement

0:50:24.740,0:50:30.909
Okay, it didn't work. Sorry. Okay. Okay fantastic. They know I did so this is the beginning right?

0:50:30.980,0:50:34.449
that's the starting point and then you get

0:50:36.980,0:50:38.980
Yes, you're allowed to do oh

0:50:40.970,0:50:44.289
It's fine. Oh, oh, this is all right. This is very spiky

0:50:44.599,0:50:51.729
So you're gonna figure out in the next class what happened here, but this is a very different thing right. These are smooth transformations

0:50:52.550,0:50:54.550
Somehow smooth. This is very very

0:50:55.550,0:50:57.500
Angular, right?

0:50:57.500,0:50:59.500
and this one and

0:51:00.349,0:51:04.539
How cute is this right so finally final remarks and then I let you go

0:51:04.540,0:51:11.769
I know it's dinner time, sorry for keeping you here two minutes late so final remarks are the following then

0:51:12.440,0:51:14.359
Yeah, check the Piazza

0:51:14.359,0:51:21.699
so this is basically an untrained neural network those I just show you in the module with the three items the

0:51:22.760,0:51:24.170
linear transformation

0:51:24.170,0:51:30.940
Positive part, linear transformation or affine transformation is your first linear deep neural network?

0:51:30.980,0:51:34.689
It's not that deep but still makes pretty damn awesome

0:51:35.390,0:51:41.800
Drawings I think in my opinion so I'm like a just initialize network an untrained Network

0:51:41.800,0:51:45.909
We start with this kind of transformation, but we have seen from the first video

0:51:45.910,0:51:49.060
I show you tonight that we are aiming for a

0:51:49.490,0:51:54.580
Transformation which is, you know instrumental to perform a specific task, which is for example

0:51:54.890,0:51:59.320
The classification of those points that are belonging to the different five spiral

0:51:59.320,0:52:02.949
So in the next class we're going to figure out how do I take this?

0:52:04.040,0:52:11.949
initial, you know arbitrary transformation and I can pull it apart and manipulate such that I achieve the

0:52:11.950,0:52:13.950
final goal, which is for example

0:52:14.240,0:52:20.919
Make my points linearly separable in the final layer. Okay, so this is gonna be for the next class

0:52:21.440,0:52:23.440
otherwise stay warm

0:52:23.450,0:52:25.839
And I see you next time, bye-bye
