0:00:00.500,0:00:07.230
[Student] Have you been to Isoldi in New York?

0:00:05.370,0:00:10.230
I love their lasagna. [Alfredo] No, I haven't been to

0:00:07.230,0:00:15.470
Isoldi. I usually go to two places, one is

0:00:10.230,0:00:16.619
called Norma, it's here on 33rd and 3rd

0:00:15.470,0:00:20.279
Avenue,

0:00:16.619,0:00:21.330
it's just Sicilian, very authentic I love

0:00:20.279,0:00:23.220
it.

0:00:21.330,0:00:25.470
The other one which is absolutely the

0:00:23.220,0:00:28.170
best pizza in the world,

0:00:25.470,0:00:32.219
it's called Sorbillo, it's very

0:00:28.170,0:00:34.410
close to NYU. The pizza is just like in

0:00:32.219,0:00:37.350
Naples and it's like you can't find

0:00:34.410,0:00:39.329
anything better on this planet, so you

0:00:37.350,0:00:40.710
know, you should go to Sorbillo. And if

0:00:39.329,0:00:45.500
you mention my name you get discount,

0:00:40.710,0:00:49.739
right, so yeah I have a special power.

0:00:45.500,0:00:51.989
Yeah... Chicago pizza is not pizza, it's

0:00:49.739,0:00:54.449
pie. So if you call it

0:00:51.989,0:00:58.820
Chicago pie, it's fantastic, it's not

0:00:54.449,0:01:02.579
pizza. Napoli pizza is the only pizza.

0:00:58.820,0:01:04.920
Okay, all right, so what do we talk today

0:01:02.579,0:01:08.220
about? Today we talk about something

0:01:04.920,0:01:10.830
called The Truck Backer-Upper. What are

0:01:08.220,0:01:12.360
we trying to do today in this lecture? So

0:01:10.830,0:01:14.340
this is the first lecture where you're

0:01:12.360,0:01:18.270
going to help me, basically reading with you

0:01:14.340,0:01:20.280
along, a paper such that we can

0:01:18.270,0:01:23.720
figure out whether things make sense.

0:01:20.280,0:01:25.530
This is how we educate ourselves in the

0:01:23.720,0:01:29.220
research world, you don't have

0:01:25.530,0:01:31.079
necessarily Yann on your side all the

0:01:29.220,0:01:32.369
time so you have to read papers and you

0:01:31.079,0:01:35.490
have to make sense of what's written

0:01:32.369,0:01:38.909
there. Usually I transcribe them

0:01:35.490,0:01:41.729
back with Typora just to fix

0:01:38.909,0:01:44.759
the main topics in in my mind, and

0:01:41.729,0:01:45.540
to commit to time such that I can

0:01:44.759,0:01:48.240
check

0:01:45.540,0:01:51.509
later what's going on. So

0:01:48.240,0:01:53.460
let's get started. So what is this setup?

0:01:51.509,0:01:56.969
what are we trying to do here? So we are

0:01:53.460,0:01:59.009
trying to design by self-learning of a

0:01:56.969,0:02:01.590
nonlinear controller to control the

0:01:59.009,0:02:03.869
steering of a trailer truck while

0:02:01.590,0:02:07.170
backing up to a loading dock from an

0:02:03.869,0:02:09.929
arbitrary initial position. Only backing

0:02:07.170,0:02:11.819
up is allowed. So what does this mean?

0:02:09.929,0:02:13.920
What we are trying to do is going to be

0:02:11.819,0:02:17.760
learning how to drive a truck,

0:02:13.920,0:02:20.910
which is maybe not that complicated if

0:02:17.760,0:02:25.020
you go forward, but we are trying to park

0:02:20.910,0:02:27.990
a truck, so it just goes backwards and only

0:02:25.020,0:02:31.110
backwards. So you know if you try to park

0:02:27.990,0:02:33.060
your car in a parallel parking, it's a

0:02:31.110,0:02:37.080
little bit complicated perhaps sometimes

0:02:33.060,0:02:39.900
and not always you can get it done with

0:02:37.080,0:02:44.180
one manoeuvre, if you have a trailer

0:02:39.900,0:02:48.360
truck attached to your back it's a mess.

0:02:44.180,0:02:51.870
We are figuring out this very soon. So

0:02:48.360,0:02:54.690
how does this trailer truck

0:02:51.870,0:02:58.830
works? We have two items, we have a cab

0:02:54.690,0:03:02.220
which is the top right part there, so we

0:02:58.830,0:03:04.110
have an angle of the cab with

0:03:02.220,0:03:07.080
respect to the x-axis, and then we have

0:03:04.110,0:03:09.209
the coordinates x and y of the 

0:03:07.080,0:03:13.500
joint between the cab and the trailer.

0:03:09.209,0:03:16.470
Okay then in the part below we have the

0:03:13.500,0:03:19.230
trailer and therefore we have like the

0:03:16.470,0:03:21.540
x and y location of the back of the trailer

0:03:19.230,0:03:23.519
truck and then we have the theta trailer,

0:03:21.540,0:03:25.500
which is telling us what is the angle of

0:03:23.519,0:03:29.130
this trailer truck with respect to the

0:03:25.500,0:03:33.150
x-axis. Our objective is to drive this

0:03:29.130,0:03:36.540
guy backwards until the back of the

0:03:33.150,0:03:38.970
trailer hits basically the dock location,

0:03:36.540,0:03:43.650
which is represented there with the x_dock

0:03:38.970,0:03:46.380
and y_dock coordinate. Moreover, we

0:03:43.650,0:03:48.450
would like to have the theta trailer

0:03:46.380,0:03:52.440
which is the angle of the trailer to be

0:03:48.450,0:03:54.959
0 such that the trailer is

0:03:52.440,0:03:58.739
orthogonal to the docking station and

0:03:54.959,0:04:00.750
basically the rear part of the... the rear

0:03:58.739,0:04:02.310
part, front and rear, 

0:04:00.750,0:04:04.470
is 'rear' back, right?

0:04:02.310,0:04:06.269
I'm speaking English, I guess it's

0:04:04.470,0:04:10.799
correct. So the rear part of the

0:04:06.269,0:04:13.019
trailer should be parallel

0:04:10.799,0:04:17.039
to the docking station and as close as

0:04:13.019,0:04:21.690
possible to the location of the dock. So

0:04:17.039,0:04:25.169
far make sense, right? Yeah, ok, all right.

0:04:21.690,0:04:27.570
So let's read a little bit more further in

0:04:25.169,0:04:31.800
this paper, so we have some

0:04:27.570,0:04:36.240
state variables, there are six, which

0:04:31.800,0:04:38.330
I think this is perhaps not

0:04:36.240,0:04:41.580
correct, we'll figure this out soon.

0:04:38.330,0:04:45.150
So the state variables are the theta_cab

0:04:41.580,0:04:47.760
which is the angle of the truck. Then 

0:04:45.150,0:04:51.150
x_cab and y_cab, which is the Cartesian

0:04:47.760,0:04:54.360
position of the yoke, which is the part

0:04:51.150,0:04:56.520
behind the cab. And then you have x_trailer and

0:04:54.360,0:05:00.000
y_trailer which is the position of the

0:04:56.520,0:05:02.330
rear of the trailer, plus theta trailer

0:05:00.000,0:05:05.640
which is the angle of the trailer. Okay.

0:05:02.330,0:05:06.060
So basically, how the 

0:05:05.640,0:05:08.400
procedure goes is

0:05:06.060,0:05:11.400
the following: The

0:05:08.400,0:05:12.980
truck backs up until it hits the dock

0:05:11.400,0:05:16.140
and then it stops.

0:05:12.980,0:05:18.120
The goal is to back the trailer to be

0:05:16.140,0:05:20.220
parallel to the loading

0:05:18.120,0:05:21.930
dock, right? So the the goal is

0:05:20.220,0:05:23.730
to have the back side of the trailer to

0:05:21.930,0:05:27.150
be parallel to the docking station. And

0:05:23.730,0:05:29.910
then, having the x_trailer and y_trailer, 

0:05:27.150,0:05:33.450
the location of the back of the trailer,

0:05:29.910,0:05:37.380
as close as possible to the x_dock

0:05:33.450,0:05:37.770
and y_dock. Okay, are you with me so

0:05:37.380,0:05:40.080
far?

0:05:37.770,0:05:42.450
So the initial position is going to be

0:05:40.080,0:05:45.900
randomly set and then we had to back up

0:05:42.450,0:05:49.830
until we hit

0:05:45.900,0:05:52.740
the trailer and the dock

0:05:49.830,0:05:57.240
with the back of the trailer and we are

0:05:52.740,0:06:02.490
exactly orthogonal. Okay? There are a

0:05:57.240,0:06:04.410
few difficulties with this, and we're

0:06:02.490,0:06:08.640
gonna figure out right now what

0:06:04.410,0:06:15.540
these difficulties are. All right, so we go 

0:06:08.640,0:06:18.570
cd Work/GitHub/pDL. Then now we go conda activate pDL

0:06:15.540,0:06:23.010
right? Now here we have a Jupiter notebook.

0:06:18.570,0:06:27.870
So in this case we are going to

0:06:23.010,0:06:30.090
go over this truck_backer-upper.

0:06:27.870,0:06:32.310
Something I really like to do in

0:06:30.090,0:06:35.640
Jupiter notebook is to use actually

0:06:32.310,0:06:38.190
unicode, since we are using

0:06:35.640,0:06:39.419
Python 3 we can use unicode, right? So to

0:06:38.190,0:06:41.430
write pi there

0:06:39.419,0:06:44.970
I just need to \pi 

0:06:41.430,0:06:53.400
and tab and you get π. Or you

0:06:44.970,0:06:55.290
can do \alpha \beta \gamma, okay? This is not

0:06:53.400,0:06:59.100
coding, this is notebooks so you can

0:06:55.290,0:07:01.980
do ugly things like this. Alright so I

0:06:59.100,0:07:06.510
just initialize some libraries, this is

0:07:01.980,0:07:09.500
our setup, I initialize some object here

0:07:06.510,0:07:13.080
we don't care right now and we start by

0:07:09.500,0:07:14.670
visualizing this guy here, okay? And I

0:07:13.080,0:07:22.650
think I had one zoom a little bit

0:07:14.670,0:07:25.350
because you can't see. There you go, cool. Okay so

0:07:22.650,0:07:28.980
now we start the interactive part. We'd like

0:07:25.350,0:07:32.160
to draw this guy, so let's say

0:07:28.980,0:07:36.090
with zero angle of the steering wheel

0:07:32.160,0:07:38.820
and I keep executing

0:07:36.090,0:07:43.710
this, alright? So this guy here keeps

0:07:38.820,0:07:48.360
going and then what's happening here

0:07:43.710,0:07:52.260
after the next step is that my computer

0:07:48.360,0:07:53.910
now is complaining and there

0:07:52.260,0:07:56.370
you go, so you get the truck is

0:07:53.910,0:07:59.160
jackknifed. What does it mean the truck

0:07:56.370,0:08:01.350
has is jackknifed? It means you simply broke your

0:07:59.160,0:08:03.750
truck because you drove into yourself.

0:08:01.350,0:08:06.090
That's very interesting but you can

0:08:03.750,0:08:11.850
drive inside yourself with these trucks.

0:08:06.090,0:08:15.570
So let me reset the state with

0:08:11.850,0:08:17.820
something a bit decent, maybe like... okay

0:08:15.570,0:08:19.620
someone, any volunteers? what is

0:08:17.820,0:08:24.150
going to be now the angle you'd like me

0:08:19.620,0:08:26.750
to steer the wheel? You can give me

0:08:24.150,0:08:29.910
anything from 0 to 45 degrees, I think.

0:08:26.750,0:08:32.460
-10, okay so I go -10 which is gonna

0:08:29.910,0:08:39.140
be turning to the right 10 degrees and I

0:08:32.460,0:08:41.760
go 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 steps. 

0:08:39.140,0:08:44.400
If I keep going you're gonna be

0:08:41.760,0:08:46.770
jackknifing soon. Okay? So what should I

0:08:44.400,0:08:53.310
do right now? someone else? or maybe still

0:08:46.770,0:08:56.770
you. +15. Okay, let's try +15 degrees.

0:08:53.310,0:09:00.880
We go 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.

0:08:56.770,0:09:01.990
Hmm okay. What next? Should I

0:09:00.880,0:09:05.260
keep going? Yeah, 

0:09:01.990,0:09:08.710
1, 2, 3, 4, 5, 6, 7, 8, 9, 10. We are gonna be

0:09:05.260,0:09:12.160
going off screen. Maybe alternate plus

0:09:08.710,0:09:14.500
and minus? Then you go straight, right? If

0:09:12.160,0:09:16.450
I keep going like this you can see that

0:09:14.500,0:09:19.870
this truck is gonna be going outside,

0:09:16.450,0:09:22.750
we're gonna be, you know, going basically

0:09:19.870,0:09:25.870
game over, so you don't have a driving

0:09:22.750,0:09:28.420
license. So -15, okay?

0:09:25.870,0:09:34.150
Do you agree all? should I go with

0:09:28.420,0:09:37.660
-15? I go with -15. 1, 2, 3, 4, 5, 6, 7, 8, 9, 10

0:09:34.150,0:09:42.100
Ok now we cannot drove drive forward.

0:09:37.660,0:09:43.860
+45. We messed up. No no I don't think

0:09:42.100,0:09:46.600
you messed up I think it's still good.

0:09:43.860,0:09:50.050
0. okay someone said 0 let's try

0:09:46.600,0:10:02.920
with 0. Not yet, okay, what do you want

0:09:50.050,0:10:04.450
me to do? +45. Okay, +45. I can keep

0:10:02.920,0:10:11.380
going but then we are gonna be just... oh oh,

0:10:04.450,0:10:17.050
yeah. One more -45 okay, let's go

0:10:11.380,0:10:18.400
-45 twice, then twice more, then I'm

0:10:17.050,0:10:22.540
gonna go oh wait no,

0:10:18.400,0:10:24.610
six more, so 1, 2, 3, 4 ,5 , 6. OK.

0:10:22.540,0:10:27.250
So if I keep going like this we are

0:10:24.610,0:10:29.530
gonna be going off the screen, right? So I

0:10:27.250,0:10:31.870
think you got the picture, right?

0:10:29.530,0:10:34.420
Is it twice more? No, it's an older

0:10:31.870,0:10:37.030
message. Okay, the point here is that

0:10:34.420,0:10:40.360
this stuff it's a bit you know tricky.

0:10:37.030,0:10:42.280
You can get the hang of it

0:10:40.360,0:10:43.690
and maybe the

0:10:42.280,0:10:45.700
final solution is going to be like

0:10:43.690,0:10:49.270
something where we go like

0:10:45.700,0:10:51.940
this and then we go in the other

0:10:49.270,0:10:57.550
direction to rotate, something like +10

0:10:51.940,0:11:01.360
and then it's gonna be killing each

0:10:57.550,0:11:03.930
other here, so plus maybe 25 or maybe,

0:11:01.360,0:11:03.930
let's see...

0:11:04.339,0:11:13.370
Maybe +20, see? so we can turn around and

0:11:11.420,0:11:21.529
now we should basically undo this thing.

0:11:13.370,0:11:22.220
So if I go like, I think +40, and

0:11:21.529,0:11:30.079
there you go.

0:11:22.220,0:11:37.279
And we can go basically straight. Still

0:11:30.079,0:11:39.350
something, +20 maybe? Okay? and then we can

0:11:37.279,0:11:41.449
go zero... See? I've been teaching this

0:11:39.350,0:11:45.769
forever so you know I can actually drive

0:11:41.449,0:11:48.529
this thing, okay? So there you go, 

0:11:45.769,0:11:51.110
Alf is a truck driver. There you go, see? 

0:11:48.529,0:11:54.499
oh my God, I'm actually managing to do this. We

0:11:51.110,0:11:57.050
had to fix a little bit, honk honk yeah,

0:11:54.499,0:12:01.220
honk the horn, I actually had my horn

0:11:57.050,0:12:05.110
there, so we had to actually oo-oh 

0:12:01.220,0:12:05.110
oh no no okay sorry.

0:12:07.170,0:12:13.149
Okay fine. So this is actually considered

0:12:09.970,0:12:15.999
success. Okay now my computer now is

0:12:13.149,0:12:17.439
complaining because there is some lag. I

0:12:15.999,0:12:21.189
should have a turned a little bit before.

0:12:17.439,0:12:21.999
Anyhow, the point 

0:12:21.189,0:12:23.290
is that it's

0:12:21.999,0:12:26.170
not quite

0:12:23.290,0:12:28.660
straightforward to figure

0:12:26.170,0:12:30.759
out how to drive this guy, because it's

0:12:28.660,0:12:32.800
highly nonlinear, so we had to figure

0:12:30.759,0:12:36.540
out how to implement a high nonlinear

0:12:32.800,0:12:39.819
system, how to invert a high nonlinear

0:12:36.540,0:12:41.470
kinematic model basically, such that if

0:12:39.819,0:12:43.509
we had a kinematic model, you know how

0:12:41.470,0:12:45.730
the vehicle behaves given an

0:12:43.509,0:12:47.050
action, if you invert the kinematic model

0:12:45.730,0:12:50.019
you figure out what action you would

0:12:47.050,0:12:53.709
like to take in order to drive

0:12:50.019,0:12:54.999
to a final destination. But since we

0:12:53.709,0:12:57.430
don't know how to do this analytically,

0:12:54.999,0:12:59.470
or maybe we didn't know in the 90's,

0:12:57.430,0:13:03.209
we can train a neural net and then

0:12:59.470,0:13:05.709
we can simply figure out whether we can

0:13:03.209,0:13:07.990
learn how to

0:13:05.709,0:13:11.079
to drive backwards.

0:13:07.990,0:13:13.059
Okay, are you excited? are

0:13:11.079,0:13:15.819
you interesting to know how we can do

0:13:13.059,0:13:20.670
this? Yeah? No?

0:13:15.819,0:13:27.209
Yes! okay let me think.

0:13:20.670,0:13:30.819
So the overall 

0:13:27.209,0:13:36.009
objective here is gonna be that given an

0:13:30.819,0:13:37.629
initial position in this map here, 

0:13:36.009,0:13:40.600
I'd like to know

0:13:37.629,0:13:42.910
what sequence of actions, which is gonna

0:13:40.600,0:13:47.620
be basically what sequence of steering

0:13:42.910,0:13:50.259
angle for the wheels, I should apply in

0:13:47.620,0:13:52.899
this six dimensional space, so it's

0:13:50.259,0:13:55.149
not just 2D. This

0:13:52.899,0:13:57.370
screen here is gonna be the 2D screen

0:13:55.149,0:13:59.800 
but then you have six values, right? You

0:13:57.370,0:14:02.019
have the (x, y) of the cabs, (x, y) of the

0:13:59.800,0:14:04.329
trailer and the two angles, so you have a six

0:14:02.019,0:14:06.699
dimensional space and then in this six

0:14:04.329,0:14:08.740
dimensional space you'd like to infer,

0:14:06.699,0:14:10.839
so you get

0:14:08.740,0:14:12.759
a network which is telling you: For this

0:14:10.839,0:14:14.050
specific configuration of the truck or

0:14:12.759,0:14:17.709
the trailer truck you should be

0:14:14.050,0:14:18.899
outputting this specific value, it is a

0:14:17.709,0:14:20.730
regression network somehow.

0:14:18.899,0:14:24.029
It's going to be outputting a

0:14:20.730,0:14:29.819
scalar which is going from -45 to

0:14:24.029,0:14:32.759
+45 I think. Yeah, yeah, I think so,

0:14:29.819,0:14:35.369
I think that's the range. For every

0:14:32.759,0:14:37.139
position. So our goal is gonna be

0:14:35.369,0:14:39.449
training a neural net that goes from

0:14:37.139,0:14:42.209
points in this six dimensional space to

0:14:39.449,0:14:46.769
one scalar, which is gonna be the scalar

0:14:42.209,0:14:48.749
that allows me to get 

0:14:46.769,0:14:51.329
a sequence of scalars, so one

0:14:48.749,0:14:54.809
scalar at the time, such that you would

0:14:51.329,0:14:56.449
like to drive these track backwards to

0:14:54.809,0:14:59.369
the final destination.

0:14:56.449,0:15:04.110
Did I make sense? Does it make sense?

0:14:59.369,0:15:06.029
Maybe I was confused. Is it okay? 

0:15:04.110,0:15:09.300
Alright, so let's figure out how to get

0:15:06.029,0:15:12.990
all this stuff going. Back to the slides.

0:15:09.300,0:15:16.019
Training. So the

0:15:12.990,0:15:18.420
training involves two stages: The first

0:15:16.019,0:15:21.209
one we have to train a network, 

0:15:18.420,0:15:24.449
a neural net, to be an emulator of the

0:15:21.209,0:15:26.100
truck and trailer kinematics. This is how

0:15:24.449,0:15:28.379
the paper have done, 

0:15:26.100,0:15:31.589
so that's not the only option but it's

0:15:28.379,0:15:33.569
what we are going for; Then a second

0:15:31.589,0:15:35.490
stage involves training of a neural

0:15:33.569,0:15:36.870
network controller, to control the

0:15:35.490,0:15:38.639
emulator, which is gonna be basically

0:15:36.870,0:15:40.920
doing the task that we were doing right

0:15:38.639,0:15:43.410
now when we were coming up with

0:15:40.920,0:15:47.040
a value for this steering angle such

0:15:43.410,0:15:48.660
that we can reach destination. And 

0:15:47.040,0:15:50.839
destination, like "success" is

0:15:48.660,0:15:54.649
determined by two factors:

0:15:50.839,0:15:59.100
closeness to the docking station and the

0:15:54.649,0:16:00.870
orientation of the trailer. So this is the

0:15:59.100,0:16:03.689
overall diagram. You are going to have a 

0:16:00.870,0:16:05.999
neural net, a controller, which was me right now

0:16:03.689,0:16:07.920
following your suggestions through the

0:16:05.999,0:16:11.850
chat which is providing you this

0:16:07.920,0:16:14.009
steering signal at the discrete

0:16:11.850,0:16:16.259
time interval k. Then we have a

0:16:14.009,0:16:18.329
trailer-truck kinematics which are the

0:16:16.259,0:16:20.129
equations that allowed me to 

0:16:18.329,0:16:24.389
tell you what is the next configuration

0:16:20.129,0:16:26.360
of the truck which is 

0:16:24.389,0:16:28.860
giving you the next state, given that you

0:16:26.360,0:16:31.860
provide the previous state inside and

0:16:28.860,0:16:32.900
then the steering signal. And this Delta

0:16:31.860,0:16:35.840
here is simply

0:16:32.900,0:16:37.700
time delay that tells you

0:16:35.840,0:16:40.370
that this is the next state. 

0:16:37.700,0:16:43.330
These are 

0:16:40.370,0:16:46.070
diagrams from the

0:16:43.330,0:16:47.900
electronics, like Electrical Engineering

0:16:46.070,0:16:49.730
diagrams, because

0:16:47.900,0:16:54.140
there was no computer

0:16:49.730,0:16:58.030
science back in the day. Alright,

0:16:54.140,0:17:01.520
so a state k is fed to the controller

0:16:58.030,0:17:03.950
which provides a steering signal k

0:17:01.520,0:17:08.240
between -1 in this case and +1

0:17:03.950,0:17:12.500
for the truck. So they kind of use a Tanh

0:17:08.240,0:17:15.110
at the output. At the time index is k. Each

0:17:12.500,0:17:18.470
time cycle, the truck backs up by a fixed

0:17:15.110,0:17:21.200
small distance. So these are the

0:17:18.470,0:17:24.470
equations for the trailer-truck with

0:17:21.200,0:17:27.860
several trucks. You had the location of

0:17:24.470,0:17:29.540
the x and y of the cab, and then, 

0:17:27.860,0:17:32.900
given that you know the distance,

0:17:29.540,0:17:34.610
the length both of the the cab and also

0:17:32.900,0:17:39.100
of the trailers,

0:17:34.610,0:17:43.960
you can estimate what is the

0:17:39.100,0:17:47.450
variation of the angle given the

0:17:43.960,0:17:48.290
input phi. The phi is this negative angle

0:17:47.450,0:17:53.150
because it's on the right-hand

0:17:48.290,0:17:54.830
side. So we have that s is the signed speed

0:17:53.150,0:17:57.350
so you can go forward and backward and

0:17:54.830,0:17:59.900
then phi is this negative steering angle,

0:17:57.350,0:18:01.450
positive angles being on

0:17:59.900,0:18:06.290
the right-hand side so it's like

0:18:01.450,0:18:08.680
swapped. And then x and y is the

0:18:06.290,0:18:12.860
location here at the back of the of the cab.

0:18:08.680,0:18:15.710
Notice now that basically you have the x

0:18:12.860,0:18:18.590
and y position of the trailer is

0:18:15.710,0:18:21.860
actually determined by the x and y

0:18:18.590,0:18:25.580
position of the cab and the distance d1

0:18:21.860,0:18:27.950
and the theta_1. Okay so before I was

0:18:25.580,0:18:31.220
telling you that we had

0:18:27.950,0:18:33.710
six values for the state, but as you can

0:18:31.220,0:18:35.780
tell from now, we just need four values.

0:18:33.710,0:18:38.930
You have the x and y, and you have

0:18:35.780,0:18:41.420
the theta_0 which is the

0:18:38.930,0:18:43.280
angle of the cab and then theta_1 that

0:18:41.420,0:18:46.250
is the angle of the trailer,

0:18:43.280,0:18:49.400
so you have only four

0:18:46.250,0:18:51.740
independent values. Here these x and y

0:18:49.400,0:18:55.180
of the trailer is completely determined

0:18:51.740,0:19:00.680
given these other values.

0:18:55.180,0:19:04.070
Question: Aren't these velocities? So

0:19:00.680,0:19:06.200
these are the equations, yes so this is

0:19:04.070,0:19:08.210
how the the position changes, so

0:19:06.200,0:19:10.850
these are velocities, but whenever you

0:19:08.210,0:19:14.690
have a state, the state in this case

0:19:10.850,0:19:16.730
is x, y, theta_0, theta_1, and then whenever

0:19:14.690,0:19:17.270
you'd like to write the equation of the

0:19:16.730,0:19:19.340
motion,

0:19:17.270,0:19:22.100
you're gonna write the

0:19:19.340,0:19:25.790
variation in time, sothe

0:19:22.100,0:19:28.010
velocity of x, velocity over y, the

0:19:25.790,0:19:29.930
angular velocity over this guy, and the

0:19:28.010,0:19:32.690
angular velocity of the other guy are

0:19:29.930,0:19:34.400
gonna be expressed by these equations in

0:19:32.690,0:19:36.650
continuous-time. Then we're going to be

0:19:34.400,0:19:39.950
discretizing them since we are using a

0:19:36.650,0:19:42.380
computer. But this is how we will

0:19:39.950,0:19:46.610
express a dynamic model,

0:19:42.380,0:19:48.770
a model that evolves in time. All

0:19:46.610,0:19:50.240
right so we have the equations. Let's

0:19:48.770,0:19:53.300
figure out now how we train these

0:19:50.240,0:19:55.670
networks. So this is how we train the

0:19:53.300,0:19:58.370
network for emulating the truck,

0:19:55.670,0:20:00.650
trailer-truck kinematics. On the left

0:19:58.370,0:20:02.540
hand side we provide a random input

0:20:00.650,0:20:06.980
which is going to be is going to be like

0:20:02.540,0:20:09.650
a random initial value for the

0:20:06.980,0:20:12.160
steering angle and then we provide this

0:20:09.650,0:20:14.990
random steering angle to the truck

0:20:12.160,0:20:17.480
dynamics which is going to tell me: Given

0:20:14.990,0:20:20.090
the previous state, what is what is going

0:20:17.480,0:20:21.710
to be the next state? And then on the

0:20:20.090,0:20:24.110
bottom part I'm gonna have my first

0:20:21.710,0:20:26.300
network which is gonna be trained as a

0:20:24.110,0:20:28.040
regressor and it's going to

0:20:26.300,0:20:30.770
be trying to minimize the difference

0:20:28.040,0:20:34.130
between the actual next state

0:20:30.770,0:20:36.410
and this state that is predicted. Then

0:20:34.130,0:20:40.100
the difference between the prediction

0:20:36.410,0:20:44.930
and the actual ground truth is used in

0:20:40.100,0:20:46.730
order to, and the

0:20:44.930,0:20:50.000
term they are using the article is "adapt

0:20:46.730,0:20:53.450
the weights of this network", which is

0:20:50.000,0:20:55.790
basically train the network, so

0:20:53.450,0:20:58.340
how you how do you update the weights of

0:20:55.790,0:20:59.870
the network? The weights of the network

0:20:58.340,0:21:02.330
are updated by

0:20:59.870,0:21:04.400
using this error, so question now is

0:21:02.330,0:21:06.590
going to be for you:

0:21:04.400,0:21:10.010
What kind of loss function are they

0:21:06.590,0:21:12.950
using here? Since the signal that is used

0:21:10.010,0:21:15.440
to update these weights is actually

0:21:12.950,0:21:18.830
the difference between the target and

0:21:15.440,0:21:21.230
the actual prediction.

0:21:18.830,0:21:24.049
You should be able to tell me now, it's

0:21:21.230,0:21:26.769
actually in the midterm right now, it's

0:21:24.049,0:21:26.769
one of the question.

0:21:26.909,0:21:33.419
MSE. Why MSE? Because if you compute the

0:21:30.090,0:21:34.979
derivative of the MSE you get the

0:21:33.419,0:21:38.999
difference 

0:21:34.979,0:21:40.799
between

0:21:38.999,0:21:43.320
your prediction and the 

0:21:40.799,0:21:47.359
target.So this difference,

0:21:43.320,0:21:50.519
which is here swapped, right?

0:21:47.359,0:21:53.909
is actually used here to change the

0:21:50.519,0:21:55.799
values. In our course we perform

0:21:53.909,0:21:58.049
gradient descent, so you get the

0:21:55.799,0:22:00.210
positive Delta, you have

0:21:58.049,0:22:02.340
prediction minus ground truth and then you

0:22:00.210,0:22:04.109
use that one to compute the partial

0:22:02.340,0:22:07.619
derivatives, and then you subtract that

0:22:04.109,0:22:08.849
to the parameter, such that you go in

0:22:07.619,0:22:11.309
the opposite direction. Here they

0:22:08.849,0:22:13.379
actually use the inverted sign,

0:22:11.309,0:22:16.619
this prediction minus the ground truth

0:22:13.379,0:22:18.779
is factor for adapting,

0:22:16.619,0:22:20.999
which is changing,

0:22:18.779,0:22:25.460
these parameters, but basically is the

0:22:20.999,0:22:28.169
same thing. There is a question: Why are we

0:22:25.460,0:22:30.090
training the emulator if you already

0:22:28.169,0:22:32.419
have a model for the track movement?

0:22:30.090,0:22:35.700
Okay that's a very good question.

0:22:32.419,0:22:37.590
Because in this case we have equations

0:22:35.700,0:22:38.970
and therefore we could actually get a

0:22:37.590,0:22:42.840
partial derivatives through these

0:22:38.970,0:22:45.779
questions but you may not have the

0:22:42.840,0:22:47.970
equations, let's say you have a

0:22:45.779,0:22:52.349
much more complex system, you may just

0:22:47.970,0:22:55.799
observe several experts driving

0:22:52.349,0:22:59.090
this you know complex systems and then

0:22:55.799,0:23:00.929
you actually, through this sequence of

0:22:59.090,0:23:03.359
trajectories,

0:23:00.929,0:23:06.570
sequence of

0:23:03.359,0:23:09.590
states variables, you can learn a network

0:23:06.570,0:23:12.299
that is able to emulate what is the

0:23:09.590,0:23:14.429
kinematics of

0:23:12.299,0:23:18.899
this system, okay?

0:23:14.429,0:23:22.499
That was the answer for Joseph. Alright,

0:23:18.899,0:23:24.269
cool. So right now let's see how this

0:23:22.499,0:23:26.869
keeps going, or maybe 

0:23:24.269,0:23:30.960
let me actually switch to

0:23:26.869,0:23:33.239
this guy here. Right so let's actually

0:23:30.960,0:23:36.989
start training this stuff. So we

0:23:33.239,0:23:39.359
get Torch, and then we're

0:23:36.989,0:23:39.950
gonna be running this for loop at the

0:23:39.359,0:23:42.110
beginning.

0:23:39.950,0:23:44.540
And so what happens here is gonna be, you

0:23:42.110,0:23:47.750
know, we provide some random initial

0:23:44.540,0:23:50.270
steering angle and then we use

0:23:47.750,0:23:52.250
the kinematics model to learn what is

0:23:50.270,0:23:54.500
the connection between previous state

0:23:52.250,0:23:56.020
and next state. Whenever the track goes

0:23:54.500,0:24:00.560
outside we just kill it,

0:23:56.020,0:24:02.570
and these keeps going until we we

0:24:00.560,0:24:05.960
have enough points such that we can

0:24:02.570,0:24:08.510
train these network to emulate the

0:24:05.960,0:24:10.040
trailer-truck kinematics. Again,

0:24:08.510,0:24:12.230
in this case it wouldn't be necessary

0:24:10.040,0:24:13.670
because we have the equations, but

0:24:12.230,0:24:16.160
let's say we don't have the equations

0:24:13.670,0:24:18.260
but we just have observations

0:24:16.160,0:24:20.810
from the real world, then you

0:24:18.260,0:24:22.610
actually have to 

0:24:20.810,0:24:25.430
learn those functions such that

0:24:22.610,0:24:29.180
we can differentiate from, we can

0:24:25.430,0:24:31.640
run gradients through. So if we keep going

0:24:29.180,0:24:34.400
like that my computer is gonna crash.

0:24:31.640,0:24:35.750
So right now you can see that this is

0:24:34.400,0:24:38.750
taking forever. Why is taking forever?

0:24:35.750,0:24:40.130
Because there is this visualization, so

0:24:38.750,0:24:44.480
in this case I turn off the

0:24:40.130,0:24:46.490
visualization such that it doesn't draw

0:24:44.480,0:24:49.790
things there and then I can run now for

0:24:46.490,0:24:51.620
10,000 times. Oh okay, and

0:24:49.790,0:24:54.410
this happened because I interrupted the

0:24:51.620,0:24:55.300
script, okay how

0:24:54.410,0:24:59.840
lovely.

0:24:55.300,0:25:02.840
Okay boom. This is quite quick 

0:24:59.840,0:25:05.540
because it doesn't have the

0:25:02.840,0:25:10.810
rendering. [Student] So with the emulator

0:25:05.540,0:25:14.690
you are emulating what players playing the game would do?

0:25:10.810,0:25:17.420
[Alfredo] So the emulator here is

0:25:14.690,0:25:19.690
gonna be trying to learn what is the

0:25:17.420,0:25:22.970
next state given the previous state

0:25:19.690,0:25:25.370
given I provide a specific random

0:25:22.970,0:25:28.400
steering signal here. So given a

0:25:25.370,0:25:30.680
state and given a steering angle I try

0:25:28.400,0:25:32.600
to learn what is the next state, and this

0:25:30.680,0:25:36.230
is coming from the ground truth which is

0:25:32.600,0:25:37.640
this box here. This is not a

0:25:36.230,0:25:40.160
recurrent net, it's just a normal net,

0:25:37.640,0:25:43.190
you have an input which is

0:25:40.160,0:25:45.080
state plus action and then the output is

0:25:43.190,0:25:48.880
going to be just action, there is no

0:25:45.080,0:25:51.850
recurrence right now. The

0:25:48.880,0:25:55.420
signals are always random at every step,

0:25:51.850,0:25:57.340
the steering signal is random. The

0:25:55.420,0:26:00.600
state,I collect the whole trajectory

0:25:57.340,0:26:04.420
while I input a random steering angle.

0:26:00.600,0:26:07.840
Okay, very long question: Does this

0:26:04.420,0:26:10.150
matter that the

0:26:07.840,0:26:12.010
data you're collecting

0:26:10.150,0:26:14.920
is a bit different from the

0:26:12.010,0:26:17.680
human test time action? The data you're

0:26:14.920,0:26:21.250
collecting changes directions rapidly

0:26:17.680,0:26:24.010
frequently.

0:26:21.250,0:26:26.380
There is no time. Here my training,

0:26:24.010,0:26:30.490
we haven't talked about training yet...

0:26:26.380,0:26:33.550
So this is gonna be a just

0:26:30.490,0:26:36.370
normal neural net that given a input

0:26:33.550,0:26:41.080
state is gonna map it to the

0:26:36.370,0:26:45.010
output state given a specific angle for

0:26:41.080,0:26:47.680
the wheels, there is no time. So you

0:26:45.010,0:26:53.400
have one state you have one angle that's

0:26:47.680,0:26:56.550
the output, no time right now. 

0:26:53.400,0:26:59.350
Okay so we go here, these are my inputs

0:26:56.550,0:27:01.600
and the outputs, like that I collected

0:26:59.350,0:27:06.520
over these trajectories so if you check

0:27:01.600,0:27:08.410
here I just have the initial

0:27:06.520,0:27:11.710
initial state, I get the state from the

0:27:08.410,0:27:13.690
truck, then I have a phi which is my

0:27:11.710,0:27:16.810
angle which is going to be

0:27:13.690,0:27:19.930
something between random minus 0.5, so

0:27:16.810,0:27:22.930
from -45 to +45.

0:27:19.930,0:27:24.820
Then I have my input, so it's gonna be

0:27:22.930,0:27:26.260
the state plus the angle and

0:27:24.820,0:27:27.850
then the output is going to be the

0:27:26.260,0:27:32.290
output of the truck

0:27:27.850,0:27:34.630
which has step with angle phi. 

0:27:32.290,0:27:40.330
Alright, so we have this thing here, I can

0:27:34.630,0:27:43.140
can create my network and then I

0:27:40.330,0:27:43.140
can start

0:27:43.250,0:27:49.460
training my network. And this will keep

0:27:46.640,0:27:51.560
going until forever, but then basically

0:27:49.460,0:27:54.980
here we are trying to get a neural net

0:27:51.560,0:27:58.160
which is simply a couple of layers, here

0:27:54.980,0:28:00.320
right so Linear, ReLU, Linear. We start

0:27:58.160,0:28:03.410
from steering 

0:28:00.320,0:28:06.110
size which is 1

0:28:03.410,0:28:10.490
plus the state size which was

0:28:06.110,0:28:14.030
6, like the x and y and

0:28:10.490,0:28:16.730
angle for both 

0:28:14.030,0:28:20.000
the cab and the trailer. Then you

0:28:16.730,0:28:22.550
have a number of hidden units which are

0:28:20.000,0:28:23.870
gonna be described now in the paper, then

0:28:22.550,0:28:27.250
have a ReLU, and then a

0:28:23.870,0:28:27.250
final Linear output.

0:28:27.490,0:28:37.780
MSE and SGD. Alright, let's go

0:28:32.900,0:28:42.220
back to the presentation. So

0:28:37.780,0:28:45.200
Figure 3, which is the this one, shows 

0:28:42.220,0:28:49.160
how to train the emulator. So the

0:28:45.200,0:28:51.080
truck backs up randomly and the

0:28:49.160,0:28:53.540
emulator learns to generate the next

0:28:51.080,0:28:56.900
position state vector given the present

0:28:53.540,0:28:58.850
state vector and the steering signal. And

0:28:56.900,0:29:01.910
you can hear now my computer fan

0:28:58.850,0:29:05.540
spinning because it's training ok. Sorry

0:29:01.910,0:29:07.850
for the bad audio. Alright, so this is how

0:29:05.540,0:29:09.730
we train this system, how do you train

0:29:07.850,0:29:13.640
the controller. So this is state

0:29:09.730,0:29:15.350
transition flow diagram. C represents

0:29:13.640,0:29:17.900
the controller, so it's another neural net

0:29:15.350,0:29:20.960
whereas T represents the truck and

0:29:17.900,0:29:23.000
trailer emulator, So all the truck

0:29:20.960,0:29:29.240
kinematics or the trailer emulator,

0:29:23.000,0:29:33.200
either or. So how is this thing working?

0:29:29.240,0:29:35.450
How is now time added to the

0:29:33.200,0:29:38.630
system? So we start with this controller C,

0:29:35.450,0:29:43.100
this controller C, we said, provides

0:29:38.630,0:29:46.940
what? The steering angle to the truck or

0:29:43.100,0:29:50.690
the truck emulator. So the controller

0:29:46.940,0:29:53.900
provides an angle given that is fed with

0:29:50.690,0:29:57.140
the initial state, which

0:29:53.900,0:30:01.640
we can call h of K minus 1 timestamp.

0:29:57.140,0:30:03.800
And if we provide

0:30:01.640,0:30:07.520
these previous states to the controller

0:30:03.800,0:30:09.980
and the truck, the truck we basically get

0:30:07.520,0:30:12.920
the next state. So you can think about

0:30:09.980,0:30:19.030
these two guys as just one element

0:30:12.920,0:30:22.640
of a recurrent network which has

0:30:19.030,0:30:24.050
no input, or well it could have an input

0:30:22.640,0:30:26.210
but the input is not connected

0:30:24.050,0:30:28.610
so this is like one of

0:30:26.210,0:30:30.650
the multiple cells we usually seen in a

0:30:28.610,0:30:34.300
recurrent net, but there is a different

0:30:30.650,0:30:37.580
diagram inside. So how do we train this

0:30:34.300,0:30:40.070
item? Well, you already know

0:30:37.580,0:30:42.650
the answer, right? So you get this one

0:30:40.070,0:30:44.390
down here, we don't have any input on the

0:30:42.650,0:30:46.160
bottom, and then you stack

0:30:44.390,0:30:47.900
another one, you stack on another one, and

0:30:46.160,0:30:50.540
then you keep going until you actually

0:30:47.900,0:30:52.910
start from the initial location of the

0:30:50.540,0:30:55.430
truck which is the initial hidden state

0:30:52.910,0:30:58.300
or which is basically the initial

0:30:55.430,0:31:01.460
truck location and configuration. 

0:30:58.300,0:31:02.780
And then, on the right hand side

0:31:01.460,0:31:05.210
you keep going

0:31:02.780,0:31:09.020
and then whatever until the end,

0:31:05.210,0:31:11.330
where you reach the final point, which

0:31:09.020,0:31:14.360
final condition can be a few of the

0:31:11.330,0:31:17.120
following: Run out of steps, jackknife or

0:31:14.360,0:31:19.070
third part: You hit one of the edges and

0:31:17.120,0:31:22.460
then I check what is the distance

0:31:19.070,0:31:24.560
between your back and the docking

0:31:22.460,0:31:27.710
station and then I check what is your

0:31:24.560,0:31:30.830
angle or your orientation of the

0:31:27.710,0:31:33.800
truck which should have been horizontal.

0:31:30.830,0:31:36.860
So those are the answers to

0:31:33.800,0:31:38.600
the question: What are the terminal

0:31:36.860,0:31:42.470
conditions. There are three terminal

0:31:38.600,0:31:45.890
conditions: Jackknifing, running out of

0:31:42.470,0:31:49.550
steps, or hitting an edge and whenever

0:31:45.890,0:31:52.520
you hit an edge you want to

0:31:49.550,0:31:54.200
actually minimize now what is the

0:31:52.520,0:31:56.690
distance between the

0:31:54.200,0:31:59.990
docking station and then you want to try

0:31:56.690,0:32:02.570
to minimize whatever angle you get 

0:31:59.990,0:32:06.629
for the trailer.

0:32:02.570,0:32:10.230
Cool. So figure five: Training the

0:32:06.629,0:32:12.389
controller with backpropagation. As you

0:32:10.230,0:32:14.220
you saw before in the previous

0:32:12.389,0:32:16.710
diagram we were 

0:32:14.220,0:32:18.509
training the emulator, we have

0:32:16.710,0:32:23.009
something similar with this feedback

0:32:18.509,0:32:25.620
loop. The final state, so after

0:32:23.009,0:32:28.230
you complete this whole trajectory, the

0:32:25.620,0:32:31.529
final state will be ending with some

0:32:28.230,0:32:33.480
specific configuration. I enforce this

0:32:31.529,0:32:36.629
final state to be as close as possible

0:32:33.480,0:32:39.389
to my target state which means you want

0:32:36.629,0:32:41.340
to have the x_trailer as close

0:32:39.389,0:32:43.200
as possible to the dock trailer, the 

0:32:41.340,0:32:46.769
y_trailer as close as possible to

0:32:43.200,0:32:49.200
y_dock and then the final angle of the

0:32:46.769,0:32:51.990
trailer, you know horizontals so equal to 0.

0:32:49.200,0:32:55.620
Then you make the difference and you send

0:32:51.990,0:32:58.259
the difference back to adapt

0:32:55.620,0:33:00.299
these weights, but of course it's not

0:32:58.259,0:33:02.879
just a line, the whole thing goes through

0:33:00.299,0:33:05.190
as usual chain rule.

0:33:02.879,0:33:07.789
So this actually travels through

0:33:05.190,0:33:10.409
all previous T/C, so it goes inside

0:33:07.789,0:33:13.080
modules. The visualization shows that

0:33:10.409,0:33:16.139
only the 'C', the controller blocks, are

0:33:13.080,0:33:19.590
updated, also proportionally to the final

0:33:16.139,0:33:20.610
error, which implies an MSE loss. Again,

0:33:19.590,0:33:23.940
the other thing that we came up with

0:33:20.610,0:33:27.210
before. Cool.

0:33:23.940,0:33:31.440
So the initial position is set at random,

0:33:27.210,0:33:34.220
the track backs up until it stops. Final

0:33:31.440,0:33:36.269
error is just for back-propagation and

0:33:34.220,0:33:40.519
this is back-propagation through time

0:33:36.269,0:33:43.710
with a variable unrolling period k. 

0:33:40.519,0:33:46.110
So the weight changes in C, the

0:33:43.710,0:33:49.379
controller, are taken as the sum of the

0:33:46.110,0:33:53.190
tentative changes. What is the

0:33:49.379,0:33:58.309
meaning of this sentence? Well now you

0:33:53.190,0:34:02.790
maybe appreciate why PyTorch is

0:33:58.309,0:34:07.020
accumulating the gradients every time.

0:34:02.790,0:34:08.790
Do see the point? So in this case you get

0:34:07.020,0:34:12.230
this gradient coming back from the

0:34:08.790,0:34:14.540
future back to the past, and then the

0:34:12.230,0:34:16.880
meaningful thing is gonna be

0:34:14.540,0:34:19.500
accumulating all these gradients, right?

0:34:16.880,0:34:23.070
Because we have reused the same module

0:34:19.500,0:34:25.230
multiple times, when you go and perform

0:34:23.070,0:34:30.419
back-propagation this back-propagation

0:34:25.230,0:34:33.270
will sum up things, as many times as we

0:34:30.419,0:34:33.570
went through this module.

0:34:33.270,0:34:36.570
Right?

0:34:33.570,0:34:38.580
That's why PyTorch accumulates gradient

0:34:36.570,0:34:41.460
whenever you compute backdrop. If it

0:34:38.580,0:34:42.900
would be just computing them

0:34:41.460,0:34:45.110
and replacing whatever it was before,

0:34:42.900,0:34:48.750
then you just have the gradients of the

0:34:45.110,0:34:51.350
oldest iteration,

0:34:48.750,0:34:54.240
the one most back in the past.

0:34:51.350,0:34:57.570
Instead in this case, which what which is

0:34:54.240,0:35:00.660
written here, which say is that the all

0:34:57.570,0:35:02.550
the tentative changes are summed

0:35:00.660,0:35:06.920
together means you accumulate

0:35:02.550,0:35:09.840
the gradient over time. Okay, cool.

0:35:06.920,0:35:13.470
Finally repeat another initial position

0:35:09.840,0:35:15.720
back up until he stops. So the

0:35:13.470,0:35:18.390
network detail, this is

0:35:15.720,0:35:21.870
architecture diagrams of network

0:35:18.390,0:35:24.210
architectures back in in the 90's you

0:35:21.870,0:35:27.150
start with six values for the state x

0:35:24.210,0:35:30.440
and y and theta, x and Y and theta for

0:35:27.150,0:35:34.050
the two items, then you get through these

0:35:30.440,0:35:36.390
items here that are called

0:35:34.050,0:35:40.020
potentiometers which are

0:35:36.390,0:35:42.000
basically variable resistance which are

0:35:40.020,0:35:44.460
representing these variable

0:35:42.000,0:35:45.960
weights. Variable weights as in weights

0:35:44.460,0:35:48.810
that can be tuned, okay? So these are

0:35:45.960,0:35:50.670
tunable weights, so weights in a neural net.

0:35:48.810,0:35:52.350
Okay but again this is the symbol

0:35:50.670,0:35:56.010
for a tunable resistor.

0:35:52.350,0:35:59.280
You have 25 of these guys,

0:35:56.010,0:36:01.530
so from 6 we go to 25 and then from 25

0:35:59.280,0:36:04.430
we go to 1 which is a steering signal.

0:36:01.530,0:36:07.110
So first affine transformation squashing,

0:36:04.430,0:36:09.300
second affine transformation squashing

0:36:07.110,0:36:12.540
and then this guy is gonna be the

0:36:09.300,0:36:16.790
emulator, so you go from 7 which is

0:36:12.540,0:36:19.620
6 of the state plus the steering angle

0:36:16.790,0:36:23.310
to 45. So you have a fine transformation

0:36:19.620,0:36:26.100
squashing, and then from these final 45

0:36:23.310,0:36:28.980
you have an affine transformation to 6

0:36:26.100,0:36:31.830
which is the final next state.

0:36:28.980,0:36:36.150
Cool.

0:36:31.830,0:36:39.360
So that's it, right? So analogous to a

0:36:36.150,0:36:42.240
neural net having a number of affine

0:36:39.360,0:36:45.390
transformations equal to 4 times the

0:36:42.240,0:36:48.990
number of backing up steps. So for every

0:36:45.390,0:36:52.590
trajectory we train a net

0:36:48.990,0:36:55.620
which has a length that is

0:36:52.590,0:36:58.910
depending on how many time steps this

0:36:55.620,0:37:04.800
specific truck took in order to reach

0:36:58.910,0:37:08.700
one stopping 

0:37:04.800,0:37:11.790
condition...

0:37:08.700,0:37:14.490
yeah, stopping condition.

0:37:11.790,0:37:16.620
Alright so the number of steps

0:37:14.490,0:37:19.080
varies with the initial position of the

0:37:16.620,0:37:19.410
trailer 

0:37:19.080,0:37:22.680
or the truck and the trailer.

0:37:19.410,0:37:26.040
So you train the core

0:37:22.680,0:37:29.370
item of this network, which has several

0:37:26.040,0:37:33.300
steps or several layers, the length

0:37:29.370,0:37:36.870
of these network changes based on each

0:37:33.300,0:37:39.480
specific episode and then we train this

0:37:36.870,0:37:41.550
stuff with back-propagation and each

0:37:39.480,0:37:42.360
module is the same module replicated

0:37:41.550,0:37:44.790
multiple times

0:37:42.360,0:37:47.520
therefore the gradients have to be summed

0:37:44.790,0:37:51.200
as you go through, as that's what

0:37:47.520,0:37:55.260
PyTorch does. Makes sense? Cool.

0:37:51.200,0:37:56.880
So these are a few examples: You

0:37:55.260,0:38:00.420
start with this initial position and

0:37:56.880,0:38:03.840
then after a few steps the network

0:38:00.420,0:38:06.210
manages to reach the destination. Another

0:38:03.840,0:38:09.960
one is here, they started with the

0:38:06.210,0:38:12.450
trailer pointing away from the dock and

0:38:09.960,0:38:14.520
you can see here how it manages to

0:38:12.450,0:38:16.980
circulate around and to get you know

0:38:14.520,0:38:18.870
back to the correct location. And the

0:38:16.980,0:38:21.390
final state is horizontal,

0:38:18.870,0:38:23.520
so it looks almost

0:38:21.390,0:38:26.340
horizontal. Or this ono, you start

0:38:23.520,0:38:28.410
orthogonal in a jackknife position right,

0:38:26.340,0:38:30.180
that's really like being bastards but

0:38:28.410,0:38:34.650
nevertheless the network

0:38:30.180,0:38:39.530
can figure out how to solve this

0:38:34.650,0:38:42.240
very difficult configuration. And then,

0:38:39.530,0:38:43.560
this is also really annoying

0:38:42.240,0:38:46.830
but you know the network doesn't

0:38:43.560,0:38:49.460
complain. Be like on your network... no,

0:38:46.830,0:38:49.460
just kidding.

0:38:54.910,0:39:01.720
Okay additional resources, full working

0:38:57.910,0:39:03.130
demo iss offered here on

0:39:01.720,0:39:06.880
this link. I'm gonna be showing you

0:39:03.130,0:39:09.579
because in the notebook the code stops

0:39:06.880,0:39:13.779
there. So here I just show you how you

0:39:09.579,0:39:16.809
train the emulator and we got like

0:39:13.779,0:39:22.349
an MSE loss down to a very very tiny

0:39:16.809,0:39:25.390
value, 0.00...

0:39:22.349,0:39:28.150
well you can read this number.

0:39:25.390,0:39:32.440
Right and then this is my

0:39:28.150,0:39:35.559
value for the for the testing set,

0:39:32.440,0:39:39.069
so this is going to be 38 micro MSE if

0:39:35.559,0:39:42.700
you want to call it. Here if someone

0:39:39.069,0:39:46.420
wants, an extra grade maybe, you can add

0:39:42.700,0:39:50.559
the code for training the controller and

0:39:46.420,0:39:53.079
it's not that trivial because we

0:39:50.559,0:39:56.829
cover how to make it work in the 

0:39:53.079,0:40:01.059
class but a bit finicky. So I just show

0:39:56.829,0:40:05.200
you a final version, you can even copy

0:40:01.059,0:40:07.869
from here if you want, and

0:40:05.200,0:40:13.269
if you can submit would be nice,

0:40:07.869,0:40:15.160
you can get a nice reward.

0:40:13.269,0:40:18.609
So here we can start with a random position

0:40:15.160,0:40:21.970
and then you can drive using the

0:40:18.609,0:40:25.720
controller, let's increase the speed, okay

0:40:21.970,0:40:28.720
and boom! Another random position, okay

0:40:25.720,0:40:32.440
it's too easy. Let's make something a bit

0:40:28.720,0:40:34.599
annoying, so for trailer let's say

0:40:32.440,0:40:40.720
180° and let's have

0:40:34.599,0:40:45.210
this one 0°. Change angle. Okay so

0:40:40.720,0:40:48.770
this is really annoying and go

0:40:45.210,0:40:48.770
see? Back and...

0:40:49.790,0:40:56.060
there we go, boom. So here you have

0:40:53.390,0:40:57.830
the code, it's training in your browser, you

0:40:56.060,0:41:00.740
can go also at the bottom of this page

0:40:57.830,0:41:06.230
and you have this source in GitHub, so

0:41:00.740,0:41:09.230
you can or even are encouraged to

0:41:06.230,0:41:13.670
port this project here which is written

0:41:09.230,0:41:16.040
in JavaScript to PyTorch. It's going to

0:41:13.670,0:41:19.100
be very a very good exercise for you to

0:41:16.040,0:41:22.850
learn. We would have actually a running

0:41:19.100,0:41:26.650
notebook, which is left as

0:41:22.850,0:41:30.770
an exercise for you and you could get an

0:41:26.650,0:41:33.470
additional grade I guess. Alright, so that

0:41:30.770,0:41:36.320
was it for today's class. I hope you

0:41:33.470,0:41:38.990
enjoyed, let me see if there are

0:41:36.320,0:41:42.620
questions. What if we train a policy

0:41:38.990,0:41:44.450
gradient? Yeah we don't know about 

0:41:42.620,0:41:45.620
reinforcement learning,

0:41:44.450,0:41:51.020
I don't know anything about

0:41:45.620,0:41:52.820
reinforcement learning, sorry. [Student] I'm still

0:41:51.020,0:41:54.920
confused about the architecture, can we

0:41:52.820,0:41:59.630
look at the diagram of that again? [Alfredo] Yeah,

0:41:54.920,0:42:04.670
of course. So basically the

0:41:59.630,0:42:08.290
controller goes from 6 to 25 and then

0:42:04.670,0:42:13.220
from 25 to 1, and they use some kind of

0:42:08.290,0:42:17.360
tanh for your activation. So 6

0:42:13.220,0:42:20.330
to 25, 25 to 1 and this is the controller.

0:42:17.360,0:42:23.270
And instead for the 

0:42:20.330,0:42:27.170
trailer-truck emulator we go from 7,

0:42:23.270,0:42:32.420
which is 6: The x and y and the

0:42:27.170,0:42:35.630
angle times 2 which is 6, plus 1 equal 7. So from

0:42:32.420,0:42:38.660
7 to 45 and then for from from 45 to 6.

0:42:35.630,0:42:40.400
So this is my predictive model, the model

0:42:38.660,0:42:43.610
that predicts the future given the past

0:42:40.400,0:42:46.370
in the actual input action. And that's

0:42:43.610,0:42:49.370
how I implemented this one here. So I

0:42:46.370,0:42:52.220
have my state size which is 6, x and y and

0:42:49.370,0:42:57.080
theta times 2, and steering is 1 as it's just the

0:42:52.220,0:43:00.290
angle, and we say we have 45 units,

0:42:57.080,0:43:02.780
so we have 45 units here so we go from

0:43:00.290,0:43:03.320
steering size plus

0:43:02.780,0:43:07.280
state size

0:43:03.320,0:43:09.980
which is 7 to this 45, then I have ReLU.

0:43:07.280,0:43:12.470
Again the it looks like they used a tanh

0:43:09.980,0:43:14.480
here so okay you can write tanh here,

0:43:12.470,0:43:17.990
and then you have a linear that

0:43:14.480,0:43:20.350
goes from these 45 to state size, which

0:43:17.990,0:43:23.150
is 6, which is going to be the next

0:43:20.350,0:43:25.760
output here. So there is a

0:43:23.150,0:43:27.320
linear output, and again this is also

0:43:25.760,0:43:29.450
something that we just put in the

0:43:27.320,0:43:30.800
midterm, I mean I'm giving you the

0:43:29.450,0:43:34.520
answer of the midterm right now basically.

0:43:30.800,0:43:38.540
[Student] So where are you enforcing that

0:43:34.520,0:43:41.390
the emulator actually emulates the way this

0:43:38.540,0:43:44.540
simulation works? [Alfredo] Yeah,

0:43:41.390,0:43:46.460
here. So emulator training? Yeah, 

0:43:44.540,0:43:49.880
I didn't show you this one,

0:43:46.460,0:43:51.710
you're right. So here I just get

0:43:49.880,0:43:53.780
the length of the training input and I

0:43:51.710,0:43:57.590
get a random permutation so that I pick

0:43:53.780,0:43:59.750
at random. So I have my phi, my

0:43:57.590,0:44:01.790
my angle, and the state which are going

0:43:59.750,0:44:04.280
to be the 7 coordinates is going to

0:44:01.790,0:44:06.050
be picked from the ith location of these

0:44:04.280,0:44:08.930
training inputs, and these training

0:44:06.050,0:44:10.670
inputs are coming down from here,

0:44:08.930,0:44:13.160
whenever I extract it. So you have

0:44:10.670,0:44:16.850
training inputs, inputs are gonna be

0:44:13.160,0:44:19.190
appended to this list, which is this

0:44:16.850,0:44:21.650
input list, you append the

0:44:19.190,0:44:24.170
phi, which is the steering angle, and

0:44:21.650,0:44:27.200
then the initial state which comes from

0:44:24.170,0:44:29.390
the truck. So this is my input and then

0:44:27.200,0:44:31.820
the output is going to be my 

0:44:29.390,0:44:37.130
output state

0:44:31.820,0:44:41.480
of the of the truck. So if you go back

0:44:37.130,0:44:44.450
here you get the phi, the angle, and the

0:44:41.480,0:44:46.550
state are going to be this first item of

0:44:44.450,0:44:48.830
this training input, at the location ith,

0:44:46.550,0:44:50.420
the ith item of the running input,

0:44:48.830,0:44:52.130
and then you get the next state

0:44:50.420,0:44:54.410
prediction which is going to be the output of

0:44:52.130,0:44:57.230
this emulator, which has a linear layer

0:44:54.410,0:44:59.360
as output, right? Cool.

0:44:57.230,0:45:02.390
Then you have the next state which is

0:44:59.360,0:45:05.360
going to be the output at

0:45:02.390,0:45:09.190
the ith location and now you have loss

0:45:05.360,0:45:12.710
which is the criterion, which was an MSE,

0:45:09.190,0:45:15.390
criterion MSE.

0:45:12.710,0:45:17.430
So you have the MSE between the next

0:45:15.390,0:45:20.130
state prediction which is this one and

0:45:17.430,0:45:22.500
the next state, the true next state, then

0:45:20.130,0:45:28.230
I do basically stochastic gradient descent,

0:45:22.500,0:45:29.760
I clean up the gradient... [Student] I see, so

0:45:28.230,0:45:31.110
you're basically training the emulator

0:45:29.760,0:45:35.550
before you're training the rest of the

0:45:31.110,0:45:38.010
next. [Alfredo] I train the emulator only before,

0:45:35.550,0:45:40.830
so we train two models: First model you

0:45:38.010,0:45:42.990
train the emulator, then whenever the

0:45:40.830,0:45:48.600
emulator is trained you train the

0:45:42.990,0:45:51.540
controller which is driving the emulator,

0:45:48.600,0:45:53.160
but the emulator is not longer trained. The

0:45:51.540,0:45:56.970
emulator is trained only once before,

0:45:53.160,0:46:00.450
then we use the network in order to

0:45:56.970,0:46:01.890
train the controller. [Student] So you're first

0:46:00.450,0:46:03.540
training the emulator and then you're

0:46:01.890,0:46:04.830
using the network you trained as

0:46:03.540,0:46:08.550
emulator kind of control.

0:46:04.830,0:46:11.640
[Alfredo] Correct, yeah, so whenever I'm here,

0:46:08.550,0:46:13.610
I already trained the trailer emulator.

0:46:11.640,0:46:15.990
So to train the emulator,

0:46:13.610,0:46:18.630
as I show you right now the code and

0:46:15.990,0:46:20.160
then I can show you also this slide. So

0:46:18.630,0:46:23.310
this was the training of

0:46:20.160,0:46:25.550
the emulator. Tthe kinematics: You have the

0:46:23.310,0:46:29.040
next state given the previous state and

0:46:25.550,0:46:31.680
the angle and then you enforce this

0:46:29.040,0:46:33.870
emulator to learn, to basically do a

0:46:31.680,0:46:37.320
regression and you try to copy the

0:46:33.870,0:46:40.050
output. After you're done

0:46:37.320,0:46:42.180
you actually go and train

0:46:40.050,0:46:45.570
the controller. To train the controller

0:46:42.180,0:46:48.090
you have this chain of

0:46:45.570,0:46:51.780
blocks, which is controller and

0:46:48.090,0:46:53.940
trailer-truck network, and

0:46:51.780,0:46:57.540
then you get a

0:46:53.940,0:47:00.240
trajectory, and then you enforce that the

0:46:57.540,0:47:04.380
final location and the final orientation

0:47:00.240,0:47:07.590
of this trajectory, they must be

0:47:04.380,0:47:09.960
the docking station and 0 for the angle,

0:47:07.590,0:47:12.540
and now you run back-propagation through

0:47:09.960,0:47:15.600
this chain of things, so it's backdrop

0:47:12.540,0:47:17.790
through time in order to adapt, they use

0:47:15.600,0:47:21.330
the term 'adapt' in this paper,

0:47:17.790,0:47:25.050
the weights of the controller such that

0:47:21.330,0:47:25.760
it manages to map the original initial

0:47:25.050,0:47:29.930
random

0:47:25.760,0:47:32.930
position to this final target position

0:47:29.930,0:47:34.820
and orientation configuration, let's call

0:47:32.930,0:47:38.210
it configuration. So we start with a

0:47:34.820,0:47:41.030
random initial configuration which is

0:47:38.210,0:47:44.150
corresponding to position and

0:47:41.030,0:47:47.270
angles, and then you enforce that the

0:47:44.150,0:47:50.480
final output of this sequence

0:47:47.270,0:47:53.990
of modules is going to be giving you the

0:47:50.480,0:47:58.460
the docking station and 0 on the

0:47:53.990,0:48:01.790
backside of the truck. So this is two

0:47:58.460,0:48:04.670
parts: Training first the

0:48:01.790,0:48:08.180
emulator, finish that, then you train

0:48:04.670,0:48:10.730
the controller in order to 

0:48:08.180,0:48:13.670
actually reach a specific goal. The

0:48:10.730,0:48:17.150
number of red boxes here varies and

0:48:13.670,0:48:19.550
it depends on every episode because you

0:48:17.150,0:48:23.120
don't know how many steps are goning be

0:48:19.550,0:48:27.680
required for you to reach destination

0:48:23.120,0:48:32.120
given initial condition. So

0:48:27.680,0:48:34.730
many words I said, oh my God, does it make

0:48:32.120,0:48:39.620
sense? [Student] Yes. [Alfredo] OK, very good.

0:48:34.730,0:48:41.810
Next question. [Student] Somebody did ask this,

0:48:39.620,0:48:44.480
why we needed to train the

0:48:41.810,0:48:48.680
emulator instead of just using the model.

0:48:44.480,0:48:50.930
[Alfredo] Yeah, the answer was that not

0:48:48.680,0:48:55.510
every time you actually have the

0:48:50.930,0:48:59.600
questions of the

0:48:55.510,0:49:01.430
kinematics, so let's say, and this

0:48:59.600,0:49:02.570
is going to be coming up next lesson I

0:49:01.430,0:49:04.910
think whenever I'm going to be talking

0:49:02.570,0:49:07.370
about my own research. I'd like to figure

0:49:04.910,0:49:10.370
out what is the behavior of other cars

0:49:07.370,0:49:13.250
when you drive in a highway, but I can't

0:49:10.370,0:49:15.740
control other cars, I have no idea how

0:49:13.250,0:49:17.630
what is the behavior of other cars,

0:49:15.740,0:49:20.180
so the only way I can learn how other

0:49:17.630,0:49:22.790
cars react to my actions is actually

0:49:20.180,0:49:25.190
through observations and therefore we

0:49:22.790,0:49:27.700
we have some

0:49:25.190,0:49:29.900
cameras mounted on a 30-story building

0:49:27.700,0:49:33.080
looking at the highway

0:49:29.900,0:49:35.170
section and then you

0:49:33.080,0:49:37.130
basically figure out what is the

0:49:35.170,0:49:39.290
interaction between vehicles, and

0:49:37.130,0:49:40.670
therefore we had to learn these forward models

0:49:39.290,0:49:42.650
called predictive model,

0:49:40.670,0:49:45.230
which is figuring out what is going to

0:49:42.650,0:49:49.130
be the reaction of other vehicles given

0:49:45.230,0:49:53.870
your own actions. So in this case, 

0:49:49.130,0:49:56.030
you don't need the emulator but they

0:49:53.870,0:49:58.100
train these emulators such that it's

0:49:56.030,0:50:02.180
more generic, you don't need to have

0:49:58.100,0:50:07.070
differentiable equations. [Student] I see,

0:50:02.180,0:50:08.890
okay. One one more question, so when

0:50:07.070,0:50:11.960
you said the length of this recurrent

0:50:08.890,0:50:14.540
network will be variable, there was

0:50:11.960,0:50:19.040
something about having it be like four

0:50:14.540,0:50:23.330
times the length of the number of steps

0:50:19.040,0:50:24.650
or something like that, could you go into

0:50:23.330,0:50:27.980
that a bit more?

0:50:24.650,0:50:32.330
[Alfredo] Yes, so here we assume that each length of

0:50:27.980,0:50:35.090
each episode is capital K, so the

0:50:32.330,0:50:38.000
lowercase k is the actual

0:50:35.090,0:50:40.760
index, where you go like 0, 1, 2, 3, 4, 5, 

0:50:38.000,0:50:44.930
whatever, so each episode

0:50:40.760,0:50:47.150
has whatever capital K number

0:50:44.930,0:50:52.400
of steps. So capital K is going to

0:50:47.150,0:50:56.390
be different for every episode. So

0:50:52.400,0:50:59.090
each of these two items here, this guy

0:50:56.390,0:51:00.740
here has two affine transformations and

0:50:59.090,0:51:01.700
this guy here has two affine

0:51:00.740,0:51:04.370
transformations,

0:51:01.700,0:51:07.070
so overall the network that you are

0:51:04.370,0:51:11.260
seeing here has four affine

0:51:07.070,0:51:11.260
transformations times capital K.

0:51:11.270,0:51:18.160
[Student] Oh I se, okay. [Alfredo] That's basically one 

0:51:14.330,0:51:20.540
neural net, right? So it's a neural net which is

0:51:18.160,0:51:22.850
not even a recurrent neural net, it's

0:51:20.540,0:51:27.440
just a feed-forward neural net

0:51:22.850,0:51:29.780
with four times capital K number of

0:51:27.440,0:51:32.450
affine transformations. And now you train

0:51:29.780,0:51:34.400
with back prop in order to enforce

0:51:32.450,0:51:36.830
always the same target, so that's

0:51:34.400,0:51:40.190
actually funny to see in this way. So you

0:51:36.830,0:51:42.910
have a neural network which label or

0:51:40.190,0:51:45.800
target is going to be always the same,

0:51:42.910,0:51:48.560
but then the network can change lengths

0:51:45.800,0:51:50.810
and the input can be different. So

0:51:48.560,0:51:53.840
you had you have a network, 

0:51:50.810,0:51:56.090
you input different things, you

0:51:53.840,0:51:57.800
can change the length, the height,

0:51:56.090,0:52:00.890
the depth of the network but you always

0:51:57.800,0:52:02.980
have the same target here. So

0:52:00.890,0:52:05.510
usually when you do regression or

0:52:02.980,0:52:08.420
classification we have a fixed network,

0:52:05.510,0:52:10.850
you input different inputs like here and

0:52:08.420,0:52:13.010
then you have different targets on here,

0:52:10.850,0:52:16.760
target or classes if you're doing

0:52:13.010,0:52:20.900
classification or labels. In

0:52:16.760,0:52:23.359
this case, you have different inputs, the

0:52:20.900,0:52:26.560
target is always fixed and you have you

0:52:23.359,0:52:31.040
know different lengths; so you train a

0:52:26.560,0:52:34.609
network, a variable depth network with

0:52:31.040,0:52:36.800
variable inputs and a fixed target. How

0:52:34.609,0:52:40.100
cool is that?

0:52:36.800,0:52:42.590
[Student] Do we enforce like a maximum length...

0:52:40.100,0:52:47.660
[Alfredo] yeah, of course,

0:52:42.590,0:52:49.280
otherwise you can wooo... Do we need an

0:52:47.660,0:52:52.160
emulator to train the neural net

0:52:49.280,0:52:53.750
emulator? Is the point of having a neural

0:52:52.160,0:52:55.430
net emulator to have a differentiable...

0:52:53.750,0:52:56.810
Yeah that's the point, the whole

0:52:55.430,0:53:01.130
point is to have a differentiable

0:52:56.810,0:53:04.310
emulator, which is not always the case, in

0:53:01.130,0:53:07.220
case of you just have

0:53:04.310,0:53:08.990
observations then you don't have

0:53:07.220,0:53:10.760
gradients, you just have observations. And

0:53:08.990,0:53:12.410
you want to learn a network that allows

0:53:10.760,0:53:15.050
you to tell you what is gonna be the

0:53:12.410,0:53:18.900
Jacobian as you go back.

0:53:15.050,0:53:21.890
More questions? [Student] I have a question more

0:53:18.900,0:53:24.600
related to just like implementation,

0:53:21.890,0:53:27.740
it seems like for training the

0:53:24.600,0:53:30.630
controller we freeze the weights for t

0:53:27.740,0:53:33.210
but we still need to pass the

0:53:30.630,0:53:35.570
gradients through in order to update

0:53:33.210,0:53:38.280
freely each of the cells, is that right? So I

0:53:35.570,0:53:39.870
guess, would we then when we define

0:53:38.280,0:53:42.840
our optimizer we're just essentially

0:53:39.870,0:53:45.450
just feeding it the controller

0:53:42.840,0:53:47.520
parameters, but when we called the

0:53:45.450,0:53:49.160
backwards it's all still connected to

0:53:47.520,0:53:53.120
the same network?

0:53:49.160,0:54:00.180
[Alfredo] So this is gonna be exactly,

0:53:53.120,0:54:03.560
PyTtorch examples, what we have seen

0:54:00.180,0:54:15.510
last week when we were going through the

0:54:03.560,0:54:19.350
DC GAN, so you have an optimizer...

0:54:15.510,0:54:24.000
hold on, where is it,

0:54:19.350,0:54:25.770
you're gonna have an optimizer from the one network 

0:54:24.000,0:54:27.930
and I have an optimizer for the other network,

0:54:25.770,0:54:29.670
that's it, whenever you have the training

0:54:27.930,0:54:31.830
you actually have two distinct training,

0:54:29.670,0:54:34.020
in this case when you train a generative

0:54:31.830,0:54:36.930
adversarial network you have both

0:54:34.020,0:54:39.210
networks stepping in the same loop but

0:54:36.930,0:54:40.920
you can have one training thing

0:54:39.210,0:54:42.870
first, you start with the first network,

0:54:40.920,0:54:45.630
then later below you're gonna

0:54:42.870,0:54:47.520
have the other 

0:54:45.630,0:54:49.830
network step in there. So you

0:54:47.520,0:54:52.020
had two optimizers which are

0:54:49.830,0:54:53.730
'adapting', if you use this word

0:54:52.020,0:54:55.350
there from this paper, the weights at

0:54:53.730,0:54:58.050
different time. It's actually two

0:54:55.350,0:54:59.550
different networks which don't even

0:54:58.050,0:55:01.860
train at the same time. So you first

0:54:59.550,0:55:04.440
train the predictive model, the forward

0:55:01.860,0:55:07.520
model. Whenever you finish that

0:55:04.440,0:55:09.990
you use that as a mean to send back

0:55:07.520,0:55:12.810
gradients from the

0:55:09.990,0:55:15.720
future. How do we choose capital K?

0:55:12.810,0:55:18.140
Capital K is the number of iterations

0:55:15.720,0:55:22.680
that are necessary in order for you to

0:55:18.140,0:55:25.560
reach any edge, you just go back until

0:55:22.680,0:55:27.660
you hit something. Whenever you hit

0:55:25.560,0:55:32.310
something, that's capital K.

0:55:27.660,0:55:34.440
So actually whenever we drive forward we

0:55:32.310,0:55:36.900
use the kinematic model such that you

0:55:34.440,0:55:39.030
have a truthful final

0:55:36.900,0:55:40.410
location, but then in order to run the

0:55:39.030,0:55:43.530
gradients backwards you're going to be

0:55:40.410,0:55:45.510
using the emulator network. So you use

0:55:43.530,0:55:47.070
the kinematics model to do the forward

0:55:45.510,0:55:50.420
pass and you do the backward pass

0:55:47.070,0:55:52.920
through using the emulator network. I

0:55:50.420,0:55:54.960
think this can be done better with

0:55:52.920,0:55:56.520
policy gradient and deep RL model.

0:55:54.960,0:56:00.780
Okay we don't know about

0:55:56.520,0:56:04.440
RL, RL for us doesn't make sense. I'm

0:56:00.780,0:56:06.240
just repeating what the boss says. You

0:56:04.440,0:56:08.820
can try, you can definitely try out

0:56:06.240,0:56:10.320
and see whether it works. Again, this

0:56:08.820,0:56:14.910
stuff was done in the 90's, so

0:56:10.320,0:56:20.370
that's old stuff but it's

0:56:14.910,0:56:27.540
is always you know, how do you call it, 'pertinent'

0:56:20.370,0:56:30.270
there you go. More questions? [Student] Hi Alfredo

0:56:27.540,0:56:33.420
I'm still confused about training for controller and

0:56:30.270,0:56:36.090
emulator. So the emulator is trained

0:56:33.420,0:56:39.240
at each time step because we are

0:56:36.090,0:56:42.720
comparing the predicted

0:56:39.240,0:56:45.990
state versus the truth... [Alfredo] This one, right? 

0:56:42.720,0:56:48.960
[Student] Yeah, each time step, so we are updating the

0:56:45.990,0:56:51.690
parameters for every time step?

0:56:48.960,0:56:53.760
[Alfredo] Well you can also do a batch if you

0:56:51.690,0:56:54.690
want but you can do stochastic gradient,

0:56:53.760,0:56:56.610
this is okay,

0:56:54.690,0:56:58.290
so you can provide a new sample

0:56:56.610,0:57:00.330
and then you update your sample update

0:56:58.290,0:57:03.420
and so on. Or you can actually 

0:57:00.330,0:57:06.980
step after several 

0:57:03.420,0:57:10.740
time steps. [Student] Okay and when we hit

0:57:06.980,0:57:12.720
the big K, we just... [Alfredo] This is not about

0:57:10.740,0:57:16.320
the emulator, there is no capital K

0:57:12.720,0:57:20.010
here. [Student] Oh. I'm confused because

0:57:16.320,0:57:22.560
we do the training for

0:57:20.010,0:57:25.200
emulator first and then when we hit

0:57:22.560,0:57:29.340
the terminate state we then do backdrop

0:57:25.200,0:57:33.780
for controller. [Alfredo] So first you train this

0:57:29.340,0:57:35.880
network. Finished. Done. Second step: You

0:57:33.780,0:57:37.680
train the controller, next network. 

0:57:35.880,0:57:40.590
Alright so you train first the first

0:57:37.680,0:57:41.519
network, this one with random numbers,

0:57:40.590,0:57:43.469
with random steering signal,

0:57:41.519,0:57:47.069
there is no controller here, right?

0:57:43.469,0:57:48.839
[Student] Yeah. [Alfredo] Okay, cool. So you first

0:57:47.069,0:57:53.549
trained this emulator such that it can

0:57:48.839,0:57:55.409
replicate these dynamics. [Student] Okay.

0:57:53.549,0:57:57.869
[Alfredo] Then, second part is gonna be training the

0:57:55.409,0:58:00.569
controller, and the controller is trained

0:57:57.869,0:58:04.559
in this manner: You provide initial

0:58:00.569,0:58:06.209
condition, you feed-forward this initial

0:58:04.559,0:58:08.909
condition, you basically end up with a

0:58:06.209,0:58:12.599
trajectory of 'h' case

0:58:08.909,0:58:15.839
until you reach one of the

0:58:12.599,0:58:18.749
three final conditions, which are:

0:58:15.839,0:58:20.399
Jackknifing, running out of steps

0:58:18.749,0:58:22.380
or you actually hit a wall.

0:58:20.399,0:58:25.439
If you hit a wall then you run 

0:58:22.380,0:58:27.299
back-propagation through this network and

0:58:25.439,0:58:29.999
then you do gradient descent.

0:58:27.299,0:58:32.369
[Student] And now you're doing gradient descent

0:58:29.999,0:58:36.269
with regards to the controller. [Alfredo] Only C

0:58:32.369,0:58:36.989
yes, yes, yes. [Student] Okay, okay, yeah I got it,

0:58:36.269,0:58:43.949
thank you. [Alfredo] Okay,

0:58:36.989,0:58:45.929
that's awesome. That's it, I think.

0:58:43.949,0:58:48.449
And so you made it until the end of the lesson.

0:58:45.929,0:58:51.449
Congratulations. So how can you

0:58:48.449,0:58:53.130
better get an understanding of what we

0:58:51.449,0:58:56.599
cover today? So there are a few things

0:58:53.130,0:58:59.099
you can do to keep going.

0:58:56.599,0:59:01.259
Comprehension: You have some questions?

0:58:59.099,0:59:04.319
ask them just in the comment section

0:59:01.259,0:59:06.659
below, we'll answer every one. News: If you

0:59:04.319,0:59:08.819
follow me on Twitter under @alfcnz,

0:59:06.659,0:59:11.999
you can get the latest information as I

0:59:08.819,0:59:13.409
post them online. Updates: If you subscribe

0:59:11.999,0:59:15.269
to the channel and turn on the

0:59:13.409,0:59:17.989
notification button you will not lose any

0:59:15.269,0:59:20.279
of the videos I'm posting here.

0:59:17.989,0:59:22.229
Appreciation: Again, if you like this

0:59:20.279,0:59:24.689
video and the content and everything I

0:59:22.229,0:59:27.839
do, I would really appreciate if you put

0:59:24.689,0:59:29.939
a like on the video. Searching:

0:59:27.839,0:59:32.159
Every video has an English transcription

0:59:29.939,0:59:33.269
which can be searchable and you

0:59:32.159,0:59:35.029
can find it in the video description

0:59:33.269,0:59:37.829
below.

0:59:35.029,0:59:40.439
Language: Sei parla italiano? hablas español?

0:59:37.829,0:59:42.329
你会说中文吗? Do you speak Korean?

0:59:40.439,0:59:44.369
Turkish, we have now! All these

0:59:42.329,0:59:47.999
translations are now available for you.

0:59:44.369,0:59:51.569
I'm planning to add more languages as we

0:59:47.999,0:59:54.140
have volunteers. PyTorch: If you'd like

0:59:51.569,0:59:56.730
to have a concrete understanding and

0:59:54.140,0:59:59.220
digest better this topic, I highly

0:59:56.730,1:00:01.830
recommend to you to try to train the

0:59:59.220,1:00:04.820
controller yourself, and if he works you

1:00:01.830,1:00:07.440
can submit a pull request and

1:00:04.820,1:00:09.150
that's actually the next point,

1:00:07.440,1:00:11.790
(Contribute) such that we're gonna have now a

1:00:09.150,1:00:14.640
notebook which will have a running

1:00:11.790,1:00:16.800
controller, so this is left to you

1:00:14.640,1:00:20.520
as an exercise such that you can

1:00:16.800,1:00:22.350
actually master this topic. Alright,

1:00:20.520,1:00:25.430
thank you again for listening, see you

1:00:22.350,1:00:25.430
next time. Bye bye.
