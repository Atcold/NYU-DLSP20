0:00:00.500,0:00:07.230
have you been to isoldi in New York lobster lasagna no I haven't been to

0:00:07.230,0:00:15.470
Italy I usually go to two places one is called Norma it's here on 33rd and 3rd

0:00:15.470,0:00:20.279
Avenue it's just Sicilian very authentic I love

0:00:20.279,0:00:23.220
it the other one which is absolutely the

0:00:23.220,0:00:28.170
best pizza in the world it's called sort of below it's very

0:00:28.170,0:00:34.410
close to NYU the pizza is just like in Naples and it's like you can't find

0:00:34.410,0:00:39.329
anything better on this planet so you know you should go to Seoul below and if

0:00:39.329,0:00:45.500
you mention my name you get discount right so yeah I have a special power

0:00:45.500,0:00:51.989
yeah Chicago pizza is not Pizza is um pie so if you call it

0:00:51.989,0:00:58.820
Chicago pie it's fantastic it's not pizza Napoli pizza is the only pizza

0:00:58.820,0:01:04.920
okay all right so what do we talk today about today we talk about something

0:01:04.920,0:01:10.830
called the track beggar rapper what are we trying to do today in this lecture so

0:01:10.830,0:01:14.340
this is the first lecture where you're gonna help me basically reading with you

0:01:14.340,0:01:20.280
along in a paper again such that we can figure out whether things make sense

0:01:20.280,0:01:25.530
this is how we educate ourselves in the research world you don't have

0:01:25.530,0:01:31.079
necessarily young on your side all the time so you had to read papers and you

0:01:31.079,0:01:35.490
had to make sense of what's written there usually I transcribe them again

0:01:35.490,0:01:41.729
back with type or ax just for the to fix the main topics in in my mind right and

0:01:41.729,0:01:45.540
to commit to time right such that I can check

0:01:45.540,0:01:51.509
I can check later what's going on so let's get started so what is this setup

0:01:51.509,0:01:56.969
what are we trying to do here so we are trying to design by self learning of a

0:01:56.969,0:02:01.590
nonlinear controller to control the steering of a trailer truck while

0:02:01.590,0:02:07.170
backing up to a loading dock from an arbitrary initial position only backing

0:02:07.170,0:02:11.819
up is allowed so what does this mean what we are trying to do is going to be

0:02:11.819,0:02:17.760
learning how to drive a truck which is maybe not that complicated if

0:02:17.760,0:02:25.020
you go forward but we are trying to park a track so it just go backward and only

0:02:25.020,0:02:31.110
backward so you know if you try to park your car in a parallel parking it's a

0:02:31.110,0:02:37.080
little bit complicated perhaps sometimes and not always you can get it done with

0:02:37.080,0:02:44.180
one manoeuvre if you have a trailer truck attached to your back it's a mess

0:02:44.180,0:02:51.870
we are figuring out this very soon so how does this you know trailer truck

0:02:51.870,0:02:58.830
works we have two items we have a cab which is the top right partner so we

0:02:58.830,0:03:04.110
have an angle of the cab of the cab with respect to the x-axis and then we have

0:03:04.110,0:03:09.209
the coordinates x and y of the of the joint between the cab and the trailer

0:03:09.209,0:03:16.470
okay then in the part below we have the trailer and therefore we have like the

0:03:16.470,0:03:21.540
X&Y location of the back of the trailer track and then we have the theta trailer

0:03:21.540,0:03:25.500
which is telling us what is the angle of this trailer truck with respect to the

0:03:25.500,0:03:33.150
x-axis our objective is to drive this guy backwards until the back of the

0:03:33.150,0:03:38.970
trailer hits basically the dock location which is represented there with the X

0:03:38.970,0:03:46.380
dock and Y dog coordinate moreover we would like to have the theta trailer

0:03:46.380,0:03:52.440
which is the angle of the trailer to be 0 such that basically the trailer is

0:03:52.440,0:03:58.739
orthogonal to the docking station and basically the rear part or the the rear

0:03:58.739,0:04:02.310
yet front and we are earlier part of the is we are back right

0:04:02.310,0:04:06.269
I'm speaking English I guess it's correct so there we are part of the

0:04:06.269,0:04:13.019
track of the trailer should be parallel to the docking station and as close as

0:04:13.019,0:04:21.690
possible to the location of the dock so far make sense right yeah ok all right

0:04:21.690,0:04:27.570
so let's read a little bit more for them this paper so we have a state some

0:04:27.570,0:04:36.240
state variables there are six and which is not quite I think this is perhaps not

0:04:36.240,0:04:41.580
correct what we'll figure this out soon so the state variables are the theta cab

0:04:41.580,0:04:47.760
which is the angle of the track then X cab and y car which is the Cartesian

0:04:47.760,0:04:54.360
position of the yoke which is the part behind the cab and then you have x + y

0:04:54.360,0:05:00.000
trailer which is the position of the rear of the trailer Plus D theta trailer

0:05:00.000,0:05:05.640
which is the angle of the trailer okay so basically how it goes is the

0:05:05.640,0:05:08.400
following the whole procedure is the following the

0:05:08.400,0:05:12.980
track backs up until it hits the dock and then it stops

0:05:12.980,0:05:18.120
the goal is to back the trailer to be parallel to the locking to the loading

0:05:18.120,0:05:21.930
dock right so the back of so the goal is to have the back side of the trailer to

0:05:21.930,0:05:27.150
be parallel of the docking station and then having the x-trail ER and white

0:05:27.150,0:05:33.450
trailer the location of the back of the trailer as close as possible to the X

0:05:33.450,0:05:37.770
dock and why dog okay are you with me so far

0:05:37.770,0:05:42.450
so the initial position is going to be randomly set and then we had to back up

0:05:42.450,0:05:49.830
until we saw the objectives to back up until we hit the trailer and the dock

0:05:49.830,0:05:57.240
with the back of the trailer and we are exactly like orthogonal okay there are a

0:05:57.240,0:06:04.410
few difficulties with this and we're gonna figure out right now what are

0:06:04.410,0:06:15.540
these all right so we go CD work key table PTL now we go Conda activate PDL

0:06:15.540,0:06:23.010
right now here we have a Jupiter not work so in this case we are going to be

0:06:23.010,0:06:30.090
going over these track becquer rapper so something I really like to do in in

0:06:30.090,0:06:35.640
Jupiter notebook is who use actually you know the Unicode since we are using

0:06:35.640,0:06:39.419
Python 3 we can use unicode right so to write PI there

0:06:39.419,0:06:44.970
I just told backslash Pi and I press tab you get pie okay or you

0:06:44.970,0:06:55.290
can do alpha beat okay this is not coding this is not books okay so you can

0:06:55.290,0:07:01.980
do ugly things like this alright so I just initialize some libraries this is

0:07:01.980,0:07:09.500
our setup I initialize some object here we don't care right now and we start by

0:07:09.500,0:07:14.670
visualizing this guy here okay and I think I had one zoom a little bit

0:07:14.670,0:07:25.350
because you can't see cool okay so now we start the interactive part we'd like

0:07:25.350,0:07:32.160
to draw this guy so let me go let's say with zero angle of the steering wheel

0:07:32.160,0:07:38.820
and I keep I keep you know executing this alright so this guy here keeps

0:07:38.820,0:07:48.360
going and then what's happening here after the next step is that my computer

0:07:48.360,0:07:53.910
now is gonna be is complaining and there you go so you get the track is

0:07:53.910,0:07:59.160
jackknifed what does it mean the track has is jackknifed you simply broke your

0:07:59.160,0:08:03.750
track because you draw into yourself that's very interesting but you can

0:08:03.750,0:08:11.850
drive inside yourself with these trucks okay so let me reset the state with

0:08:11.850,0:08:17.820
something a bit decent maybe like okay just someone down volunteers what is

0:08:17.820,0:08:24.150
going to be now the angle you'd like me to steer the the wheel you can give me

0:08:24.150,0:08:29.910
anything from 0 to 45 degrees I think minus 10 so I go minus 10 which is gonna

0:08:29.910,0:08:39.140
be turning to the right 10 degrees and I go 1 2 3 4 5 6 7 8 9 10 steps ok off

0:08:39.140,0:08:44.400
yeah if I keep going you're gonna be jackknifing soon okay so what should I

0:08:44.400,0:08:53.310
do right now someone else or maybe still you class 15 okay let's try plus 15

0:08:53.310,0:09:00.880
we go on two three four five six seven eight nine ten hmm okay what next show

0:09:00.880,0:09:05.260
you keep going yeah 1 2 3 4 5 6 7 8 9 10 we are gonna be

0:09:05.260,0:09:12.160
going off screen maybe alternate plus and minus then you go straight right if

0:09:12.160,0:09:16.450
I keep going like this you can see that this track is gonna be going outside

0:09:16.450,0:09:22.750
we're gonna be you know going basically game over so you don't have a driving

0:09:22.750,0:09:28.420
license so minus 15 okay do you agree all should I go with minus

0:09:28.420,0:09:37.660
15 I go with minus 15 1 2 3 4 5 6 7 8 9 10 ok now we cannot drove drive forward

0:09:37.660,0:09:43.860
plus 45 we messed up no no I don't think you messed up I think it's still good

0:09:43.860,0:09:50.050
zero okay someone said zero let's try with zero not yet okay what do you want

0:09:50.050,0:10:04.450
me to do plus 45 okay plus 45 I can keep going but then we are gonna be just oh

0:10:04.450,0:10:17.050
yeah one more minus 44 you okay let's go - 45 twice then twice more then I'm

0:10:17.050,0:10:22.540
gonna go oh wait no six more sorry well 10 1 2 3 4 5 6 ok

0:10:22.540,0:10:27.250
so if I keep going like this we are gonna be going off the screen right so I

0:10:27.250,0:10:31.870
think you got the picture right is it twice twice more no it's an older

0:10:31.870,0:10:37.030
message that okay the point here is that this stuff it's a bit you know tricky

0:10:37.030,0:10:42.280
you can get I you can get like a hand of it and maybe it's gonna be like the

0:10:42.280,0:10:45.700
final solution is going to be like something there we go we keep going like

0:10:45.700,0:10:51.940
this and then we go in the other direction to rotate something like plus

0:10:51.940,0:11:01.360
10 and then it's gonna be killing each other here so plus maybe 25 or maybe

0:11:01.360,0:11:03.930
let's see B plus 20 C so we can turn around and

0:11:11.420,0:11:21.529
now we should basically undo this thing so if I go like I think plus 40 and

0:11:21.529,0:11:30.079
there you go and we can go basically straight steal

0:11:30.079,0:11:39.350
something 20 maybe okay and then we can go zero see I've been teaching this

0:11:39.350,0:11:45.769
forever so you know I can actually drive this thing okay so there you go yeah

0:11:45.769,0:11:51.110
I physicai can there you go see oh my god I'm actually managing to do this we

0:11:51.110,0:11:57.050
had to fix a little bit Hong Kong yeah honk the horn I actually had my horn

0:11:57.050,0:12:05.110
there so we had to actually oh [ __ ] [ __ ] [ __ ] [ __ ] [ __ ] oh no no okay sorry

0:12:07.170,0:12:13.149
okay fine so this actually consider success okay now my computer now is

0:12:13.149,0:12:17.439
complaining because there is some lag I should have a turn a little bit before

0:12:17.439,0:12:21.999
anyhow the point was that it's not ok done

0:12:21.999,0:12:26.170
the point is that it's not quite straightforward to you know to figure

0:12:26.170,0:12:30.759
out how to drive this guy because it's highly nonlinear and so we had to figure

0:12:30.759,0:12:36.540
out how to implement a high nonlinear system how to invert a high nonlinear

0:12:36.540,0:12:41.470
kinematic model basically such that if we had a kinematic model you know how

0:12:41.470,0:12:45.730
the vehicle behaves right given an action if you invert the kinematic model

0:12:45.730,0:12:50.019
you figure out what action you would like to take in order to you know drive

0:12:50.019,0:12:54.999
to a final destination but since we don't know how to do this analytically

0:12:54.999,0:12:59.470
or maybe we didn't know and the nighties we can train on your net right and then

0:12:59.470,0:13:05.709
we can simply figure out whether we can do some you know we can learn how

0:13:05.709,0:13:11.079
whether we can learn how to you know drive backwards okay are you excited are

0:13:11.079,0:13:15.819
you interesting to know how we can do this ya know

0:13:15.819,0:13:27.209
yes okay let me think so the overall they were all basically

0:13:27.209,0:13:36.009
objective here is gonna be that given a initial position in this map here give

0:13:36.009,0:13:40.600
an initial position I'd like to know what sequence of actions which is gonna

0:13:40.600,0:13:47.620
be basically what sequence of steering angle for the wheels I should apply in

0:13:47.620,0:13:52.899
this six dimensional space right so it's not just to D because to D so this this

0:13:52.899,0:13:57.370
screen here is gonna be the 2d screen but then you have six values right you

0:13:57.370,0:14:02.019
have the X Y of the Cubs X Y of the trailer the two angles so you have a six

0:14:02.019,0:14:06.699
dimensional space and then in this six dimensional space you'd like to in fear

0:14:06.699,0:14:10.839
like yours or you'd like to yeah you get a network which is telling you for this

0:14:10.839,0:14:14.050
specific configuration of the track or the trailer track you should be

0:14:14.050,0:14:18.899
outputting this specific value is a regression network

0:14:18.899,0:14:24.029
how is going to be outputting you a scalar which is going from minus 45 to

0:14:24.029,0:14:32.759
plus 45 I think yeah - yeah yeah I think so I think that's the range for every

0:14:32.759,0:14:37.139
position right so our goal is gonna be training a neural net that goes from

0:14:37.139,0:14:42.209
points in this six dimensional space to one scalar which is gonna be the scalar

0:14:42.209,0:14:48.749
that allows me to you know get a you know a sequence of scalars so but one

0:14:48.749,0:14:54.809
scalar at the time such that you would like to drive these track backwards to

0:14:54.809,0:14:59.369
the final destination and did I make sense does it make sense

0:14:59.369,0:15:06.029
maybe I was confused is he okay alright alright so let's figure out how to get

0:15:06.029,0:15:12.990
all this stuff going back to the slides training boom okay training so the

0:15:12.990,0:15:18.420
training involves two stages the first one we have to train a network and

0:15:18.420,0:15:24.449
you're on that to be an emulator of the truck and trailer kinematics this is how

0:15:24.449,0:15:28.379
the paper these people have done right so that's not the only option but it's

0:15:28.379,0:15:33.569
what we are going for then a second stage involves training of a neural

0:15:33.569,0:15:36.870
network controller to control the emulator which is gonna be basically

0:15:36.870,0:15:40.920
doing the task that we were doing right now when we were you know coming up with

0:15:40.920,0:15:47.040
a value for this steering angle such that we can reach destination and you

0:15:47.040,0:15:50.839
know destination like success is determined by two points due to factors

0:15:50.839,0:15:59.100
closeness to the docking station and the orientation of the trader so this is the

0:15:59.100,0:16:03.689
overall diagram you can I have a neural net a controller which was me right now

0:16:03.689,0:16:07.920
following your suggestions through the chat which is providing you this

0:16:07.920,0:16:14.009
steering signal at the time k discrete time interval k then we have a

0:16:14.009,0:16:18.329
trailer-truck kinematics which are the equations that allowed me to you know

0:16:18.329,0:16:24.389
tell you what is the next configuration of the track which is again we are

0:16:24.389,0:16:28.860
giving you the next state given that you provide the previous state inside and

0:16:28.860,0:16:32.900
then the steering signal and this Delta here is simply

0:16:32.900,0:16:37.700
time delay right such that it tells you that this is the next state and this is

0:16:37.700,0:16:43.330
the previous state these are a little bit these are like diagrams from the

0:16:43.330,0:16:47.900
electronics like Electrical Engineering diagram so you're going to see because

0:16:47.900,0:16:54.140
that's you know there was no computer science back in the days right alright

0:16:54.140,0:17:01.520
so a state ok is fed to the controller which provides a steering signal ok

0:17:01.520,0:17:08.240
between minus 1 in this case and plus 1 for the track so they kind of use a 10 H

0:17:08.240,0:17:15.110
at the output at the time index K each time cycle the truck backs up by a fixed

0:17:15.110,0:17:21.200
a small distance yeah so these are the equations for the trailer track with

0:17:21.200,0:17:27.860
several tracks you had the location of the X&Y of the cap and then you have

0:17:27.860,0:17:32.900
like given that you know the distance the length both of the the cab and also

0:17:32.900,0:17:39.100
of the trailers the one the two so on you can estimate what is the you know

0:17:39.100,0:17:47.450
the the variation of the angle given the input by the Phi is this negative angle

0:17:47.450,0:17:53.150
right because it's on the right-hand side so we have that s is the sine speed

0:17:53.150,0:17:57.350
so you can go forward and backward and then Phi is this negative steering angle

0:17:57.350,0:18:01.450
positive great positive angles being on the right-hand side right so it's like

0:18:01.450,0:18:08.680
sweep swapped and then x and y is the location here back of the of the cab

0:18:08.680,0:18:15.710
notice now that basically you have the x and y position of the trailer is

0:18:15.710,0:18:21.860
actually determined by the x and y position of the cab and the distance d1

0:18:21.860,0:18:27.950
and the theta one okay so before I was selling I was telling you that we had

0:18:27.950,0:18:33.710
six values for the state but as you can tell from now we just need four values

0:18:33.710,0:18:38.930
right you have the x and y now you have the theta 0 which is do you know the

0:18:38.930,0:18:43.280
angle of the cab and then theta 1 that is the angle of the first of the trailer

0:18:43.280,0:18:49.400
so you have only four independent values right here these X&Y

0:18:49.400,0:18:55.180
of the trailer is completely determined given these other values nevertheless

0:18:55.180,0:19:04.070
question aren't these velocities so these are the equation yes so this is

0:19:04.070,0:19:08.210
how the the position changes right so these are velocities but so whenever you

0:19:08.210,0:19:14.690
have like a state the state in this case is X Y theta 0 theta 1 and then whenever

0:19:14.690,0:19:17.270
you'd like to write the equation of the motion

0:19:17.270,0:19:22.100
you're gonna write that you know the variation in time so d ya with the

0:19:22.100,0:19:28.010
velocity of X velocity over Y and the angular velocity over this guy and the

0:19:28.010,0:19:32.690
angular velocity of the other guy are gonna be expressed by these questions in

0:19:32.690,0:19:36.650
continuous-time then we're going to be discretized in them since we are using a

0:19:36.650,0:19:42.380
computer but this is yeah how we will express you know a dynamic model right

0:19:42.380,0:19:48.770
like a model that evolves in time all right so we have the equations let's

0:19:48.770,0:19:53.300
figure out now how we train these networks so this is how we train the

0:19:53.300,0:19:58.370
network for emulating the track trailer-truck kinematics on the left

0:19:58.370,0:20:02.540
hand side we provide a random input which is going to be is going to be like

0:20:02.540,0:20:09.650
a random initial value for the for the steering angle and then we provide this

0:20:09.650,0:20:14.990
random steering angle to the track dynamics which is gonna telling me given

0:20:14.990,0:20:20.090
the previous state what is what is going to be the next state and then on the

0:20:20.090,0:20:24.110
bottom part I'm gonna have my first network which is gonna be trained as a

0:20:24.110,0:20:28.040
regression regressor and it's going to be trying to minimize the difference

0:20:28.040,0:20:34.130
between you know the actual next state and this state that is predicted then

0:20:34.130,0:20:40.100
the difference between the prediction and the actual ground truth it's used in

0:20:40.100,0:20:46.730
order to and they call these adapt the term they are using the article is adapt

0:20:46.730,0:20:53.450
the weights of this network which is basically you know train the network so

0:20:53.450,0:20:58.340
how you how do you update the weights of the network the weights of the network

0:20:58.340,0:21:02.330
are updated by using this error so question now is

0:21:02.330,0:21:06.590
going to be for you what kind of loss function are they

0:21:06.590,0:21:12.950
using here since the signal that is used to update these weights it's actually

0:21:12.950,0:21:18.830
the difference between the target and the actual prediction

0:21:18.830,0:21:24.049
you should be able to tell me now it's actually in the midterm right now it's

0:21:24.049,0:21:26.769
one of the question MSE why MSE because if you compute the

0:21:30.090,0:21:34.979
derivative of the MSE you get the difference right between the target and

0:21:34.979,0:21:40.799
your well you get the the difference between your prediction and the in the

0:21:40.799,0:21:47.359
target right and so this div this difference which is here swapped right

0:21:47.359,0:21:53.909
is actually used here to change the values in a in our course we perform

0:21:53.909,0:21:58.049
gradient descent right so you get the positive Delta the positive you have

0:21:58.049,0:22:02.340
prediction - ground truth and that you use that one to compute the partial

0:22:02.340,0:22:07.619
derivatives and then you subtract that write the parameter such that you go in

0:22:07.619,0:22:11.309
the opposite direction here they actually use the inverted sine sign

0:22:11.309,0:22:16.619
right in this prediction - the ground truth is you know factor for you know

0:22:16.619,0:22:20.999
adapting which is you know changing these parameters but basically is the

0:22:20.999,0:22:28.169
same thing it's a question why are we training the emulator if you already

0:22:28.169,0:22:32.419
have a model for the track movement again that's a very good question

0:22:32.419,0:22:37.590
because in this case we have a questions and therefore we could actually get a

0:22:37.590,0:22:42.840
partial derivatives through these questions but you may not have the

0:22:42.840,0:22:47.970
equations right let's say you have a much more complex system you may just

0:22:47.970,0:22:55.799
observe right several experts driving this you know complex systems and then

0:22:55.799,0:23:00.929
you actually through this sequence of basically trajectory and on this

0:23:00.929,0:23:06.570
sequence of location so sequence of states variables you can learn a network

0:23:06.570,0:23:12.299
that is able to emulate what is the dynamics of these which is the

0:23:12.299,0:23:18.899
kinematics sorry of this system okay that was the answer for Joseph alright

0:23:18.899,0:23:24.269
cool so right now let's see how this keeps going oh maybe we should check

0:23:24.269,0:23:30.960
them they let me actually switch to the 2d this guy here right so let's actually

0:23:30.960,0:23:36.989
start training this stuff right so we we get like towards right and then we're

0:23:36.989,0:23:39.950
gonna be running this for loop at the beginning

0:23:39.950,0:23:44.540
and so what happens here is gonna be you know we provide some random initial

0:23:44.540,0:23:50.270
steering angle and then you know we use the kinematics model to learn what is

0:23:50.270,0:23:54.500
the connection between previous state and next state whenever the track goes

0:23:54.500,0:24:00.560
outside we just kill it and these keeps going right until we we

0:24:00.560,0:24:05.960
have enough points such that we can train these networks to emulate the

0:24:05.960,0:24:10.040
track the trailer-truck kinematics again in this case it wouldn't be necessary

0:24:10.040,0:24:13.670
because I can we have the equations but let's say we don't have the equations

0:24:13.670,0:24:18.260
but we just have you know observations from the real real world then you

0:24:18.260,0:24:22.610
actually have to you know you actually had to learn those functions such that

0:24:22.610,0:24:29.180
we can differentiate from right we can run gradients ok so if we keep going

0:24:29.180,0:24:34.400
like that my computer is gonna crash so right now you can see that this is

0:24:34.400,0:24:38.750
taking forever why is taking forever because there is this visualization so

0:24:38.750,0:24:44.480
in this case I turn off the visualization such that it doesn't draw

0:24:44.480,0:24:49.790
things there and then I can run now for ten thousand times right oh okay and

0:24:49.790,0:24:54.410
this happened because I interrupted the other thing right so it's okay how

0:24:54.410,0:24:59.840
lovely okay boom and this is quite quick right

0:24:59.840,0:25:05.540
because it doesn't have the graphical sorry the rendering okay you're

0:25:05.540,0:25:14.690
emulating what players so the emulator let me show you the emulator here is

0:25:14.690,0:25:19.690
gonna be trying to learn what is the next state given the previous state

0:25:19.690,0:25:25.370
given I provide a specific random steering signal here right so given a

0:25:25.370,0:25:30.680
state and given a steering angle I try to learn what is the next state and this

0:25:30.680,0:25:36.230
is coming from the ground truth which is this box here okay this is not a

0:25:36.230,0:25:40.160
recurrent net right it's just a normal net you have you know an input which is

0:25:40.160,0:25:45.080
state plus action and then the output is going to be just action there is no

0:25:45.080,0:25:51.850
recurrence right now okay signals are always random at every step

0:25:51.850,0:25:57.340
the steering signal it's random this state I collect the whole trajectory

0:25:57.340,0:26:04.420
while I input a random steering angle okay a very long question does does is

0:26:04.420,0:26:10.150
does this matter that okay it's too long does it matter that the data you're

0:26:10.150,0:26:14.920
collecting is a bit different from the human test time action the data you're

0:26:14.920,0:26:21.250
collecting changes directions rapidly frequently so there is no it doesn't

0:26:21.250,0:26:26.380
there is no time right here my training we haven't talked about training it but

0:26:26.380,0:26:33.550
here I'm so this is gonna be a just normal neural net that given a input

0:26:33.550,0:26:41.080
state is gonna map it map it to the output state given a specific angle for

0:26:41.080,0:26:47.680
the wheels there is no time right so you have one state you have one angle that's

0:26:47.680,0:26:56.550
the output no no time right now okay okay so we go here these are my inputs

0:26:56.550,0:27:01.600
and the outputs like that I collected over these trajectories so if you check

0:27:01.600,0:27:08.410
here I just have the initial I have the initial state I get the state from the

0:27:08.410,0:27:13.690
track then I have a Phi which is my you know angle which is going to be

0:27:13.690,0:27:19.930
something between random minus 0.5 so minus 5 so from 45 to minus 45 to plus

0:27:19.930,0:27:24.820
45 then I have my input so it's gonna be you know the state plus the angle and

0:27:24.820,0:27:27.850
then the output is going to be the output of the tracker

0:27:27.850,0:27:34.630
track which has step with angle Phi all right so we have this thing here I can

0:27:34.630,0:27:43.140
split I can create my network and then I can start

0:27:43.250,0:27:49.460
training my network and a zone will keep going until forever but then basically

0:27:49.460,0:27:54.980
here we are trying to get a neural net which is simply a couple of layers here

0:27:54.980,0:28:00.320
right so linear really linear we start from steering Engle states Terry

0:28:00.320,0:28:06.110
steering's so steering size which is 1 plus the state size which is which was

0:28:06.110,0:28:14.030
which was 6 right like the x and y and angle for both so x and y and angle for

0:28:14.030,0:28:20.000
both the cab and the trailer then you have a number of hidden units which are

0:28:20.000,0:28:23.870
gonna be described now in the paper then have very low and then you have the

0:28:23.870,0:28:27.250
final inner output MSC and you know STD alright let's go

0:28:32.900,0:28:42.220
back to the computer presentation so figure 3 which is the this one shows the

0:28:42.220,0:28:49.160
train how to train the emulator so the track the track begs up randomly and the

0:28:49.160,0:28:53.540
emulator learns to generate the next position state vector given the present

0:28:53.540,0:28:58.850
state vector and the steering signal and you can hear now my computer fan

0:28:58.850,0:29:05.540
spinning because it's training ok sorry for the bad audio alright so this is how

0:29:05.540,0:29:09.730
we train this system how do you train the controller so this is state

0:29:09.730,0:29:15.350
transition flow diagram see represents the controller Sue's another neural net

0:29:15.350,0:29:20.960
whereas T represents the truck and trailer emulator so all the truck

0:29:20.960,0:29:29.240
kinematics or the trailer emulator either or so how is this thing working

0:29:29.240,0:29:35.450
ok so how is now time added to the system so we start with this controller

0:29:35.450,0:29:43.100
see this controller see we said provides what the steering angle to the truck or

0:29:43.100,0:29:50.690
the truck emulator so the controller provides an angle given that is fed with

0:29:50.690,0:29:57.140
the initial state right which in which we can which we can call H of the

0:29:57.140,0:30:03.800
k minus one time stamp and if we provide these previous states to the controller

0:30:03.800,0:30:09.980
and the track the track we basically get the next state so you can think about

0:30:09.980,0:30:19.030
these two guys as you know just one element of a recurrent Network which has

0:30:19.030,0:30:24.050
no input or well it could have an input but there is no the input is not

0:30:24.050,0:30:28.610
connected right so this is like one of the multiple cells we usually seen in a

0:30:28.610,0:30:34.300
recurrent net but there is a different diagram inside so how do we train this

0:30:34.300,0:30:40.070
this this is item well you already know the answer right so you get this one

0:30:40.070,0:30:44.390
down here we don't have any input on the bottom all right and then you stack

0:30:44.390,0:30:47.900
another one you stack on another one and then you keep going until you actually

0:30:47.900,0:30:52.910
start from the initial location of the track which is the initial hidden state

0:30:52.910,0:30:58.300
or which is basically the initial tracked location and configuration right

0:30:58.300,0:31:02.780
and then how on the right hand side so on the right hand side you keep going

0:31:02.780,0:31:09.020
right and then whatever until the end where you reach the final point which

0:31:09.020,0:31:14.360
final condition can be a few of the following run out of steps jackknife or

0:31:14.360,0:31:19.070
third part you hit one of the edges and then I check what is the distance

0:31:19.070,0:31:24.560
between your back and the docking station and then I check what is your

0:31:24.560,0:31:30.830
angle range or your orientation of the track which should have been horizontal

0:31:30.830,0:31:36.860
right okay so those are the answer to the question what is the terminal

0:31:36.860,0:31:42.470
conditions there are three terminal conditions jackknifing running out of

0:31:42.470,0:31:49.550
steps or hitting an edge and whenever you hit an edge you try to you want to

0:31:49.550,0:31:54.200
actually minimize now right what is the distance between the trail that the

0:31:54.200,0:31:59.990
docking station and then you want to try to minimize whatever angle you get right

0:31:59.990,0:32:06.629
for the trailer cool so figure five training the

0:32:06.629,0:32:12.389
controller with backpropagation as you were as you saw before in the previous

0:32:12.389,0:32:16.710
diagram we were trying where we were training the emulator we have some seen

0:32:16.710,0:32:23.009
something similar with this feedback loop the final state so after you know

0:32:23.009,0:32:28.230
you complete this whole trajectory the final state will be ending with some

0:32:28.230,0:32:33.480
specific configuration I enforce this final state to be as close as possible

0:32:33.480,0:32:39.389
to my target state which means you want to have you know the X trailer as close

0:32:39.389,0:32:43.200
as possible to the dog trailer the wide trailer as close as possible to the walk

0:32:43.200,0:32:49.200
why doc and then the final angle of the trailer you know horizontals equal to 0

0:32:49.200,0:32:55.620
let you make the difference and you send the difference back basically to abduct

0:32:55.620,0:33:00.299
these weights but of course it's not just a line the whole thing goes through

0:33:00.299,0:33:05.190
it so you use well as usual chain rule right so this actually travels through

0:33:05.190,0:33:10.409
all previous TCS right so it goes inside modules the visualization shows that

0:33:10.409,0:33:16.139
only the see the controller blocks are updated also proportionally to the final

0:33:16.139,0:33:20.610
error which implies an MSc loss again the other thing that we came up with

0:33:20.610,0:33:27.210
before cool so the initial position is set at random

0:33:27.210,0:33:34.220
the track backs up until it stops final error is just for back propagation and

0:33:34.220,0:33:40.519
this is back propagation through time with a variable unrolling period k right

0:33:40.519,0:33:46.110
so the weight changes in C the controller are taken as the sum of the

0:33:46.110,0:33:53.190
tentative changes what is what is the meaning of this sentence well now you

0:33:53.190,0:34:02.790
maybe appreciate why PI torch is accumulating the gradients every time

0:34:02.790,0:34:08.790
see the point so in this case you get this gradient coming back from the

0:34:08.790,0:34:14.540
future back to the past and then the meaningful thing is gonna be

0:34:14.540,0:34:19.500
accumulating all these gradients right because we have reused the same module

0:34:19.500,0:34:25.230
multiple time when you go and perform back propagation this back propagation

0:34:25.230,0:34:33.270
will sum up things as many times as we went through the you know this module

0:34:33.270,0:34:36.570
right that's why PI torch accumulates gradient

0:34:36.570,0:34:41.460
whenever you compute backdrop if it would be just you know computing them

0:34:41.460,0:34:45.110
and replacing whatever it was before then you just have the gradients of the

0:34:45.110,0:34:51.350
oldest iteration high all the welders back the one most back in the past right

0:34:51.350,0:34:57.570
instead in this case which what which is written here which say is that the all

0:34:57.570,0:35:02.550
the tentative changes are you know some together means you know you accumulate

0:35:02.550,0:35:09.840
the gradient over time okay cool finally repeat another initial position

0:35:09.840,0:35:15.720
back up until he stops done so the network detail this is you know

0:35:15.720,0:35:21.870
architecture diagrams of network architectures back in in the 90s you

0:35:21.870,0:35:27.150
start with six values for the state x and Y and theta x and Y and theta for

0:35:27.150,0:35:34.050
the two items then you get through these items here that are if they are called

0:35:34.050,0:35:40.020
potential potentiometers which are basically variable resistance which are

0:35:40.020,0:35:44.460
again representing these variable weights variable weights as in weights

0:35:44.460,0:35:48.810
that can be tuned okay so these are tunable weights so weights in a neural

0:35:48.810,0:35:52.350
net okay but again this is the symbol for a tunable weight and attainable

0:35:52.350,0:35:59.280
resistor you have 24 325 of these guys so from six we go to 25 and then from 25

0:35:59.280,0:36:04.430
we go to one which is a steering signal so first affine transformation squashing

0:36:04.430,0:36:09.300
second affine transformation squashing and then this guy is gonna be the

0:36:09.300,0:36:16.790
emulator so you go from seven which is six of the state plus the steering angle

0:36:16.790,0:36:23.310
2:45 so you have a fine transformation squashing and then from these final 45

0:36:23.310,0:36:28.980
you have an affine transformation to 6 right which is define and you know next

0:36:28.980,0:36:36.150
state cool so that's it right so analogous to a

0:36:36.150,0:36:42.240
neural net having a number of affine transformations equal to 4 times the

0:36:42.240,0:36:48.990
number of baking up steps so for every time for every trajectory we train a net

0:36:48.990,0:36:55.620
which has you know a length that is depending on how many time steps this

0:36:55.620,0:37:04.800
specific track took in order to reach you no one's stopping you call it one

0:37:04.800,0:37:11.790
stopping what was the world condition right stopping yeah I guess stopping

0:37:11.790,0:37:16.620
condition alright so the number of steps varies with the initial position of the

0:37:16.620,0:37:19.410
trailer or the track track in the trailer

0:37:19.410,0:37:26.040
right so you have you train the core item of this network which has several

0:37:26.040,0:37:33.300
steps so have several layers the length of these network changes based on each

0:37:33.300,0:37:39.480
specific episode and then we train this stuff with back propagation and each

0:37:39.480,0:37:42.360
module is the same module replicated multiple times

0:37:42.360,0:37:47.520
therefore the gradients have to be some as you go through right as that's what

0:37:47.520,0:37:55.260
PI torch does make sense mmm so these are a few examples you

0:37:55.260,0:38:00.420
start with this initial position and then after a few steps the network

0:38:00.420,0:38:06.210
manages to reach the destination another one is here they started with the

0:38:06.210,0:38:12.450
trailer pointing away from the dock and you can see here how we manage to

0:38:12.450,0:38:16.980
circulate around and to get you know back to the correct location in the

0:38:16.980,0:38:21.390
final state again is horizont and rain so that's is like it looks almost

0:38:21.390,0:38:26.340
horizontal or these on you start orthogonal in a jackknife position right

0:38:26.340,0:38:30.180
that's really like being bastards nevertheless the net

0:38:30.180,0:38:39.530
can figure out how to solve this you know [ __ ] up configuration and then

0:38:39.530,0:38:43.560
this is also you know really annoying but you know the network doesn't

0:38:43.560,0:38:49.460
complain be like on your network not just kidding

0:38:54.910,0:39:01.720
okay additional resources full working demo it's offered here so in this on

0:39:01.720,0:39:06.880
this link I'm gonna be showing you because in the notebook the cold stops

0:39:06.880,0:39:13.779
there so here I just show you how you train the emulator and we got like like

0:39:13.779,0:39:22.349
an MSc loss down to very very tiny volume like a point like zero point

0:39:22.349,0:39:28.150
which is this or there okay you can read this number right and then this is my

0:39:28.150,0:39:35.559
value for the for the testing site right so this is going to be 38 micro MSE if

0:39:35.559,0:39:42.700
you want to call it here if someone wants an extra grade maybe you can add

0:39:42.700,0:39:50.559
the code for training the controller and it's not that trivial because I mean we

0:39:50.559,0:39:56.829
cover how to make it work in the in the class but a bit finicky so I just show

0:39:56.829,0:40:05.200
you a final version you can even copy from here if you want and I really like

0:40:05.200,0:40:13.269
if you can submit would be nice I mean you can get you know a nice reward so

0:40:13.269,0:40:18.609
here we can start with a random position and then you can do drive using the

0:40:18.609,0:40:25.720
controller let's increase the speed okay and boom another random position okay

0:40:25.720,0:40:32.440
it's too easy let's make something a bit you know annoying so trailer let's go

0:40:32.440,0:40:40.720
this one let's say 180 degrees and let's have this one zero change angle okay so

0:40:40.720,0:40:48.770
this is really annoying and go see buck and

0:40:49.790,0:40:56.060
there we go boom okay so here you have the code is training in your browser you

0:40:56.060,0:41:00.740
can go also at the bottom of this page and you have this source in github so

0:41:00.740,0:41:09.230
you can or even you know encouraged to port this project here which is written

0:41:09.230,0:41:16.040
in JavaScript to PI torch it's going to be very a very good exercise for you to

0:41:16.040,0:41:22.850
learn we would have actually running notebook which is you know left for as

0:41:22.850,0:41:30.770
an exercise for you and you forget additional great I guess alright so that

0:41:30.770,0:41:36.320
was it for today class I hope you enjoyed let me see if there are

0:41:36.320,0:41:42.620
questions but if we train a policy gradient yeah we don't know about we

0:41:42.620,0:41:45.620
don't know about reinforcement learning I don't know anything about

0:41:45.620,0:41:52.820
reinforcement learning sorry I'm still confused about the architecture can we

0:41:52.820,0:41:59.630
look at the diagram of that again yeah of course here so basically the

0:41:59.630,0:42:08.290
controller goes from 6 to 25 and then from 25 to 1 and they use some kind of

0:42:08.290,0:42:17.360
finite an age right your activation so 6 to 25 25 to 1 and this is the controller

0:42:17.360,0:42:23.270
and instead for the trailer the the trailer-truck emulator we go from 7

0:42:23.270,0:42:32.420
which is 6 right the X&Y and and the angle times 2 side is 6 plus 1 7 so from

0:42:32.420,0:42:38.660
7 to 45 and then for from from 45 to 6 so this is my predictive model the model

0:42:38.660,0:42:43.610
that predicts the future given the past in the actual input action and that's

0:42:43.610,0:42:49.370
how I implemented this one here so I have my state size which is 6x and Y and

0:42:49.370,0:42:57.080
theta times 2 and steering is 1 just the angle and we say we have 45 units right

0:42:57.080,0:43:02.780
so we have 45 units here so we go from steering signal like steering size Plus

0:43:02.780,0:43:07.280
stay sighs g72 this 45 then I have real ooh

0:43:07.280,0:43:12.470
again the it looks like they use at an age here so okay you can write that H

0:43:12.470,0:43:17.990
here and then you have a linear that goes from these 45 to state size which

0:43:17.990,0:43:23.150
is 6 which is going to be the next output here right and so there is a

0:43:23.150,0:43:27.320
linear output and again this is also something that we just put in the

0:43:27.320,0:43:30.800
midterm right I mean I'll give you the answer of the midterm right now

0:43:30.800,0:43:38.540
basically so what are you in the emulator actually emulates the way this

0:43:38.540,0:43:44.540
villager works the way it works yeah here so emulator training yeah we

0:43:44.540,0:43:49.880
haven't I I didn't show you this one you're right so here I just you know get

0:43:49.880,0:43:53.780
the length of the training input and I get a random permutation so that I pick

0:43:53.780,0:43:59.750
you know at random so I have my file my my angle and the state which are going

0:43:59.750,0:44:04.280
to be the seven coordinates is going to be picked from the ice location of these

0:44:04.280,0:44:08.930
training inputs and these training inputs are coming down from here

0:44:08.930,0:44:13.160
whenever I extract the dry so you have training inputs inputs are gonna be

0:44:13.160,0:44:19.190
appending to this list which is this list right input list you append the

0:44:19.190,0:44:24.170
file which is the steering angle and then the initial state which comes from

0:44:24.170,0:44:29.390
the track so this is my input and then the output is going to be my next the

0:44:29.390,0:44:37.130
output step like sorry the output state of the of the track so if you go back

0:44:37.130,0:44:44.450
here you get the find the angle and the state are going to be this first item of

0:44:44.450,0:44:48.830
this training input okay at the location I'm sorry the ice item of training input

0:44:48.830,0:44:52.130
and then you get the next state prediction is going to be the output of

0:44:52.130,0:44:57.230
this emulator which has a linear layer as output right cool

0:44:57.230,0:45:02.390
then you have the next state which is going to be going to be the output at

0:45:02.390,0:45:09.190
the ice location and now you have loss which is the criterion which was an MSc

0:45:09.190,0:45:15.390
criterion MSE so you have the MSE between the next

0:45:15.390,0:45:20.130
state prediction which is this one and the next state the true next state then

0:45:20.130,0:45:28.230
I do basically stochastically in the centrai I clean up the gradient I see so

0:45:28.230,0:45:31.110
you're basically training the emulator before you're training the rest of the

0:45:31.110,0:45:38.010
next Oh I train the emulator only before so we train two models first model you

0:45:38.010,0:45:42.990
train the emulator then whenever the emulator is trained you train the

0:45:42.990,0:45:51.540
controller which is driving the emulator but the emulator is not longer train the

0:45:51.540,0:45:56.970
emulator is trained only once before then we use the network in order to

0:45:56.970,0:46:01.890
train the controller so your first training the emulator and then you're

0:46:01.890,0:46:04.830
using the network you trained as emulator kind of control

0:46:04.830,0:46:11.640
correct yeah so whenever I'm here I feel I already trained this the trailer and

0:46:11.640,0:46:15.990
you later right so to train the emulator as I show you right now the code and

0:46:15.990,0:46:20.160
then I can show you also this slide so this is well this was the training of

0:46:20.160,0:46:25.550
the emulator the kinematics you have the next state given the previous state and

0:46:25.550,0:46:31.680
the angle and then you enforce this emulator to learn to basically do a

0:46:31.680,0:46:37.320
regression and you try to copy the output FinFET 5 after you're done when

0:46:37.320,0:46:42.180
you're done you actually go and train the controller to train the controller

0:46:42.180,0:46:48.090
and you basically have this chain of you know blocks which is controller and

0:46:48.090,0:46:53.940
trailer-truck did the track network and then you know you get basically a

0:46:53.940,0:47:00.240
trajectory and then you enforce that the final location and the final orientation

0:47:00.240,0:47:07.590
of this trajectory they must be you know the docking station and 0 for the angle

0:47:07.590,0:47:12.540
and now you run back propagation through this chain of things so it's backdrop

0:47:12.540,0:47:17.790
through time in order to adapt the use determine the word adapt in this paper

0:47:17.790,0:47:25.050
the weights of the controller such that it managed to map the original initial

0:47:25.050,0:47:29.930
run position to this final target position

0:47:29.930,0:47:34.820
and orientation configuration let's call it configuration so we start with a

0:47:34.820,0:47:41.030
random initial configuration which is corresponding to position and you know

0:47:41.030,0:47:47.270
angles and then you enforce that the final output of this you know sequence

0:47:47.270,0:47:53.990
of modules is going to be giving you the final the docking station and 0 on the

0:47:53.990,0:48:01.790
backside of the track ok so this is two parts training training first the

0:48:01.790,0:48:08.180
emulator Phoenix finished that you train the controller in order to follow to

0:48:08.180,0:48:13.670
actually reach a specific goal and the number of red boxes here is variable and

0:48:13.670,0:48:19.550
it depends on every episode because you don't know how many steps is gonna be

0:48:19.550,0:48:27.680
required for you to reach destination in every four given initial condition so

0:48:27.680,0:48:34.730
many words I said oh my god does it make sense yes ok very good

0:48:34.730,0:48:41.810
next question so somebody did ask this about why we needed to train the

0:48:41.810,0:48:48.680
emulator instead of just using the model you know yeah the answer was that not

0:48:48.680,0:48:55.510
every time you actually have the questions of the of the of the object

0:48:55.510,0:49:01.430
kinematics right so let's say and this is going to be coming up next lesson I

0:49:01.430,0:49:04.910
think whenever I'm going to be talking about my own research I'd like to figure

0:49:04.910,0:49:10.370
out what is the behavior of other cars when you drive in a highway but I can't

0:49:10.370,0:49:15.740
control other cars I have no idea how what is the behavior of other cars right

0:49:15.740,0:49:20.180
so the only way I can learn how other cars react to my actions is actually

0:49:20.180,0:49:25.190
through observations and therefore we run like you know we we have some

0:49:25.190,0:49:29.900
cameras mounted on a 30-story building watching you know looking at the highway

0:49:29.900,0:49:35.170
station a highway section and then you basically figure out what is the

0:49:35.170,0:49:39.290
interaction between vehicles and therefore we had to learn these four

0:49:39.290,0:49:42.650
our model is called predictive model which is figuring out what is going to

0:49:42.650,0:49:49.130
be the reaction of other vehicles given to your own actions so in this case yeah

0:49:49.130,0:49:56.030
you don't need the emulator but they train these emulators such that it's

0:49:56.030,0:50:02.180
more generic you don't need to have differentiable equations again I see

0:50:02.180,0:50:08.890
okay one one more question is so when you said the length of this recurrent

0:50:08.890,0:50:14.540
network will be variable there was something about having it be like four

0:50:14.540,0:50:23.330
times the length of the number of steps or something like that could you go into

0:50:23.330,0:50:27.980
that a bit more so here we assume that each length of

0:50:27.980,0:50:35.090
each episode is capital K okay so the lower cake lowercase K is the actual

0:50:35.090,0:50:40.760
index where you go like zero one two three four five whatever so each episode

0:50:40.760,0:50:47.150
has you know whatever capital K number of steps right so capital K is going to

0:50:47.150,0:50:56.390
be different for every episode right so each of these two items here this guy

0:50:56.390,0:51:00.740
here has to affine transformations and this guy here has to affine

0:51:00.740,0:51:04.370
transformations so overall the network that you are

0:51:04.370,0:51:11.260
seeing here has four affine transformations times capital K

0:51:11.270,0:51:18.160
oh I see okay that's basically one your net right so is a neural net which is

0:51:18.160,0:51:22.850
it's not even a recurrent neural net is a is a just a feed-forward neural net

0:51:22.850,0:51:29.780
with four times capital K number of affine transformations and now you train

0:51:29.780,0:51:34.400
with back prop in order to enforce always the same target right so that's

0:51:34.400,0:51:40.190
actually funny to see in this way so you have a neural network which label or

0:51:40.190,0:51:45.800
target is going to be always the same but then the network can change lengths

0:51:45.800,0:51:50.810
and the input can be different right so you had you have a network you have a

0:51:50.810,0:51:56.090
network you input different things you can change the length the height of the

0:51:56.090,0:52:00.890
the depth of the network but you always have the same target here right so

0:52:00.890,0:52:05.510
usually when you do a regression or classification we have a fixed network

0:52:05.510,0:52:10.850
you input different inputs like here and now you have different targets on here

0:52:10.850,0:52:16.760
right target or classes if you're doing classification or yeah labels right in

0:52:16.760,0:52:23.359
this case you have different inputs the target is always fixed and you have you

0:52:23.359,0:52:31.040
know different lengths so you train a network a variable depth network with

0:52:31.040,0:52:36.800
variable inputs and a fixed target how cool is that huh

0:52:36.800,0:52:42.590
do we enforce like a maximum length of the I I of course of course of course

0:52:42.590,0:52:49.280
otherwise you can move why do we need an emulator to train the neural net

0:52:49.280,0:52:53.750
emulator is the point of having a neural net emulator to have a differentiable

0:52:53.750,0:52:56.810
yeah that's the point right the whole point is to have a differentiable

0:52:56.810,0:53:04.310
emulator which is not always the case in case of you know just you had just

0:53:04.310,0:53:08.990
observations then you don't have gradients you just have observations and

0:53:08.990,0:53:12.410
you want to learn a network that allows you to tell you what is gonna be the

0:53:12.410,0:53:18.900
Jacobian as you go back more questions I have a question more

0:53:18.900,0:53:24.600
related to just like implementation mmm it seems like for training the

0:53:24.600,0:53:30.630
controller we freeze the weights for tea and so but we still need to pass the

0:53:30.630,0:53:35.570
gradients through in order to update freely each of the cells that really I

0:53:35.570,0:53:39.870
guess would we then like when we define our optimizer we're just essentially

0:53:39.870,0:53:45.450
just feeding it the controller parameters but when we called the

0:53:45.450,0:53:49.160
backwards it's all still connected to the same network

0:53:49.160,0:54:00.180
it's crap so this is gonna be exactly why torch examples what we have seen

0:54:00.180,0:54:15.510
last week when we were going through the DC gun so you have like a optimizer hold

0:54:15.510,0:54:24.000
on what is it yeah so you're gonna have an optimizer from the one network and I

0:54:24.000,0:54:27.930
have an optimizer for the other Network that's it whenever you have the training

0:54:27.930,0:54:31.830
you actually have two distinct training in this case when you train a generative

0:54:31.830,0:54:36.930
address on your network you have both networks stepping in the same loop but

0:54:36.930,0:54:40.920
you can have you know one training thing first you start with the first Network

0:54:40.920,0:54:45.630
then you all later below you're gonna have the other you're gonna have the

0:54:45.630,0:54:49.830
other network step in there right so you don't you had to optimizers which are

0:54:49.830,0:54:53.730
you know adopting if you use this word there from this paper the weights a

0:54:53.730,0:54:58.050
different time it's actually two different networks which don't even

0:54:58.050,0:55:01.860
train at the same time so you first train the predictive model the former

0:55:01.860,0:55:07.520
model finish whenever you finish that you use that as a mean to send back

0:55:07.520,0:55:12.810
gradients through the future from the future how do we choose capital K

0:55:12.810,0:55:18.140
capital K is the number of iterations that are necessary in order for you to

0:55:18.140,0:55:25.560
reach any edge you just go back until you hit something whenever you hit

0:55:25.560,0:55:32.310
something that's capital gain so actually whenever we drive forward we

0:55:32.310,0:55:36.900
use the kinematic model such that you have a truthful you know we find a

0:55:36.900,0:55:40.410
location but then in order to run the gradients backwards you're going to be

0:55:40.410,0:55:45.510
using the emulator network so you use the kinematics model to do the forward

0:55:45.510,0:55:50.420
pass and you do the backward pass through using the emulator network I

0:55:50.420,0:55:54.960
think this can be done better with policy gradient and deep are any model

0:55:54.960,0:56:00.780
okay we don't know about RL already for us doesn't make sense I'm

0:56:00.780,0:56:06.240
just repeating what the boss says you can try right you can definitely try out

0:56:06.240,0:56:10.320
and see whether it works again this stuff was done in the 90s right so

0:56:10.320,0:56:20.370
that's yeah it's it's all stuff but it's is always you know I call it pertinent

0:56:20.370,0:56:30.270
there you go more questions hi Alfred is about training for controller and

0:56:30.270,0:56:36.090
enumerator so the enumerator is trained at each time stab because we are

0:56:36.090,0:56:42.720
comparing the predict take the predicted state versus the reason right yeah at

0:56:42.720,0:56:48.960
each time step so so we are updating the parameters of any word for every time

0:56:48.960,0:56:53.760
step well you can also do a batch if you want but you can do stochastic gradient

0:56:53.760,0:56:56.610
this is okay so you can provide like you know sample

0:56:56.610,0:57:00.330
and then you update your sample updater and so on right or you can actually you

0:57:00.330,0:57:06.980
know step after several after several time steps okay okay and when we hit

0:57:06.980,0:57:12.720
okay we just we don't this is not about the emulator right there is no capital K

0:57:12.720,0:57:20.010
here oh it's like I'm confused because it's like we we do the training for

0:57:20.010,0:57:25.200
enumerative first and then when we hit the terminate state we don't do backdrop

0:57:25.200,0:57:33.780
for controller so first you train this network finish done second step you

0:57:33.780,0:57:37.680
train the controller next next next alright so you train first the first

0:57:37.680,0:57:41.519
network this one with random numbers here with randoms

0:57:41.519,0:57:47.069
during signal there is no controller here right yeah okay cool so you first

0:57:47.069,0:57:53.549
trained is emulator such that it can replicate these dynamics okay then

0:57:53.549,0:57:57.869
second part is gonna be training the controller and the controller is trained

0:57:57.869,0:58:04.559
in this manner you provide initial condition you feed forward this initial

0:58:04.559,0:58:08.909
condition you basically end up with a trajectory of several you know of each

0:58:08.909,0:58:15.839
case until you reach the one of the three final conditions which is you know

0:58:15.839,0:58:20.399
jackknifing running running out of steps or you actually hit a wall

0:58:20.399,0:58:25.439
if you hit a wall then you run back propagation through this network and

0:58:25.439,0:58:29.999
then you do like you're in the center right and now you're doing greatness and

0:58:29.999,0:58:36.269
with regards to the controller only see yes yes yes okay okay yeah I got it

0:58:36.269,0:58:43.949
thank you okay that's awesome that's it I think and so

0:58:43.949,0:58:48.449
you made it until the end of the lesson congratulations alright so how can you

0:58:48.449,0:58:53.130
better get an understanding of what we cover today so there are a few things

0:58:53.130,0:58:59.099
you can do to keep keep going right comprehension you have some questions

0:58:59.099,0:59:04.319
ask them just in the comment section below will answer everyone news if you

0:59:04.319,0:59:08.819
follow me on twitter under alpha CN z you can get the latest information as i

0:59:08.819,0:59:13.409
post them online update if you subscribe to the channel and turn on the

0:59:13.409,0:59:17.989
notification back you will not lose any of the videos i'm posting here

0:59:17.989,0:59:22.229
appreciation again if you like this video and the content and everything I

0:59:22.229,0:59:27.839
do I would really appreciate if you put a like in the on the video searching

0:59:27.839,0:59:32.159
every video has an English transcription which can be searchable and it is you

0:59:32.159,0:59:35.029
can find it in the video description below

0:59:35.029,0:59:40.439
language SEPA italiano hablas espanol equation putin gua you speak korean

0:59:40.439,0:59:44.369
turkish we have now all these translations are now available for you

0:59:44.369,0:59:51.569
implying to add more languages is we have volunteers PI torch if you'd like

0:59:51.569,0:59:56.730
to have a concrete understanding and digest better this topic I highly

0:59:56.730,1:00:01.830
recommend to you to try to train the controller yourself and if he works you

1:00:01.830,1:00:07.440
know you can submit a pull request and that's actually the next point and so

1:00:07.440,1:00:11.790
that such that we're gonna have now a notebook which will have a running

1:00:11.790,1:00:16.800
controller so this again is left to you as an exercise such that you can

1:00:16.800,1:00:22.350
actually master this topic okay alright thank you again for listening I see you

1:00:22.350,1:00:25.430
next time bye bye
