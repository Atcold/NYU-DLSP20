0:00:00.979,0:00:05.730
the recording is running and so as you

0:00:03.689,0:00:09.510
can see today we have a guest lecturer

0:00:05.730,0:00:11.519
we have a shun mistre Asian misra is a

0:00:09.510,0:00:14.309
research scientist at Facebook AI

0:00:11.519,0:00:16.320
research fair where he works on computer

0:00:14.309,0:00:18.840
vision and machine learning his research

0:00:16.320,0:00:20.939
interest is in reducing the need for

0:00:18.840,0:00:24.119
supervision in visual learning

0:00:20.939,0:00:25.680
I finished his PhD at the robotics

0:00:24.119,0:00:27.930
Institute at the Carnegie Mellon

0:00:25.680,0:00:32.369
University where he worked with Martin

0:00:27.930,0:00:35.610
help Hobart and Abhinav Gupta his PhD

0:00:32.369,0:00:37.649
thesis was about I was titled visual

0:00:35.610,0:00:40.559
learning with minimal human supervision

0:00:37.649,0:00:43.530
for which he received the SCS

0:00:40.559,0:00:48.000
distinguished dissertation award so in

0:00:43.530,0:00:49.440
2018 so with less how to say with

0:00:48.000,0:00:52.620
further ado I don't have to speak

0:00:49.440,0:00:54.809
English let's get we cannot even have

0:00:52.620,0:00:56.340
the round of applause you know can we

0:00:54.809,0:00:59.730
have like in the chat round of applause

0:00:56.340,0:01:01.770
for our speaker so everyone my name is

0:00:59.730,0:01:02.940
Isha I'll be talking about self

0:01:01.770,0:01:06.330
supervised learning in computer vision

0:01:02.940,0:01:07.890
today and a lot of the focus is actually

0:01:06.330,0:01:10.200
going to be sort of more on the

0:01:07.890,0:01:11.790
discriminative style of approaches and

0:01:10.200,0:01:13.229
it's not really going to be on

0:01:11.790,0:01:15.210
generative set of approaches and I sort

0:01:13.229,0:01:18.630
of go about it more and more as I go

0:01:15.210,0:01:21.509
into my talk so this sort of success

0:01:18.630,0:01:23.070
story for representation learning or

0:01:21.509,0:01:25.439
like computer vision so far has been

0:01:23.070,0:01:28.770
clearly this sort of pre training step

0:01:25.439,0:01:31.409
or the imagenet moment of like computer

0:01:28.770,0:01:33.840
vision so what has worked really well is

0:01:31.409,0:01:35.220
that when we have a large label data set

0:01:33.840,0:01:37.470
like image net we can learn a

0:01:35.220,0:01:39.540
representation by performing an image

0:01:37.470,0:01:42.420
classification task on this large data

0:01:39.540,0:01:44.070
set and what is very useful is not just

0:01:42.420,0:01:46.320
performing this particular task at hand

0:01:44.070,0:01:48.000
but to take these representations that

0:01:46.320,0:01:49.680
you learn and they're to use them for

0:01:48.000,0:01:51.810
downstream tasks where you may not have

0:01:49.680,0:01:54.149
enough label data and this has worked

0:01:51.810,0:01:57.140
really really well and sort of them also

0:01:54.149,0:02:01.310
standard recipe of success

0:01:57.140,0:02:03.170
now the so this really involves

0:02:01.310,0:02:06.410
collecting a large dataset of supervisor

0:02:03.170,0:02:08.390
images and you need to get a bunch of

0:02:06.410,0:02:10.190
these large diverse images and label

0:02:08.390,0:02:12.950
them with a bunch of large diverse

0:02:10.190,0:02:17.480
concepts so let's try to first see

0:02:12.950,0:02:19.370
whether we can sort of collect these

0:02:17.480,0:02:22.280
labels and what are sort of the

0:02:19.370,0:02:25.160
difficulties in doing so so the image

0:02:22.280,0:02:28.100
net data set is a very sort of small

0:02:25.160,0:02:30.530
data set in the grander scheme of things

0:02:28.100,0:02:33.650
for example image net just has 14

0:02:30.530,0:02:36.380
million images and it has roughly 22,000

0:02:33.650,0:02:37.550
concepts and just labeling this entire

0:02:36.380,0:02:40.160
thing if you look at the amount of

0:02:37.550,0:02:43.090
effort that was spent it's about 22

0:02:40.160,0:02:45.560
human years to label this entire dataset

0:02:43.090,0:02:47.330
for contrast a lot of people started

0:02:45.560,0:02:49.400
looking at these alternative supervision

0:02:47.330,0:02:52.250
approaches where you are predicting

0:02:49.400,0:02:54.950
something like not really a very sort of

0:02:52.250,0:02:57.620
pristine nice label but something which

0:02:54.950,0:03:00.170
is more easy to get for example predict

0:02:57.620,0:03:02.750
like hashtags or to take GPS locations

0:03:00.170,0:03:04.880
of images or what we're going to really

0:03:02.750,0:03:06.950
focus on in this lecture is going to be

0:03:04.880,0:03:11.420
about Excel supervised learning which is

0:03:06.950,0:03:12.709
going to be using the data itself so the

0:03:11.420,0:03:15.680
first question that I always like to

0:03:12.709,0:03:17.120
sort of start out with is why why don't

0:03:15.680,0:03:19.519
you just like get labels for all your

0:03:17.120,0:03:22.010
data why do you even want to invent this

0:03:19.519,0:03:24.650
entire line of research why not just get

0:03:22.010,0:03:26.780
all the labels so I did this small

0:03:24.650,0:03:28.519
exercise where I plotted the amount of

0:03:26.780,0:03:32.269
supervision that we have for vision data

0:03:28.519,0:03:33.650
sets so what I did is basically I'd

0:03:32.269,0:03:36.470
looked at all the images which have

0:03:33.650,0:03:39.110
bounding boxes and so these are images

0:03:36.470,0:03:40.549
where you know what kind of concepts are

0:03:39.110,0:03:42.170
in the image and you also have a box

0:03:40.549,0:03:43.640
drawn around them and this is sort of

0:03:42.170,0:03:46.070
the standard thing to do for something

0:03:43.640,0:03:47.540
like an object detection model so if you

0:03:46.070,0:03:49.160
look at all the data sets in vision that

0:03:47.540,0:03:52.370
have bounding boxes you'll get roughly

0:03:49.160,0:03:53.870
about a million or so images now if you

0:03:52.370,0:03:55.760
relax this constraint and you say that

0:03:53.870,0:03:57.769
okay I don't really care about where the

0:03:55.760,0:03:59.540
object is located all I care about is

0:03:57.769,0:04:01.670
what objects are located what objects

0:03:59.540,0:04:03.260
are present in the image and so if you

0:04:01.670,0:04:05.810
relax that constraint you immediately

0:04:03.260,0:04:08.569
get an order of magnitude more data so

0:04:05.810,0:04:10.910
you basically get about that yeah about

0:04:08.569,0:04:12.950
40 million images or so

0:04:10.910,0:04:14.540
now if you further sort of relax this

0:04:12.950,0:04:16.250
constraint and you say that I don't

0:04:14.540,0:04:19.040
really care about this image level

0:04:16.250,0:04:21.350
supervision either all I care about is

0:04:19.040,0:04:25.070
internet internet pictures that are

0:04:21.350,0:04:27.020
present you get basically about five

0:04:25.070,0:04:30.680
orders of magnitude more amount of data

0:04:27.020,0:04:32.300
and so if you look at this plot now you

0:04:30.680,0:04:34.040
can see immediately that the amount of

0:04:32.300,0:04:36.040
data that we have which is labeled even

0:04:34.040,0:04:38.180
at a bounding box or an image level is

0:04:36.040,0:04:40.610
basically nothing compared to what

0:04:38.180,0:04:43.610
images exist on in the internet scale

0:04:40.610,0:04:46.430
and I haven't really forgotten these

0:04:43.610,0:04:47.480
images like forgotten the bars on the

0:04:46.430,0:04:49.310
left hand side it's just that they

0:04:47.480,0:04:50.750
completely disappear and you really need

0:04:49.310,0:04:52.820
to make this plot something like a log

0:04:50.750,0:04:58.010
plot to actually even get these bars to

0:04:52.820,0:04:59.900
appear so now of course internet photos

0:04:58.010,0:05:01.100
do not represent everything about the

0:04:59.900,0:05:02.870
world there are things that really

0:05:01.100,0:05:04.640
require motion or things that really

0:05:02.870,0:05:07.340
require other physical senses to learn

0:05:04.640,0:05:08.630
so in the real world there are going to

0:05:07.340,0:05:10.880
be far more things that you actually

0:05:08.630,0:05:13.400
experience far more sensory inputs that

0:05:10.880,0:05:15.250
you can get and it's really hard to

0:05:13.400,0:05:17.540
obtain labels for all this data and

0:05:15.250,0:05:19.790
again to put things in perspective

0:05:17.540,0:05:22.310
imagenet which is just for teens in

0:05:19.790,0:05:24.890
images and with a very small number of

0:05:22.310,0:05:26.840
concepts that you have required a lot of

0:05:24.890,0:05:29.240
time the label so clearly labeling is

0:05:26.840,0:05:30.800
not really going to scale to either all

0:05:29.240,0:05:35.960
of Internet photos or even the real

0:05:30.800,0:05:38.960
world so the other sort of problem with

0:05:35.960,0:05:41.120
labeling is that for complex concepts

0:05:38.960,0:05:44.210
like video it's just really hard to sort

0:05:41.120,0:05:47.630
of scale labeling the second problem is

0:05:44.210,0:05:50.810
that rare concepts sort of are really

0:05:47.630,0:05:53.030
hard to label so for example this is one

0:05:50.810,0:05:55.580
of the popular image data sets called

0:05:53.030,0:05:57.590
label me and over here we can see that

0:05:55.580,0:05:59.330
if you look at the kinds of concepts you

0:05:57.590,0:06:01.610
observe there are a lot of concepts that

0:05:59.330,0:06:03.710
are so rare that you're going to have

0:06:01.610,0:06:06.920
the label a lot of data to even get a

0:06:03.710,0:06:09.770
few instances of these concepts so in

0:06:06.920,0:06:12.680
this data set 10% of the classes account

0:06:09.770,0:06:14.660
for more than 93% of the data which

0:06:12.680,0:06:17.120
already tells you that in order to sort

0:06:14.660,0:06:19.190
of scale labeling to like more and more

0:06:17.120,0:06:21.560
concepts you'll need a lot and lot more

0:06:19.190,0:06:23.630
data with very diminishing returns so

0:06:21.560,0:06:24.840
this is sort of the standard long-tailed

0:06:23.630,0:06:29.340
problem

0:06:24.840,0:06:30.900
and of course pre-training is not right

0:06:29.340,0:06:32.400
always the right thing to do for example

0:06:30.900,0:06:34.710
if you just completely change your

0:06:32.400,0:06:36.330
domain to now move it to say medical

0:06:34.710,0:06:37.919
imaging it's not clear whether a

0:06:36.330,0:06:40.860
missionary training is the right sort of

0:06:37.919,0:06:42.360
thing for this task or if you do not

0:06:40.860,0:06:44.520
know sort of the downstream tasks a

0:06:42.360,0:06:45.960
priority how do you collect a big data

0:06:44.520,0:06:48.060
set and how do you do this entire free

0:06:45.960,0:06:52.410
training a downstream task fine evening

0:06:48.060,0:06:54.570
recipe so self supervised loading sort

0:06:52.410,0:06:56.700
of comes in between and it tries to give

0:06:54.570,0:06:59.729
you an alternate way to pre train your

0:06:56.700,0:07:01.710
models or to learn from data or learn

0:06:59.729,0:07:06.780
from experiences without requiring

0:07:01.710,0:07:08.729
pristine supervision so in this case so

0:07:06.780,0:07:09.870
there are sort of two simple definitions

0:07:08.729,0:07:12.120
that you can come up with for self

0:07:09.870,0:07:13.770
supervised learning the first is more

0:07:12.120,0:07:16.560
from like a discriminative or like a

0:07:13.770,0:07:17.970
supervised training perspective so in

0:07:16.560,0:07:20.100
imagenet for example you have an image

0:07:17.970,0:07:22.110
and you can it can be classified into

0:07:20.100,0:07:24.210
one of thousand levels so self to

0:07:22.110,0:07:27.410
provide everything can be thought of as

0:07:24.210,0:07:30.419
a way to obtain labels from the data

0:07:27.410,0:07:31.919
using an automatic process so that

0:07:30.419,0:07:33.570
automatic process does not really

0:07:31.919,0:07:36.030
require a lot of human intervention

0:07:33.570,0:07:38.220
and so once you get these automatic

0:07:36.030,0:07:42.060
labels now you can sort of go ahead and

0:07:38.220,0:07:43.350
train your model with these labels the

0:07:42.060,0:07:45.419
other way of thinking about self

0:07:43.350,0:07:47.250
supervised learning is that it's really

0:07:45.419,0:07:49.770
a prediction problem where you are

0:07:47.250,0:07:52.169
trying to predict a part of the data

0:07:49.770,0:07:54.840
from the other parts of the data so you

0:07:52.169,0:07:56.550
have some observed data and you have

0:07:54.840,0:07:58.950
some hidden data and you can now

0:07:56.550,0:08:00.870
formulate a task where given the

0:07:58.950,0:08:03.060
observed data you try to predict either

0:08:00.870,0:08:06.360
the hidden data or some property of the

0:08:03.060,0:08:07.740
hidden data and so pretty much a lot of

0:08:06.360,0:08:09.330
sort of the cell supervised techniques

0:08:07.740,0:08:10.930
can be viewed in this particular

0:08:09.330,0:08:13.930
framework

0:08:10.930,0:08:16.600
so the term sort of self supervisor

0:08:13.930,0:08:18.160
thing I really like to give this analogy

0:08:16.600,0:08:21.100
which is from Virginia Tessa

0:08:18.160,0:08:22.449
so where she sort of tries to

0:08:21.100,0:08:24.130
distinguish between the three terms

0:08:22.449,0:08:27.250
supervised unsupervised and self

0:08:24.130,0:08:30.430
supervised and so supervised learning

0:08:27.250,0:08:32.289
you have say an input cow and you're

0:08:30.430,0:08:35.020
given the exact target for it which is

0:08:32.289,0:08:36.640
say going to be the label cow and

0:08:35.020,0:08:39.070
unsupervised learning you're given this

0:08:36.640,0:08:41.200
input and it's not clear what really the

0:08:39.070,0:08:43.599
entire target is what exactly is the

0:08:41.200,0:08:47.200
objective function or so on cell

0:08:43.599,0:08:49.959
supervised learning is sort of the term

0:08:47.200,0:08:53.020
which is preferred now more and more and

0:08:49.959,0:08:54.940
the idea is that the label really comes

0:08:53.020,0:08:57.130
from either a co-occurring mortality or

0:08:54.940,0:08:58.779
co-occurring part of the data itself so

0:08:57.130,0:09:01.120
really all of the power is in the data

0:08:58.779,0:09:02.410
and you're really trying to predict sort

0:09:01.120,0:09:07.839
of predict either parts of it are

0:09:02.410,0:09:09.730
properties of the data so some very sort

0:09:07.839,0:09:11.680
of standard and successful examples of

0:09:09.730,0:09:16.150
this are safe either the word to that

0:09:11.680,0:09:18.850
model they're given this say a sentence

0:09:16.150,0:09:20.500
for example the cat sits on the mat you

0:09:18.850,0:09:22.209
are given a part of the sentence that

0:09:20.500,0:09:24.490
you observe so which is in this case

0:09:22.209,0:09:26.890
labeled as the context or the history

0:09:24.490,0:09:29.650
and then you have a part of the sentence

0:09:26.890,0:09:31.300
of word in this case which is not

0:09:29.650,0:09:35.200
observed which you sort of hide from

0:09:31.300,0:09:37.450
this entire model and given this context

0:09:35.200,0:09:39.820
you ask the model to predict this target

0:09:37.450,0:09:42.459
and so you have yourself supervisor

0:09:39.820,0:09:44.529
objective you can minimize it in a

0:09:42.459,0:09:46.209
particular fashion and now you will

0:09:44.529,0:09:49.839
learn a representation for your input

0:09:46.209,0:09:51.279
data and word to back has been I mean it

0:09:49.839,0:09:53.410
has actually shown a lot of promise in

0:09:51.279,0:09:55.329
the riot II of applications and this

0:09:53.410,0:09:57.160
entire sort of predictive model has

0:09:55.329,0:10:00.880
inspired a lot of work in computer

0:09:57.160,0:10:03.339
vision as well the success of Cell

0:10:00.880,0:10:05.980
supervisor thing is sort of undebatable

0:10:03.339,0:10:07.990
in natural language processing so in

0:10:05.980,0:10:11.260
2018 there was this really successful

0:10:07.990,0:10:14.440
model called pert which basically is a

0:10:11.260,0:10:16.660
form of a mast or two encoder and this

0:10:14.440,0:10:18.100
modular sort of revolutionized the

0:10:16.660,0:10:20.110
amount of things that you can do in NLP

0:10:18.100,0:10:22.420
with limited amount of data and a lot of

0:10:20.110,0:10:24.430
people call this the image net moment of

0:10:22.420,0:10:28.360
energy

0:10:24.430,0:10:30.160
so in this talk we'll sort of again to

0:10:28.360,0:10:32.410
motivate why we want to use self

0:10:30.160,0:10:37.150
supervised learning we are really going

0:10:32.410,0:10:38.980
to focus on sort of how you can look at

0:10:37.150,0:10:40.660
data and you can use observations and

0:10:38.980,0:10:42.520
interactions of the data to formulate

0:10:40.660,0:10:45.070
self supervised tasks how you can

0:10:42.520,0:10:46.570
leverage multiple modalities and I'll

0:10:45.070,0:10:49.000
talk a little bit more about what this

0:10:46.570,0:10:51.810
term modalities means or structure in

0:10:49.000,0:10:55.720
the data to sort of learn

0:10:51.810,0:10:57.760
representations so let's move on to the

0:10:55.720,0:10:59.860
context of computer vision and I'll sort

0:10:57.760,0:11:01.450
of now try to define things that I've

0:10:59.860,0:11:03.640
been talking about in a slightly high

0:11:01.450,0:11:05.800
level in more concrete fashion first

0:11:03.640,0:11:07.540
question so cell supervised learning is

0:11:05.800,0:11:14.440
basically just unsupervised learning

0:11:07.540,0:11:17.590
right yes I mean yes yes I mean

0:11:14.440,0:11:21.250
basically the sort of main differences

0:11:17.590,0:11:23.140
like unsupervised is sort of very poorly

0:11:21.250,0:11:26.730
defined term so there is supervised but

0:11:23.140,0:11:28.990
what is unsupervised so for example the

0:11:26.730,0:11:31.240
analogy given by Jeetendra malloc is

0:11:28.990,0:11:34.210
there is a cat but there is no category

0:11:31.240,0:11:35.530
called on cat so that's the reason to

0:11:34.210,0:11:37.510
sort of come like

0:11:35.530,0:11:39.520
refer this term more and more that it's

0:11:37.510,0:11:41.980
really about using the data or the

0:11:39.520,0:11:43.480
properties of the data itself to come up

0:11:41.980,0:11:50.260
with supervision so that's why self

0:11:43.480,0:11:53.980
super so for my so Jason is a subset yes

0:11:50.260,0:11:57.790
I guess yes I mean I guess you know my

0:11:53.980,0:11:59.560
reason for Konya this is that the

0:11:57.790,0:12:01.330
algorithms the algorithms are

0:11:59.560,0:12:02.440
essentially the same as supervised

0:12:01.330,0:12:04.390
learning algorithms with some

0:12:02.440,0:12:07.450
modification as because you're kind of

0:12:04.390,0:12:09.240
training the system to learn part of its

0:12:07.450,0:12:11.830
input from another part of the input so

0:12:09.240,0:12:13.720
it's very similar to supervised many

0:12:11.830,0:12:17.890
many ways except that you need to handle

0:12:13.720,0:12:19.450
uncertainty better and the negative

0:12:17.890,0:12:22.830
category if you want may be much larger

0:12:19.450,0:12:24.640
which is kind of an issue but

0:12:22.830,0:12:27.460
unsupervised running is really not very

0:12:24.640,0:12:30.040
well defined so surprise running is kind

0:12:27.460,0:12:31.120
of a very different concept it's not

0:12:30.040,0:12:33.960
entirely clear it's a subset of

0:12:31.120,0:12:33.960
unsupervised

0:12:38.890,0:12:43.750
so moving ahead and now sort of try to

0:12:41.459,0:12:47.470
talk about self supervised learning more

0:12:43.750,0:12:50.050
in the context of vision so envision a

0:12:47.470,0:12:54.310
lot of these sort of prediction problems

0:12:50.050,0:12:57.550
have been framed as pretext tasks so lot

0:12:54.310,0:13:00.060
of the vision algorithms sort of and

0:12:57.550,0:13:02.620
this term comes more from 2015 where

0:13:00.060,0:13:06.490
from this particular paper by Carl Tosh

0:13:02.620,0:13:09.250
and the idea here was that you have a

0:13:06.490,0:13:10.959
text task or the sort of task that you

0:13:09.250,0:13:13.270
really care about at the end like image

0:13:10.959,0:13:16.660
classification but of course you don't

0:13:13.270,0:13:18.880
have a lot of data for that or you so

0:13:16.660,0:13:22.270
you want to solve a task before going to

0:13:18.880,0:13:24.339
the real task so a pretext task so this

0:13:22.270,0:13:26.380
pretext task is a prediction task that

0:13:24.339,0:13:29.800
you are solving but it's not often the

0:13:26.380,0:13:31.570
real task that you really care about so

0:13:29.800,0:13:34.089
you solve this particular task to learn

0:13:31.570,0:13:35.649
a representation and then you finally

0:13:34.089,0:13:37.270
get your downstream tasks where you want

0:13:35.649,0:13:38.200
to use this representation to perform

0:13:37.270,0:13:40.329
something meaningful

0:13:38.200,0:13:45.070
so these pretext tasks are sort of funny

0:13:40.329,0:13:46.810
they're often fairly like people got

0:13:45.070,0:13:51.600
very creative with sort of coming up

0:13:46.810,0:13:54.250
with these pretext asks so let's look at

0:13:51.600,0:13:56.740
how you can define a bunch of three text

0:13:54.250,0:13:59.680
tasks and what each of these pretext

0:13:56.740,0:14:02.140
tasks is trying to do and so you can use

0:13:59.680,0:14:04.420
either images video video and sound when

0:14:02.140,0:14:06.070
you're trying to do these things and in

0:14:04.420,0:14:08.110
each case you'll have a bunch of observe

0:14:06.070,0:14:09.880
data and you'll try to either predict

0:14:08.110,0:14:12.250
hidden data or you try to predict a

0:14:09.880,0:14:16.050
property of type in beta and this sort

0:14:12.250,0:14:18.399
of distinguishes a bunch of approaches

0:14:16.050,0:14:22.770
so let's look at how you can use images

0:14:18.399,0:14:25.390
to define something like a pretext task

0:14:22.770,0:14:28.540
so the paper that introduced this term

0:14:25.390,0:14:31.540
pretext task came up with this a fairly

0:14:28.540,0:14:36.250
sort of funny method but what you do is

0:14:31.540,0:14:38.350
you take say two image patches basically

0:14:36.250,0:14:39.730
take the network and you ask a network

0:14:38.350,0:14:42.490
to predict what is the relative position

0:14:39.730,0:14:45.220
of each patch with respect to the other

0:14:42.490,0:14:48.080
so in this case say I first sample a

0:14:45.220,0:14:51.170
blue patch and now I sample another

0:14:48.080,0:14:52.610
Dutch so what I do is I basically feed

0:14:51.170,0:14:55.220
forward both of these patches through a

0:14:52.610,0:14:56.930
cornet and I have a classifier that is

0:14:55.220,0:14:59.600
going to solve the a2 a classification

0:14:56.930,0:15:01.340
problem and how do I get the label for

0:14:59.600,0:15:03.530
this classification problem well I just

0:15:01.340,0:15:05.900
look at where the red patch is located

0:15:03.530,0:15:08.030
with respect to the blue patch and

0:15:05.900,0:15:09.800
that's it so at the end of it you're

0:15:08.030,0:15:11.270
just predicting you're just solving an

0:15:09.800,0:15:14.240
eight-way classification task

0:15:11.270,0:15:16.220
you got your labels by basically doing

0:15:14.240,0:15:19.490
this sort of exploiting this property of

0:15:16.220,0:15:22.100
the input data and that's it now you you

0:15:19.490,0:15:24.410
can use this to basically train and this

0:15:22.100,0:15:28.070
entire con that

0:15:24.410,0:15:29.660
sort of to sort of look at it in a

0:15:28.070,0:15:32.570
different way it's only solving a very

0:15:29.660,0:15:34.220
small classification problem

0:15:32.570,0:15:37.180
it's just solving basically eight

0:15:34.220,0:15:39.560
possible locations sort of a problem

0:15:37.180,0:15:42.110
surprisingly enough doing this sort of

0:15:39.560,0:15:45.980
pretext task actually learns something

0:15:42.110,0:15:48.020
fairly reasonable so the one way to look

0:15:45.980,0:15:50.120
at what this network has learned is to

0:15:48.020,0:15:51.320
look at what it considers our nearest

0:15:50.120,0:15:55.700
neighbors in its face with

0:15:51.320,0:15:57.680
representation so to explain this plot a

0:15:55.700,0:15:59.780
little bit more on the left-hand side

0:15:57.680,0:16:01.610
you have the input patch so you feed

0:15:59.780,0:16:05.630
forward this input patch through that

0:16:01.610,0:16:08.150
CNN and you basically extract a bunch of

0:16:05.630,0:16:10.580
patches on the data on your data set so

0:16:08.150,0:16:11.960
in this case imagine it and you compute

0:16:10.580,0:16:14.720
feature representations for each of

0:16:11.960,0:16:16.160
these patches now for the particular

0:16:14.720,0:16:18.020
input patch that you sent through the

0:16:16.160,0:16:20.150
content you compute the nearest

0:16:18.020,0:16:21.560
neighbors of all the patches from the

0:16:20.150,0:16:23.210
data set and you can use three different

0:16:21.560,0:16:25.970
networks to compute the feature

0:16:23.210,0:16:27.560
representations so the first column is

0:16:25.970,0:16:29.900
the relative positioning free text task

0:16:27.560,0:16:32.510
and the second column is basically a

0:16:29.900,0:16:34.640
randomly initialized Alex net and then

0:16:32.510,0:16:36.320
the third case is third column is

0:16:34.640,0:16:41.300
basically an image net pre-trained Alex

0:16:36.320,0:16:43.400
net so if you sort of look at what this

0:16:41.300,0:16:45.230
relative positioning task is capturing

0:16:43.400,0:16:47.510
it's really able to find very good

0:16:45.230,0:16:50.810
patches patches that are identical or

0:16:47.510,0:16:52.970
very close to the input patch and you

0:16:50.810,0:16:55.130
also see that it's for example like in

0:16:52.970,0:16:57.290
the row of the cat so that's the fourth

0:16:55.130,0:16:59.270
row you can see that it's actually able

0:16:57.290,0:17:01.610
to figure out it's slightly invariant to

0:16:59.270,0:17:03.260
say the colors so the input carrot was

0:17:01.610,0:17:04.460
black and white but it's actually able

0:17:03.260,0:17:06.860
to pick out cats which are not just

0:17:04.460,0:17:09.050
black and white so it's really doing

0:17:06.860,0:17:12.110
something it's trying it's at least able

0:17:09.050,0:17:15.170
to reason about patches as a whole so

0:17:12.110,0:17:18.620
why should this representation do

0:17:15.170,0:17:20.180
anything which is semantic so the

0:17:18.620,0:17:22.040
nearest neighbor visualization technique

0:17:20.180,0:17:24.710
is good at telling you what this

0:17:22.040,0:17:27.080
representation space has captured so in

0:17:24.710,0:17:29.810
this case what we can confidently say is

0:17:27.080,0:17:32.570
that this relative patch representation

0:17:29.810,0:17:35.000
has learned to sort of associate a bunch

0:17:32.570,0:17:36.230
of these local patches together local

0:17:35.000,0:17:37.890
patches that have roughly the same

0:17:36.230,0:17:40.110
appearance

0:17:37.890,0:17:42.030
and so because it is able to reason

0:17:40.110,0:17:43.770
about these local patches maybe it's

0:17:42.030,0:17:45.750
actually able to reason about an image

0:17:43.770,0:17:48.420
because image can sort of be viewed as a

0:17:45.750,0:17:50.550
bunch of local patches together so it's

0:17:48.420,0:17:54.680
able to sort of put these patches in one

0:17:50.550,0:17:54.680
part of the representation space

0:17:55.700,0:18:00.350
the now people have like I said people

0:17:58.280,0:18:02.510
have gotten fairly creative with the

0:18:00.350,0:18:05.750
kinds of pretext tasks they do so

0:18:02.510,0:18:07.780
another sort of popular pretext task is

0:18:05.750,0:18:10.820
predicting rotations of an image and

0:18:07.780,0:18:13.280
this so this task is very

0:18:10.820,0:18:15.890
straightforward you have an image you

0:18:13.280,0:18:19.610
can either apply a rotation of 0 degrees

0:18:15.890,0:18:22.420
90 degrees 180 degrees or 270 degrees to

0:18:19.610,0:18:24.410
it and basically you send in that

0:18:22.420,0:18:26.360
particular image after applying a

0:18:24.410,0:18:28.370
rotation and you ask the network to

0:18:26.360,0:18:30.770
predict what was the exact rotation

0:18:28.370,0:18:33.230
applied to the image and it just solves

0:18:30.770,0:18:34.940
a four-way classification problem so it

0:18:33.230,0:18:41.960
predicts basically either if the

0:18:34.940,0:18:43.490
rotation is 0 90 180 or 270 and this 3

0:18:41.960,0:18:45.140
text task is actually one of the most

0:18:43.490,0:18:47.299
popular pretext tasks now because it's

0:18:45.140,0:18:50.480
so easy to implement you basically just

0:18:47.299,0:18:51.860
take an image it's very very simple you

0:18:50.480,0:18:54.049
don't really need to sample too many

0:18:51.860,0:18:55.580
patches or solve any sort of complicated

0:18:54.049,0:18:57.799
thing it's a very standard architecture

0:18:55.580,0:19:00.650
and you can solve this let's become

0:18:57.799,0:19:02.150
fairly popular now so the network is

0:19:00.650,0:19:03.620
going to be basically trained so the

0:19:02.150,0:19:06.410
feature are trained in order to solve

0:19:03.620,0:19:09.200
this problem right so the output will be

0:19:06.410,0:19:11.690
somehow dependent on the specific task

0:19:09.200,0:19:14.510
someone is going to be peaking somehow

0:19:11.690,0:19:16.730
right yes so this is again this is a

0:19:14.510,0:19:18.320
pretext task so we are not really

0:19:16.730,0:19:19.970
interested in predicting the rotations

0:19:18.320,0:19:22.190
of an image we are just using this task

0:19:19.970,0:19:24.440
as a proxy to learn some features so

0:19:22.190,0:19:26.059
that on the downstream tasks say when

0:19:24.440,0:19:28.490
someone gives us a thousand labels

0:19:26.059,0:19:30.020
images of a cat we can then use this pre

0:19:28.490,0:19:31.299
trained feature representation to do

0:19:30.020,0:19:33.830
that particular task

0:19:31.299,0:19:35.210
so these pretext tests are often really

0:19:33.830,0:19:37.820
not going to make a lot of semantic

0:19:35.210,0:19:40.090
sense and that's problem like that sort

0:19:37.820,0:19:42.380
of the reason for calling them pretext

0:19:40.090,0:19:44.000
because you have a downstream task where

0:19:42.380,0:19:48.100
you actually have some semantics or some

0:19:44.000,0:19:48.100
label that you actually know is good

0:19:48.130,0:19:56.140
Thanks why would the predicting

0:19:51.620,0:19:59.480
rotations give us any sort of useful

0:19:56.140,0:20:01.160
representations yes so in fact when this

0:19:59.480,0:20:03.770
paper came out this was the question of

0:20:01.160,0:20:05.090
many many people and it was my question

0:20:03.770,0:20:07.480
as well

0:20:05.090,0:20:11.810
empirically this actually works really

0:20:07.480,0:20:13.940
and sort of my intuition for this has

0:20:11.810,0:20:16.460
basically been that in order to predict

0:20:13.940,0:20:18.410
what sort of the rotation of an object

0:20:16.460,0:20:20.930
is it needs to it roughly understand

0:20:18.410,0:20:23.120
what the boundaries or what sort of some

0:20:20.930,0:20:25.610
concepts in this image are for example

0:20:23.120,0:20:28.130
to predict that this particular image is

0:20:25.610,0:20:30.740
rotated by 180 degrees it needs to at

0:20:28.130,0:20:33.800
least recognize a sort of segregate the

0:20:30.740,0:20:35.870
sky from like the sand or the sky from

0:20:33.800,0:20:38.810
the water or at least understand that

0:20:35.870,0:20:41.330
for a tree the leaves are generally not

0:20:38.810,0:20:44.720
below sort of the bar trees don't go

0:20:41.330,0:20:46.910
grow like downwards they grow upwards so

0:20:44.720,0:20:49.310
it sort of needs to reason about some

0:20:46.910,0:20:51.340
things implicitly it's not super clear

0:20:49.310,0:20:55.000
what it really needs to do but this task

0:20:51.340,0:20:59.750
empirically works very well has then

0:20:55.000,0:21:01.910
only been tried or works as a task with

0:20:59.750,0:21:03.860
like a discrete classification or has it

0:21:01.910,0:21:05.750
has been tried on like a continuous

0:21:03.860,0:21:06.610
scale of angles at which the image is

0:21:05.750,0:21:10.790
rotated

0:21:06.610,0:21:12.440
yes so you can do both versions so you

0:21:10.790,0:21:14.120
can I mean you can sort of increase the

0:21:12.440,0:21:15.950
number of Bin's you want and as you

0:21:14.120,0:21:17.870
basically make it very very large

0:21:15.950,0:21:20.810
approaching more of a regression problem

0:21:17.870,0:21:23.360
where you have a continuous variable in

0:21:20.810,0:21:30.080
practice these four sort of angles were

0:21:23.360,0:21:32.210
pretty well increasing and there is a

0:21:30.080,0:21:34.250
question about the previous slide how

0:21:32.210,0:21:36.410
does the nearest neighborhood work in

0:21:34.250,0:21:40.040
this context do you run every patch each

0:21:36.410,0:21:41.720
patch through the CNN yes so this is

0:21:40.040,0:21:44.240
just for visualization this is just for

0:21:41.720,0:21:46.970
sort of understanding so it although it

0:21:44.240,0:21:48.620
is like sort of expensive to compute

0:21:46.970,0:21:50.300
this it gives you a very good idea of

0:21:48.620,0:21:52.760
what the representation has learned so

0:21:50.300,0:21:54.440
what the authors did was basically

0:21:52.760,0:21:56.390
extract a bunch of patches from each

0:21:54.440,0:22:00.530
image for roughly ten to nine patches

0:21:56.390,0:22:01.710
and so on a small set of images so I

0:22:00.530,0:22:03.120
think in this case it was they

0:22:01.710,0:22:04.950
fifty two hundred thousand images and

0:22:03.120,0:22:06.539
then you basically just compute nearest

0:22:04.950,0:22:08.960
neighbors on those those patches of

0:22:06.539,0:22:08.960
those images

0:22:10.470,0:22:12.530
you

0:22:12.780,0:22:22.200
that's good so another task which is

0:22:19.610,0:22:26.539
also very popular is called colorization

0:22:22.200,0:22:28.950
so in this case given a grayscale image

0:22:26.539,0:22:30.809
you basically try to predict the colors

0:22:28.950,0:22:32.490
of that image so you can really

0:22:30.809,0:22:34.710
formulate this task for any image you

0:22:32.490,0:22:36.870
can take an image you can remove its

0:22:34.710,0:22:38.580
color and you can ask a network to

0:22:36.870,0:22:40.020
basically predict the color from this

0:22:38.580,0:22:44.510
black and white or sort of grayscale

0:22:40.020,0:22:47.429
image and this task by itself is not as

0:22:44.510,0:22:50.490
it's actually useful in some respect so

0:22:47.429,0:22:52.890
a lot of like old movies when you sort

0:22:50.490,0:22:54.840
of see them colorized select movies

0:22:52.890,0:22:57.900
short and say the 40s or 30s when there

0:22:54.840,0:22:59.669
was not a lot of color technology you

0:22:57.900,0:23:01.530
can actually have this task really sort

0:22:59.669,0:23:03.630
of be applied there so in some way it

0:23:01.530,0:23:07.350
actually is more useful than other

0:23:03.630,0:23:09.690
pretext tasks and why does this task

0:23:07.350,0:23:11.549
learn something meaningful well it needs

0:23:09.690,0:23:13.740
to sort of recognize that trees are

0:23:11.549,0:23:15.990
green it needs to understand what sort

0:23:13.740,0:23:19.200
of object categories it is in order to

0:23:15.990,0:23:20.490
color it sadly well and so in practice

0:23:19.200,0:23:22.980
this has now sort of been extended to

0:23:20.490,0:23:24.809
the video domain and there are a lot of

0:23:22.980,0:23:28.890
follow-up works on sort of polarization

0:23:24.809,0:23:31.260
itself if interesting because I think

0:23:28.890,0:23:32.909
the colour mapping is not that it's not

0:23:31.260,0:23:36.350
deterministic right I mean not a mistake

0:23:32.909,0:23:41.220
yes so several several there are several

0:23:36.350,0:23:43.740
possible true solutions right yes so so

0:23:41.220,0:23:45.450
the initial paper was basically sort of

0:23:43.740,0:23:47.520
proposing a deterministic mapping so you

0:23:45.450,0:23:50.460
were solving either a classification or

0:23:47.520,0:23:52.740
the regression problem so you only could

0:23:50.460,0:23:54.740
have say a blue colored umbrella and you

0:23:52.740,0:23:58.679
could never sort of predict a gray color

0:23:54.740,0:24:00.570
and so what ended up happening was for a

0:23:58.679,0:24:04.049
lot of categories which have different

0:24:00.570,0:24:05.669
kinds of colors so for example let's

0:24:04.049,0:24:07.440
assume say you have a ball and that ball

0:24:05.669,0:24:09.450
can appear either in the red blue or

0:24:07.440,0:24:11.700
green colors the netbook would sort of

0:24:09.450,0:24:13.140
predict that to be great because I mean

0:24:11.700,0:24:15.260
that sort of the mean of all of these

0:24:13.140,0:24:18.480
things so that's the best it can do

0:24:15.260,0:24:21.149
there was follow-up work from David

0:24:18.480,0:24:22.710
Foresight's group in UIUC which tried to

0:24:21.149,0:24:24.360
sort of come up with variational

0:24:22.710,0:24:25.900
auto-encoders so you actually had a

0:24:24.360,0:24:28.240
latent variable

0:24:25.900,0:24:30.370
would have diverse colorization so in

0:24:28.240,0:24:32.320
practice you can basically do approaches

0:24:30.370,0:24:34.300
like that so you can actually have now a

0:24:32.320,0:24:35.500
green colored ball and because you're

0:24:34.300,0:24:36.970
doing that for the entire scene you can

0:24:35.500,0:24:38.800
actually have consistent colorings of

0:24:36.970,0:24:40.809
the entire scene yeah yeah that's what I

0:24:38.800,0:24:42.460
think we will be we've been talking with

0:24:40.809,0:24:44.890
yarn or whenever we have like some

0:24:42.460,0:24:48.160
mapping that goes from one to many and

0:24:44.890,0:24:49.840
then we should choose like a little

0:24:48.160,0:24:51.910
variable model which allow us to choose

0:24:49.840,0:24:59.679
a multiple solution given that we have

0:24:51.910,0:25:01.360
the same input so if I think the reason

0:24:59.679,0:25:03.580
why like people did not really focus on

0:25:01.360,0:25:07.960
a lot on that particular aspect in this

0:25:03.580,0:25:09.370
case was at least back in the day one it

0:25:07.960,0:25:11.620
was not here what was working and what

0:25:09.370,0:25:13.480
was not and second this was still a

0:25:11.620,0:25:15.520
pretext task and people were not really

0:25:13.480,0:25:16.679
concerned about the colorization quality

0:25:15.520,0:25:19.240
people were more concerned about

0:25:16.679,0:25:21.520
representation quality but I think now a

0:25:19.240,0:25:23.290
lot of us understand that both of them

0:25:21.520,0:25:25.480
are fairly sort of tied to one another

0:25:23.290,0:25:27.790
that you really need to have this sort

0:25:25.480,0:25:30.760
of non-deterministic mapping to get

0:25:27.790,0:25:35.530
something more out of the data scene

0:25:30.760,0:25:37.450
thanks and finally so this is an

0:25:35.530,0:25:40.330
apologize for this picture it's from the

0:25:37.450,0:25:42.160
paper I think it was the resolution but

0:25:40.330,0:25:44.410
so this is another task which is like

0:25:42.160,0:25:46.330
context auto-encoders so the idea is

0:25:44.410,0:25:49.330
basically borrowed pretty much from say

0:25:46.330,0:25:51.880
board to back so you hide a particular

0:25:49.330,0:25:53.230
part of the image and now given the

0:25:51.880,0:25:55.120
surrounding part of the image you need

0:25:53.230,0:25:56.530
to predict what was hidden so it's

0:25:55.120,0:25:58.630
really sort of the fill in the blanks

0:25:56.530,0:26:02.090
task

0:25:58.630,0:26:03.710
and why should this work well it's at

0:26:02.090,0:26:07.250
least trying to reason about what

0:26:03.710,0:26:09.320
objects are present so cars can run on

0:26:07.250,0:26:11.539
roads or like buildings are basically

0:26:09.320,0:26:13.279
consist consists of like windows and

0:26:11.539,0:26:15.470
closer to the ground they're supposed to

0:26:13.279,0:26:17.029
have doors and so on so it needs to

0:26:15.470,0:26:19.460
learn something more about like the

0:26:17.029,0:26:23.960
implicit structure of the data by

0:26:19.460,0:26:26.840
performing this task so this was just

0:26:23.960,0:26:28.909
about images and now I'll sort of talk

0:26:26.840,0:26:34.159
about what are the other tasks that you

0:26:28.909,0:26:36.470
can do in video so in video the sort of

0:26:34.159,0:26:40.390
main source of supervision is this

0:26:36.470,0:26:42.830
notion of sequential 'ti of frames so

0:26:40.390,0:26:45.080
frames basically have an inherent order

0:26:42.830,0:26:47.510
in them and you want to sort of use that

0:26:45.080,0:26:49.070
order to get something for example say

0:26:47.510,0:26:51.500
predict the order of frames or fill in

0:26:49.070,0:26:53.240
the blanks and a bunch of sort of other

0:26:51.500,0:26:54.399
pretext tasks that are all dependent on

0:26:53.240,0:26:58.309
sequential nature

0:26:54.399,0:27:00.799
so here I'll sort of talk about one of

0:26:58.309,0:27:03.440
the works that I did in 2016 which was

0:27:00.799,0:27:05.990
about predicting the temporally correct

0:27:03.440,0:27:08.539
or incorrect order of frames this is

0:27:05.990,0:27:10.909
very much inspired from earlier that

0:27:08.539,0:27:13.250
yawn and basically others stayed on sort

0:27:10.909,0:27:15.260
of sequential ordering of frames through

0:27:13.250,0:27:16.760
contrast of the thing and I'll talk

0:27:15.260,0:27:18.520
about those towards the end when I

0:27:16.760,0:27:22.429
actually talk about contrast observing

0:27:18.520,0:27:24.350
so in this particular work we were very

0:27:22.429,0:27:26.960
much inspired by like the pretext asks

0:27:24.350,0:27:29.299
again and we saw the binary

0:27:26.960,0:27:32.120
classification problem so given a bunch

0:27:29.299,0:27:34.279
of frames we extract three frames and if

0:27:32.120,0:27:36.529
we extract them in the right order we

0:27:34.279,0:27:38.690
label them plus one and if we shuffle

0:27:36.529,0:27:40.520
them basically we label them as zero and

0:27:38.690,0:27:42.020
so now we need to solve a binary

0:27:40.520,0:27:44.700
classification problem to predict

0:27:42.020,0:27:47.880
whether something is shuffled or not

0:27:44.700,0:27:52.070
and the reason this sort of works is

0:27:47.880,0:27:54.720
because so given three frames or let's

0:27:52.070,0:27:57.090
think of them as basically start middle

0:27:54.720,0:28:00.780
and end this network really tries to

0:27:57.090,0:28:02.640
learn given a start and end point is

0:28:00.780,0:28:04.260
this point of valid sort of

0:28:02.640,0:28:05.850
interpolation of the start and end

0:28:04.260,0:28:09.050
points so it really tries to sort of

0:28:05.850,0:28:13.710
interpolate smoothly these features

0:28:09.050,0:28:15.240
given these given this visual input so

0:28:13.710,0:28:17.760
the network is fairly straightforward

0:28:15.240,0:28:20.700
it's a sort of triplets Iommi's network

0:28:17.760,0:28:22.800
you have three frames you feed forward

0:28:20.700,0:28:24.390
each one of them independently you

0:28:22.800,0:28:25.980
concatenate the features that you obtain

0:28:24.390,0:28:27.480
from these three frames and the new

0:28:25.980,0:28:29.640
perform a binary classification problem

0:28:27.480,0:28:30.930
so you predict whether this thing is

0:28:29.640,0:28:33.240
correct or incorrect

0:28:30.930,0:28:36.210
whether it's basically a shuffle does

0:28:33.240,0:28:37.410
not shuffled you get up you can

0:28:36.210,0:28:38.820
basically minimize this with

0:28:37.410,0:28:41.900
cross-entropy loss and you can train

0:28:38.820,0:28:41.900
this entire network end-to-end

0:28:42.140,0:28:48.060
so again like I had mentioned earlier

0:28:46.230,0:28:49.530
nearest neighbor is sort of a good way

0:28:48.060,0:28:52.890
to visualize what these networks are

0:28:49.530,0:28:54.630
learning so we further player work can

0:28:52.890,0:28:58.260
be basically looked at the nearest

0:28:54.630,0:29:00.300
neighbors of frames so on the left hand

0:28:58.260,0:29:02.070
side you have a query frame and you feed

0:29:00.300,0:29:04.260
forward that frame you get a feature and

0:29:02.070,0:29:05.730
then you basically look at the nearest

0:29:04.260,0:29:08.580
neighbors in that feature representation

0:29:05.730,0:29:11.850
so we will do that for image net shuffle

0:29:08.580,0:29:14.700
and learn and then random features so

0:29:11.850,0:29:16.260
what you observe is there's sort of sort

0:29:14.700,0:29:19.500
of very stark difference between what

0:29:16.260,0:29:22.500
image net shuffle and random give you so

0:29:19.500,0:29:24.810
the first row if you look at the sort of

0:29:22.500,0:29:26.880
gym scene emission it is really good at

0:29:24.810,0:29:28.890
figuring out that it's a gym scene it's

0:29:26.880,0:29:30.930
the nearest neighbor it retrieves looks

0:29:28.890,0:29:32.820
is very different from the initial scene

0:29:30.930,0:29:35.670
that we like the initial image that

0:29:32.820,0:29:38.340
we've given so like the floor is much

0:29:35.670,0:29:42.240
better late in the query the floor was

0:29:38.340,0:29:43.650
actually black and the exact exercise

0:29:42.240,0:29:45.780
being performed is not really the same

0:29:43.650,0:29:47.850
but imagenet is sort of really good at

0:29:45.780,0:29:50.760
collapsing this entire semantic category

0:29:47.850,0:29:52.740
and really sort of bringing in various

0:29:50.760,0:29:56.130
different gem scenes together close by

0:29:52.740,0:29:58.380
in the representation space the same

0:29:56.130,0:30:00.660
thing sort of goes for the row below

0:29:58.380,0:30:02.309
so can you have an outdoor scene and

0:30:00.660,0:30:04.140
emission it is immediately able to sort

0:30:02.309,0:30:05.789
of pick up on that outdoor part of it

0:30:04.140,0:30:08.190
it's able to figure out there is grass

0:30:05.789,0:30:11.179
and so on and it sort of brings these

0:30:08.190,0:30:14.640
two points together in the feature space

0:30:11.179,0:30:17.039
if you look at say the sort of rightmost

0:30:14.640,0:30:19.890
the nearest neighbors retrieve by the

0:30:17.039,0:30:22.740
random network you see that it really

0:30:19.890,0:30:24.270
focuses on the color so in the top row

0:30:22.740,0:30:26.429
it's a sort of focusing on the black

0:30:24.270,0:30:29.160
floor it's really looking at maybe it's

0:30:26.429,0:30:30.480
sort of the black color in this image

0:30:29.160,0:30:32.970
and that's how it's written against

0:30:30.480,0:30:34.650
nearest neighbor now if you look at the

0:30:32.970,0:30:37.080
shuffle and learn the nearest neighbors

0:30:34.650,0:30:38.580
they're fairly odd it's not immediately

0:30:37.080,0:30:40.470
clear whether it's focusing on the color

0:30:38.580,0:30:43.530
or whether it's focusing on that entire

0:30:40.470,0:30:46.260
semantic concept and so on sort of

0:30:43.530,0:30:48.510
further inspection and after looking at

0:30:46.260,0:30:50.190
a lot of these examples we figured out

0:30:48.510,0:30:52.470
that it was really looking at the pose

0:30:50.190,0:30:54.299
of the person so if you look at in the

0:30:52.470,0:30:56.610
top row the person is doing sort of an

0:30:54.299,0:30:57.990
upset is upside down and that's sort of

0:30:56.610,0:31:00.659
the nearest neighbor retrieved as well

0:30:57.990,0:31:03.299
and in the second row also the person is

0:31:00.659,0:31:05.400
sort of has their foot and of like has a

0:31:03.299,0:31:07.440
feet in the particular way and it's

0:31:05.400,0:31:08.820
really trying to sort of get there with

0:31:07.440,0:31:11.549
its nearest neighbor and it's sort of

0:31:08.820,0:31:14.429
ignoring the entire stream it's not

0:31:11.549,0:31:16.139
really focused on the background

0:31:14.429,0:31:18.269
and when we were thinking about this why

0:31:16.139,0:31:20.940
would a netbook even try to do something

0:31:18.269,0:31:23.700
of this sort well we looked we thought

0:31:20.940,0:31:26.429
back to our pretext asked so the pretext

0:31:23.700,0:31:28.110
asked was predicting the order or

0:31:26.429,0:31:30.480
basically predicting whether things are

0:31:28.110,0:31:32.820
in the right order or not and to do this

0:31:30.480,0:31:35.700
you really need to focus on what is

0:31:32.820,0:31:38.399
moving in the same or sort of the in

0:31:35.700,0:31:39.840
this case the people so if you focus on

0:31:38.399,0:31:40.889
the background you will never be able to

0:31:39.840,0:31:42.450
answer this question

0:31:40.889,0:31:44.159
fare thee well because well the

0:31:42.450,0:31:46.409
background doesn't change a lot between

0:31:44.159,0:31:48.179
three frames that had taken sort of

0:31:46.409,0:31:49.919
close by in a video the only thing that

0:31:48.179,0:31:51.210
sort of changes is the person or the

0:31:49.919,0:31:54.749
sort of things that are moving in that

0:31:51.210,0:31:56.789
video so sort of accidentally we

0:31:54.749,0:31:58.740
basically trained a network that was

0:31:56.789,0:32:00.659
really trying to sort of look at things

0:31:58.740,0:32:03.029
that are moving and then ended up

0:32:00.659,0:32:07.019
focusing on the pose of this pose of

0:32:03.029,0:32:09.419
people now of course this is my

0:32:07.019,0:32:13.230
interpretation we wanted to verify this

0:32:09.419,0:32:15.749
quantitatively so what we did is we took

0:32:13.230,0:32:17.460
our representation and we fine-tuned it

0:32:15.749,0:32:19.679
on this task of human key point

0:32:17.460,0:32:22.169
estimation so this task is basically

0:32:19.679,0:32:25.529
given up human you need to sort of

0:32:22.169,0:32:27.749
predict where certain key points are so

0:32:25.529,0:32:30.779
the key points are going to keep they're

0:32:27.749,0:32:34.019
defined as basically say the nose the

0:32:30.779,0:32:36.840
neck the left shoulder right shoulder

0:32:34.019,0:32:38.309
right elbow left elbow wrist and so on

0:32:36.840,0:32:40.440
so you basically have these bunch of

0:32:38.309,0:32:42.419
predefined key points and you train the

0:32:40.440,0:32:44.399
network to sort of predict this so this

0:32:42.419,0:32:48.139
is really useful for something like

0:32:44.399,0:32:51.509
tracking or pose estimation of a person

0:32:48.139,0:32:54.419
so we took our shuffle and learn self

0:32:51.509,0:32:56.220
supervised method and we fine-tuned it

0:32:54.419,0:32:59.399
on these two data sets called flick and

0:32:56.220,0:33:01.710
n PII and we did the same thing for a

0:32:59.399,0:33:03.600
mission and supervised network and this

0:33:01.710,0:33:04.919
is back in the days of Alex Nets so Alex

0:33:03.600,0:33:09.990
net was the architecture that we used

0:33:04.919,0:33:12.210
and in sort of fairly surprisingly what

0:33:09.990,0:33:14.519
we found is that the self supervised

0:33:12.210,0:33:16.320
representation was very competitive or

0:33:14.519,0:33:18.600
even slightly better than imagining

0:33:16.320,0:33:21.509
supervised representation at this task

0:33:18.600,0:33:23.399
of key point estimation so in this case

0:33:21.509,0:33:25.200
what I'm measuring is a you see which is

0:33:23.399,0:33:27.929
area under the curve so higher is better

0:33:25.200,0:33:28.350
and you can see that it's performing

0:33:27.929,0:33:30.960
fairly

0:33:28.350,0:33:32.490
which was very surprising to us because

0:33:30.960,0:33:35.190
we hadn't any thought about this task

0:33:32.490,0:33:37.710
when we were designing a pretext RSP

0:33:35.190,0:33:39.450
really thought that I think this pretext

0:33:37.710,0:33:42.540
task will help us understand actions

0:33:39.450,0:33:44.190
better but it turns out that if like you

0:33:42.540,0:33:45.990
you can have sort of surprising outcomes

0:33:44.190,0:33:48.300
depending on what you ended up or what

0:33:45.990,0:33:50.880
you end up creating as a pretext task so

0:33:48.300,0:33:52.880
in this case that was both estimation so

0:33:50.880,0:33:56.580
for this example

0:33:52.880,0:33:58.770
you said you fine-tuned it on human key

0:33:56.580,0:34:02.880
point estimation so is that kind of like

0:33:58.770,0:34:07.610
a supervised step like once you have

0:34:02.880,0:34:10.110
your yes pretext representations yes so

0:34:07.610,0:34:12.330
so the pipeline basically generally goes

0:34:10.110,0:34:15.360
like you have you do a pre training step

0:34:12.330,0:34:16.650
so that can basically be say supervision

0:34:15.360,0:34:18.510
which is predicting one of thousand

0:34:16.650,0:34:19.950
classes and then you have a downstream

0:34:18.510,0:34:22.530
task where you have a few amount of

0:34:19.950,0:34:24.240
labels so you basically just so in this

0:34:22.530,0:34:28.020
case that's predicting the human key

0:34:24.240,0:34:30.210
points so the this way of evaluation

0:34:28.020,0:34:32.580
what it does is it basically has it

0:34:30.210,0:34:34.410
takes a bunch of three trained networks

0:34:32.580,0:34:36.810
and then it fine gives them using the

0:34:34.410,0:34:40.020
same supervised data at the end and so

0:34:36.810,0:34:42.030
what you're evaluating is how good was

0:34:40.020,0:34:43.560
it if I started from say a mission and

0:34:42.030,0:34:45.570
supervised network or a shuffle and

0:34:43.560,0:34:49.880
learn network to perform this task of

0:34:45.570,0:34:54.030
key point estimation okay thank you

0:34:49.880,0:34:57.690
change that this well since shuffle and

0:34:54.030,0:34:59.700
all focuses on the background so it

0:34:57.690,0:35:02.040
actually focuses a lot on the four count

0:34:59.700,0:35:04.080
so that's what I was trying to sort of

0:35:02.040,0:35:06.330
come up with this talk about in this

0:35:04.080,0:35:07.860
example if you look at like what the

0:35:06.330,0:35:09.510
nearest neighbor that is really looking

0:35:07.860,0:35:11.310
at the person to come up with this right

0:35:09.510,0:35:12.870
it's looking at the upside-down person

0:35:11.310,0:35:16.710
to sort of come up with its nearest

0:35:12.870,0:35:18.950
neighborhood and the reason is if you

0:35:16.710,0:35:20.970
want to talk about ordering of frames

0:35:18.950,0:35:23.160
actually need to focus on things that

0:35:20.970,0:35:25.260
move and in these videos people are the

0:35:23.160,0:35:26.760
things that move so if it focuses on the

0:35:25.260,0:35:30.270
background it actually will not be able

0:35:26.760,0:35:32.020
to solve the shuffle and learn tasks

0:35:30.270,0:35:35.750
you

0:35:32.020,0:35:39.109
all right so this was sort of surprising

0:35:35.750,0:35:41.060
and it sort of goes to show that if you

0:35:39.109,0:35:43.400
design your pretext ask well it will

0:35:41.060,0:35:47.270
work well for a certain sort of set of

0:35:43.400,0:35:51.260
downstream tasks and there have been

0:35:47.270,0:35:52.670
sort of fairly nice methods since then

0:35:51.260,0:35:55.970
which have been basically about

0:35:52.670,0:35:57.590
predicting this sort of using

0:35:55.970,0:35:58.850
sequentiality and sort of predicting

0:35:57.590,0:36:01.160
whether things are in the correct order

0:35:58.850,0:36:02.900
or not so this is odd without networks

0:36:01.160,0:36:04.940
which basically rather than solving a

0:36:02.900,0:36:07.400
binary classification problem it

0:36:04.940,0:36:10.970
actually tries to predict which which of

0:36:07.400,0:36:12.650
the frames is the unlike sort of the one

0:36:10.970,0:36:16.369
that is odd one out the one that is sort

0:36:12.650,0:36:17.690
of a shuffled and this because you're

0:36:16.369,0:36:19.130
sort of increasing the amount of

0:36:17.690,0:36:21.770
information that you're predicting at

0:36:19.130,0:36:23.869
the output this sort of network ends up

0:36:21.770,0:36:27.550
doing better and better and it also sort

0:36:23.869,0:36:27.550
of reasons about more frames at a time

0:36:27.930,0:36:33.580
so now you've seen sort of images and

0:36:31.060,0:36:36.460
video there's been a lot of creative

0:36:33.580,0:36:38.380
work at the sort of multimodal so where

0:36:36.460,0:36:42.220
you have to sip modalities video and

0:36:38.380,0:36:43.960
sound or to sensory inputs and these two

0:36:42.220,0:36:47.680
have been sort of very popular and very

0:36:43.960,0:36:51.490
nice sort of work coming out of this

0:36:47.680,0:36:54.190
regime so the key sort of signaling in

0:36:51.490,0:36:57.490
these works is predicting whether an

0:36:54.190,0:37:00.490
image or say a video clip corresponds to

0:36:57.490,0:37:04.170
an audio clip so the way you can sort of

0:37:00.490,0:37:06.700
construct these tasks is to take a video

0:37:04.170,0:37:09.850
and you can basically just sample any

0:37:06.700,0:37:11.800
frame from it and this similarly take an

0:37:09.850,0:37:13.870
audio track and sample any part of that

0:37:11.800,0:37:15.040
and now the problem is basically to

0:37:13.870,0:37:20.590
predict whether these things are

0:37:15.040,0:37:23.520
corresponding or not so essentially

0:37:20.590,0:37:26.320
in this entire sort of video surfer drum

0:37:23.520,0:37:27.910
you can sample the frame and the

0:37:26.320,0:37:30.760
corresponding audio and call that the

0:37:27.910,0:37:33.550
positive and in this case you basically

0:37:30.760,0:37:35.140
take a different video and you take the

0:37:33.550,0:37:37.210
audio from the drum video and that

0:37:35.140,0:37:38.320
becomes your negative and so again you

0:37:37.210,0:37:40.150
can solve a binary classification

0:37:38.320,0:37:43.200
problem by taking these bunch of

0:37:40.150,0:37:43.200
positives and negatives

0:37:44.130,0:37:48.000
so the architecture for this is fairly

0:37:46.920,0:37:49.980
straightforward

0:37:48.000,0:37:52.740
you take in an image you pass it through

0:37:49.980,0:37:54.570
a vision sub Network now you have your

0:37:52.740,0:37:57.720
audio you pass it through an audio sub

0:37:54.570,0:38:00.990
Network and get 128 dimensional features

0:37:57.720,0:38:03.660
for them so also embeddings then you

0:38:00.990,0:38:05.610
sort of fuse them together and have a

0:38:03.660,0:38:07.230
binary classification problem saying

0:38:05.610,0:38:09.360
whether these things correspond or not

0:38:07.230,0:38:14.760
so at the end of it is just solving a

0:38:09.360,0:38:18.420
single binary problem what it sort of

0:38:14.760,0:38:20.460
shows is that it you can actually do a

0:38:18.420,0:38:22.770
bunch of sort of nice things when you

0:38:20.460,0:38:24.510
train that works this way so you can

0:38:22.770,0:38:26.610
answer the question what is making a

0:38:24.510,0:38:29.370
sound because the network really needs

0:38:26.610,0:38:31.050
to focus on say to predict whether the

0:38:29.370,0:38:33.690
sound is coming from this video it also

0:38:31.050,0:38:36.330
needs to identify what in the video

0:38:33.690,0:38:38.040
might be making the sound so if it's the

0:38:36.330,0:38:39.810
sound of a guitar it needs to sort of

0:38:38.040,0:38:42.210
understand what our guitars roughly

0:38:39.810,0:38:43.650
looks like or if it's a drum it sort of

0:38:42.210,0:38:49.560
things to roughly identify were two

0:38:43.650,0:38:51.680
drummers so in this particular case the

0:38:49.560,0:38:54.480
author sort of looked at visualizations

0:38:51.680,0:38:57.960
for in this case two instruments so you

0:38:54.480,0:39:00.900
have a piano and a flute and you look at

0:38:57.960,0:39:03.840
just the radio information and nothing

0:39:00.900,0:39:06.480
else the network autumn already sort of

0:39:03.840,0:39:10.170
puts a very high sort of visual

0:39:06.480,0:39:12.540
importance on the piano and on the flute

0:39:10.170,0:39:14.400
and this is because it autumn when you

0:39:12.540,0:39:15.480
sort of feed forward this image it knows

0:39:14.400,0:39:17.720
that there are going to be these two

0:39:15.480,0:39:21.000
kinds of things that can produce sounds

0:39:17.720,0:39:24.650
so it really sort of learns to identify

0:39:21.000,0:39:24.650
these kinds of objects automatically

0:39:25.360,0:39:30.710
you know about the the slide before

0:39:28.400,0:39:33.230
whenever you had the convolutional net

0:39:30.710,0:39:35.420
over the space program do you know what

0:39:33.230,0:39:37.460
is the kernel size for that audio

0:39:35.420,0:39:39.220
content just I'm interested to know like

0:39:37.460,0:39:44.630
whether it makes sense to have like

0:39:39.220,0:39:47.810
rectangular or a square kernel size I

0:39:44.630,0:39:49.940
mean now there are sort of modem proof

0:39:47.810,0:39:52.190
models so this is basically operating on

0:39:49.940,0:39:54.230
the log spec program so yeah it is still

0:39:52.190,0:39:55.990
handcraft you need to decide how your

0:39:54.230,0:39:58.070
computing that spectrogram exactly

0:39:55.990,0:40:00.050
people have now figured out that you can

0:39:58.070,0:40:02.180
actually use the raw audio and you can

0:40:00.050,0:40:04.850
actually apply cons directly on the

0:40:02.180,0:40:06.710
audio signal yeah yeah sure sure and for

0:40:04.850,0:40:08.540
that it's generally a small window it

0:40:06.710,0:40:11.120
really depends on what the corresponding

0:40:08.540,0:40:13.220
video that you're using so roughly about

0:40:11.120,0:40:21.380
a seconds worth of audio in a second

0:40:13.220,0:40:23.840
worth of video so now that I've sort of

0:40:21.380,0:40:25.730
shown you how there are like multiple

0:40:23.840,0:40:30.410
different creative ways of defining what

0:40:25.730,0:40:32.930
a pretext ask is let's try to see what a

0:40:30.410,0:40:35.270
pretext ask learns and how can you sort

0:40:32.930,0:40:38.810
of if the if I give you 25 different

0:40:35.270,0:40:40.430
pretext asks how can you a priori decide

0:40:38.810,0:40:42.020
which one is the one that you want to

0:40:40.430,0:40:47.930
use and what are they going to sort of

0:40:42.020,0:40:50.000
learn so the first thing is pretext asks

0:40:47.930,0:40:52.610
are actually complementary so there was

0:40:50.000,0:40:55.910
this really nice paper in 2017 that

0:40:52.610,0:40:58.280
looked at two of these sort of tasks so

0:40:55.910,0:41:00.230
relative position was the first pretext

0:40:58.280,0:41:01.760
asked I talked about where you take two

0:41:00.230,0:41:03.320
patches and you try to predict what

0:41:01.760,0:41:05.660
their relative position with respect to

0:41:03.320,0:41:07.490
one another is and colorization is

0:41:05.660,0:41:10.100
basically taking a grayscale image and

0:41:07.490,0:41:11.600
trying to predict its colors and so what

0:41:10.100,0:41:14.810
these authors showed is basically that

0:41:11.600,0:41:16.460
if you train a single network to do both

0:41:14.810,0:41:18.920
of these tasks to predict both the

0:41:16.460,0:41:20.600
colorize colorize output as well as

0:41:18.920,0:41:23.210
relative position you can actually get

0:41:20.600,0:41:24.590
gains in performance so again this is

0:41:23.210,0:41:26.000
evaluated the same way I was talking

0:41:24.590,0:41:27.530
about earlier you have a pre area

0:41:26.000,0:41:29.120
network

0:41:27.530,0:41:31.130
then you're basically evaluating it on

0:41:29.120,0:41:34.210
an end task in this case imagenet

0:41:31.130,0:41:36.910
classification and detection benchmark

0:41:34.210,0:41:39.980
and in both cases you sort of can get

0:41:36.910,0:41:42.710
gains by performing both of these tasks

0:41:39.980,0:41:44.840
so you get best of both words so in some

0:41:42.710,0:41:47.060
way what this also shows you is that a

0:41:44.840,0:41:49.220
single pretext task may not be the right

0:41:47.060,0:41:50.900
answer so predicting just coloured or

0:41:49.220,0:41:53.750
predicting just relative position may

0:41:50.900,0:41:57.500
not be the right answer to learn cell

0:41:53.750,0:41:59.090
supervised representations in fact if

0:41:57.500,0:42:01.520
you sort of reason about what

0:41:59.090,0:42:04.790
information is being predicted it really

0:42:01.520,0:42:06.590
varies a lot across tasks so starting

0:42:04.790,0:42:08.030
with the relative position task you're

0:42:06.590,0:42:10.010
predicting a fairly low level

0:42:08.030,0:42:12.980
information you're predicting just sort

0:42:10.010,0:42:15.500
of eight possible locations so just to a

0:42:12.980,0:42:16.580
to a classification problem or for that

0:42:15.500,0:42:18.140
shuffle unknown problem you're

0:42:16.580,0:42:19.580
predicting whether things are shuffled

0:42:18.140,0:42:22.070
or not so it's just a simple binary

0:42:19.580,0:42:23.560
problem so it's very sort of less amount

0:42:22.070,0:42:26.030
of information that's being predicted

0:42:23.560,0:42:28.310
whereas if you look at on the extreme

0:42:26.030,0:42:30.080
right if you are trying to predict what

0:42:28.310,0:42:31.580
is missing in an image and you're trying

0:42:30.080,0:42:33.230
to reconstruct the pixels you're

0:42:31.580,0:42:35.870
predicting all sort of information

0:42:33.230,0:42:38.270
because that entire box contains I mean

0:42:35.870,0:42:40.070
it can have a very you can have a very

0:42:38.270,0:42:42.320
different appearance space right so if

0:42:40.070,0:42:44.180
you have in pixels then you can

0:42:42.320,0:42:45.980
basically have a lot of different values

0:42:44.180,0:42:47.450
for that entire predictive region so

0:42:45.980,0:42:49.610
you're predicting a lot of information

0:42:47.450,0:42:52.070
there so essentially this is one simple

0:42:49.610,0:42:54.290
way of thinking about pretext asks how

0:42:52.070,0:42:56.830
much information are you predicting and

0:42:54.290,0:42:59.000
that can give you already a good idea of

0:42:56.830,0:43:01.070
you know whether you're actually

0:42:59.000,0:43:03.080
predicting a lot of information so

0:43:01.070,0:43:08.300
probably that representation is actually

0:43:03.080,0:43:09.830
going to be better so in general this is

0:43:08.300,0:43:13.670
sort of going to guide the next part of

0:43:09.830,0:43:15.740
my talk you can think of this sort of

0:43:13.670,0:43:17.270
predicting more information part as on

0:43:15.740,0:43:18.940
an axis and I'll talk about three

0:43:17.270,0:43:21.470
different sort of categories and this

0:43:18.940,0:43:23.060
actually two different categories so

0:43:21.470,0:43:24.950
pretext asks is what I've been talking

0:43:23.060,0:43:28.130
about till now which is just predicting

0:43:24.950,0:43:30.260
simple classification problems like

0:43:28.130,0:43:33.170
different degrees of rotation or so on I

0:43:30.260,0:43:34.970
sort of move to contrastive methods

0:43:33.170,0:43:36.470
which are which actually predict say

0:43:34.970,0:43:39.980
more information than these pretext

0:43:36.470,0:43:41.180
tasks and in this particular talk I'm

0:43:39.980,0:43:43.130
actually not going to talk about

0:43:41.180,0:43:45.500
generative models but interactive models

0:43:43.130,0:43:48.559
predict more information than say a

0:43:45.500,0:43:49.940
typical contrastive method and so this

0:43:48.559,0:43:53.480
is basically one way of thinking about

0:43:49.940,0:43:56.990
these classes of methods question how do

0:43:53.480,0:43:59.510
we train multiple training pre training

0:43:56.990,0:44:02.150
tasks do we shuffle data for both tasks

0:43:59.510,0:44:06.200
it's training dividual you want it lead

0:44:02.150,0:44:07.730
to catastrophic forget in right so the

0:44:06.200,0:44:10.400
simple way of doing that is basically

0:44:07.730,0:44:12.530
that you have so you can basically

0:44:10.400,0:44:14.660
alternate batches so you can have the

0:44:12.530,0:44:16.220
same network and in one batch you

0:44:14.660,0:44:17.990
basically feed it black-and-white images

0:44:16.220,0:44:20.780
and you ask it to predict the colored

0:44:17.990,0:44:23.390
part of it and in the second now in the

0:44:20.780,0:44:24.890
second batch you basically feed it

0:44:23.390,0:44:26.480
patches and you ask it to do the

0:44:24.890,0:44:31.430
relative position tasks you basically

0:44:26.480,0:44:33.829
have two different like head like fully

0:44:31.430,0:44:35.720
connected layers at the top so you can

0:44:33.829,0:44:38.150
basically alternate between these tasks

0:44:35.720,0:44:39.190
what the authors of the paper did was

0:44:38.150,0:44:44.619
actually slightly more sophisticated

0:44:39.190,0:44:48.740
they had they basically had sort of

0:44:44.619,0:44:50.569
multi task network which was three or

0:44:48.740,0:44:52.460
four depending on the number of pretext

0:44:50.569,0:44:54.470
tasks you have and you actually solve

0:44:52.460,0:44:56.869
all of them at once but they there was

0:44:54.470,0:44:58.819
sort of more involved weight sharing

0:44:56.869,0:45:08.329
across these four three four different

0:44:58.819,0:45:10.910
task networks hi so about the pretest

0:45:08.329,0:45:13.010
asks what performance should be aimed

0:45:10.910,0:45:15.349
for in a pretext ask when do we know

0:45:13.010,0:45:17.930
that this is enough or when can we stop

0:45:15.349,0:45:19.940
and because ultimately we care about the

0:45:17.930,0:45:22.220
performance on the downstream that's

0:45:19.940,0:45:23.930
question one and question two is you

0:45:22.220,0:45:27.650
were speaking about low information and

0:45:23.930,0:45:29.299
more information for example in the case

0:45:27.650,0:45:30.680
where you mentioned where you were

0:45:29.299,0:45:32.780
predicting whether it's in the correct

0:45:30.680,0:45:35.210
sequence or not you could have also

0:45:32.780,0:45:38.510
predicted the actual permutation of the

0:45:35.210,0:45:40.670
images right so how do you decide

0:45:38.510,0:45:45.470
between which task to follow and based

0:45:40.670,0:45:47.690
on work so both parts the second part of

0:45:45.470,0:45:49.700
the question actually that's going to be

0:45:47.690,0:45:51.980
in a couple of slides I'll sort of defer

0:45:49.700,0:45:53.390
to that question or that one later but

0:45:51.980,0:45:54.480
the first part how much do you train

0:45:53.390,0:45:58.200
this model on a

0:45:54.480,0:46:00.870
texts asked so a sort of good sign of a

0:45:58.200,0:46:02.970
pretext asked is that as your accuracy

0:46:00.870,0:46:04.410
on the pretext asked improves so as you

0:46:02.970,0:46:05.970
get better at predicting whether things

0:46:04.410,0:46:08.970
are shuffled or not or as you get better

0:46:05.970,0:46:10.830
at predicting rotations the sort of

0:46:08.970,0:46:13.950
accuracy on the downstream semantic

0:46:10.830,0:46:15.870
tasks will also improve so a good rule

0:46:13.950,0:46:18.680
of thumb for is basically using these

0:46:15.870,0:46:21.570
pretext tasks is we sort of have a very

0:46:18.680,0:46:24.060
difficult pretext ask or try to make it

0:46:21.570,0:46:26.340
as difficult as possible and then sort

0:46:24.060,0:46:28.800
of optimize or like reduce the loss on

0:46:26.340,0:46:31.260
that pretext task so so that your final

0:46:28.800,0:46:34.580
downstream accuracy improves so it's

0:46:31.260,0:46:34.580
very correlated

0:46:34.720,0:46:38.920
right so in practice you'll actually

0:46:36.760,0:46:41.079
drain the entire pipeline each line each

0:46:38.920,0:46:42.760
time like the pretext and the downstream

0:46:41.079,0:46:44.740
and measure the performance and rise so

0:46:42.760,0:46:46.180
it's not like you stop the pretext at a

0:46:44.740,0:46:47.950
certain point and then switch over to

0:46:46.180,0:46:49.390
only like downstream or something so

0:46:47.950,0:46:51.550
that's um generally how these methods

0:46:49.390,0:46:53.230
are evaluated but I guess when you're

0:46:51.550,0:46:55.690
developing you probably do this pipeline

0:46:53.230,0:46:58.000
multiple times

0:46:55.690,0:47:00.579
so these methods are sort of trained

0:46:58.000,0:47:02.650
like you do you're pretext ask then you

0:47:00.579,0:47:04.329
stop and then you perform your

0:47:02.650,0:47:06.609
downstream evolution task and that gives

0:47:04.329,0:47:08.289
you the final sort of measurement of how

0:47:06.609,0:47:11.849
good your pretext asked was and that's

0:47:08.289,0:47:15.210
it you do do this entire thing once

0:47:11.849,0:47:15.210
right thank you

0:47:16.339,0:47:19.849
the second part of your question the

0:47:18.109,0:47:24.609
mode information part I'll sort of come

0:47:19.849,0:47:24.609
to it later the permutation and so on

0:47:24.640,0:47:30.319
good so these are sort of the three main

0:47:27.770,0:47:34.520
buckets and the first two were what are

0:47:30.319,0:47:37.460
going to be covered basically now so

0:47:34.520,0:47:39.170
this was another word peep did which was

0:47:37.460,0:47:41.690
basically about scaling self supervised

0:47:39.170,0:47:45.140
learning so in this particular work we

0:47:41.690,0:47:46.640
focused on two problems one was the

0:47:45.140,0:47:49.930
colorization problem that I had talked

0:47:46.640,0:47:53.809
about earlier and the second is this

0:47:49.930,0:47:56.180
more sort of in film or information

0:47:53.809,0:47:59.000
variant of the relative position task so

0:47:56.180,0:48:00.770
this task is called jigsaw puzzles the

0:47:59.000,0:48:02.150
idea is that you take an image and you

0:48:00.770,0:48:05.299
split it into multiple different patches

0:48:02.150,0:48:06.799
and you try to predict exactly and even

0:48:05.299,0:48:09.049
if shuffle these patches basically by a

0:48:06.799,0:48:11.420
permutation and then you predict which

0:48:09.049,0:48:13.309
permutation was applied to the input so

0:48:11.420,0:48:16.480
that's very similar to what Chris was

0:48:13.309,0:48:16.480
suggesting here

0:48:17.349,0:48:22.670
alright so the way you solve this

0:48:19.880,0:48:24.799
problem is you take say in this case

0:48:22.670,0:48:26.480
three patches you feed forward each one

0:48:24.799,0:48:28.609
of these patches independently you

0:48:26.480,0:48:30.589
concatenate their feature and then you

0:48:28.609,0:48:34.039
classify which permutation was basically

0:48:30.589,0:48:37.339
used to permute these input patches now

0:48:34.039,0:48:38.900
the authors used nine patches to solve

0:48:37.339,0:48:42.289
this problem and that's basically going

0:48:38.900,0:48:44.650
to be nine factorial which is like 360

0:48:42.289,0:48:47.000
thousand number of permutations of

0:48:44.650,0:48:48.799
course when you're trying to perform

0:48:47.000,0:48:50.359
this classification at the end this

0:48:48.799,0:48:52.730
means that you're fully connected layer

0:48:50.359,0:48:55.730
should have 360 thousand output neurons

0:48:52.730,0:48:57.319
which is a very large number so in

0:48:55.730,0:49:00.650
practice what the authors did was

0:48:57.319,0:49:03.950
basically have a sort of a subset of

0:49:00.650,0:49:05.780
permutations that they use so say they

0:49:03.950,0:49:08.030
sample one hundred permutations from the

0:49:05.780,0:49:10.010
nine factorial permutations and then

0:49:08.030,0:49:13.579
just have this perform this hundred

0:49:10.010,0:49:15.980
weight classification right so in some

0:49:13.579,0:49:18.380
way you can look at this the size of

0:49:15.980,0:49:19.789
this subset as the problem complexity or

0:49:18.380,0:49:21.770
the amount of information that you're

0:49:19.789,0:49:23.660
predicting if you predict the full nine

0:49:21.770,0:49:25.670
factorial thing you're actually solving

0:49:23.660,0:49:27.500
that you'd basically predicting a lot of

0:49:25.670,0:49:29.539
information at the output if you only

0:49:27.500,0:49:30.770
subsample say two or three permutations

0:49:29.539,0:49:32.510
and you're basically not predicting a

0:49:30.770,0:49:34.069
lot of information so the problem

0:49:32.510,0:49:38.750
basically gets harder and harder as the

0:49:34.069,0:49:40.339
size of the subset increases so in this

0:49:38.750,0:49:43.819
paper we basically wanted to study this

0:49:40.339,0:49:45.500
the entire role of how much information

0:49:43.819,0:49:48.170
that you predict and how good is the

0:49:45.500,0:49:51.319
final representation that you learn so

0:49:48.170,0:49:53.329
in terms of evaluation there are two

0:49:51.319,0:49:56.150
ways to sort of evaluate once you have a

0:49:53.329,0:49:57.589
self supervised pretend network and this

0:49:56.150,0:49:59.299
is a lot of debate on which one is

0:49:57.589,0:50:02.750
exactly the right method to evaluate

0:49:59.299,0:50:04.609
networks so the first way is to

0:50:02.750,0:50:06.710
basically fine-tune all the layers of a

0:50:04.609,0:50:09.289
network so that you have a downstream

0:50:06.710,0:50:11.510
tasks a pose estimation or say image

0:50:09.289,0:50:13.279
classification you train this network

0:50:11.510,0:50:15.069
can you update all the parameters of

0:50:13.279,0:50:18.410
this network for the downstream tasks

0:50:15.069,0:50:20.329
the second way is to just use your

0:50:18.410,0:50:22.130
network as a feature extractor so you

0:50:20.329,0:50:23.930
basically run your images through it you

0:50:22.130,0:50:25.579
get your feature representation and now

0:50:23.930,0:50:27.579
you only train a linear classifier on

0:50:25.579,0:50:30.200
top of that fixed feature representation

0:50:27.579,0:50:32.120
so in this but

0:50:30.200,0:50:33.800
we said that a good representation

0:50:32.120,0:50:36.590
should transfer with little amount of

0:50:33.800,0:50:38.600
training so we opted basically for the

0:50:36.590,0:50:41.090
second part which is just to train a

0:50:38.600,0:50:43.580
linear classifier on top of a network

0:50:41.090,0:50:45.200
treated as a feature extractor so there

0:50:43.580,0:50:48.110
are of course different pros and cons of

0:50:45.200,0:50:50.620
using both methods so the first method

0:50:48.110,0:50:53.870
that is fine tuning all the layers is

0:50:50.620,0:50:55.580
treating the cell supervised network as

0:50:53.870,0:50:57.890
an initialization because you're

0:50:55.580,0:50:59.690
basically updating the entire network so

0:50:57.890,0:51:02.210
if your downstream tasks basically has

0:50:59.690,0:51:03.710
say 1 million images your base updating

0:51:02.210,0:51:06.290
your entire network for that 1 million

0:51:03.710,0:51:08.090
images whereas in the second case you're

0:51:06.290,0:51:09.950
just training very limited number of

0:51:08.090,0:51:12.320
parameters on the feeds fixed feature

0:51:09.950,0:51:14.570
extractor so in some way basically the

0:51:12.320,0:51:18.500
second one is measuring how good of a

0:51:14.570,0:51:22.230
feature is that that you've done

0:51:18.500,0:51:24.030
all right so the other thing that is

0:51:22.230,0:51:25.920
sort of critical in evaluating self

0:51:24.030,0:51:28.860
supervised methods is to evaluate them

0:51:25.920,0:51:30.300
on a bunch of different tasks so earlier

0:51:28.860,0:51:32.100
when I talked about that shuffle and

0:51:30.300,0:51:34.380
learn work I just showed you results in

0:51:32.100,0:51:36.900
pose estimation so on pose estimation it

0:51:34.380,0:51:38.790
was doing really there but I actually

0:51:36.900,0:51:40.920
did not do really well on other tasks

0:51:38.790,0:51:43.440
like say action recognition so in this

0:51:40.920,0:51:44.910
particular evaluation we sort of wanted

0:51:43.440,0:51:47.580
to correct that mistake and we wanted to

0:51:44.910,0:51:49.260
focus on multiple different tasks so a

0:51:47.580,0:51:51.050
variety of different tasks like say

0:51:49.260,0:51:53.790
image classification you short learning

0:51:51.050,0:51:56.370
object detection 3d understanding

0:51:53.790,0:51:58.080
navigation and so on so we defined

0:51:56.370,0:52:03.720
basically like a set of nine different

0:51:58.080,0:52:05.580
tasks so the way to evaluate the

0:52:03.720,0:52:07.500
representations is basically to extract

0:52:05.580,0:52:09.210
fixed features and you can extract these

0:52:07.500,0:52:11.160
fixed features from different parts of

0:52:09.210,0:52:12.810
the network so they can come basically

0:52:11.160,0:52:14.850
from a layer which is very close to the

0:52:12.810,0:52:16.770
input or from a very high-level layer

0:52:14.850,0:52:18.030
which is very close to the output so in

0:52:16.770,0:52:19.590
this way you sort of measuring the

0:52:18.030,0:52:21.920
semantic Ness of each of these different

0:52:19.590,0:52:21.920
layers

0:52:22.619,0:52:26.789
and the sort of standard thing we did

0:52:25.109,0:52:29.430
floor a lot of these experiments was to

0:52:26.789,0:52:32.880
use an image classification task to sort

0:52:29.430,0:52:34.769
of understand what is going on so the

0:52:32.880,0:52:36.960
image classification task is on this

0:52:34.769,0:52:37.980
data set called the EOC which is fairly

0:52:36.960,0:52:40.710
standard for detection and

0:52:37.980,0:52:44.099
classification and the idea is to

0:52:40.710,0:52:48.150
predict whether an image has one of

0:52:44.099,0:52:49.650
twenty classes so and an image can

0:52:48.150,0:52:52.109
actually have more than one class for

0:52:49.650,0:52:54.480
example like that picture of a person

0:52:52.109,0:52:56.369
with a dog that has both person and dog

0:52:54.480,0:52:57.809
so this network now needs to recognize

0:52:56.369,0:52:59.759
both the objects in it so it's not

0:52:57.809,0:53:02.759
slightly harder than image net where you

0:52:59.759,0:53:07.039
basically need to only certified n25 one

0:53:02.759,0:53:07.039
of the key objects in the image

0:53:07.390,0:53:12.099
so so the first thing we did was

0:53:10.390,0:53:13.510
basically to verify the hypothesis

0:53:12.099,0:53:15.640
whether increasing the amount of

0:53:13.510,0:53:18.670
information predicted actually results

0:53:15.640,0:53:21.099
in better representations so on the

0:53:18.670,0:53:23.440
x-axis and we are increasing the number

0:53:21.099,0:53:24.880
of permutations that we are using to

0:53:23.440,0:53:28.089
basically train our network so that's

0:53:24.880,0:53:29.769
going from 100 to 10,000 and on the

0:53:28.089,0:53:31.630
y-axis we are basically measuring the

0:53:29.769,0:53:33.519
downstream transferred performance of

0:53:31.630,0:53:35.769
these pre-trained representations and

0:53:33.519,0:53:38.470
it's measured using a metric called map

0:53:35.769,0:53:41.339
which is mean average precision so

0:53:38.470,0:53:43.450
essentially because this is a fairly

0:53:41.339,0:53:45.339
this is a sort of multi-label

0:53:43.450,0:53:47.049
classification problem you're going to

0:53:45.339,0:53:48.849
measure average precision for each of

0:53:47.049,0:53:50.559
the different 20 classes and then you're

0:53:48.849,0:53:52.480
going to compute the mean of that of

0:53:50.559,0:53:55.269
this precision so higher is better in

0:53:52.480,0:53:57.250
this case so we do that for two

0:53:55.269,0:53:59.349
different architectures Aleks net what

0:53:57.250,0:54:02.289
was originally used in the jigsaw paper

0:53:59.349,0:54:05.230
and then the resonate 50 and what you

0:54:02.289,0:54:07.869
observe is for Alex net increasing the

0:54:05.230,0:54:09.640
amount of permutations is useful up to a

0:54:07.869,0:54:12.609
certain point but the gain is overall

0:54:09.640,0:54:14.710
limited whereas for ResNet if you

0:54:12.609,0:54:16.690
increase the amount of permutations the

0:54:14.710,0:54:20.710
representation quality gets better and

0:54:16.690,0:54:22.240
better and our hypothesis was basically

0:54:20.710,0:54:24.339
that the resonant model has enough

0:54:22.240,0:54:26.170
capacity that it can actually solve a

0:54:24.339,0:54:28.119
very difficult permutation problem and

0:54:26.170,0:54:30.279
when it solves a difficult permutation

0:54:28.119,0:54:32.259
problem it's able to sort of learn much

0:54:30.279,0:54:38.740
better representations that generalize

0:54:32.259,0:54:40.509
to different downstream tasks so the

0:54:38.740,0:54:42.910
next thing we did was to evaluate our

0:54:40.509,0:54:44.950
method on the object detection task so

0:54:42.910,0:54:47.349
object detection is basically where you

0:54:44.950,0:54:49.390
try to identify what objects are present

0:54:47.349,0:54:51.910
in an image we try to draw a box around

0:54:49.390,0:54:54.339
them and your measured basically based

0:54:51.910,0:54:56.170
on how sort of good the boxes around the

0:54:54.339,0:54:58.170
object and whether you were able to

0:54:56.170,0:55:01.000
identify all the objects in an image and

0:54:58.170,0:55:02.550
again for this one we use the same vo C

0:55:01.000,0:55:05.490
beta set

0:55:02.550,0:55:08.160
so this was the setting where we

0:55:05.490,0:55:09.900
basically fine-tuned all the layers of a

0:55:08.160,0:55:12.920
network because that's what standard in

0:55:09.900,0:55:15.930
detection and what we observed was

0:55:12.920,0:55:19.080
basically on two different splits of

0:55:15.930,0:55:21.200
this video see data set the jigsaw

0:55:19.080,0:55:24.330
method was actually fairly comparable

0:55:21.200,0:55:27.060
within the margin of error to basically

0:55:24.330,0:55:29.070
training a emission supervised method so

0:55:27.060,0:55:30.600
you have a emission supervised Network

0:55:29.070,0:55:33.330
you find you in that on the task of

0:55:30.600,0:55:35.369
detection and you get a mean average

0:55:33.330,0:55:37.560
precision of 70 point five or seventy

0:55:35.369,0:55:39.240
six point two and the jigsaw method is

0:55:37.560,0:55:42.030
basically within the margin of error of

0:55:39.240,0:55:45.660
these methods which in itself sort of

0:55:42.030,0:55:47.880
shows that it actually had some sort of

0:55:45.660,0:55:53.880
nice semantic property and it was able

0:55:47.880,0:55:56.760
to localize objects a level and to put

0:55:53.880,0:55:59.340
this sort of in context for semantic

0:55:56.760,0:56:01.410
feature learning on like in computer

0:55:59.340,0:56:03.480
vision especially object detection is

0:56:01.410,0:56:05.640
sort of considered the benchmark data

0:56:03.480,0:56:08.580
set to to reach something like really

0:56:05.640,0:56:10.080
belong and this result basically when

0:56:08.580,0:56:12.030
we've sort of published it was the

0:56:10.080,0:56:14.850
closest anyone had ever come to

0:56:12.030,0:56:17.150
supervise free training in terms of

0:56:14.850,0:56:17.150
detection

0:56:17.490,0:56:24.890
right it's some question um so is

0:56:23.270,0:56:27.119
TechStars

0:56:24.890,0:56:28.500
similar to what we could try achieving

0:56:27.119,0:56:31.500
with transfer learning is it like a

0:56:28.500,0:56:33.570
subset of that or yes so I mean the way

0:56:31.500,0:56:35.550
you evaluate these pretext tasks is by

0:56:33.570,0:56:37.260
transfer learning so you perform your

0:56:35.550,0:56:39.660
original pretext tasks and then you find

0:56:37.260,0:56:41.790
unit on a data set for a particular task

0:56:39.660,0:56:44.810
like detection so the evaluation is

0:56:41.790,0:56:44.810
always transfer learning

0:56:48.330,0:56:53.830
so the next task we looked at was

0:56:51.190,0:56:56.350
surface normal evaluation so this is

0:56:53.830,0:56:58.630
basically given input you try to

0:56:56.350,0:57:01.330
estimate what are the 3d properties of

0:56:58.630,0:57:03.640
the like basically at each pixel

0:57:01.330,0:57:06.730
location in the input you try to predict

0:57:03.640,0:57:10.660
what is the surface orientation so in 3d

0:57:06.730,0:57:13.060
basically the XY & z vectors at each

0:57:10.660,0:57:14.410
particular surface so it's a sort of

0:57:13.060,0:57:16.690
dense prediction problem where you need

0:57:14.410,0:57:19.390
to assign that XYZ vector to each

0:57:16.690,0:57:22.109
location in the input and for that to

0:57:19.390,0:57:26.470
use this nice dataset created by N by U

0:57:22.109,0:57:29.050
and we basically measured the prediction

0:57:26.470,0:57:31.450
properties of our method with risk and

0:57:29.050,0:57:33.940
compared it to an image net supervised

0:57:31.450,0:57:35.740
method and so in this case we measured

0:57:33.940,0:57:38.770
the median error and the percentage

0:57:35.740,0:57:40.540
correct predictions so the median error

0:57:38.770,0:57:42.070
basically means that lower is better and

0:57:40.540,0:57:45.520
percentage correct means higher is

0:57:42.070,0:57:47.230
better so it turned out that the jigsaw

0:57:45.520,0:57:49.990
pre-training task was actually really

0:57:47.230,0:57:51.670
good in this case and it provided like

0:57:49.990,0:57:54.190
significant improvements over a

0:57:51.670,0:57:56.080
missionary training so it was basically

0:57:54.190,0:57:57.730
across some multiple different sets

0:57:56.080,0:58:00.160
multiple different splits it was able to

0:57:57.730,0:58:03.280
really easily outperform the image net

0:58:00.160,0:58:05.740
supervised Praetorian method so again it

0:58:03.280,0:58:07.720
sort of goes on to show that evaluating

0:58:05.740,0:58:09.850
a pretext task on multiple different

0:58:07.720,0:58:12.310
tasks and multiple different data sets

0:58:09.850,0:58:14.770
is really important to understand what

0:58:12.310,0:58:17.500
is really going on in a pretext task so

0:58:14.770,0:58:20.470
somehow jigsaw is really incorporating

0:58:17.500,0:58:21.880
something about like geometry and

0:58:20.470,0:58:23.830
something about like pixel level

0:58:21.880,0:58:26.640
information much better than image net

0:58:23.830,0:58:26.640
supervised methods

0:58:27.840,0:58:33.270
so finally we found sort of the Achilles

0:58:30.690,0:58:35.610
heel of this method like the tics of

0:58:33.270,0:58:38.010
returning tasks so to do this we

0:58:35.610,0:58:40.170
evaluated on like the setting called few

0:58:38.010,0:58:42.960
short loading so in few short loading

0:58:40.170,0:58:45.060
you have very sort of limited number of

0:58:42.960,0:58:47.130
training examples and you are training

0:58:45.060,0:58:49.830
your classifier just on these very

0:58:47.130,0:58:52.380
limited number of training examples so

0:58:49.830,0:58:54.030
on the x-axis I have the number of

0:58:52.380,0:58:56.460
training examples that were used to

0:58:54.030,0:58:59.670
train a method so that goes from say 1

0:58:56.460,0:59:01.830
to 96 and I'm sort of showing you curves

0:58:59.670,0:59:03.660
for for like ourselves like 2 different

0:59:01.830,0:59:04.890
cell supervised methods so jigsaw

0:59:03.660,0:59:07.740
methods trained on two different data

0:59:04.890,0:59:11.070
sets imagenet which is on the top and a

0:59:07.740,0:59:13.110
random has next 50 so what you can

0:59:11.070,0:59:14.580
observe is that there is a significant

0:59:13.110,0:59:16.380
gap in performance between a Cell

0:59:14.580,0:59:19.500
supervised method and a supervised

0:59:16.380,0:59:21.240
method and that gap basically just does

0:59:19.500,0:59:24.150
not seem to reduce as you increase the

0:59:21.240,0:59:25.890
number of labeled examples which point

0:59:24.150,0:59:27.600
which sort of shows that cell supervised

0:59:25.890,0:59:29.700
representations although they may be

0:59:27.600,0:59:32.760
good at tasks like say pose estimation

0:59:29.700,0:59:35.040
or particular tasks like surface normal

0:59:32.760,0:59:37.050
estimation there is still a lot of

0:59:35.040,0:59:38.850
difference between what sort of semantic

0:59:37.050,0:59:41.310
aspect of the data they captured because

0:59:38.850,0:59:43.890
this in this sort of few short learning

0:59:41.310,0:59:45.600
tasks if I give you one image and if

0:59:43.890,0:59:47.250
you're able to say something about it

0:59:45.600,0:59:50.750
your feature representation needs to be

0:59:47.250,0:59:50.750
really good to solve that task

0:59:52.089,0:59:57.680
the other lady evaluated this method was

0:59:55.730,1:00:00.349
to basically look at what it learns at

0:59:57.680,1:00:04.640
each different layer so we basically

1:00:00.349,1:00:06.770
trained linear classifiers on different

1:00:04.640,1:00:09.410
like different clear representations in

1:00:06.770,1:00:11.240
a ResNet 50 so from the con one which is

1:00:09.410,1:00:13.430
going to be the layer closest to the

1:00:11.240,1:00:15.500
input to the output say of there is two

1:00:13.430,1:00:17.569
block there is three block and there is

1:00:15.500,1:00:19.010
five block so this five is basically the

1:00:17.569,1:00:21.380
sort of highest level representation

1:00:19.010,1:00:23.510
that you get out from resonate 50 and

1:00:21.380,1:00:25.280
after that representation is where you

1:00:23.510,1:00:28.040
perform this entire jigsaw like

1:00:25.280,1:00:30.799
predicting the permutation task and so

1:00:28.040,1:00:32.780
you look at in this case the x-axis

1:00:30.799,1:00:35.750
represents the sort of where the feature

1:00:32.780,1:00:38.000
is coming from con 1 or s 5 and on the

1:00:35.750,1:00:40.280
y-axis we are looking at the again mean

1:00:38.000,1:00:44.000
after position of image classification

1:00:40.280,1:00:46.730
on GOC and funnily enough what you see

1:00:44.000,1:00:48.859
is basically that the representation

1:00:46.730,1:00:51.530
quality improves when you go from corn 1

1:00:48.859,1:00:53.619
to s 4 so it steadily in sort of

1:00:51.530,1:00:57.200
increases in the mean average precision

1:00:53.619,1:00:59.930
but towards the end there's a sharp drop

1:00:57.200,1:01:02.390
so restful to res 5 is a sharp drop in

1:00:59.930,1:01:04.339
performance which is that due to the

1:01:02.390,1:01:08.329
finally specializes to the specific task

1:01:04.339,1:01:10.490
yes exactly so this was very worrying

1:01:08.329,1:01:13.640
because if you were to sort of plot this

1:01:10.490,1:01:15.920
thing for a supervised Network you

1:01:13.640,1:01:17.839
observe that from convent to rs5 the

1:01:15.920,1:01:19.940
representation quality always improves

1:01:17.839,1:01:22.730
and this is true for like pretty much

1:01:19.940,1:01:24.650
any good supervised network whereas for

1:01:22.730,1:01:26.450
a lot of the self supervised networks we

1:01:24.650,1:01:28.910
sort of repeated this experiment for the

1:01:26.450,1:01:30.619
rotation network but colorization for

1:01:28.910,1:01:33.650
relative position he would always

1:01:30.619,1:01:38.150
observe this very sharp gap in from

1:01:33.650,1:01:40.220
Brest fortress 5 and so this says that

1:01:38.150,1:01:43.010
the end task that we are solving the

1:01:40.220,1:01:45.680
pretext asked is probably not very nice

1:01:43.010,1:01:49.040
because it's not very well aligned to

1:01:45.680,1:01:50.860
the downstream semantic tasks that we

1:01:49.040,1:01:53.290
really want to solve

1:01:50.860,1:01:55.780
which basically brings me to the next

1:01:53.290,1:01:57.970
part which is to understand what is

1:01:55.780,1:02:01.200
missing from these pretext are these

1:01:57.970,1:02:01.200
sort of proxy tasks

1:02:01.470,1:02:07.080
so recap pretext tasks are basically

1:02:04.770,1:02:10.890
something like predicting rotation or to

1:02:07.080,1:02:12.720
predict say jigsaw puzzles and it's very

1:02:10.890,1:02:14.310
sort of if you look at it in the bigger

1:02:12.720,1:02:16.890
picture of things they're very

1:02:14.310,1:02:18.900
surprising and the fact that they even

1:02:16.890,1:02:22.080
work is super surprising

1:02:18.900,1:02:23.460
so for pretext tasks we have this

1:02:22.080,1:02:26.010
pre-training step where which is

1:02:23.460,1:02:28.109
supervised and then we have our transfer

1:02:26.010,1:02:30.900
tasks which are imaged classification or

1:02:28.109,1:02:32.730
detection and it's really a lot of

1:02:30.900,1:02:34.980
wishful thinking and a lot of hope that

1:02:32.730,1:02:37.980
the pre-training task and the transfer

1:02:34.980,1:02:40.080
task are super aligned and there is no

1:02:37.980,1:02:42.060
evidence really it's a lot of just like

1:02:40.080,1:02:43.770
wishing really really hard that whatever

1:02:42.060,1:02:45.090
pretext ask we've come up with this

1:02:43.770,1:02:47.580
really better line with our transfer

1:02:45.090,1:02:49.800
task and solving that p-tex task will do

1:02:47.580,1:02:51.840
really well in transfer tasks so what of

1:02:49.800,1:02:54.180
research basically goes into designing

1:02:51.840,1:02:58.800
these pretext tasks and implementing

1:02:54.180,1:03:00.869
them really well but it's not clear why

1:02:58.800,1:03:03.119
solving something like jigsaw puzzles

1:03:00.869,1:03:07.230
should teach us anything about semantics

1:03:03.119,1:03:08.640
or for example even the case of say beat

1:03:07.230,1:03:11.010
supervisor thing where you are trying to

1:03:08.640,1:03:13.050
predict hashtags from an image it's not

1:03:11.010,1:03:14.609
clear by predicting hashtags of an image

1:03:13.050,1:03:18.210
is actually going to do something well

1:03:14.609,1:03:21.869
for learning some like a good classifier

1:03:18.210,1:03:25.140
on transfer tasks so this question

1:03:21.869,1:03:26.849
remains that how do you design good pre

1:03:25.140,1:03:32.160
training tasks which are well aligned

1:03:26.849,1:03:35.940
with your transfer tasks so this hope of

1:03:32.160,1:03:37.770
generalization is basically you can and

1:03:35.940,1:03:39.119
the way we can sort of evaluate this is

1:03:37.770,1:03:41.280
basically by looking at the

1:03:39.119,1:03:43.680
representation that each layer and if

1:03:41.280,1:03:45.089
the last clear we do not see

1:03:43.680,1:03:47.280
representations that are well aligned

1:03:45.089,1:03:49.650
with the transfer task then that is a

1:03:47.280,1:03:51.660
red flag in that sort of telling us that

1:03:49.650,1:03:54.040
maybe this retaining task is not really

1:03:51.660,1:03:56.290
the right task to solve

1:03:54.040,1:03:58.330
so like I mentioned earlier this

1:03:56.290,1:04:00.700
basically is the sort of pattern that we

1:03:58.330,1:04:03.370
get for jigsaw and this shows us that

1:04:00.700,1:04:07.410
probably the last layers are very much

1:04:03.370,1:04:07.410
specialized towards that Excel problem

1:04:07.440,1:04:13.710
right so in general what we really want

1:04:11.339,1:04:15.750
from pre-trained features is that they

1:04:13.710,1:04:18.869
should represent how images are related

1:04:15.750,1:04:20.940
to one another so feature representation

1:04:18.869,1:04:22.289
stood and this basically goes back to

1:04:20.940,1:04:24.569
say the nearest neighbor visualizations

1:04:22.289,1:04:26.640
that I had it should really be able to

1:04:24.569,1:04:30.059
group together images that are

1:04:26.640,1:04:32.549
semantically related in some way and the

1:04:30.059,1:04:35.460
second property is basically a property

1:04:32.549,1:04:38.099
that has been the backbone of designing

1:04:35.460,1:04:39.809
vision features so even before sale the

1:04:38.099,1:04:41.369
deep learning features were popular the

1:04:39.809,1:04:43.500
handcrafted features were always all

1:04:41.369,1:04:45.480
about invariance about sort of being

1:04:43.500,1:04:47.520
invariant to things like lighting or

1:04:45.480,1:04:50.010
things like exact color or exact

1:04:47.520,1:04:51.690
location so these are the two properties

1:04:50.010,1:04:56.339
that we really want in that retain

1:04:51.690,1:04:58.530
features and there are sort of two ways

1:04:56.339,1:05:00.510
of achieving these things one is

1:04:58.530,1:05:03.720
clustering and the other is contrast

1:05:00.510,1:05:06.240
observing and both these methods have

1:05:03.720,1:05:09.410
promised because they are really solving

1:05:06.240,1:05:11.730
that basically trying to get these

1:05:09.410,1:05:13.859
properties when they're sort of trying

1:05:11.730,1:05:16.020
to learn representations and I believe

1:05:13.859,1:05:17.970
that's why they've actually now started

1:05:16.020,1:05:19.950
performing so much better than whatever

1:05:17.970,1:05:24.779
pretext asks that were hand designed for

1:05:19.950,1:05:27.109
so far so now I sort of focus on two

1:05:24.779,1:05:29.130
recent works that we have which are

1:05:27.109,1:05:31.890
which fall into this pocket of

1:05:29.130,1:05:33.359
clustering and invariances so one is

1:05:31.890,1:05:35.430
called plus surfeit the other is called

1:05:33.359,1:05:40.079
purl and both of them will be presented

1:05:35.430,1:05:43.020
at CVG artists yeah so the first work is

1:05:40.079,1:05:45.869
classified it's a method which we think

1:05:43.020,1:05:50.279
is very good to improve generalization

1:05:45.869,1:05:52.380
of visual representations so the

1:05:50.279,1:05:54.480
clustering is basically a good way to

1:05:52.380,1:05:56.609
understand what images are grouped

1:05:54.480,1:05:58.680
together what images go together and

1:05:56.609,1:06:01.200
whatever it is do not go together and

1:05:58.680,1:06:02.609
it's sort of dip you by basically

1:06:01.200,1:06:05.160
performing clustering on the feature

1:06:02.609,1:06:07.710
space you can get these nice buckets of

1:06:05.160,1:06:11.579
images that are related and images that

1:06:07.710,1:06:14.609
are not related so the main idea of this

1:06:11.579,1:06:17.069
paper is extremely simple there are just

1:06:14.609,1:06:19.529
two steps one is the cost of step the

1:06:17.069,1:06:21.000
other is the predict step so what we do

1:06:19.529,1:06:23.340
is we take any up

1:06:21.000,1:06:25.800
network and this can be any preacher a

1:06:23.340,1:06:27.900
net worth it it does not really have to

1:06:25.800,1:06:30.270
be just a self supervised network it can

1:06:27.900,1:06:32.310
either be a imaginary train network or a

1:06:30.270,1:06:34.440
network pre-trained say using hashtags

1:06:32.310,1:06:36.600
or a cell supervised network like one

1:06:34.440,1:06:38.970
train to predict jigs or permutations

1:06:36.600,1:06:40.250
and you take this free trade network

1:06:38.970,1:06:45.060
when you extract a bunch of features

1:06:40.250,1:06:47.640
from it on a set of images and of course

1:06:45.060,1:06:49.440
these images have no labels you extract

1:06:47.640,1:06:52.170
these features when you perform k-means

1:06:49.440,1:06:55.260
clustering and what you now get is

1:06:52.170,1:06:57.690
basically for each label for each image

1:06:55.260,1:07:00.690
you know which cluster it belongs to and

1:06:57.690,1:07:02.520
that becomes its label so in the second

1:07:00.690,1:07:06.210
fit step what you do is you train a

1:07:02.520,1:07:08.970
network from scratch so like from random

1:07:06.210,1:07:12.660
bits and you train this network to

1:07:08.970,1:07:13.800
predict just these pseudo labels so if

1:07:12.660,1:07:15.480
pseudo because they were basically

1:07:13.800,1:07:17.820
obtained using clustering so they're not

1:07:15.480,1:07:19.290
really hard labels which were given by

1:07:17.820,1:07:22.230
say a human annotator

1:07:19.290,1:07:23.550
and so now this second network is just

1:07:22.230,1:07:26.220
trying to predict these cluster

1:07:23.550,1:07:27.960
assignments so it takes our image and it

1:07:26.220,1:07:29.730
tries to predict which one of the K

1:07:27.960,1:07:34.070
clusters that you got from your k-means

1:07:29.730,1:07:36.450
does this image belong to so a standard

1:07:34.070,1:07:38.160
pre train and transfer task is to

1:07:36.450,1:07:40.320
basically perform your pre training so

1:07:38.160,1:07:42.000
that's the top row is to perform your

1:07:40.320,1:07:44.700
pre training on an objective like

1:07:42.000,1:07:46.830
predicting hashtags or predicting GPS

1:07:44.700,1:07:50.070
locations and then to evaluate this

1:07:46.830,1:07:54.150
feature based by learning linear probe

1:07:50.070,1:07:55.470
in the cluster fit world we basically do

1:07:54.150,1:07:57.260
not touch the pre-training so you

1:07:55.470,1:07:59.970
perform your free training as you were

1:07:57.260,1:08:03.000
you just insert a step in between which

1:07:59.970,1:08:04.770
is the cluster fit step where you take a

1:08:03.000,1:08:07.230
dataset D and you take your praetor

1:08:04.770,1:08:10.020
Network and you learn a new network from

1:08:07.230,1:08:11.910
scratch on this data and finally you

1:08:10.020,1:08:16.799
basically use this like green network

1:08:11.910,1:08:20.220
for all your downstream tasks so the

1:08:16.799,1:08:23.670
reason we believe that this method works

1:08:20.220,1:08:24.900
is because the clustering step and then

1:08:23.670,1:08:27.150
you are sort of clustering just these

1:08:24.900,1:08:29.940
images you are only capturing the

1:08:27.150,1:08:32.190
essential information which is basically

1:08:29.940,1:08:34.469
what images go together and what images

1:08:32.190,1:08:36.150
do not go together so you read through

1:08:34.469,1:08:38.369
away all the other information that is

1:08:36.150,1:08:41.819
present in the original Network just

1:08:38.369,1:08:43.440
capturing the sort of entered image

1:08:41.819,1:08:47.089
relationships that were captured and let

1:08:43.440,1:08:50.130
that were modeled by the initial network

1:08:47.089,1:08:52.109
and to sort of understand this we

1:08:50.130,1:08:54.719
performed a fairly simple experiment we

1:08:52.109,1:08:56.819
added label noise so synthetic label

1:08:54.719,1:08:59.339
noise to imagenet and we trained a

1:08:56.819,1:09:02.029
network basically on this noisy image

1:08:59.339,1:09:06.059
net so just flip a bunch of image labels

1:09:02.029,1:09:08.009
and train a network and now you evaluate

1:09:06.059,1:09:10.199
the feature representation from this

1:09:08.009,1:09:12.210
network on a downstream task which is

1:09:10.199,1:09:14.190
again a mesh net but it's a much larger

1:09:12.210,1:09:19.139
version of image net so it's 9,000

1:09:14.190,1:09:21.599
weight classification so we basically on

1:09:19.139,1:09:23.819
the x-axis have the amount of label

1:09:21.599,1:09:27.449
noise added to the images so that's

1:09:23.819,1:09:28.979
going from 0% to 75% and on the y-axis

1:09:27.449,1:09:31.650
we are looking at the transfer

1:09:28.979,1:09:36.089
performance on the larger image net the

1:09:31.650,1:09:37.799
emission at 9,000 dataset so the pink

1:09:36.089,1:09:40.650
line is showing you the pre-trained

1:09:37.799,1:09:42.690
network which is of it and basically as

1:09:40.650,1:09:44.549
the amount of label noise increases the

1:09:42.690,1:09:46.769
pre-trained networks performance on the

1:09:44.549,1:09:49.710
downstream tasks decreases and well this

1:09:46.769,1:09:51.329
is not surprising because as your labels

1:09:49.710,1:09:53.130
become less and less reliable of course

1:09:51.329,1:09:55.679
your representation quality is going to

1:09:53.130,1:10:00.530
suffer so that sort of goes down very

1:09:55.679,1:10:02.610
quickly in the sort of blue line of the

1:10:00.530,1:10:04.590
experiment with this technique called

1:10:02.610,1:10:07.019
module desolations where you take your

1:10:04.590,1:10:10.260
initial network and you use that to

1:10:07.019,1:10:11.940
generate labels so you look at the

1:10:10.260,1:10:13.920
output of that network and you look at

1:10:11.940,1:10:15.809
the sort of confidence in the outputs

1:10:13.920,1:10:17.940
generate labels for a second network and

1:10:15.809,1:10:20.309
that's called modelled isolation so

1:10:17.940,1:10:22.079
model resolution generally performs

1:10:20.309,1:10:24.150
better than the pre trained network and

1:10:22.079,1:10:25.920
you can see that all across so as

1:10:24.150,1:10:27.989
they'll amount of label noise increases

1:10:25.920,1:10:31.590
the distillation model actually is much

1:10:27.989,1:10:33.389
better than the original and finally

1:10:31.590,1:10:35.249
towards the end we have classified so

1:10:33.389,1:10:36.510
that's the green line and you can see

1:10:35.249,1:10:40.139
that the classified model is

1:10:36.510,1:10:41.880
consistently better than basically any

1:10:40.139,1:10:44.369
of these methods either distillation or

1:10:41.880,1:10:47.099
pre-training and consistently gives

1:10:44.369,1:10:48.010
better results including when you have

1:10:47.099,1:10:49.929
zero level noise

1:10:48.010,1:10:57.670
which is basically when you have a

1:10:49.929,1:11:00.850
pre-trained imagenet network so we

1:10:57.670,1:11:02.560
applied elaborate on the difference

1:11:00.850,1:11:08.920
between distillation and clustered fit

1:11:02.560,1:11:10.600
once more yes so in yes so in

1:11:08.920,1:11:13.510
distillation what you would do is you

1:11:10.600,1:11:15.190
would basically so in this first step

1:11:13.510,1:11:16.660
you would take the pre-trained Network

1:11:15.190,1:11:20.920
and you would use the labels this

1:11:16.660,1:11:23.260
network is predicting so say the the

1:11:20.920,1:11:26.920
network basically predicts 1,000 classes

1:11:23.260,1:11:28.870
so you basically use those labels in a

1:11:26.920,1:11:32.679
software fashion to generate generate

1:11:28.870,1:11:34.960
labels for your images so say the

1:11:32.679,1:11:37.239
network was trained to predict 100

1:11:34.960,1:11:40.000
different types of dogs so you take your

1:11:37.239,1:11:42.250
images and you get a distribution over

1:11:40.000,1:11:43.780
100 different types of dogs and use that

1:11:42.250,1:11:46.449
distribution to train your second

1:11:43.780,1:11:48.910
network whereas in cluster fit you don't

1:11:46.449,1:11:51.670
really care about the label space or the

1:11:48.910,1:11:52.989
sort of output output space of the pre

1:11:51.670,1:11:54.910
trained network you only look at the

1:11:52.989,1:11:56.560
features you don't even look at the last

1:11:54.910,1:12:01.570
fully connected you just look at the

1:11:56.560,1:12:03.580
previous features got it all so why

1:12:01.570,1:12:05.560
would the software distribution help

1:12:03.580,1:12:07.989
with training like why we're training on

1:12:05.560,1:12:10.960
this be helped what's like the intuition

1:12:07.989,1:12:12.610
behind this solution relations mean

1:12:10.960,1:12:14.800
intuition is basically that if your

1:12:12.610,1:12:17.699
network was trained really well so

1:12:14.800,1:12:21.400
suppose you had no label noise this

1:12:17.699,1:12:23.620
because a lot of things are not really a

1:12:21.400,1:12:26.560
lot of images really don't belong in the

1:12:23.620,1:12:28.360
in this sort of same classes so suppose

1:12:26.560,1:12:30.130
your data set actually had hundred two

1:12:28.360,1:12:32.440
hundred different types of dogs but you

1:12:30.130,1:12:34.150
had only hundred of them labeled and so

1:12:32.440,1:12:37.330
for a lot of these images say you

1:12:34.150,1:12:39.250
actually had to assign you had to pick

1:12:37.330,1:12:41.350
basically which one of the dogs it was a

1:12:39.250,1:12:43.600
software distribution is basically going

1:12:41.350,1:12:46.690
to help you discover hidden categories

1:12:43.600,1:12:49.510
so it's basically 0.5 kind this guide

1:12:46.690,1:12:52.090
type of dog in point 5 this kind of dog

1:12:49.510,1:12:55.690
so basically having these sort of

1:12:52.090,1:12:57.850
software labels helps you enhance sort

1:12:55.690,1:13:00.120
of the initial class distribution that

1:12:57.850,1:13:00.120
you have

1:13:00.239,1:13:14.110
okay thank you so we applied this method

1:13:10.449,1:13:15.699
to the cell supervised learning so the

1:13:14.110,1:13:17.409
jigsaw task that me I talked about

1:13:15.699,1:13:19.420
earlier and we were able to see

1:13:17.409,1:13:22.150
surprising amounts of gains across a

1:13:19.420,1:13:25.570
bunch of data sets so the jigsaw method

1:13:22.150,1:13:27.099
is in the top row which and I'm in each

1:13:25.570,1:13:29.949
of those sort of columns you're looking

1:13:27.099,1:13:32.440
at the transfer performance of basically

1:13:29.949,1:13:34.960
this jigsaw method on a bunch of

1:13:32.440,1:13:38.079
different data sets if you apply cluster

1:13:34.960,1:13:40.329
fit to district saw method you actually

1:13:38.079,1:13:42.849
can see gains across all of these data

1:13:40.329,1:13:44.769
sets and they're fairly consistent and

1:13:42.849,1:13:46.539
we perform this test on a bunch of

1:13:44.769,1:13:49.659
different three training methods like

1:13:46.539,1:13:51.969
coordinate so predicting rotations and

1:13:49.659,1:13:54.389
again we could see fairly nice gains

1:13:51.969,1:13:57.670
across these four different data sets

1:13:54.389,1:13:59.829
and surprisingly enough cluster fit

1:13:57.670,1:14:01.630
really works on any pre-trained Network

1:13:59.829,1:14:04.179
so it can be either a fully supervised

1:14:01.630,1:14:07.289
Network or a weekly supervised Network

1:14:04.179,1:14:10.150
so say a network that was trained to

1:14:07.289,1:14:13.360
predict hashtags or a weekly supervised

1:14:10.150,1:14:15.280
video network or basically any cell

1:14:13.360,1:14:17.289
supervised network and in each of these

1:14:15.280,1:14:19.780
cases we can observe fairly consistent

1:14:17.289,1:14:21.400
and large gains when you have like

1:14:19.780,1:14:23.590
specific so it's actually able to

1:14:21.400,1:14:25.690
improve the generalization of most of

1:14:23.590,1:14:28.110
these methods I think you're dragging

1:14:25.690,1:14:39.099
your microphone around it's very noisy

1:14:28.110,1:14:41.079
yeah so the second thing is basically

1:14:39.099,1:14:42.760
these gains were possible without extra

1:14:41.079,1:14:44.559
data labels or changes in the

1:14:42.760,1:14:47.710
architecture so in some ways you can

1:14:44.559,1:14:50.679
think of this as being self supervised

1:14:47.710,1:14:52.210
find you next step so you have your pre

1:14:50.679,1:14:53.800
trained network and then you basically

1:14:52.210,1:14:55.769
perform this cluster step which is

1:14:53.800,1:14:58.989
classified step which is completely

1:14:55.769,1:15:01.150
supervised or unsupervised and then you

1:14:58.989,1:15:07.750
can observe that the representation

1:15:01.150,1:15:09.730
quality improves I had a question in the

1:15:07.750,1:15:12.050
in the slide that you showed the

1:15:09.730,1:15:14.500
improvement with jigsaw and

1:15:12.050,1:15:17.240
and by using classified so in this

1:15:14.500,1:15:20.120
cluster for it is it's everything right

1:15:17.240,1:15:21.950
it is not using jigsaw at all so it is

1:15:20.120,1:15:24.740
applied on top of the jigsaw method

1:15:21.950,1:15:27.710
right so there was a pretend network

1:15:24.740,1:15:29.390
from which you exact features right so

1:15:27.710,1:15:33.100
in this case that pretend network is the

1:15:29.390,1:15:34.790
tricks or pretend network oh okay

1:15:33.100,1:15:36.500
participate and network and then you

1:15:34.790,1:15:47.000
basically perform yourself it on top of

1:15:36.500,1:15:49.130
it okay I think the main sort of

1:15:47.000,1:15:52.430
intuition is that when you say perform

1:15:49.130,1:15:54.770
the jigsaw task the last layer becomes

1:15:52.430,1:15:56.180
very much fine-tuned for that particular

1:15:54.770,1:15:58.850
jigsaw task right so we saw that

1:15:56.180,1:16:00.470
accuracy go down now when you take those

1:15:58.850,1:16:02.800
features and you perform clustering on

1:16:00.470,1:16:04.700
it you can think of this as basically

1:16:02.800,1:16:07.490
you're reducing the amount of

1:16:04.700,1:16:09.230
information right here if I drain the

1:16:07.490,1:16:10.790
second network to directly regress the

1:16:09.230,1:16:13.760
features of the first network I would

1:16:10.790,1:16:15.320
basically get the same exact network but

1:16:13.760,1:16:17.660
if I drain the second network only to

1:16:15.320,1:16:19.820
predict what images are grouped together

1:16:17.660,1:16:23.150
in the first one I'm actually predicting

1:16:19.820,1:16:25.220
lesser information and I thinking is

1:16:23.150,1:16:27.290
basically that clustering is some kind

1:16:25.220,1:16:29.240
of a noise removal technique so it's

1:16:27.290,1:16:32.180
really removing all the artifacts that

1:16:29.240,1:16:33.950
are specific to jigsaw from that like

1:16:32.180,1:16:35.210
feature space and so the second network

1:16:33.950,1:16:39.440
is actually learning something slightly

1:16:35.210,1:16:41.180
more generic all right that's sort of

1:16:39.440,1:16:42.890
the reason for like this experiment as

1:16:41.180,1:16:45.200
well so in this case we sort of

1:16:42.890,1:16:47.390
empirically validate that hypothesis by

1:16:45.200,1:16:49.820
actually ingesting amount of label noise

1:16:47.390,1:16:51.800
so the last layer basically is going to

1:16:49.820,1:16:53.210
get more and more than oisi and when you

1:16:51.800,1:16:55.790
do cluster fit on top of this you

1:16:53.210,1:16:57.020
actually again see improvement so that's

1:16:55.790,1:17:01.060
sort of our validation of this

1:16:57.020,1:17:03.800
hypothesis I had another question

1:17:01.060,1:17:05.660
so did you measure the performance of

1:17:03.800,1:17:07.880
class defect on object detection like

1:17:05.660,1:17:10.670
did it perform as well or it was it just

1:17:07.880,1:17:13.430
great in classification so it performs

1:17:10.670,1:17:17.990
well in detection as well so it actually

1:17:13.430,1:17:19.850
performs well indeed yes so there were

1:17:17.990,1:17:22.829
initial experimental detection where it

1:17:19.850,1:17:25.539
actually does perform the

1:17:22.829,1:17:27.249
we did not really push a lot of the

1:17:25.539,1:17:29.530
detection aspect of it in this

1:17:27.249,1:17:32.320
particular paper people sort of more

1:17:29.530,1:17:33.579
interested in the retrieval or like

1:17:32.320,1:17:36.579
linear classification kind of

1:17:33.579,1:17:39.010
experiments okay because either thinking

1:17:36.579,1:17:42.239
is feels like making these pseudo labels

1:17:39.010,1:17:44.349
we were basically making it I'm able to

1:17:42.239,1:17:46.479
classification tasks instead of

1:17:44.349,1:17:48.099
detection task maybe we could lose one

1:17:46.479,1:17:53.289
of some of those features that jigsaw

1:17:48.099,1:17:55.840
got right that is possible at least the

1:17:53.289,1:17:57.939
initial experiments that I had run did

1:17:55.840,1:17:59.530
not seem to suggest this there was

1:17:57.939,1:18:02.110
improvement in detection it was minor

1:17:59.530,1:18:04.119
but detection improvements overall like

1:18:02.110,1:18:05.650
the gap in performance is already so

1:18:04.119,1:18:08.280
small that the improvements actually

1:18:05.650,1:18:15.699
they're generally very small in general

1:18:08.280,1:18:18.789
okay in the same cluster fit algorithm

1:18:15.699,1:18:21.820
so we'll the final layer of cluster fit

1:18:18.789,1:18:24.219
algorithm not get again covariant to the

1:18:21.820,1:18:27.459
to the labels that were used for

1:18:24.219,1:18:29.769
training it on that task it becomes less

1:18:27.459,1:18:31.809
covariant so what we found was if you

1:18:29.769,1:18:32.860
were to sort of the paper has this plot

1:18:31.809,1:18:34.689
I don't have it at the slide

1:18:32.860,1:18:40.119
unfortunately the paper has the plot

1:18:34.689,1:18:42.519
where okay this particular plot where we

1:18:40.119,1:18:43.989
were looking at con one to res 5 plus if

1:18:42.519,1:18:46.389
it is much better so there s files

1:18:43.989,1:18:48.010
through as for gap for cluster fit is

1:18:46.389,1:18:51.789
much smaller than it is for say chicks

1:18:48.010,1:18:55.150
or rotten egg but was it better than rs4

1:18:51.789,1:18:57.939
it was slightly worse so it was on on

1:18:55.150,1:19:00.400
GOC on classification it was better but

1:18:57.939,1:19:02.320
for other tasks like imagine it was

1:19:00.400,1:19:07.510
slightly worse so it did not completely

1:19:02.320,1:19:09.909
fix the problem okay which was sort of

1:19:07.510,1:19:13.570
the motivation for poll so basically

1:19:09.909,1:19:15.939
I'll not talk about well so soul was

1:19:13.570,1:19:17.679
sort of born from the hypothesis again

1:19:15.939,1:19:22.419
that you need to be invariant to please

1:19:17.679,1:19:24.579
free text tasks so before I get into the

1:19:22.419,1:19:26.800
details of poll I will talk really a

1:19:24.579,1:19:29.260
little bit about Angelica contrast of

1:19:26.800,1:19:35.880
learning how many minutes do I have by

1:19:29.260,1:19:38.679
the way 15 minutes more or less okay so

1:19:35.880,1:19:41.920
contrasted learning is basically a sort

1:19:38.679,1:19:44.500
of general framework that tries to learn

1:19:41.920,1:19:47.080
a feature space that can combine

1:19:44.500,1:19:49.300
together or sort of put together points

1:19:47.080,1:19:51.730
that are related and push apart points

1:19:49.300,1:19:53.830
that are not related so in this case

1:19:51.730,1:19:55.150
imagine like the blue boxes are the

1:19:53.830,1:19:56.650
related points the greens are the

1:19:55.150,1:20:00.520
related and the purple are the related

1:19:56.650,1:20:02.199
points you will extract features for

1:20:00.520,1:20:04.389
each of these or like each of these data

1:20:02.199,1:20:06.460
points through a shared network so which

1:20:04.389,1:20:09.969
is called a signees network you get a

1:20:06.460,1:20:12.429
bunch of image features for these each

1:20:09.969,1:20:14.650
of these data points and then you apply

1:20:12.429,1:20:17.520
a loss function which is a contrastive

1:20:14.650,1:20:19.750
loss function which is going to try to

1:20:17.520,1:20:23.020
like sort of minimize the distance

1:20:19.750,1:20:25.449
between the blue points as opposed to

1:20:23.020,1:20:28.300
say the distance between the dew point

1:20:25.449,1:20:30.040
and the green point but the distance

1:20:28.300,1:20:31.750
basically between the blue points should

1:20:30.040,1:20:33.880
be less than the distance between the

1:20:31.750,1:20:36.280
blue point and the green point or the

1:20:33.880,1:20:39.010
view point and the virtual point so

1:20:36.280,1:20:40.780
embeddings me from the related samples

1:20:39.010,1:20:42.730
should be much closer than embeddings

1:20:40.780,1:20:44.980
from the undulated samples so that's

1:20:42.730,1:20:47.350
sort of the general idea or fortress of

1:20:44.980,1:20:48.520
learning and of course yon was one of

1:20:47.350,1:20:50.739
the first teacher to sort of propose

1:20:48.520,1:20:54.280
this method and his earlier people that

1:20:50.739,1:20:56.139
I also teach is called dr. Lim and so

1:20:54.280,1:20:57.940
contrastive learning has now made a

1:20:56.139,1:20:59.590
resurgence in self supervise I think

1:20:57.940,1:21:01.389
pretty much a lord of the self

1:20:59.590,1:21:05.679
supervised state-of-the-art methods are

1:21:01.389,1:21:07.960
really based on contrasted learning and

1:21:05.679,1:21:11.560
the main question is how do you define

1:21:07.960,1:21:13.000
what is related and unrelated so in the

1:21:11.560,1:21:15.190
case of supervised learning that's

1:21:13.000,1:21:18.130
fairly clear all of the dog images are

1:21:15.190,1:21:19.659
related images all and any image that is

1:21:18.130,1:21:21.940
not a dog image is basically an

1:21:19.659,1:21:23.830
unrelated image but it's not so clear

1:21:21.940,1:21:24.580
how to define this elated and

1:21:23.830,1:21:27.719
unlimitedness

1:21:24.580,1:21:30.489
in this case of self supervised learning

1:21:27.719,1:21:33.429
the other sort of main difference from

1:21:30.489,1:21:35.860
something like a free text ask is that

1:21:33.429,1:21:38.940
contrasted birthing really reasons about

1:21:35.860,1:21:42.670
the entire or like a lot of data at once

1:21:38.940,1:21:44.469
so so go back to my previous slide this

1:21:42.670,1:21:47.170
if you look at the loss function it

1:21:44.469,1:21:48.550
always involves multiple images right it

1:21:47.170,1:21:50.290
involves

1:21:48.550,1:21:52.210
so in the first two it involves

1:21:50.290,1:21:54.430
basically the blue images and the green

1:21:52.210,1:21:56.380
images in the second row it involves the

1:21:54.430,1:21:58.930
blue images and the political images

1:21:56.380,1:22:01.060
whereas if you look at a task like say

1:21:58.930,1:22:03.220
jigsaw or a task like rotation

1:22:01.060,1:22:06.160
you're always reasoning about a single

1:22:03.220,1:22:08.500
image independently so that's sort of

1:22:06.160,1:22:09.790
another difference with contrast of

1:22:08.500,1:22:11.440
learning contrasted learning always

1:22:09.790,1:22:16.360
reason support for multiple data points

1:22:11.440,1:22:18.130
at once so now coming to the questions

1:22:16.360,1:22:22.660
how do you define related or unrelated

1:22:18.130,1:22:24.100
images you can actually use similar

1:22:22.660,1:22:27.040
techniques to what I was talking about

1:22:24.100,1:22:28.690
earlier you can use frames of a video so

1:22:27.040,1:22:32.530
you can use the sort of sequential

1:22:28.690,1:22:35.860
nature of data so to sort of understand

1:22:32.530,1:22:37.750
that frames that are nearby in a video

1:22:35.860,1:22:39.910
are related and range say from a

1:22:37.750,1:22:42.970
different video or which are further

1:22:39.910,1:22:44.760
away in time or unrelated and that sort

1:22:42.970,1:22:47.080
of has formed the basis of a lot of

1:22:44.760,1:22:49.390
supervised learning methods in this area

1:22:47.080,1:22:51.160
so if you know of this popular method

1:22:49.390,1:22:53.350
called CPC which is contrastive

1:22:51.160,1:22:56.320
predictive coding that really relies on

1:22:53.350,1:22:58.660
the sequential nature of a signal and it

1:22:56.320,1:23:01.780
basically says that samples that are

1:22:58.660,1:23:03.310
closed by in like the time space are

1:23:01.780,1:23:05.290
related and samples that are further

1:23:03.310,1:23:09.450
apart in the time space are unrelated

1:23:05.290,1:23:12.610
and it's a fairly large amount of work

1:23:09.450,1:23:14.830
basically exploiting this it can either

1:23:12.610,1:23:17.380
be in the speech the domain it can

1:23:14.830,1:23:21.130
either be in video it can be in text or

1:23:17.380,1:23:22.900
it can be in particular images and

1:23:21.130,1:23:25.720
recently we've also been working on

1:23:22.900,1:23:27.700
video and audio so basically saying this

1:23:25.720,1:23:30.490
is that a video and it's corresponding

1:23:27.700,1:23:33.100
audio are relate examples like video and

1:23:30.490,1:23:38.560
audio from a different image video are

1:23:33.100,1:23:41.670
basically underrated samples and some of

1:23:38.560,1:23:44.160
the early work in like sort of

1:23:41.670,1:23:47.020
supervised everything also use this

1:23:44.160,1:23:48.790
quadratic learning method and really

1:23:47.020,1:23:51.520
define to later examples was fairly

1:23:48.790,1:23:54.610
interesting so you run a tracker an

1:23:51.520,1:23:56.380
object tracker over a video and that

1:23:54.610,1:23:59.170
sort of gives you a point like a sort of

1:23:56.380,1:24:02.010
moving patch and what you say is that

1:23:59.170,1:24:04.230
any patch that was tracked by

1:24:02.010,1:24:06.420
cracker is related to my original patch

1:24:04.230,1:24:09.420
whereas any patch from a different video

1:24:06.420,1:24:11.460
is based is not related patch and so

1:24:09.420,1:24:14.040
that basically gives you these bunch of

1:24:11.460,1:24:16.620
related and unselected samples so if you

1:24:14.040,1:24:19.670
look at in this case Figure see where

1:24:16.620,1:24:21.989
you have this like distance notation

1:24:19.670,1:24:23.610
what this network tries to learn is

1:24:21.989,1:24:25.860
basically that patches that are coming

1:24:23.610,1:24:27.840
from the same video are related and

1:24:25.860,1:24:30.390
patches that are coming from words from

1:24:27.840,1:24:33.390
different videos are not related and so

1:24:30.390,1:24:37.020
in some bait automatically learns about

1:24:33.390,1:24:38.370
different poses of a object so a cycle

1:24:37.020,1:24:41.280
viewed from like different viewing

1:24:38.370,1:24:44.100
angles on or like different poses of a

1:24:41.280,1:24:50.850
dog and it tries to sort of group them

1:24:44.100,1:24:54.320
together so in general if you just talk

1:24:50.850,1:24:57.090
about images a lot of work is done on

1:24:54.320,1:25:00.030
looking at nearby image patches versus

1:24:57.090,1:25:02.550
distant patches so most of the sort of

1:25:00.030,1:25:04.590
CPC version one and CPC version two

1:25:02.550,1:25:06.930
methods are really a sort of exploiting

1:25:04.590,1:25:09.420
this property of images so what you do

1:25:06.930,1:25:11.850
is you have image patches that are close

1:25:09.420,1:25:15.360
by you call them as positives and image

1:25:11.850,1:25:17.640
patches that are further apart like far

1:25:15.360,1:25:19.290
farther away in the image are considered

1:25:17.640,1:25:22.140
as negatives and then you basically just

1:25:19.290,1:25:23.580
minimize a contrast if loss using this

1:25:22.140,1:25:28.830
sort of definition of positives and

1:25:23.580,1:25:31.670
negatives the more sort of popular or

1:25:28.830,1:25:34.770
like performant way of doing this is to

1:25:31.670,1:25:36.720
look at patches coming from an image and

1:25:34.770,1:25:39.690
contrast them with patches coming from a

1:25:36.720,1:25:41.790
different image so this sort of forms

1:25:39.690,1:25:44.550
the basis of a lot of popular methods

1:25:41.790,1:25:48.660
like instance discrimination moco pearl

1:25:44.550,1:25:50.970
sims here the idea is basically what's

1:25:48.660,1:25:53.880
shown in the image you sort of get into

1:25:50.970,1:25:56.040
more detail what these methods do is to

1:25:53.880,1:25:57.840
extract two completely random patches

1:25:56.040,1:26:00.270
from an image so these patches can be

1:25:57.840,1:26:01.890
overlapping they can actually become two

1:26:00.270,1:26:04.920
contained within one another or they can

1:26:01.890,1:26:06.840
be completely far apart and it then

1:26:04.920,1:26:08.730
applies some sort of data augmentation

1:26:06.840,1:26:12.120
so in this case say a color chittering

1:26:08.730,1:26:14.219
or removing the color or so on and then

1:26:12.120,1:26:15.110
you define these two patches to be your

1:26:14.219,1:26:17.720
sort of positive

1:26:15.110,1:26:19.760
examples you extract another patch from

1:26:17.720,1:26:21.860
a different image and this is again a

1:26:19.760,1:26:25.580
random patch and that basically becomes

1:26:21.860,1:26:28.220
just negative and a lot of these methods

1:26:25.580,1:26:30.170
will extract a lot of negative patches

1:26:28.220,1:26:32.900
and then they will basically perform

1:26:30.170,1:26:34.850
contrastive learning so you are relating

1:26:32.900,1:26:35.960
to positive samples but you have a sort

1:26:34.850,1:26:39.010
of negative sample that you are

1:26:35.960,1:26:39.010
contrasting this against

1:26:39.840,1:26:46.679
so the now moving to Pearl a little bit

1:26:43.980,1:26:48.630
let's sort of try to understand what the

1:26:46.679,1:26:50.579
main difference of three text tasks is

1:26:48.630,1:26:53.489
and what contrast is everything is sort

1:26:50.579,1:26:54.840
of very different from ptex tasks so the

1:26:53.489,1:26:56.699
one thing i already mentioned was

1:26:54.840,1:26:59.820
pretext tasks always reason about a

1:26:56.699,1:27:02.610
single limit at once so the idea is that

1:26:59.820,1:27:03.869
given an image you apply a transform to

1:27:02.610,1:27:07.020
that image so in this case they are

1:27:03.869,1:27:10.800
jigsaw transform and then you give

1:27:07.020,1:27:12.750
basically input this transformed image

1:27:10.800,1:27:14.219
into a contact and you try to predict

1:27:12.750,1:27:16.469
the property of the transform that you

1:27:14.219,1:27:18.239
applied so the permutation that you

1:27:16.469,1:27:20.520
applied or the rotation that you applied

1:27:18.239,1:27:24.329
or the kind of color that you removed

1:27:20.520,1:27:26.489
and so on so the pretext asks always

1:27:24.329,1:27:28.500
reason about a single image and the

1:27:26.489,1:27:31.230
second thing is that the task that

1:27:28.500,1:27:33.989
you're performing in this case really

1:27:31.230,1:27:35.429
has to capture some property of the

1:27:33.989,1:27:38.099
transform so it really needs to capture

1:27:35.429,1:27:39.840
the exact permutation that you applied

1:27:38.099,1:27:42.449
or the kind of rotation that you applied

1:27:39.840,1:27:44.460
which means that the last layer

1:27:42.449,1:27:47.010
representations are actually going to Co

1:27:44.460,1:27:50.699
vary or sort of vary a lot as the

1:27:47.010,1:27:52.199
transform C changes and that is by

1:27:50.699,1:27:55.110
design because you are really trying to

1:27:52.199,1:27:57.270
solve that pretext task but

1:27:55.110,1:28:00.030
unfortunately what this means is that

1:27:57.270,1:28:02.010
the last layer representations capture a

1:28:00.030,1:28:04.199
very low-level property of the signal so

1:28:02.010,1:28:07.469
they capture like things like rotation

1:28:04.199,1:28:09.599
or so on whereas what is sort of

1:28:07.469,1:28:11.579
designed or what is expected of these

1:28:09.599,1:28:13.320
representations is that they are sort of

1:28:11.579,1:28:15.119
in Burien to these things which you

1:28:13.320,1:28:16.650
should be able to recognize a cat no

1:28:15.119,1:28:18.449
matter whether the cat is upright or

1:28:16.650,1:28:20.789
that the cat has say you know tend

1:28:18.449,1:28:21.690
towards liking by 90 degrees whereas

1:28:20.789,1:28:23.849
when you're solving that particular

1:28:21.690,1:28:25.079
pretext ask you're imposing the exact

1:28:23.849,1:28:26.969
opposite thing you're saying that I

1:28:25.079,1:28:28.590
should be able to recognize whether this

1:28:26.969,1:28:34.289
picture is upright or whether this

1:28:28.590,1:28:36.659
picture is basically tilted sideways so

1:28:34.289,1:28:38.099
there are many exceptions in which you

1:28:36.659,1:28:42.030
really want these low level

1:28:38.099,1:28:43.739
representations to be covariant and I

1:28:42.030,1:28:46.199
thought if it really has to do on the

1:28:43.739,1:28:48.599
tasks that you're performing and quite a

1:28:46.199,1:28:50.519
few tasks in 3d really wants to be

1:28:48.599,1:28:53.280
predictive so you want to sort of

1:28:50.519,1:28:54.990
predict what camera transforms you have

1:28:53.280,1:28:57.480
you're looking at two views of the same

1:28:54.990,1:28:59.760
object or so on but unless you have that

1:28:57.480,1:29:01.710
kind of a specific application for a lot

1:28:59.760,1:29:03.780
of semantic tasks you really want to be

1:29:01.710,1:29:08.940
invariant to the transform the reduced

1:29:03.780,1:29:11.940
as a to use that input so invariance has

1:29:08.940,1:29:14.340
sort of been the workhorse for feature

1:29:11.940,1:29:18.540
learning so something makes it which is

1:29:14.340,1:29:20.640
a fairly popular handcrafted feature the

1:29:18.540,1:29:23.100
eye in SIPP really stands for invariant

1:29:20.640,1:29:25.410
and supervised networks for example

1:29:23.100,1:29:27.090
supervised dialects nets or supervisors

1:29:25.410,1:29:30.000
next they are trained to be invariant

1:29:27.090,1:29:32.400
potato augmentation you want it one this

1:29:30.000,1:29:34.200
network to classify different crops for

1:29:32.400,1:29:37.350
different rotations of this image as a

1:29:34.200,1:29:39.300
three rather than ask it to predict what

1:29:37.350,1:29:43.110
exactly was the transformation apply for

1:29:39.300,1:29:46.140
the input so this is what inspired both

1:29:43.110,1:29:48.660
so foil stands for pretext invariant

1:29:46.140,1:29:50.670
representation learning where the idea

1:29:48.660,1:29:52.740
is that you want the representation to

1:29:50.670,1:29:55.470
be invariant or capture as little

1:29:52.740,1:29:59.220
information as possible of the input

1:29:55.470,1:30:01.170
transform so you have the image you have

1:29:59.220,1:30:03.030
the transform version of the image you

1:30:01.170,1:30:04.800
feed forward both of these images

1:30:03.030,1:30:06.860
through a cornet you have get a

1:30:04.800,1:30:09.000
representation and then you basically

1:30:06.860,1:30:12.600
encourage these representations to be

1:30:09.000,1:30:14.610
similar so in terms of the notation I

1:30:12.600,1:30:18.570
was talking about earlier you basically

1:30:14.610,1:30:20.760
say that the image I and any pretext

1:30:18.570,1:30:23.670
transformed version of this image I are

1:30:20.760,1:30:27.870
related samples and any other image is

1:30:23.670,1:30:29.430
an unrated sample so in this way when

1:30:27.870,1:30:31.980
you train the network this

1:30:29.430,1:30:33.690
representation hopefully it contains

1:30:31.980,1:30:37.680
very little information about this

1:30:33.690,1:30:39.720
transform T and the SU training is in

1:30:37.680,1:30:42.750
contrast if learning so contrast a

1:30:39.720,1:30:44.970
learning part is to basically you have

1:30:42.750,1:30:47.160
save feature V I coming from the

1:30:44.970,1:30:50.010
original image I and you have the

1:30:47.160,1:30:51.780
feature V IT coming from the transform

1:30:50.010,1:30:54.450
version and you want both of these

1:30:51.780,1:30:56.570
representations to be the same and the

1:30:54.450,1:30:57.750
paper we looked at two different

1:30:56.570,1:30:59.700
state-of-the-art

1:30:57.750,1:31:01.320
complete x transforms so that is the

1:30:59.700,1:31:03.390
jigsaw and the rotation method that I

1:31:01.320,1:31:04.830
talked about over here and we also

1:31:03.390,1:31:07.410
explored combinations of these

1:31:04.830,1:31:09.690
transforms so apply Pacific

1:31:07.410,1:31:11.490
rotation at the same time so in some way

1:31:09.690,1:31:13.290
this is like multitask learning but

1:31:11.490,1:31:15.120
they're not really trying to predict

1:31:13.290,1:31:19.970
both disjoint rotation you're trying to

1:31:15.120,1:31:23.120
be invariant to Botha conservation so

1:31:19.970,1:31:25.830
the key thing that has sort of made

1:31:23.120,1:31:28.200
contrastive learning work well in the

1:31:25.830,1:31:30.560
past take sort of successful attempts is

1:31:28.200,1:31:35.280
really using a large number of negatives

1:31:30.560,1:31:37.020
and one of the good sort of paper that

1:31:35.280,1:31:40.980
introduced this was this instance

1:31:37.020,1:31:42.750
discrimination paper from 2018 which

1:31:40.980,1:31:45.960
introduced this concept of a memory bank

1:31:42.750,1:31:47.520
and this is powered I would say most of

1:31:45.960,1:31:49.370
the sort of recent methods which are

1:31:47.520,1:31:51.720
state of the art including more copper

1:31:49.370,1:31:53.580
and they're all sort of page I sort of

1:31:51.720,1:31:55.950
hinge on this idea of of empty part I

1:31:53.580,1:31:57.120
asked you to employ your headphones from

1:31:55.950,1:31:59.220
the computer because it's very noisy

1:31:57.120,1:32:04.760
because it's the microphone is picked

1:31:59.220,1:32:04.760
from the headphones and let's be very

1:32:06.320,1:32:14.880
maybe I don't know it's right okay next

1:32:09.180,1:32:17.040
an so the memory bank is a sort of nice

1:32:14.880,1:32:19.410
day to get a large number of negatives

1:32:17.040,1:32:22.770
without really increasing the sort of

1:32:19.410,1:32:26.430
compute requirement so what you do is

1:32:22.770,1:32:28.860
you store a feature vector per image in

1:32:26.430,1:32:30.660
sort of memory and then you use that

1:32:28.860,1:32:34.860
feature vector in your contrast if done

1:32:30.660,1:32:37.590
so okay let's sort of first talk about

1:32:34.860,1:32:40.650
how you would do this entire pearl setup

1:32:37.590,1:32:43.800
without using a memory bank so you have

1:32:40.650,1:32:45.560
an image I you have an image i T you

1:32:43.800,1:32:49.050
feed forward both of these images you

1:32:45.560,1:32:52.350
get a feature vector F of VI from the

1:32:49.050,1:32:55.920
original image I you get a feature G of

1:32:52.350,1:32:58.290
VI T from the transformed versions the

1:32:55.920,1:33:00.570
patches in this case and what you want

1:32:58.290,1:33:02.700
is the features F and G to be similar

1:33:00.570,1:33:05.370
and you want features from any other

1:33:02.700,1:33:10.740
image so an unrelated image to basically

1:33:05.370,1:33:14.040
be this simpler so in this case what we

1:33:10.740,1:33:15.870
now can do is rather then if we want a

1:33:14.040,1:33:17.400
lot of negatives we would really want a

1:33:15.870,1:33:19.350
lot of these negative images to be

1:33:17.400,1:33:21.000
feed-forward at the same time which

1:33:19.350,1:33:24.390
really means that you need a

1:33:21.000,1:33:26.640
large bat size to be able to do this and

1:33:24.390,1:33:29.130
of course a large bat size means is not

1:33:26.640,1:33:31.920
really sort of good is not possible on

1:33:29.130,1:33:33.450
say unlimited amount of GPU memory so

1:33:31.920,1:33:34.800
the way to sort of do that is to use

1:33:33.450,1:33:37.530
something called a memory bank

1:33:34.800,1:33:40.170
so what this memory bank does is that it

1:33:37.530,1:33:42.630
stores a feature vector for each of the

1:33:40.170,1:33:44.430
images in your dataset and when you're

1:33:42.630,1:33:46.470
doing contrasts of learning rather than

1:33:44.430,1:33:48.690
using feature vectors say from a

1:33:46.470,1:33:50.580
different a negative image a sort of a

1:33:48.690,1:33:52.650
different image in your batch you can

1:33:50.580,1:33:55.500
just retrieve these features from a

1:33:52.650,1:33:57.600
memory so you can just retrieve features

1:33:55.500,1:33:59.070
of any other unrelated image from the

1:33:57.600,1:34:02.220
memory and you can just substitute that

1:33:59.070,1:34:04.650
to perform contrast of them so in Perl

1:34:02.220,1:34:07.140
we divided the objective into two parts

1:34:04.650,1:34:10.040
there was a in like a contrast ship term

1:34:07.140,1:34:13.950
to bring the feature vector from the

1:34:10.040,1:34:15.480
transformed image so G of VI similar to

1:34:13.950,1:34:19.290
the representation that we have in the

1:34:15.480,1:34:21.180
memory so M of I and similarly we have a

1:34:19.290,1:34:24.240
second contrast septum that tries to

1:34:21.180,1:34:25.860
bring the feature at for VI close to the

1:34:24.240,1:34:28.680
feature representation that we have in

1:34:25.860,1:34:31.620
memory so essentially G is being pulled

1:34:28.680,1:34:34.230
close to MI and F is being pulled close

1:34:31.620,1:34:36.360
to MI so by transitivity

1:34:34.230,1:34:38.460
F and G are being pulled close to one

1:34:36.360,1:34:41.460
another and the reason for separating

1:34:38.460,1:34:44.330
this out was it sort of stabilized

1:34:41.460,1:34:46.290
training and we were able to train

1:34:44.330,1:34:47.790
without doing this basically the

1:34:46.290,1:34:50.220
training would not really converge and

1:34:47.790,1:34:52.980
so by separating this out into two forms

1:34:50.220,1:34:54.960
rather than doing like direct contrast

1:34:52.980,1:34:56.340
if nothing between F and G we were able

1:34:54.960,1:35:01.620
to stabilize training and actually get

1:34:56.340,1:35:04.860
it working so the way to evaluate this

1:35:01.620,1:35:07.080
is basically like by standard sort of

1:35:04.860,1:35:09.360
pre training evaluation setup so

1:35:07.080,1:35:12.390
transfer learning where we can pre train

1:35:09.360,1:35:14.010
on images without labels so the standard

1:35:12.390,1:35:16.100
way of doing this is to take a mesh net

1:35:14.010,1:35:19.140
throw away the labels and pretend it is

1:35:16.100,1:35:21.810
unsupervised and then evaluate using

1:35:19.140,1:35:24.120
saiful fine-tuning or using on training

1:35:21.810,1:35:26.190
a linear classifier the second thing we

1:35:24.120,1:35:28.410
did was also a test purl and its

1:35:26.190,1:35:31.230
robustness to images image distributions

1:35:28.410,1:35:32.740
by training it on in the wild images so

1:35:31.230,1:35:34.810
we just took one

1:35:32.740,1:35:36.970
randomly from Flickr so this is the why

1:35:34.810,1:35:39.610
FCC data set and then we basically

1:35:36.970,1:35:41.110
perform transfer learning episode free

1:35:39.610,1:35:43.930
training on these images and then

1:35:41.110,1:35:48.910
perform transfer learning on different

1:35:43.930,1:35:51.420
data sets so I had a question about the

1:35:48.910,1:35:55.720
pole method about the memory bank where

1:35:51.420,1:35:57.610
the m wouldnt those like feature

1:35:55.720,1:36:02.920
representation stored in the memory bank

1:35:57.610,1:36:04.720
be like out of date yeah so they do go a

1:36:02.920,1:36:06.220
little bit out of date but in practice

1:36:04.720,1:36:09.070
it really does not make that much of a

1:36:06.220,1:36:11.860
difference so that this sort of

1:36:09.070,1:36:14.050
particular way of updating them using so

1:36:11.860,1:36:17.200
M of I is a moving average of the

1:36:14.050,1:36:19.900
representation F and that sort of moving

1:36:17.200,1:36:22.000
average although it's still it actually

1:36:19.900,1:36:25.630
does not matter a lot in practice you

1:36:22.000,1:36:28.150
can still continue to use them so

1:36:25.630,1:36:31.030
assuming like I I recently read the

1:36:28.150,1:36:33.820
paper simpler which you huge bad size

1:36:31.030,1:36:37.540
like 8,000 or something so using like

1:36:33.820,1:36:39.610
the memory bank approach and and getting

1:36:37.540,1:36:43.000
these 8,000 examples and one loss

1:36:39.610,1:36:45.940
function is that possible like yes sort

1:36:43.000,1:36:47.980
of Cynthia B of doing it really requires

1:36:45.940,1:36:49.780
a large pad size because you're getting

1:36:47.980,1:36:52.330
negatives from different images in the

1:36:49.780,1:36:53.860
same batch whereas if you use something

1:36:52.330,1:36:55.660
like the memory bank you really do not

1:36:53.860,1:36:57.630
need a large batch size so you can train

1:36:55.660,1:37:00.160
this with like 32 images in a batch

1:36:57.630,1:37:02.380
because all the negatives are really

1:37:00.160,1:37:03.790
coming from the memory bank which does

1:37:02.380,1:37:06.010
not really require you to do multiple

1:37:03.790,1:37:10.520
key forwards

1:37:06.010,1:37:12.170
okay thank you very using memory bank

1:37:10.520,1:37:14.330
till you can't back propagate to the

1:37:12.170,1:37:19.280
negative example so is that not the

1:37:14.330,1:37:20.510
problem all right in it does not create

1:37:19.280,1:37:22.489
that much of a problem

1:37:20.510,1:37:25.010
really so that was one thing I was

1:37:22.489,1:37:27.110
worried about as well so in the initial

1:37:25.010,1:37:29.150
versions we did tie something which was

1:37:27.110,1:37:31.010
like using a larger bad size

1:37:29.150,1:37:34.159
but it when we switch to something like

1:37:31.010,1:37:37.610
the memory bank it did not really reduce

1:37:34.159,1:37:41.150
performance very very little very much

1:37:37.610,1:37:44.210
in the reduction in performance yeah any

1:37:41.150,1:37:47.480
intuition why that's the case so I think

1:37:44.210,1:37:50.929
overall contrastive learning is fairly

1:37:47.480,1:37:53.090
slow to converge so all like all markets

1:37:50.929,1:37:55.489
NCR index the latest version of moko and

1:37:53.090,1:37:56.390
so on all of them train for very large

1:37:55.489,1:37:59.330
number of epochs

1:37:56.390,1:38:00.890
in even so the number of bad props that

1:37:59.330,1:38:02.210
you're getting or the number of memory

1:38:00.890,1:38:04.219
sort of parameter objects that you're

1:38:02.210,1:38:06.290
doing a very large in general so the

1:38:04.219,1:38:07.699
fact that you miss out on one of them in

1:38:06.290,1:38:11.210
this particular case probably does not

1:38:07.699,1:38:16.340
have that much of an effect Thanks

1:38:11.210,1:38:18.920
that's five minutes good almost there so

1:38:16.340,1:38:21.050
yeah we basically I evaluate those on a

1:38:18.920,1:38:24.530
bunch of different tasks so the first

1:38:21.050,1:38:27.770
thing was object detection again sort of

1:38:24.530,1:38:30.050
standard tasks in vision and in this

1:38:27.770,1:38:32.210
case who was able to outperform image

1:38:30.050,1:38:34.520
net supervised training on detection for

1:38:32.210,1:38:37.730
both the VLC or seven and seven plus

1:38:34.520,1:38:38.929
twelve data sets and it outperforms on

1:38:37.730,1:38:42.020
this sort of most strict evaluation

1:38:38.929,1:38:44.150
criterion which is 80 all which is now

1:38:42.020,1:38:46.820
introduced by cocoa which was already

1:38:44.150,1:38:49.699
sort of a positive sign and then it was

1:38:46.820,1:38:51.620
able to do this the second thing we

1:38:49.699,1:38:53.960
looked at was basically evaluating pearl

1:38:51.620,1:38:55.730
on semi-supervised learning and once

1:38:53.960,1:38:58.270
again pearl was performing fairly well

1:38:55.730,1:39:01.159
it was actually better than say the

1:38:58.270,1:39:03.020
pretext task of jigsaw so the only

1:39:01.159,1:39:05.150
difference between the top row and the

1:39:03.020,1:39:07.159
bottom row is the fact that pearl is an

1:39:05.150,1:39:09.510
invariant version whereas jigsaw is a

1:39:07.159,1:39:12.010
covariant version

1:39:09.510,1:39:14.230
and in terms of linear classification

1:39:12.010,1:39:16.930
when Pearl came out it was basically at

1:39:14.230,1:39:19.060
par with CPC is latest version and was

1:39:16.930,1:39:21.250
performing fairly well on a bunch of

1:39:19.060,1:39:22.720
different like parameter settings and a

1:39:21.250,1:39:25.600
bunch of different architectures of

1:39:22.720,1:39:27.190
course now you can have like fairly good

1:39:25.600,1:39:29.830
performance by methods like synth here

1:39:27.190,1:39:31.980
so that number for simply responding

1:39:29.830,1:39:37.020
would basically be about 69 or 70

1:39:31.980,1:39:37.020
compared to like Perl 63 years number

1:39:37.200,1:39:42.130
the other thing we looked at was

1:39:39.280,1:39:44.620
basically how sort of generalizes across

1:39:42.130,1:39:47.230
data distributions so for this we looked

1:39:44.620,1:39:50.380
at just Flickr images from the biopsy

1:39:47.230,1:39:51.880
see data set and who was able to sort of

1:39:50.380,1:39:54.310
outperform methods that were trained

1:39:51.880,1:39:56.770
using hundred times more data so the

1:39:54.310,1:39:58.690
jigsaw row in the second set like a

1:39:56.770,1:40:00.480
jigsaw Oh which is the second row was

1:39:58.690,1:40:02.530
chained on 100 million images

1:40:00.480,1:40:05.980
whereas Pearl was restrained and 1

1:40:02.530,1:40:07.390
million images and despite that it's

1:40:05.980,1:40:09.670
actually able to sort of outperform the

1:40:07.390,1:40:11.890
jigsaw method fairly easily this again

1:40:09.670,1:40:13.360
shows you the power of in like sort of

1:40:11.890,1:40:15.310
breaking invariance into your

1:40:13.360,1:40:18.690
representation rather than sort of

1:40:15.310,1:40:21.660
predicting pretext asks

1:40:18.690,1:40:23.460
and finally the sort of thing I started

1:40:21.660,1:40:25.560
out with which is that whether this

1:40:23.460,1:40:26.550
thing is actually semantic so if you

1:40:25.560,1:40:29.790
look at different layers of

1:40:26.550,1:40:31.890
representations so convent - rs.5 jigsaw

1:40:29.790,1:40:34.199
basically shows a drop in performance

1:40:31.890,1:40:36.360
from restful to rs5 but as for pearl you

1:40:34.199,1:40:38.340
it's all see a sort of nicely increasing

1:40:36.360,1:40:43.620
graph whereas for and rs5 get

1:40:38.340,1:40:45.719
increasingly more and more semantic in

1:40:43.620,1:40:47.250
terms of problem complexity pearl was

1:40:45.719,1:40:49.140
very good at handling that because

1:40:47.250,1:40:50.730
you're never predicting the number of

1:40:49.140,1:40:52.980
permutations you're just using them at

1:40:50.730,1:40:55.469
input as like sort of data augmentation

1:40:52.980,1:40:58.710
so pearl can sort of scale very well to

1:40:55.469,1:41:00.810
all the 360,000 possible permutations in

1:40:58.710,1:41:02.340
the nine patches but as for jigsaw

1:41:00.810,1:41:04.080
because you're predicting that you're

1:41:02.340,1:41:09.239
very limited by the size of your output

1:41:04.080,1:41:11.760
space and the paper also shows that we

1:41:09.239,1:41:13.380
can extend pearl to not just like it's

1:41:11.760,1:41:15.300
not limited jigsaw you can do that on

1:41:13.380,1:41:17.010
rotation if you can inside do it in a

1:41:15.300,1:41:19.350
combination of jigsaw and rotation and

1:41:17.010,1:41:24.690
you can get more and more gains but you

1:41:19.350,1:41:26.670
basically start doing this so basically

1:41:24.690,1:41:28.860
if you look at these methods

1:41:26.670,1:41:31.949
starting from pretext asks to clustering

1:41:28.860,1:41:33.300
to pull as you go from the left to the

1:41:31.949,1:41:35.790
right you basically get more and more

1:41:33.300,1:41:38.580
invariants and in some way you also see

1:41:35.790,1:41:40.260
an increase in performance which sort of

1:41:38.580,1:41:41.640
suggests that baking in more and more in

1:41:40.260,1:41:44.270
various your methods is actually going

1:41:41.640,1:41:47.580
to be more helpful in the long term

1:41:44.270,1:41:48.719
there are some shortcomings which is

1:41:47.580,1:41:50.219
basically that we really do not

1:41:48.719,1:41:52.560
understand what is the set of data

1:41:50.219,1:41:54.719
transforms that matter so jigsaw works

1:41:52.560,1:41:58.739
really well but it's not very clear why

1:41:54.719,1:42:00.390
this is happening so some sort of future

1:41:58.739,1:42:02.280
work or if you want to spend your spare

1:42:00.390,1:42:04.380
cycles thinking about something is

1:42:02.280,1:42:06.270
really understanding what imbalances

1:42:04.380,1:42:08.760
really matter when you are trying to

1:42:06.270,1:42:10.290
solve a supervised task what in there is

1:42:08.760,1:42:13.800
really matter for something like image

1:42:10.290,1:42:15.719
net and that's it

1:42:13.800,1:42:17.520
so basically predict more and more

1:42:15.719,1:42:21.690
information and try to be as invariant

1:42:17.520,1:42:24.690
as possible thank you so I had a

1:42:21.690,1:42:26.820
question yes these contrastive networks

1:42:24.690,1:42:28.530
they can't use the batch norm layer

1:42:26.820,1:42:30.750
right because then information would

1:42:28.530,1:42:31.080
pass from one sample to the other and

1:42:30.750,1:42:33.540
then

1:42:31.080,1:42:35.910
network might learn a very trivial way

1:42:33.540,1:42:40.050
of separating the negatives from the

1:42:35.910,1:42:42.360
positive like so it like for Pearl for

1:42:40.050,1:42:44.040
example we really did not observe that

1:42:42.360,1:42:45.810
phenomenon at all so we did not really

1:42:44.040,1:42:47.730
have to do any special tricks with

1:42:45.810,1:42:52.260
Bachner we were able to use batch no

1:42:47.730,1:42:54.930
masses okay and it's not necessary for

1:42:52.260,1:42:57.150
all the contrast if networks to not be

1:42:54.930,1:42:59.790
using batch norm it's okay to have the

1:42:57.150,1:43:02.760
batch norm here it's yeah it's ten I

1:42:59.790,1:43:04.590
mean for example for Cynthia and so on

1:43:02.760,1:43:06.510
they try and move the sink batch norm

1:43:04.590,1:43:08.820
because if want to emulate a large batch

1:43:06.510,1:43:12.000
size so you might have to do some tweaks

1:43:08.820,1:43:13.680
in batch norm but basically if you you

1:43:12.000,1:43:15.150
cannot avoid it clearly because if you

1:43:13.680,1:43:17.190
completely remove batch norm then

1:43:15.150,1:43:20.970
training these like very deep networks

1:43:17.190,1:43:25.020
is generally very hard anyway okay do

1:43:20.970,1:43:27.090
you think that Paul paper works with the

1:43:25.020,1:43:29.520
Bashan omnious because it uses a memory

1:43:27.090,1:43:32.580
bank and all the representations are not

1:43:29.520,1:43:35.220
taken at the same time whereas I think

1:43:32.580,1:43:37.710
moco they specifically mentioned not to

1:43:35.220,1:43:41.190
use the batch norm layer or use it

1:43:37.710,1:43:42.450
spread across multiple GPUs so that that

1:43:41.190,1:43:44.820
I think is one difference for sure

1:43:42.450,1:43:46.020
because basically the negative side

1:43:44.820,1:43:48.420
you're contrasting against and the

1:43:46.020,1:43:50.460
positive from different time steps which

1:43:48.420,1:43:53.460
makes it harder for batch norm this sort

1:43:50.460,1:43:56.520
of cheating but as for the other methods

1:43:53.460,1:43:58.260
like moco and same fear they very

1:43:56.520,1:44:00.810
correlated to the particular batch that

1:43:58.260,1:44:02.880
you're evaluating right now okay so is

1:44:00.810,1:44:05.730
there any suggestion if we are using a n

1:44:02.880,1:44:07.170
pair loss rather than a memory bank is

1:44:05.730,1:44:09.120
there any suggestion how to go about

1:44:07.170,1:44:12.150
this whether we should just stick to

1:44:09.120,1:44:14.970
Alex Ned and me Gigi which don't use a

1:44:12.150,1:44:21.210
batch norm layer or is there any way to

1:44:14.970,1:44:23.600
turn it off or so what so can you

1:44:21.210,1:44:26.430
describe the setting a little bit more

1:44:23.600,1:44:30.750
so basically what I'm trying to do is

1:44:26.430,1:44:33.630
train on a frames of videos and I'm

1:44:30.750,1:44:35.910
using a n pair setting where I'm trying

1:44:33.630,1:44:39.090
to contrast between n samples rather

1:44:35.910,1:44:41.040
than two or three samples okay and what

1:44:39.090,1:44:42.720
I'm worried about is whether I should be

1:44:41.040,1:44:44.730
using batch norm or not and if I am not

1:44:42.720,1:44:45.480
using batch norm at all then which pre

1:44:44.730,1:44:49.910
brained

1:44:45.480,1:44:49.910
sorry pre architectured models can I use

1:44:51.199,1:44:55.590
let's Ricky so the one problem with

1:44:53.730,1:44:58.679
video frames is basically that fairly

1:44:55.590,1:45:01.050
correlated so in general bache norm a

1:44:58.679,1:45:02.610
sickly the performance of Bashan on B

1:45:01.050,1:45:05.520
grades and you have fairly correlated

1:45:02.610,1:45:06.620
samples so video that becomes more and

1:45:05.520,1:45:11.250
more a problem

1:45:06.620,1:45:13.710
the unfortunate sort of like the sad

1:45:11.250,1:45:15.330
news is basically that even like if you

1:45:13.710,1:45:17.429
look at a typical implementation of Alex

1:45:15.330,1:45:19.980
nineties days it will include batch now

1:45:17.429,1:45:21.300
it's just because it's much more stable

1:45:19.980,1:45:23.280
to train with that you can train with a

1:45:21.300,1:45:24.540
higher learning rate and a lot you can

1:45:23.280,1:45:26.699
basically use it for a bunch of

1:45:24.540,1:45:30.150
different downstream tasks so I think

1:45:26.699,1:45:31.710
you may still have to use batch no it's

1:45:30.150,1:45:34.380
not you can give other variants like

1:45:31.710,1:45:38.370
group norm try which basically do not

1:45:34.380,1:45:38.670
really depend on the batch size ok makes

1:45:38.370,1:45:44.600
sense

1:45:38.670,1:45:48.480
thank you okay thank you so much he Shan

1:45:44.600,1:45:52.230
there's a lot of no interesting details

1:45:48.480,1:45:54.270
I think we still have like eight minutes

1:45:52.230,1:45:58.739
if people are I think they're like still

1:45:54.270,1:46:01.320
many left in class any questions yep I

1:45:58.739,1:46:02.699
had been question which I had also put

1:46:01.320,1:46:05.489
forward in my lecture when we were

1:46:02.699,1:46:08.760
discussing Perl so this question is

1:46:05.489,1:46:13.230
about the lowest function can I answer

1:46:08.760,1:46:15.449
right now okay so when I read the paper

1:46:13.230,1:46:17.730
so there was a probability term that we

1:46:15.449,1:46:20.969
were computing after computing the VI

1:46:17.730,1:46:24.360
and the vit representation for image and

1:46:20.969,1:46:26.670
the transformed version and after

1:46:24.360,1:46:29.520
getting those probabilities then we were

1:46:26.670,1:46:33.030
using a noise contrastive estimation

1:46:29.520,1:46:35.370
loss so I was kind of confused that want

1:46:33.030,1:46:37.170
it had been better if just a negative

1:46:35.370,1:46:42.300
log of that probability had been

1:46:37.170,1:46:44.550
minimized so you can use both really so

1:46:42.300,1:46:46.380
the reason to use and C was basically

1:46:44.550,1:46:50.130
more to do with how the memory bank

1:46:46.380,1:46:51.690
paper was set up so and C you would if

1:46:50.130,1:46:54.030
you have K negatives you are basically

1:46:51.690,1:46:57.210
solving k plus 1 problems so the one

1:46:54.030,1:46:58.830
problem is based you basically have K

1:46:57.210,1:47:00.360
plus 1 different binary problems that

1:46:58.830,1:47:02.250
you

1:47:00.360,1:47:04.320
so that's one way of doing it the other

1:47:02.250,1:47:05.970
way of doing it is basically what is now

1:47:04.320,1:47:08.910
called info NC which is really the

1:47:05.970,1:47:10.320
softmax so you just supplier softmax and

1:47:08.910,1:47:13.440
you minimize the negative slope

1:47:10.320,1:47:16.290
likelihood for that it's because that

1:47:13.440,1:47:23.640
edge the probability function looked

1:47:16.290,1:47:25.380
like Softbank so yes in so at the time

1:47:23.640,1:47:27.660
and I had tied it out it actually gave

1:47:25.380,1:47:29.880
me slightly worse results and so that's

1:47:27.660,1:47:32.910
basically why you can see and this was

1:47:29.880,1:47:34.320
just initial experiments now when I'm

1:47:32.910,1:47:35.880
trying it out it actually gives me save

1:47:34.320,1:47:39.050
the results so I guess in the end it

1:47:35.880,1:47:39.050
does not make that much of a difference

1:47:41.150,1:47:46.260
yam this is more related to the course

1:47:43.830,1:47:48.360
but we are gonna have a project on sell

1:47:46.260,1:47:52.020
soup was Lonnie stern warning can you

1:47:48.360,1:47:56.660
give us information on how to get it get

1:47:52.020,1:47:59.790
us sell soup wise Lonnie model walking

1:47:56.660,1:48:02.250
as in the implementation details like

1:47:59.790,1:48:05.280
the simpler the John the high overall

1:48:02.250,1:48:10.740
high level ideas so try to get it

1:48:05.280,1:48:12.690
working quickly so I think I mean there

1:48:10.740,1:48:14.730
are certain class of techniques that are

1:48:12.690,1:48:16.740
going to be much easier to get working

1:48:14.730,1:48:17.970
from the get-go right so for example if

1:48:16.740,1:48:20.930
you were looking at just three text

1:48:17.970,1:48:23.610
tasks then you would basically look at

1:48:20.930,1:48:26.010
something like rotation because okay

1:48:23.610,1:48:27.870
it's a very easy task to implement you

1:48:26.010,1:48:29.850
really cannot go wrong with it but I

1:48:27.870,1:48:31.710
mean there are just very few things I

1:48:29.850,1:48:34.710
mean so just the number of moving pieces

1:48:31.710,1:48:38.430
a good indicator the other thing to

1:48:34.710,1:48:41.310
remain remember is basically if you're

1:48:38.430,1:48:43.590
sort of implementing a existing method

1:48:41.310,1:48:46.050
then there are going to be lots of tiny

1:48:43.590,1:48:47.790
details the authors talk about so for

1:48:46.050,1:48:49.440
example the exactly learning rate that

1:48:47.790,1:48:49.980
they used or the way they used bash norm

1:48:49.440,1:48:51.630
and so on

1:48:49.980,1:48:52.920
if there are lots of these things then

1:48:51.630,1:48:55.710
basically it's going to be harder and

1:48:52.920,1:49:00.030
harder for you to sort of reproduce more

1:48:55.710,1:49:01.320
and more things for you to get wrong the

1:49:00.030,1:49:02.820
second thing to remember is data

1:49:01.320,1:49:06.390
augmentations rate augmentations are

1:49:02.820,1:49:08.550
really critical so if you get anything

1:49:06.390,1:49:10.650
working you would try to sort of add

1:49:08.550,1:49:15.330
molded augmentations to it

1:49:10.650,1:49:17.070
I think and do you recommend us trying

1:49:15.330,1:49:21.180
Oh Lord you cannot be too difficult to

1:49:17.070,1:49:25.980
do in one month I'm not sure what the

1:49:21.180,1:49:28.590
setting is really some notch okay thanks

1:49:25.980,1:49:30.780
when it is one more ting of did you try

1:49:28.590,1:49:33.840
using momentum contrast on coal instead

1:49:30.780,1:49:35.550
of MD Bank I happened

1:49:33.840,1:49:36.930
so we basically move to the end-to-end

1:49:35.550,1:49:41.520
version which is like similar to what

1:49:36.930,1:49:42.720
Cynthia is so the thing is I mean you

1:49:41.520,1:49:44.670
can may see me gather a bunch of

1:49:42.720,1:49:46.470
negatives wrong on different GPO so in

1:49:44.670,1:49:49.410
case your pad size that actually

1:49:46.470,1:49:52.020
generally helps a lot I would suspect

1:49:49.410,1:49:54.030
more covert helped a lot as well I think

1:49:52.020,1:49:56.850
no Co but improved performance over

1:49:54.030,1:50:00.720
Sinclair by replacing end-to-end

1:49:56.850,1:50:03.960
training with moco but I think numbers

1:50:00.720,1:50:05.820
are still fairly similar and there are

1:50:03.960,1:50:07.350
small differences in evaluation protocol

1:50:05.820,1:50:11.340
that you would sort of see across these

1:50:07.350,1:50:13.140
papers so yeah I think so we're learning

1:50:11.340,1:50:15.210
to sort of release a more standardized

1:50:13.140,1:50:17.610
evaluation benchmark so we did that last

1:50:15.210,1:50:18.810
year unfortunately that was in cafe - so

1:50:17.610,1:50:21.360
we're trying to sort of crazy something

1:50:18.810,1:50:22.950
in five dots now we provide a lot of

1:50:21.360,1:50:24.510
standardized implementations so like

1:50:22.950,1:50:30.720
further and a bunch of these and a

1:50:24.510,1:50:34.320
standardized evaluation protocol I found

1:50:30.720,1:50:36.720
I had a question about above this cell

1:50:34.320,1:50:39.300
supervised learning so what do you think

1:50:36.720,1:50:42.200
is the state of like generative methods

1:50:39.300,1:50:44.130
and did you think about combining like

1:50:42.200,1:50:48.210
contrasting methods with generative

1:50:44.130,1:50:50.160
methods like simpler actually like has a

1:50:48.210,1:50:51.780
different space so they have like a

1:50:50.160,1:50:53.700
linear layer on top of the feature

1:50:51.780,1:50:55.830
representation where they compute the

1:50:53.700,1:50:59.190
actual reach the representation where

1:50:55.830,1:51:01.380
they did the contrast loss the NCE stuff

1:50:59.190,1:51:05.220
so like do you think like having another

1:51:01.380,1:51:07.830
head like that basically given like a

1:51:05.220,1:51:11.130
crop of image you just try to scale out

1:51:07.830,1:51:13.290
that crop of image and you have that

1:51:11.130,1:51:17.670
information because you crop that image

1:51:13.290,1:51:21.330
right and use them again or something so

1:51:17.670,1:51:23.670
I mean it is definitely a good idea I

1:51:21.330,1:51:24.449
think it says the tricky part is getting

1:51:23.670,1:51:27.959
these things

1:51:24.449,1:51:29.280
just non-trivial so initially like I

1:51:27.959,1:51:31.979
haven't really tried any relative

1:51:29.280,1:51:33.539
approaches in my experience that's

1:51:31.979,1:51:34.729
slightly worse when you can harder to

1:51:33.539,1:51:37.409
get to work

1:51:34.729,1:51:39.989
but I do agree I think sort of in the

1:51:37.409,1:51:42.820
longer term they are like they are sort

1:51:39.989,1:51:52.330
of the things to focus on

1:51:42.820,1:51:56.030
thank you gasps question no that's it I

1:51:52.330,1:51:59.630
guess oh I can actually ask the question

1:51:56.030,1:52:01.130
well yeah so this is regarding

1:51:59.630,1:52:03.110
distillation actually so you were

1:52:01.130,1:52:05.860
telling me how predicting software

1:52:03.110,1:52:09.920
distributions gives gives a richer

1:52:05.860,1:52:11.930
target right so can you elaborate on

1:52:09.920,1:52:13.910
that because it sort of increases the

1:52:11.930,1:52:16.490
uncertainty of our model right we are

1:52:13.910,1:52:17.840
predicting from one hot distribution and

1:52:16.490,1:52:19.340
then making it software and then we are

1:52:17.840,1:52:21.290
predicting on that so more uncertainty

1:52:19.340,1:52:23.540
and more over like why do they call it

1:52:21.290,1:52:25.310
distillation because I saw to feel like

1:52:23.540,1:52:31.220
you need more parameters to account for

1:52:25.310,1:52:34.520
this richer richer target right so the

1:52:31.220,1:52:36.170
one thing is basically if you train on

1:52:34.520,1:52:38.720
one hot labels your models tend to be

1:52:36.170,1:52:40.220
very overconfident in general so if you

1:52:38.720,1:52:42.830
have heard of these tricks called like

1:52:40.220,1:52:45.440
label smoothing which is sort of now

1:52:42.830,1:52:47.990
being used by a bunch of methods label

1:52:45.440,1:52:49.490
smoothing is like you can think of it

1:52:47.990,1:52:50.090
like the sort of simplest version of

1:52:49.490,1:52:51.740
distillation

1:52:50.090,1:52:53.690
so you have a one hot vector that you

1:52:51.740,1:52:54.920
were trying to predict but rather than

1:52:53.690,1:52:56.000
trying to predict that and Taiwan not

1:52:54.920,1:52:59.150
vector what you do is you take some

1:52:56.000,1:53:00.890
probability mass out of that so you

1:52:59.150,1:53:03.130
would predict one and a bunch of 0s so

1:53:00.890,1:53:05.930
rather than doing that you predict say

1:53:03.130,1:53:07.490
0.97 and you add point one point one

1:53:05.930,1:53:09.440
point one two I'll take the remainder

1:53:07.490,1:53:10.610
three vapors she just start a uniform

1:53:09.440,1:53:12.710
distribution to the remainder so

1:53:10.610,1:53:14.810
distillation is a sort of more informed

1:53:12.710,1:53:17.150
way of doing this so rather than like

1:53:14.810,1:53:18.860
randomly sort of increasing the

1:53:17.150,1:53:21.530
probability of a random undulated class

1:53:18.860,1:53:25.010
to actually have a network which was pre

1:53:21.530,1:53:26.720
trained which is pretty good to this in

1:53:25.010,1:53:29.800
general software distributions are very

1:53:26.720,1:53:32.050
useful for free training methods because

1:53:29.800,1:53:33.860
models tend to be overconfident

1:53:32.050,1:53:35.390
pre-training on like software

1:53:33.860,1:53:37.370
distribution is actually slightly easier

1:53:35.390,1:53:40.160
than optimization problems you converge

1:53:37.370,1:53:42.380
slightly faster as well so both of these

1:53:40.160,1:53:46.130
benefits are present in the solution and

1:53:42.380,1:53:48.710
also also because like smooth labels

1:53:46.130,1:53:50.870
allow you to have like a dog looking cat

1:53:48.710,1:53:52.670
or a cat looking dog right so if you

1:53:50.870,1:53:54.590
have a very big network that has been

1:53:52.670,1:53:55.270
trained on very many samples it will

1:53:54.590,1:53:58.000
actually

1:53:55.270,1:54:00.040
have you no idea a proper idea of what

1:53:58.000,1:54:02.650
is you know unambiguous perhaps image

1:54:00.040,1:54:04.450
right and therefore if you can actually

1:54:02.650,1:54:06.940
learn that soft idea you're gonna be

1:54:04.450,1:54:12.240
learning more than if you just give that

1:54:06.940,1:54:14.530
you know one hot label I think we are

1:54:12.240,1:54:16.420
time I think we're around the time like

1:54:14.530,1:54:18.640
half an hour ago but this was the

1:54:16.420,1:54:20.230
question answering question and answers

1:54:18.640,1:54:22.510
session

1:54:20.230,1:54:27.700
if there are no you know really really

1:54:22.510,1:54:32.080
urgent questions still pending I will be

1:54:27.700,1:54:35.170
calling it called the end of the today

1:54:32.080,1:54:38.050
lesson so thank you for tuning in I see

1:54:35.170,1:54:41.070
you tomorrow at the practically

1:54:38.050,1:54:44.470
practical session don't forget to come

1:54:41.070,1:54:47.590
and it was it so thank you so much

1:54:44.470,1:54:48.940
Asian and I see you around execution

1:54:47.590,1:54:52.020
thank you everyone take care everyone

1:54:48.940,1:54:52.020
right bye-bye

1:55:00.700,1:55:02.760
you

