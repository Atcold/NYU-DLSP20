---
lang-ref: ch.10
title: Week 10
---

## Lecture part B

In this section, we discussed the shortcomings of Pretext tasks, defined characteristics that make a good pretrained feature, and how we can achieve this using Clustering and Contrastive Learning. We then learned about ClusterFit, its steps and its performance. We also further dived into a specific simple framework for Contrastive Learning known as PIRL. We discussed its working as well as its evaluations in different contexts.