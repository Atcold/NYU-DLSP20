---
lang-ref: ch.10
title: Week 10
---


## Lecture part A

In this section, we understand the motivation behind Self-Supervised Learning, define what it is and see some of its applications in NLP and Computer Vision. We understand how pretext tasks aid with SSL and see some example pretext tasks in images, videos and videos with sound. Finally, we try to get an intuition behind the representation learned by pretext tasks.


## Lecture part B

In this section, we discussed the shortcomings of Pretext tasks, defined characteristics that make a good pretrained feature, and how we can achieve this using Clustering and Contrastive Learning. We then learned about ClusterFit, its steps and its performance. We also further dived into a specific simple framework for Contrastive Learning known as PIRL. We discussed its working as well as its evaluations in different contexts.

## Practicum

During this week's practicum, we explored the [Truck Backer-Upper](http://neuro.bstu.by/ai/To-dom/My_research/Papers-2.1-done/RL-sparce-reward/9/Ref/truckbackerupper.pdf) (Nguyen & Widrow, '90).
The Truck Backer-Upper shows how to solve an non-linear control problem using neural networks.
The goal of this problem is to find a sequence of steering angles to successfully back a truck up to a preordained location.
We do this by learning a model of a truck's kinematics.
Then, to train a controller to output correct steering angles, we backpropagate the error signal through the kinematics model to optimize the controller.
We find that the controller is able to learn complex behaviors to back the truck up through purely observational data, and show code on how to build such networks.
