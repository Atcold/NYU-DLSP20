0:00:00.560,0:00:05.200
we have today mike lewis he's a research

0:00:03.120,0:00:06.960
scientist at facebook ai research

0:00:05.200,0:00:08.639
working on natural language processing

0:00:06.960,0:00:10.080
so previously he was a postdoc at the

0:00:08.639,0:00:13.360
university of washington

0:00:10.080,0:00:15.519
and working with luke zettelmoyer

0:00:13.360,0:00:16.400
and on the search based structure

0:00:15.519,0:00:18.400
prediction

0:00:16.400,0:00:19.600
he completed his phd at the university

0:00:18.400,0:00:22.160
of edinburgh

0:00:19.600,0:00:23.519
and based on combining distributional

0:00:22.160,0:00:26.240
and logical approaches

0:00:23.519,0:00:27.920
to semantics he has a mastery degree

0:00:26.240,0:00:29.439
from the university of oxford and won

0:00:27.920,0:00:32.640
the best paper award on

0:00:29.439,0:00:35.040
eml em nlp in 2016.

0:00:32.640,0:00:37.200
so uh without further ado let's get

0:00:35.040,0:00:38.559
started with today's presentation

0:00:37.200,0:00:40.480
okay well thank you very much for the

0:00:38.559,0:00:41.520
introduction of radio and replacing me

0:00:40.480,0:00:43.440
to turk

0:00:41.520,0:00:45.039
um so yeah this lecture just wants to

0:00:43.440,0:00:47.280
try and give a

0:00:45.039,0:00:48.239
high level overview of how deep learning

0:00:47.280,0:00:51.680
is used for

0:00:48.239,0:00:53.199
natural languages processing these days

0:00:51.680,0:00:55.280
so i think it's per se it's been really

0:00:53.199,0:00:55.920
dramatic progress in nlp in the last few

0:00:55.280,0:01:00.160
years

0:00:55.920,0:01:01.920
with the playing deep learning um so

0:01:00.160,0:01:03.760
these days i mean you can get machine

0:01:01.920,0:01:05.119
translation systems which will produce

0:01:03.760,0:01:07.680
translations which

0:01:05.119,0:01:10.640
blind human narrators prefer the ones

0:01:07.680,0:01:12.560
produced by professional translators

0:01:10.640,0:01:14.240
um you can make some question answering

0:01:12.560,0:01:15.360
systems that you ask them a question

0:01:14.240,0:01:17.280
give me wikipedia

0:01:15.360,0:01:18.880
and they'll give you answers that are

0:01:17.280,0:01:21.040
races more accurate than the ones that

0:01:18.880,0:01:22.799
people will give you

0:01:21.040,0:01:24.720
i could like have language models that

0:01:22.799,0:01:28.799
can like generate

0:01:24.720,0:01:30.000
uh several paragraphs of fluent text

0:01:28.799,0:01:31.520
and for all of these things if you'd

0:01:30.000,0:01:32.159
asked me like maybe five years ago i'd

0:01:31.520,0:01:33.920
have told you

0:01:32.159,0:01:35.759
there's absolutely no way any of this is

0:01:33.920,0:01:37.600
possible in 2020

0:01:35.759,0:01:38.799
but um there seems to be a few

0:01:37.600,0:01:40.159
techniques that have been introduced

0:01:38.799,0:01:43.600
that have really

0:01:40.159,0:01:44.880
made dramatic differences and one really

0:01:43.600,0:01:47.360
nice properties actually

0:01:44.880,0:01:49.119
you can achieve all of these things with

0:01:47.360,0:01:50.479
fairly generic models so

0:01:49.119,0:01:53.040
all the models for all these tasks

0:01:50.479,0:01:54.240
actually look very similar

0:01:53.040,0:01:57.520
uh there's just a few high-level

0:01:54.240,0:01:59.600
principles which are really useful

0:01:57.520,0:02:00.799
um so i'm gonna be covering quite a lot

0:01:59.600,0:02:03.920
ground on this quite quickly

0:02:00.799,0:02:05.920
so please interrupt me often with

0:02:03.920,0:02:10.319
questions

0:02:05.920,0:02:10.319
um right so

0:02:11.680,0:02:14.640
yeah um also one thing i should say is

0:02:13.520,0:02:15.440
that with all the progress we've been

0:02:14.640,0:02:18.000
seeing

0:02:15.440,0:02:19.040
in nlp uh probably a lot of stuff i'm

0:02:18.000,0:02:20.879
going to tell you right now is going to

0:02:19.040,0:02:21.280
be out to date in a year or two i mean i

0:02:20.879,0:02:23.040
hope

0:02:21.280,0:02:24.560
we continue to make progress and stuff

0:02:23.040,0:02:26.879
continues to

0:02:24.560,0:02:28.000
be out today so as well as like

0:02:26.879,0:02:29.599
explaining some of the models we're

0:02:28.000,0:02:31.519
using i want to try and sort of give you

0:02:29.599,0:02:34.560
some intuitions about what kinds of

0:02:31.519,0:02:36.239
principles are working out well

0:02:34.560,0:02:38.879
which will hopefully have a bit more of

0:02:36.239,0:02:38.879
a shelf life

0:02:39.200,0:02:44.720
okay so um the first

0:02:42.319,0:02:46.319
topic i want to cover this lecture is

0:02:44.720,0:02:48.239
language modeling

0:02:46.319,0:02:49.920
language modeling isn't necessarily a

0:02:48.239,0:02:50.800
useful task in itself but it seems to be

0:02:49.920,0:02:53.760
a really good

0:02:50.800,0:02:57.440
building block for introducing all the

0:02:53.760,0:02:57.440
techniques that we'll need later on

0:02:57.680,0:03:02.159
um so uh i don't know any of you seen

0:03:00.879,0:03:06.000
this before this is an example

0:03:02.159,0:03:09.200
from a language model called gpt2

0:03:06.000,0:03:10.959
which came out in 2019.

0:03:09.200,0:03:12.480
um so what's going on here is that we've

0:03:10.959,0:03:15.519
got

0:03:12.480,0:03:17.120
some humans played some uh introduction

0:03:15.519,0:03:18.720
here about um

0:03:17.120,0:03:21.200
scientists finally heard of unicorns of

0:03:18.720,0:03:23.280
the andes that apparently speak english

0:03:21.200,0:03:24.560
and then given that text they've asked

0:03:23.280,0:03:27.440
this language model to

0:03:24.560,0:03:28.560
write some more texts and stats of that

0:03:27.440,0:03:30.000
and

0:03:28.560,0:03:31.440
the text we get here is actually quite

0:03:30.000,0:03:32.879
impressive like everyone was really

0:03:31.440,0:03:34.959
shocked that language roles could work

0:03:32.879,0:03:40.159
this well

0:03:34.959,0:03:41.920
uh last year so you can see um

0:03:40.159,0:03:43.519
the convenient text seems actually quite

0:03:41.920,0:03:44.720
plausible for a news article about this

0:03:43.519,0:03:48.080
it's um

0:03:44.720,0:03:49.920
talk to me talk about unicorns um

0:03:48.080,0:03:52.720
the text is very fluent grammatical it's

0:03:49.920,0:03:54.159
not really any flaws there and

0:03:52.720,0:03:55.840
it seems to like invent quite a lot of

0:03:54.159,0:03:58.720
details like the name of the scientists

0:03:55.840,0:03:58.720
who discovered them

0:03:58.840,0:04:02.720
um obviously all this is complete

0:04:01.200,0:04:05.760
nonsense nothing here is true

0:04:02.720,0:04:06.959
but um also

0:04:05.760,0:04:08.159
none of this will look like anything the

0:04:06.959,0:04:10.239
model was ever trained on like i'm

0:04:08.159,0:04:12.080
pretty sure

0:04:10.239,0:04:13.599
this paragraph over his unicorn has like

0:04:12.080,0:04:15.120
no

0:04:13.599,0:04:16.720
neighbors anywhere on the internet this

0:04:15.120,0:04:17.040
is all completely new language but it's

0:04:16.720,0:04:20.239
all

0:04:17.040,0:04:22.240
actually quite high quality text

0:04:20.239,0:04:23.520
um i'm not going to read all this out

0:04:22.240,0:04:25.440
but like if you read the rest of the

0:04:23.520,0:04:27.040
article that wrote then

0:04:25.440,0:04:30.000
um there are some flaws but they're

0:04:27.040,0:04:31.919
quite hard to spot and generally

0:04:30.000,0:04:33.520
uh this seems to be quite a good

0:04:31.919,0:04:35.120
language model

0:04:33.520,0:04:36.320
so i'm gonna try and show you like the

0:04:35.120,0:04:39.600
kind of techniques you need to actually

0:04:36.320,0:04:41.930
build the lines model that works as well

0:04:39.600,0:04:43.600
all right so um

0:04:41.930,0:04:45.120
[Music]

0:04:43.600,0:04:47.360
very briefly what is language model so

0:04:45.120,0:04:48.800
lines model is just a basically density

0:04:47.360,0:04:51.440
estimation for text

0:04:48.800,0:04:52.320
so we're going to assign a probability

0:04:51.440,0:04:55.440
to

0:04:52.320,0:04:58.080
uh every possible string and hopefully

0:04:55.440,0:04:59.759
when well puts more probability on like

0:04:58.080,0:05:02.160
strings which are fluent english than

0:04:59.759,0:05:04.720
other strings

0:05:02.160,0:05:06.240
um so how do we model this density well

0:05:04.720,0:05:08.840
um obviously

0:05:06.240,0:05:10.320
there are quite a lot of possible

0:05:08.840,0:05:12.240
sentences

0:05:10.320,0:05:14.880
exponentially many so we can't just

0:05:12.240,0:05:16.479
predict classified suits directly

0:05:14.880,0:05:18.000
um there are different techniques you

0:05:16.479,0:05:19.039
can do for this but the one i'm going to

0:05:18.000,0:05:21.039
talk about is the one that's most

0:05:19.039,0:05:22.960
popularly used which is

0:05:21.039,0:05:25.440
basically to factorize this distribution

0:05:22.960,0:05:30.160
using the chain rule

0:05:25.440,0:05:32.800
um so here all we're going to do is

0:05:30.160,0:05:34.160
um just fractionation to say it's going

0:05:32.800,0:05:37.120
to predict the first word then click

0:05:34.160,0:05:40.639
second word given the first then

0:05:37.120,0:05:40.639
the third given the previous two

0:05:41.199,0:05:46.160
um this is an exact characterization it

0:05:44.800,0:05:50.720
doesn't cost us anything to do

0:05:46.160,0:05:52.080
like this um so really what we turned is

0:05:50.720,0:05:54.000
the density estimation problem into a

0:05:52.080,0:05:55.520
series of classification problems

0:05:54.000,0:05:58.080
these classification problems are the

0:05:55.520,0:05:58.960
form given a bunch of texts predict the

0:05:58.080,0:06:00.400
next word

0:05:58.960,0:06:03.840
and that's going to be a theme through a

0:06:00.400,0:06:03.840
lot of techniques we have in this talk

0:06:04.240,0:06:08.560
so more concretely we have this uh from

0:06:06.880,0:06:10.400
this

0:06:08.560,0:06:12.080
example i showed you before we got this

0:06:10.400,0:06:12.880
um string the model output so like the

0:06:12.080,0:06:14.560
scientists

0:06:12.880,0:06:16.240
name the population after the distinct

0:06:14.560,0:06:17.840
detail on orbits and you've got to

0:06:16.240,0:06:20.479
predict the next word

0:06:17.840,0:06:22.880
and uh the correct word in this case is

0:06:20.479,0:06:22.880
unicorn

0:06:23.919,0:06:28.880
okay so um

0:06:27.440,0:06:30.560
at high level all these language models

0:06:28.880,0:06:33.199
look something like this basically we

0:06:30.560,0:06:34.240
input this text into a neural network

0:06:33.199,0:06:36.160
somehow

0:06:34.240,0:06:38.080
the neural network will map all this

0:06:36.160,0:06:40.800
context onto a vector

0:06:38.080,0:06:41.440
this vector represents the next word and

0:06:40.800,0:06:44.560
then we're going to

0:06:41.440,0:06:49.599
have some big word about matrix

0:06:44.560,0:06:51.680
so our um word evading matrix will

0:06:49.599,0:06:54.960
basically contain a vector for every

0:06:51.680,0:06:56.720
possible word model knows how to output

0:06:54.960,0:06:58.000
and then all we need to do is compute

0:06:56.720,0:06:59.280
the similarity by just doing a dot

0:06:58.000,0:07:00.720
product between

0:06:59.280,0:07:02.319
the context vector and each of these

0:07:00.720,0:07:05.120
word vectors

0:07:02.319,0:07:07.039
and uh we'll get a likelihood of

0:07:05.120,0:07:08.319
predicting the next word

0:07:07.039,0:07:12.080
then we'll just train this model by

0:07:08.319,0:07:12.080
maximum likelihood in the obvious way

0:07:13.680,0:07:19.840
okay so um

0:07:17.759,0:07:21.520
i mean the detail here is often we don't

0:07:19.840,0:07:22.479
deal with words directly we deal with

0:07:21.520,0:07:24.960
things called

0:07:22.479,0:07:28.319
sub words or even characters but um all

0:07:24.960,0:07:28.319
the modeling techniques remain the same

0:07:28.800,0:07:33.280
all right so um

0:07:31.919,0:07:34.960
how all the skill here is in this

0:07:33.280,0:07:38.800
context encoder

0:07:34.960,0:07:40.319
how do we build this um

0:07:38.800,0:07:41.520
so kind of the first approach people

0:07:40.319,0:07:44.479
took for this is um basically

0:07:41.520,0:07:46.479
convolutional models

0:07:44.479,0:07:48.560
so these convolution worlds kind of

0:07:46.479,0:07:51.280
encode this

0:07:48.560,0:07:52.720
uh inductive bias that language kind of

0:07:51.280,0:07:53.919
has this translation of variance

0:07:52.720,0:07:56.240
property

0:07:53.919,0:08:00.400
we should interpret a phrase the same

0:07:56.240,0:08:03.840
way no matter what position it occurs in

0:08:00.400,0:08:05.440
um so a typical model might look this

0:08:03.840,0:08:06.960
way basically first of all

0:08:05.440,0:08:08.479
for every word we'll just map it to some

0:08:06.960,0:08:10.240
vector um

0:08:08.479,0:08:11.680
which is just a lookup table into an

0:08:10.240,0:08:13.199
embedding matrix

0:08:11.680,0:08:16.720
so the word will get the same vector no

0:08:13.199,0:08:19.280
matter what context it appears in

0:08:16.720,0:08:21.039
and then we'll apply a bunch of layers

0:08:19.280,0:08:22.720
of the 1d convolutions followed by

0:08:21.039,0:08:24.240
non-linearities

0:08:22.720,0:08:26.000
until eventually we end up with some

0:08:24.240,0:08:29.440
kind of vector

0:08:26.000,0:08:30.879
representing that context which really

0:08:29.440,0:08:33.599
really hit the vector means what should

0:08:30.879,0:08:33.599
the next word be

0:08:34.240,0:08:39.680
um and these models were first

0:08:38.080,0:08:41.599
i think this is actually maybe the first

0:08:39.680,0:08:43.599
language model from bengio in 2003 both

0:08:41.599,0:08:46.080
best neural language model

0:08:43.599,0:08:47.360
um and uh these kind of convolutional

0:08:46.080,0:08:49.360
approaches were actually shared

0:08:47.360,0:08:51.440
if to work quite well by younger phone

0:08:49.360,0:08:52.880
in 2016 if you

0:08:51.440,0:08:55.360
reply kind of modern deep learning

0:08:52.880,0:08:58.959
techniques

0:08:55.360,0:09:00.320
um kind of the these models very fast

0:08:58.959,0:09:03.040
which is great

0:09:00.320,0:09:04.080
um actually speed is very impossible

0:09:03.040,0:09:05.680
language modeling because

0:09:04.080,0:09:08.240
typically we use huge amounts of

0:09:05.680,0:09:11.200
training data

0:09:08.240,0:09:12.399
um there's one come downside which is

0:09:11.200,0:09:15.120
that they're only able to really

0:09:12.399,0:09:17.839
condition on the certain reception field

0:09:15.120,0:09:20.480
um so in this kind of toy example uh

0:09:17.839,0:09:23.920
this word unicorn could only condition

0:09:20.480,0:09:26.320
uh the previous uh five words

0:09:23.920,0:09:29.120
uh because of the sort of kernel width

0:09:26.320,0:09:30.399
the number of layers we're using here

0:09:29.120,0:09:31.839
um obviously like realistic

0:09:30.399,0:09:34.240
convolutional worlds i have a much

0:09:31.839,0:09:36.959
bigger receptor field like this but

0:09:34.240,0:09:40.800
um natural language tends to have

0:09:36.959,0:09:40.800
extremely long range dependencies i mean

0:09:41.120,0:09:43.680
uh for an extreme example you can

0:09:42.399,0:09:46.160
imagine if you're like trying to build a

0:09:43.680,0:09:47.519
line total of a complete book

0:09:46.160,0:09:49.040
it might actually help you to be able to

0:09:47.519,0:09:50.880
condition on the title of the book at

0:09:49.040,0:09:53.440
all time steps and

0:09:50.880,0:09:54.480
obviously the title will be hundreds of

0:09:53.440,0:09:56.480
thousands of words

0:09:54.480,0:09:58.560
previously and it's quite hard to kind

0:09:56.480,0:09:59.920
of build this into

0:09:58.560,0:10:02.880
build a convolutional except to feel

0:09:59.920,0:10:02.880
it's big enough to do this

0:10:03.440,0:10:07.680
okay so how do we condition our model

0:10:05.760,0:10:10.800
context

0:10:07.680,0:10:12.160
i guess um the most popular approach

0:10:10.800,0:10:14.959
until a couple years ago

0:10:12.160,0:10:17.360
was uh what's called the current neural

0:10:14.959,0:10:20.880
networks

0:10:17.360,0:10:24.399
um this is kind of a conceptually quite

0:10:20.880,0:10:25.519
straightforward idea that basically at

0:10:24.399,0:10:27.360
every time set we're going to maintain

0:10:25.519,0:10:28.720
some state so have some state coming in

0:10:27.360,0:10:29.760
from the previous time step which

0:10:28.720,0:10:32.000
represents

0:10:29.760,0:10:33.680
what we've read so far we'll combine the

0:10:32.000,0:10:34.959
state with uh

0:10:33.680,0:10:37.120
the current word we've read and we'll

0:10:34.959,0:10:39.279
use that to update our states

0:10:37.120,0:10:40.800
and then we'll just iterate this for as

0:10:39.279,0:10:45.440
many time steps

0:10:40.800,0:10:47.279
as we need um

0:10:45.440,0:10:48.880
so i think this seems like quite a

0:10:47.279,0:10:50.640
natural model of reading i mean

0:10:48.880,0:10:52.079
i think for the most part people kind of

0:10:50.640,0:10:53.440
read left or right and maintain some

0:10:52.079,0:10:57.200
kind of states

0:10:53.440,0:10:58.959
as they go at least in principle as well

0:10:57.200,0:11:00.160
you can model unbounded contexts like

0:10:58.959,0:11:04.320
this so

0:11:00.160,0:11:06.880
um at least in principle like the

0:11:04.320,0:11:07.920
say the title of a book would affect the

0:11:06.880,0:11:11.040
hidden states

0:11:07.920,0:11:11.040
of the last word of the book

0:11:11.440,0:11:17.920
um in practice so there are some fairly

0:11:14.560,0:11:17.920
significant issues with this model

0:11:18.399,0:11:22.000
firstly um there's kind of

0:11:22.320,0:11:26.720
no free lunch here so by the time

0:11:25.600,0:11:28.160
the effect of trying to maintain

0:11:26.720,0:11:29.120
mistakes is we're going to compress the

0:11:28.160,0:11:31.760
whole

0:11:29.120,0:11:34.959
history of the document reading into a

0:11:31.760,0:11:36.320
single vector at each time step

0:11:34.959,0:11:38.079
and then you can't once you've read a

0:11:36.320,0:11:38.959
word you can never look at it again you

0:11:38.079,0:11:41.519
have to

0:11:38.959,0:11:43.600
memorize that and that means you have to

0:11:41.519,0:11:45.440
actually have to

0:11:43.600,0:11:46.959
cram a huge amount of information into a

0:11:45.440,0:11:49.120
single vector

0:11:46.959,0:11:52.240
and this is firstly it's a kind of a

0:11:49.120,0:11:53.200
bottleneck involved also i mean

0:11:52.240,0:11:54.800
there's a question about how much

0:11:53.200,0:11:57.120
information you can really store in one

0:11:54.800,0:11:59.440
vector but

0:11:57.120,0:12:02.079
also um it's kind of a practical

0:11:59.440,0:12:04.320
learning problem to you

0:12:02.079,0:12:05.920
that's the the um you get an issue

0:12:04.320,0:12:08.160
called the vanishing gradient problem

0:12:05.920,0:12:08.160
where

0:12:08.800,0:12:12.959
it means that you know every time you go

0:12:10.399,0:12:15.120
through one of these steps then

0:12:12.959,0:12:17.040
your you'll have some kind of

0:12:15.120,0:12:18.320
non-linearity which will mean

0:12:17.040,0:12:19.839
that the effective words in the past

0:12:18.320,0:12:22.000
will kind of get exponentially smaller

0:12:19.839,0:12:25.600
each time step

0:12:22.000,0:12:27.120
that means that once you have uh

0:12:25.600,0:12:28.560
no gradient for a particular word in the

0:12:27.120,0:12:29.600
past it's very hard to actually suddenly

0:12:28.560,0:12:32.639
learn later on

0:12:29.600,0:12:32.639
that word was impossible

0:12:32.959,0:12:37.680
um one final issue i want to mention

0:12:35.760,0:12:41.920
with

0:12:37.680,0:12:44.880
iron ends is they're actually quite slow

0:12:41.920,0:12:47.120
um the reason for this is particularly

0:12:44.880,0:12:47.120
training

0:12:47.600,0:12:53.519
um so the reason is that in order to

0:12:51.279,0:12:54.959
like um

0:12:53.519,0:12:56.720
build your state for a particular work

0:12:54.959,0:12:58.959
you actually have to

0:12:56.720,0:13:00.880
build your state for every previous word

0:12:58.959,0:13:02.399
first

0:13:00.880,0:13:04.720
let me essentially have a big for loop

0:13:02.399,0:13:07.440
that's going over your entire document

0:13:04.720,0:13:09.120
and the longer your document is the

0:13:07.440,0:13:10.480
bigger the full loop is

0:13:09.120,0:13:11.920
and it means you most of these

0:13:10.480,0:13:13.040
operations you can't actually confuse in

0:13:11.920,0:13:15.839
parallel you actually

0:13:13.040,0:13:17.680
have to do it sequentially and one gpu

0:13:15.839,0:13:18.880
hardware is

0:13:17.680,0:13:21.200
really based around being able to do

0:13:18.880,0:13:25.200
operations in parallel

0:13:21.200,0:13:25.200
um okay

0:13:25.839,0:13:28.880
so the convolutional network didn't have

0:13:27.519,0:13:29.839
this problem it's everything's in

0:13:28.880,0:13:32.639
parallel but

0:13:29.839,0:13:34.000
on the other hand you get a boundary

0:13:32.639,0:13:38.480
receptor field

0:13:34.000,0:13:40.959
and the recurrent models you have

0:13:38.480,0:13:42.000
in principle an infinite amount of

0:13:40.959,0:13:45.519
receptor field

0:13:42.000,0:13:45.519
but it's quite slow to train

0:13:45.920,0:13:49.440
so the solution to this is now what's

0:13:47.839,0:13:51.360
called the transformer

0:13:49.440,0:13:54.399
um which is the model that's used in old

0:13:51.360,0:13:57.279
state nlp systems these days

0:13:54.399,0:13:58.560
um so i'm going to go through

0:13:57.279,0:13:59.279
transformer in quite a lot more detail

0:13:58.560,0:14:02.639
when i did

0:13:59.279,0:14:05.440
the rnns or cnns

0:14:02.639,0:14:07.120
um transformers were introduced in 2017

0:14:05.440,0:14:09.360
by issues of swearing

0:14:07.120,0:14:11.519
and famous paper called attention is all

0:14:09.360,0:14:13.360
you need

0:14:11.519,0:14:15.760
and they really revolutionize lots of

0:14:13.360,0:14:19.199
energy

0:14:15.760,0:14:22.880
so i included a figure here from the

0:14:19.199,0:14:22.880
original transformer paper um

0:14:22.959,0:14:25.440
i know i'm confusing this to you

0:14:24.240,0:14:26.959
certainly when i first saw this figure

0:14:25.440,0:14:28.320
in 2017

0:14:26.959,0:14:30.079
it took me quite a while to get my head

0:14:28.320,0:14:31.360
around it and there's

0:14:30.079,0:14:33.120
quite a lot of details going on in these

0:14:31.360,0:14:36.720
boxes so i'm going to

0:14:33.120,0:14:36.720
just try to slowly drill into them

0:14:38.000,0:14:41.440
all right so what's going on um

0:14:42.480,0:14:46.560
basically you see we have this input

0:14:43.760,0:14:48.480
state this um

0:14:46.560,0:14:50.560
n times this transformer block and then

0:14:48.480,0:14:54.160
um an output phase

0:14:50.560,0:14:56.800
so this end times block thing just means

0:14:54.160,0:14:56.800
we're going to unroll

0:14:56.839,0:15:00.320
uh the same block with different

0:14:59.199,0:15:02.560
parameters

0:15:00.320,0:15:04.160
a certain number of times there so the

0:15:02.560,0:15:05.360
example has uh

0:15:04.160,0:15:06.959
six layers which i think had the

0:15:05.360,0:15:08.639
original transform paper which seems

0:15:06.959,0:15:10.639
quite cute these days

0:15:08.639,0:15:12.800
um these days people are training models

0:15:10.639,0:15:16.560
with billions of parameters and

0:15:12.800,0:15:16.560
uh many many dozens of layers

0:15:17.360,0:15:20.399
all right so i'm just going to drill

0:15:19.680,0:15:23.680
into this box

0:15:20.399,0:15:26.399
more detail so this can be the core of

0:15:23.680,0:15:28.639
the transformer the transformer block

0:15:26.399,0:15:29.930
you see it's actually incorporated two

0:15:28.639,0:15:31.040
different sub layers

0:15:29.930,0:15:35.759
[Music]

0:15:31.040,0:15:39.120
um which are both very important um

0:15:35.759,0:15:40.560
sub layer 2 is maybe the more

0:15:39.120,0:15:42.800
obvious one this is just a big

0:15:40.560,0:15:46.320
feedforward network

0:15:42.800,0:15:47.759
um it could be any mlp but it's

0:15:46.320,0:15:52.560
important it's actually quite

0:15:47.759,0:15:52.560
expressive um

0:15:52.839,0:15:56.000
and beneath we have this multi-headed

0:15:55.040,0:15:59.120
attention module

0:15:56.000,0:16:00.639
the multi-head attention is kind of the

0:15:59.120,0:16:03.279
key building block behind transformers

0:16:00.639,0:16:06.320
and why they work

0:16:03.279,0:16:08.000
um so

0:16:06.320,0:16:10.800
this subway is also connected by these

0:16:08.000,0:16:13.360
um boxes labeled adam norm

0:16:10.800,0:16:15.199
so the add purchase means this is a

0:16:13.360,0:16:17.839
residual connection

0:16:15.199,0:16:19.440
um which helps stopping the gradients

0:16:17.839,0:16:21.360
foundation large models

0:16:19.440,0:16:23.360
uh the norm here means uh lay

0:16:21.360,0:16:24.959
normalization

0:16:23.360,0:16:26.480
i'm not going to let it know in detail

0:16:24.959,0:16:27.600
here but

0:16:26.480,0:16:29.759
it's actually very important to make

0:16:27.600,0:16:30.880
these models work and there's actually

0:16:29.759,0:16:32.800
some specialties about

0:16:30.880,0:16:35.040
how exactly you delay normalization that

0:16:32.800,0:16:37.680
makes a big difference in practice

0:16:35.040,0:16:38.399
uh hey excuse me i have a question sure

0:16:37.680,0:16:41.199
uh

0:16:38.399,0:16:43.120
so this isn't immediately clear but

0:16:41.199,0:16:45.279
could you talk a little bit more about

0:16:43.120,0:16:47.040
just the intuition behind using

0:16:45.279,0:16:48.240
multi-headed attention as opposed to a

0:16:47.040,0:16:50.720
single head

0:16:48.240,0:16:51.680
i mean presumably each head learns

0:16:50.720,0:16:53.839
something different

0:16:51.680,0:16:54.959
and attends over its input differently

0:16:53.839,0:16:56.639
but

0:16:54.959,0:16:58.160
what's what was sort of the intuition

0:16:56.639,0:17:00.399
behind that

0:16:58.160,0:17:01.279
um i'll ask that question a bit i'm

0:17:00.399,0:17:02.959
going to go through

0:17:01.279,0:17:04.880
uh exactly what military detention is a

0:17:02.959,0:17:06.640
bit first and then i'll try and get some

0:17:04.880,0:17:07.760
iterations as to why this is a good

0:17:06.640,0:17:09.280
thing to do

0:17:07.760,0:17:11.280
uh if we don't answer your question then

0:17:09.280,0:17:13.520
please

0:17:11.280,0:17:15.679
follow me up in a few slides time thank

0:17:13.520,0:17:15.679
you

0:17:16.880,0:17:20.559
any other questions at this stage by the

0:17:18.400,0:17:20.559
way

0:17:21.520,0:17:28.319
uh i have a question uh used that the

0:17:24.959,0:17:31.679
the transformer module uses layer

0:17:28.319,0:17:33.280
normalization uh why can you provide

0:17:31.679,0:17:34.080
some intuition into why that works

0:17:33.280,0:17:38.559
better than

0:17:34.080,0:17:38.559
group normalization or uh normalization

0:17:40.480,0:17:42.880
um

0:17:43.600,0:17:46.320
i don't think i can actually give a very

0:17:44.960,0:17:48.160
satisfying technical answer to this and

0:17:46.320,0:17:49.600
i think a lot of this is quite empirical

0:17:48.160,0:17:52.480
as to why

0:17:49.600,0:17:55.280
in nlp we learn on works great and

0:17:52.480,0:17:58.720
computer vision bachelor works great

0:17:55.280,0:18:00.320
um a nice prosperous land on

0:17:58.720,0:18:02.559
is that it doesn't depend on the batch

0:18:00.320,0:18:05.679
dimension uh which

0:18:02.559,0:18:05.679
factional does so

0:18:06.080,0:18:11.200
uh in practice that's quite a big

0:18:08.480,0:18:12.480
advantage because

0:18:11.200,0:18:16.880
it's quite hard to train with large

0:18:12.480,0:18:16.880
batches with them very large models

0:18:19.520,0:18:23.760
yeah you can see people written lots of

0:18:22.160,0:18:27.440
papers and actually why things like that

0:18:23.760,0:18:27.440
even work for computer version i think

0:18:27.679,0:18:30.640
at least less how i read it's there's

0:18:29.280,0:18:31.280
still some debate as to actually what

0:18:30.640,0:18:33.520
it's doing

0:18:31.280,0:18:35.039
um maybe the intuition is the original

0:18:33.520,0:18:35.840
paperwork even batch normal works are

0:18:35.039,0:18:39.039
not great

0:18:35.840,0:18:40.559
um so personally i would say

0:18:39.039,0:18:42.240
this is one of the slightly unsatisfying

0:18:40.559,0:18:44.240
things in deep learning where

0:18:42.240,0:18:46.400
it works but it's a little bit unclear

0:18:44.240,0:18:46.400
why

0:18:47.760,0:18:57.840
okay thank you yeah maybe i was waiting

0:18:49.760,0:18:57.840
with a more satisfying answer than that

0:18:57.940,0:19:01.600
[Music]

0:18:59.760,0:19:03.280
another question is coming here is do

0:19:01.600,0:19:06.559
transformers share weights across

0:19:03.280,0:19:07.760
time steps like rnn lstms

0:19:06.559,0:19:09.760
uh yeah great question i should have

0:19:07.760,0:19:11.200
made that clear um yeah so

0:19:09.760,0:19:13.760
all these ways can be shared across

0:19:11.200,0:19:15.360
timestamps um

0:19:13.760,0:19:17.039
so it's kind of convolutional in that

0:19:15.360,0:19:18.640
sense um

0:19:17.039,0:19:20.160
so you have one block and you'll play it

0:19:18.640,0:19:22.000
every time step

0:19:20.160,0:19:23.039
uh you can actually also apply them use

0:19:22.000,0:19:24.160
the same weights and every layer and

0:19:23.039,0:19:28.080
that works quite well too

0:19:24.160,0:19:28.080
but it's not what people normally do

0:19:30.400,0:19:32.799
thank you

0:19:33.679,0:19:36.880
any other questions so far

0:19:36.960,0:19:41.840
i think those were the questions i read

0:19:39.440,0:19:46.000
so far on the chat

0:19:41.840,0:19:47.520
okay so uh what is this mysterious

0:19:46.000,0:19:50.400
multi-headed attention thing

0:19:47.520,0:19:53.840
um so here's another figure i don't know

0:19:50.400,0:19:53.840
if this helps um

0:19:54.320,0:20:01.039
uh so basically you can

0:19:57.840,0:20:04.159
compute these three quantities called um

0:20:01.039,0:20:05.440
b k and q here they stand for a query

0:20:04.159,0:20:09.039
key in value

0:20:05.440,0:20:10.559
respectively um

0:20:09.039,0:20:12.000
do the scale dot product detention

0:20:10.559,0:20:13.760
operation and then concatenate the

0:20:12.000,0:20:15.520
outputs

0:20:13.760,0:20:17.120
all right so drilling into this scale

0:20:15.520,0:20:19.520
dot product tension um

0:20:17.120,0:20:20.880
eventually we will run our boxes to

0:20:19.520,0:20:25.520
expand

0:20:20.880,0:20:25.520
um it looks something like this um

0:20:28.080,0:20:31.679
so we're going to do compute this query

0:20:30.400,0:20:34.720
and key

0:20:31.679,0:20:35.600
do a dot products and stuff max and use

0:20:34.720,0:20:38.000
this

0:20:35.600,0:20:39.840
as a way to some of the values i don't

0:20:38.000,0:20:43.200
worry that it makes sense i will

0:20:39.840,0:20:45.039
do more detail so let's look at this

0:20:43.200,0:20:47.200
example um

0:20:45.039,0:20:48.480
where the context here is let's say

0:20:47.200,0:20:49.760
these horns silver whites

0:20:48.480,0:20:52.480
and we're trying to create the next word

0:20:49.760,0:20:54.880
which in the example before was uh

0:20:52.480,0:20:58.559
unicorn

0:20:54.880,0:20:58.559
so um

0:20:58.799,0:21:01.840
for the word we're trying to predict

0:21:00.000,0:21:03.760
we're going to like compute this value

0:21:01.840,0:21:05.440
called the query

0:21:03.760,0:21:06.960
and for all the previous words we're

0:21:05.440,0:21:09.039
going to

0:21:06.960,0:21:10.880
compute the quantity called the key and

0:21:09.039,0:21:14.159
these are linear layers based on the

0:21:10.880,0:21:14.159
current states of this layer

0:21:14.559,0:21:18.240
um tomorrow we're going to be coding

0:21:16.480,0:21:19.039
this in in practice so we're going to be

0:21:18.240,0:21:21.760
seeing this

0:21:19.039,0:21:24.640
in like only the small details in the in

0:21:21.760,0:21:24.640
the code as well

0:21:24.720,0:21:31.919
okay so

0:21:28.559,0:21:34.400
um you can think of this query as the

0:21:31.919,0:21:35.840
model asking a question over here it's

0:21:34.400,0:21:39.200
context so far but it's going to help

0:21:35.840,0:21:39.200
you predict what the next word should be

0:21:39.520,0:21:43.760
so the query could be something like um

0:21:42.000,0:21:44.000
tell me what previous adjective is or

0:21:43.760,0:21:47.840
tell

0:21:44.000,0:21:51.600
me what the uh previous determiner is

0:21:47.840,0:21:55.280
um and

0:21:51.600,0:21:55.280
a disabler's word like these here

0:21:55.840,0:21:58.880
and then for the keys they're going to

0:21:57.919,0:22:00.880
be things that sort of

0:21:58.880,0:22:02.000
label the current word with telling you

0:22:00.880,0:22:02.880
some information about it so they could

0:22:02.000,0:22:04.640
be saying

0:22:02.880,0:22:06.159
this word is an adjective this word is a

0:22:04.640,0:22:08.880
determiner

0:22:06.159,0:22:10.240
this word is a verb something like that

0:22:08.880,0:22:12.320
or can be something more complex like it

0:22:10.240,0:22:14.320
could be like a

0:22:12.320,0:22:16.640
any true relation like co-reference or

0:22:14.320,0:22:16.640
something

0:22:17.039,0:22:22.559
so well completely as a

0:22:20.240,0:22:24.000
questions query and then it's going to

0:22:22.559,0:22:25.600
compute

0:22:24.000,0:22:27.919
just do a dot product with all of the

0:22:25.600,0:22:30.720
keys and use this to compute

0:22:27.919,0:22:32.000
and then you do softmax as well and this

0:22:30.720,0:22:33.840
is going to

0:22:32.000,0:22:36.559
induce a distribution over all the

0:22:33.840,0:22:36.559
previous words

0:22:36.799,0:22:40.000
so here you can imagine a query

0:22:39.200,0:22:43.039
something like telling me what

0:22:40.000,0:22:44.400
previous adjective is and the

0:22:43.039,0:22:46.159
attention will produce this kind of

0:22:44.400,0:22:47.760
distribution over

0:22:46.159,0:22:50.159
these three previous words it's going to

0:22:47.760,0:22:54.000
put most probability mass on either horn

0:22:50.159,0:22:56.320
or silver white

0:22:54.000,0:22:56.320
um

0:22:57.600,0:23:00.559
we're also going to compute this other

0:22:58.880,0:23:02.080
value this is the quantity called the

0:23:00.559,0:23:03.280
value

0:23:02.080,0:23:05.440
and we'll do that for all the previous

0:23:03.280,0:23:06.640
words as well

0:23:05.440,0:23:07.600
and maybe the value will tell you

0:23:06.640,0:23:10.640
something slightly more about what the

0:23:07.600,0:23:10.640
contents of the word is

0:23:11.919,0:23:16.000
and then i'm going to compute this

0:23:13.840,0:23:16.960
hidden state by basically marginalizing

0:23:16.000,0:23:20.240
out the

0:23:16.960,0:23:23.200
attention distribution so here this

0:23:20.240,0:23:24.320
hidden state is going to be a wasted sum

0:23:23.200,0:23:25.760
of the values

0:23:24.320,0:23:28.080
of all the previous words that's going

0:23:25.760,0:23:28.080
to be

0:23:28.320,0:23:31.840
wasted by the probability of that word

0:23:34.320,0:23:37.840
um so

0:23:38.320,0:23:41.919
that's basically what's going on the

0:23:39.360,0:23:43.840
left side of this figure here

0:23:41.919,0:23:45.200
i left out this detail about the scaling

0:23:43.840,0:23:48.320
escape that's just a

0:23:45.200,0:23:51.279
hack to make the gradients more stable

0:23:48.320,0:23:53.919
okay um but there's another detail here

0:23:51.279,0:23:56.240
which is that

0:23:53.919,0:23:58.720
uh that's kind of single-headed

0:23:56.240,0:23:59.520
attention i've described so far but

0:23:58.720,0:24:01.279
we're actually gonna do this thing

0:23:59.520,0:24:02.840
called multi-headed intention and that

0:24:01.279,0:24:05.520
basically just means we're gonna

0:24:02.840,0:24:07.039
compute the same thing with different

0:24:05.520,0:24:10.480
queries keys and values

0:24:07.039,0:24:10.480
multiple times in parallel

0:24:10.799,0:24:15.120
so this question before about like what

0:24:12.880,0:24:18.559
the intuition behind that is

0:24:15.120,0:24:19.520
um and really it's like you actually

0:24:18.559,0:24:20.640
want

0:24:19.520,0:24:22.559
let's create the next word you need to

0:24:20.640,0:24:24.400
know a lot of different things so just

0:24:22.559,0:24:26.640
this example before

0:24:24.400,0:24:26.640
um

0:24:28.000,0:24:32.640
uh let's see so let's say the next word

0:24:29.840,0:24:36.080
here should be unicorns plural

0:24:32.640,0:24:38.080
um today it should be unicorns i mean

0:24:36.080,0:24:39.760
you probably want to know both that it's

0:24:38.080,0:24:41.679
horned and silver white because

0:24:39.760,0:24:43.200
uh the conjunction of those makes it

0:24:41.679,0:24:45.279
more likely to be unicorn

0:24:43.200,0:24:46.960
but you also want to know that the uh

0:24:45.279,0:24:49.279
the determinant here was these

0:24:46.960,0:24:50.159
not a if it was like a horn syllable

0:24:49.279,0:24:52.799
white it'd be

0:24:50.159,0:24:54.559
unicorn singular the fact is these means

0:24:52.799,0:24:57.200
it should be unicorn plural so you can

0:24:54.559,0:24:59.120
plural agreements

0:24:57.200,0:25:00.880
so you actually need to like look at all

0:24:59.120,0:25:02.000
these three words at once to have a good

0:25:00.880,0:25:03.679
idea

0:25:02.000,0:25:05.360
what the next word should be a

0:25:03.679,0:25:06.960
multi-intention is a way of like letting

0:25:05.360,0:25:10.000
each word look at multiple previous

0:25:06.960,0:25:10.000
words simultaneously

0:25:10.720,0:25:16.480
a question here is why are we actually

0:25:12.960,0:25:19.840
uh in need of using the softmax

0:25:16.480,0:25:19.840
why do we use this yeah

0:25:20.880,0:25:24.000
it's a good question um

0:25:25.600,0:25:31.760
i think

0:25:29.520,0:25:33.919
firstly i mean housing on normalization

0:25:31.760,0:25:35.120
effect is probably good i mean

0:25:33.919,0:25:38.640
otherwise when you go to longer

0:25:35.120,0:25:40.240
sequences this uh

0:25:38.640,0:25:41.600
summation would get kind of bigger and

0:25:40.240,0:25:43.760
bigger the further you went through so

0:25:41.600,0:25:45.360
having a normalization

0:25:43.760,0:25:47.919
is probably good the normalization also

0:25:45.360,0:25:50.000
kind of lets the model um

0:25:47.919,0:25:52.000
discard information to you so it can say

0:25:50.000,0:25:56.080
this word

0:25:52.000,0:25:58.080
just isn't relevant um

0:25:56.080,0:25:59.360
which is good i think i have seen people

0:25:58.080,0:26:00.159
experiment with using things like really

0:25:59.360,0:26:02.880
use instead

0:26:00.159,0:26:04.559
so which kind of different different way

0:26:02.880,0:26:08.799
of discarding information but

0:26:04.559,0:26:11.840
i think the evidence is soft matches

0:26:08.799,0:26:11.840
work very best

0:26:14.240,0:26:17.840
uh another question sorry i may have

0:26:16.159,0:26:21.840
missed this um

0:26:17.840,0:26:24.960
the mask there in pink don't know what

0:26:21.840,0:26:26.320
that is briefly right mask is actually

0:26:24.960,0:26:28.480
important um

0:26:26.320,0:26:28.480
so

0:26:29.520,0:26:33.919
i'm going to say make a point first um

0:26:32.240,0:26:34.960
so one of the really big wins about this

0:26:33.919,0:26:37.200
whole

0:26:34.960,0:26:38.159
session of multi-headed attention is

0:26:37.200,0:26:41.520
that it's

0:26:38.159,0:26:43.200
extremely paralyzable um so now this

0:26:41.520,0:26:45.200
computation of queries keys and values a

0:26:43.200,0:26:46.240
given time step depends on

0:26:45.200,0:26:48.880
what you're doing at any of the other

0:26:46.240,0:26:50.320
time steps so

0:26:48.880,0:26:51.679
unlike your current network you can

0:26:50.320,0:26:54.559
actually compute all of these

0:26:51.679,0:26:54.559
simultaneously

0:26:54.799,0:26:59.440
um which plays very well with um the

0:26:57.200,0:27:00.720
kind of hardware we have these days

0:26:59.440,0:27:01.760
so not only are we going to put all the

0:27:00.720,0:27:03.440
different heads at once we're going to

0:27:01.760,0:27:03.840
compute all the time steps at once in a

0:27:03.440,0:27:08.400
single

0:27:03.840,0:27:12.000
forward pass um

0:27:08.400,0:27:13.200
so that's great except that

0:27:12.000,0:27:14.960
if you're competing all the time steps

0:27:13.200,0:27:17.039
at once there's nothing to actually stop

0:27:14.960,0:27:20.480
you

0:27:17.039,0:27:23.200
um words looking

0:27:20.480,0:27:24.559
at the future since like ultra

0:27:23.200,0:27:26.559
regressive factorization we're dealing

0:27:24.559,0:27:28.159
with here then

0:27:26.559,0:27:30.640
we only want words conditioned on

0:27:28.159,0:27:33.919
previous words

0:27:30.640,0:27:35.520
um but as i've spread them all so far

0:27:33.919,0:27:36.480
the words could look at future words too

0:27:35.520,0:27:38.240
which is

0:27:36.480,0:27:40.159
the problem because then they can cheat

0:27:38.240,0:27:42.880
and use themselves on future context to

0:27:40.159,0:27:46.320
predict themselves

0:27:42.880,0:27:48.799
so the solutions that here is um

0:27:46.320,0:27:51.360
uh so it's what we call cell potential

0:27:48.799,0:27:54.480
masking so a mask is just a

0:27:51.360,0:27:56.159
upper triangular matrix that sort of uh

0:27:54.480,0:27:58.960
has zeros and lower triangle and like

0:27:56.159,0:28:01.200
negative infinity in the upper triangle

0:27:58.960,0:28:02.799
and we're going to just add this to the

0:28:01.200,0:28:03.919
attention scores

0:28:02.799,0:28:06.880
and the effect of that is going to be

0:28:03.919,0:28:08.640
that um every word to the left has a

0:28:06.880,0:28:10.000
much higher potential score than

0:28:08.640,0:28:12.640
everywhere to the right so the model

0:28:10.000,0:28:14.880
will only end up practicing using words

0:28:12.640,0:28:17.600
to the left but this is deterministic

0:28:14.880,0:28:20.240
mask without trainable weights

0:28:17.600,0:28:21.600
um just values either zero or negative

0:28:20.240,0:28:24.559
infinity

0:28:21.600,0:28:26.000
uh so you'd only mask in case of an

0:28:24.559,0:28:28.000
application specific

0:28:26.000,0:28:29.840
training task correct if you had to just

0:28:28.000,0:28:31.120
build representations for example you

0:28:29.840,0:28:32.000
wouldn't need to ask because it wouldn't

0:28:31.120,0:28:33.840
matter

0:28:32.000,0:28:35.279
uh yeah that's a great question and so

0:28:33.840,0:28:37.039
we'll go to more general representation

0:28:35.279,0:28:40.000
learning later so

0:28:37.039,0:28:41.679
uh most where you just want a text

0:28:40.000,0:28:43.200
encoder you don't need to mask them

0:28:41.679,0:28:45.360
bidirectional context is absolutely

0:28:43.200,0:28:46.720
helpful um

0:28:45.360,0:28:48.799
in this case language modeling which

0:28:46.720,0:28:50.720
we're working through so far then

0:28:48.799,0:28:52.720
the mask is sort of crucial to make them

0:28:50.720,0:28:53.039
all mathematically correct and compute

0:28:52.720,0:28:54.960
the

0:28:53.039,0:28:59.840
correct factorization but yeah great

0:28:54.960,0:28:59.840
question thanks

0:29:03.120,0:29:06.720
okay um

0:29:07.440,0:29:12.720
okay so uh one other detail we need to

0:29:11.440,0:29:15.840
do to make all this work

0:29:12.720,0:29:17.760
is add something

0:29:15.840,0:29:20.000
should be input over positional writing

0:29:17.760,0:29:20.000
so

0:29:20.559,0:29:24.320
as i describe small so far it's actually

0:29:25.360,0:29:29.919
um it's doing a low bias model it knows

0:29:28.559,0:29:31.679
very little about language the inputs

0:29:29.919,0:29:36.080
could be anything and

0:29:31.679,0:29:36.080
it would work so um

0:29:37.440,0:29:40.399
in particular it's like i mean you can

0:29:38.799,0:29:40.799
model a set or a graph or anything like

0:29:40.399,0:29:45.039
this

0:29:40.799,0:29:45.039
it should be fine um but we know

0:29:45.279,0:29:47.840
i mean in language there are some

0:29:46.640,0:29:49.440
properties which are useful like for

0:29:47.840,0:29:52.159
example

0:29:49.440,0:29:53.760
um there's an ordering to words which is

0:29:52.159,0:29:55.840
really important to how you interpret

0:29:53.760,0:29:55.840
them

0:29:55.919,0:29:58.559
and this one doesn't actually know

0:29:57.360,0:30:00.000
anything about that and that's in

0:29:58.559,0:30:01.360
contrast to the convolutional worlds and

0:30:00.000,0:30:02.240
the parameters i showed you earlier

0:30:01.360,0:30:05.279
which

0:30:02.240,0:30:08.559
both have different ways of encoding the

0:30:05.279,0:30:10.159
order of text

0:30:08.559,0:30:12.880
um so one of the techniques that was

0:30:10.159,0:30:15.679
introduced in this paper was

0:30:12.880,0:30:17.039
called positional writing um the

0:30:15.679,0:30:18.240
different ways you can do this

0:30:17.039,0:30:19.760
they describe something in the paper

0:30:18.240,0:30:20.640
which is slightly weird actually i'm not

0:30:19.760,0:30:25.840
going to describe

0:30:20.640,0:30:25.840
but it works just as well to essentially

0:30:26.000,0:30:30.159
learn separate embedding for every time

0:30:27.440,0:30:31.919
step so for every positioning document

0:30:30.159,0:30:33.279
zero one two three four five

0:30:31.919,0:30:35.760
you just learn separate embedding and

0:30:33.279,0:30:37.200
then you add this to your input

0:30:35.760,0:30:39.520
so your input now is a summation of the

0:30:37.200,0:30:41.919
word vector and some kind of positional

0:30:39.520,0:30:41.919
vector

0:30:42.799,0:30:46.080
and it's very simple but it gives the

0:30:44.720,0:30:46.880
world kind of the order information it

0:30:46.080,0:30:51.200
needs and it

0:30:46.880,0:30:54.399
works great

0:30:51.200,0:30:57.600
okay so why are these models so good why

0:30:54.399,0:30:57.600
does everyone use them um

0:30:58.559,0:31:01.840
i think the really powerful thing about

0:31:00.880,0:31:03.200
the model is that

0:31:01.840,0:31:06.320
it kind of gives you direct connections

0:31:03.200,0:31:09.039
between every pair of words

0:31:06.320,0:31:11.440
so each word can can directly access the

0:31:09.039,0:31:14.960
hidden state of every previous word

0:31:11.440,0:31:14.960
um and

0:31:16.000,0:31:19.840
that's a contrast convolutional model

0:31:18.399,0:31:21.519
could maybe against the state of all the

0:31:19.840,0:31:23.840
words in this receptor field but nothing

0:31:21.519,0:31:27.120
further back in time than that

0:31:23.840,0:31:28.000
and our current model um

0:31:27.120,0:31:29.840
the state had to go through his

0:31:28.000,0:31:32.720
bottleneck of each time at each time

0:31:29.840,0:31:34.640
step so

0:31:32.720,0:31:36.480
um you can actually directly access the

0:31:34.640,0:31:38.159
previous words

0:31:36.480,0:31:39.600
beyond the like literally one previous

0:31:38.159,0:31:41.200
word anything further than the past

0:31:39.600,0:31:43.760
matter had to get somehow compressed and

0:31:41.200,0:31:45.279
you have lost information about this

0:31:43.760,0:31:47.279
for self attention you can in principle

0:31:45.279,0:31:50.399
put 100 attention on

0:31:47.279,0:31:52.480
any word in the distant past and see

0:31:50.399,0:31:54.240
exactly what was there

0:31:52.480,0:31:57.120
and this just makes it a really powerful

0:31:54.240,0:32:00.159
model it like avoids things like uh

0:31:57.120,0:32:02.960
issues like vanishing gradients

0:32:00.159,0:32:02.960
quite effectively

0:32:04.159,0:32:09.039
um and music can just learn very

0:32:05.679,0:32:09.039
expensive functions very easily

0:32:09.279,0:32:13.039
the other great thing about this is how

0:32:10.880,0:32:14.640
paralyzable it is i mean

0:32:13.039,0:32:17.440
so the one hand this model's doing quite

0:32:14.640,0:32:21.279
a lot of computation in that it's doing

0:32:17.440,0:32:22.159
uh this um so the self-tension operation

0:32:21.279,0:32:24.000
is quadratic

0:32:22.159,0:32:26.000
basically because every word can look at

0:32:24.000,0:32:28.240
every other word

0:32:26.000,0:32:29.279
and that sounds quite slow but the

0:32:28.240,0:32:30.080
really nice thing is you can do it in

0:32:29.279,0:32:31.600
parallel so

0:32:30.080,0:32:33.600
because all these operations are

0:32:31.600,0:32:36.799
independent to each other you just do it

0:32:33.600,0:32:38.720
as one big matrix multiplication so

0:32:36.799,0:32:40.159
even though sometimes you probably do

0:32:38.720,0:32:42.320
kind of more

0:32:40.159,0:32:43.840
add multiply operations and you would do

0:32:42.320,0:32:45.840
with the equivalent rnn

0:32:43.840,0:32:47.360
you can do all these operations um much

0:32:45.840,0:32:48.799
faster because you do them all at once

0:32:47.360,0:32:52.080
rather sequentially

0:32:48.799,0:32:52.080
so this is a really good trade-off

0:32:53.440,0:32:59.440
um i also want to quickly talk about

0:32:56.399,0:33:02.799
some other things that's great

0:32:59.440,0:33:04.320
the stuff like um multi-headed attention

0:33:02.799,0:33:05.360
and additional embeddings and stuff so

0:33:04.320,0:33:07.279
i've got all the attention

0:33:05.360,0:33:08.480
when transformers were first released

0:33:07.279,0:33:09.919
but transformers

0:33:08.480,0:33:11.440
also came along with a whole bag of

0:33:09.919,0:33:13.840
other tricks as well and these tricks

0:33:11.440,0:33:15.840
were all

0:33:13.840,0:33:17.840
actually really important to make this

0:33:15.840,0:33:20.720
stuff work

0:33:17.840,0:33:22.960
um and sometimes this paper really kind

0:33:20.720,0:33:24.480
of modernized and healthy i think

0:33:22.960,0:33:26.640
um so for example i've mentioned about

0:33:24.480,0:33:29.760
this useful layer normalization before

0:33:26.640,0:33:33.039
the light on it's really helpful

0:33:29.760,0:33:34.080
um they also have doing these things

0:33:33.039,0:33:37.360
like um

0:33:34.080,0:33:38.720
these learning rate schedules so uh for

0:33:37.360,0:33:39.679
whatever reason to make transformers

0:33:38.720,0:33:42.480
work well

0:33:39.679,0:33:44.399
uh you have to sort of linearly warm up

0:33:42.480,0:33:47.360
your learning rate from

0:33:44.399,0:33:48.799
some from zero to your goal learning

0:33:47.360,0:33:52.480
rate over

0:33:48.799,0:33:56.159
several thousand steps um

0:33:52.480,0:33:57.600
and people do do warm learning rates

0:33:56.159,0:33:59.440
warm-up learning rates in other settings

0:33:57.600,0:34:01.279
but transformers really really need this

0:33:59.440,0:34:03.919
to work

0:34:01.279,0:34:04.960
um also the things that the

0:34:03.919,0:34:06.720
initialization

0:34:04.960,0:34:09.119
actually really do matter with these and

0:34:06.720,0:34:11.119
some initializations don't work

0:34:09.119,0:34:13.040
um and they're throwing these other

0:34:11.119,0:34:15.679
tricks like a label smoothing at the

0:34:13.040,0:34:15.679
output which

0:34:15.760,0:34:18.879
uh again wasn't invented in this paper

0:34:17.520,0:34:20.639
but it turns out

0:34:18.879,0:34:23.200
quite helpful for the cast like machine

0:34:20.639,0:34:23.200
translation

0:34:23.679,0:34:29.280
all right um so to

0:34:27.359,0:34:30.879
give you some idea how well these things

0:34:29.280,0:34:34.000
are working these models described so

0:34:30.879,0:34:36.399
far um

0:34:34.000,0:34:38.560
are some results on a lime dwelling deck

0:34:36.399,0:34:40.639
benchmark um

0:34:38.560,0:34:44.240
so the number on the right is what's

0:34:40.639,0:34:44.240
called complexity which is a

0:34:44.560,0:34:48.960
measure of the likelihood of held out

0:34:45.839,0:34:52.240
data and here lower is better

0:34:48.960,0:34:54.800
um so let's see you see that an lcm for

0:34:52.240,0:34:58.879
2016 gets complexity of

0:34:54.800,0:34:58.879
uh 48 um

0:34:59.040,0:35:02.560
you see that yandere fans convolutional

0:35:00.640,0:35:04.880
models uh from

0:35:02.560,0:35:07.440
2016 uh doing quite a bit better at

0:35:04.880,0:35:09.760
about 20 about 37.

0:35:07.440,0:35:10.880
uh also people played around with a

0:35:09.760,0:35:13.599
whole bunch of

0:35:10.880,0:35:14.560
r m runes like you speak dozens of

0:35:13.599,0:35:16.960
papers on how you make

0:35:14.560,0:35:19.200
variations in lstms and some of these

0:35:16.960,0:35:20.640
getting low 30s as well

0:35:19.200,0:35:22.640
but then when you introduce transformers

0:35:20.640,0:35:26.720
you get a really big jump down to

0:35:22.640,0:35:28.880
go to 18 and 20.

0:35:26.720,0:35:32.640
and in terms of language modeling that's

0:35:28.880,0:35:32.640
a really enormous geometry performance

0:35:35.359,0:35:38.640
um i should say these games we saw were

0:35:37.520,0:35:41.599
particularly

0:35:38.640,0:35:43.200
large on uh kind of long context

0:35:41.599,0:35:45.200
language modelling so blinds modeling

0:35:43.200,0:35:46.240
where

0:35:45.200,0:35:48.160
so there's some benchmarks where you

0:35:46.240,0:35:49.680
just get a single sentence to predict uh

0:35:48.160,0:35:52.000
on this task you actually get a whole

0:35:49.680,0:35:54.960
wikipedia article so

0:35:52.000,0:35:55.280
uh potentially thousands of words and

0:35:54.960,0:35:56.640
the

0:35:55.280,0:35:58.079
transformers really shine on this what

0:35:56.640,0:36:00.400
you've got thousands of words context

0:35:58.079,0:36:04.079
model and you need to

0:36:00.400,0:36:04.079
retain information across all of them

0:36:06.880,0:36:13.839
okay um

0:36:15.359,0:36:19.760
uh yeah serious quick comparison just to

0:36:17.920,0:36:20.720
visualize how transformers and lstms

0:36:19.760,0:36:22.160
look

0:36:20.720,0:36:24.240
which it's going to indicate some points

0:36:22.160,0:36:25.440
of shame before so in the lstm

0:36:24.240,0:36:26.800
you have a lot fewer connections between

0:36:25.440,0:36:28.560
the words like everything's kind of very

0:36:26.800,0:36:29.920
sequential left to right

0:36:28.560,0:36:32.320
and transform but you don't have any of

0:36:29.920,0:36:34.079
this um

0:36:32.320,0:36:35.760
so every word is directly connected to

0:36:34.079,0:36:39.040
every other word

0:36:35.760,0:36:42.240
um i guess you should say as well

0:36:39.040,0:36:44.000
in some senses maybe slightly unnatural

0:36:42.240,0:36:46.560
well for reading so it kind of suggests

0:36:44.000,0:36:48.000
that however as well as reading text and

0:36:46.560,0:36:49.119
every time it reads a word it goes and

0:36:48.000,0:36:53.040
really reads

0:36:49.119,0:36:56.880
every other word very quickly

0:36:53.040,0:36:56.880
um but it's very effective

0:36:57.680,0:37:00.720
okay one other good thing about

0:36:59.359,0:37:01.520
transformers is they do scale up

0:37:00.720,0:37:04.560
extremely well

0:37:01.520,0:37:05.839
so um with tasks like language modelling

0:37:04.560,0:37:06.960
you get essentially infinite amounts of

0:37:05.839,0:37:09.920
data because

0:37:06.960,0:37:11.280
it's just hundreds of billions of words

0:37:09.920,0:37:12.400
out there it's far more than you'd ever

0:37:11.280,0:37:16.320
need

0:37:12.400,0:37:17.680
uh that means to actually fit this kind

0:37:16.320,0:37:20.640
of distribution you need

0:37:17.680,0:37:21.440
very big models and you just keep on

0:37:20.640,0:37:23.200
adding transform

0:37:21.440,0:37:25.440
parameters transformers they keep on

0:37:23.200,0:37:26.880
just working better and better

0:37:25.440,0:37:28.880
uh the examples i showed you forward

0:37:26.880,0:37:30.800
from this gpt2 model with two billion

0:37:28.880,0:37:33.280
parameters which was

0:37:30.800,0:37:34.800
uh quite big for 2019 but apparently

0:37:33.280,0:37:37.920
2020 or up to

0:37:34.800,0:37:39.599
17 billion and there are rumors 100

0:37:37.920,0:37:40.079
billion parameter models will be coming

0:37:39.599,0:37:43.760
along

0:37:40.079,0:37:46.400
soon uh excuse me i have a question

0:37:43.760,0:37:47.440
uh you said transform is a really good

0:37:46.400,0:37:49.200
for scaling up

0:37:47.440,0:37:51.119
i was just wondering in a language

0:37:49.200,0:37:53.040
modeling task if we have like

0:37:51.119,0:37:54.320
say a ten thousand twenty thousand word

0:37:53.040,0:37:57.520
document in an

0:37:54.320,0:37:57.520
rnn we can just

0:37:57.599,0:38:01.200
insert a word step by step and we

0:37:59.680,0:38:04.400
wouldn't need

0:38:01.200,0:38:06.560
uh a lot of memory per se like

0:38:04.400,0:38:07.920
for for a transformer we need to have a

0:38:06.560,0:38:11.040
bath size of 10

0:38:07.920,0:38:12.720
000 wouldn't we like uh like the the

0:38:11.040,0:38:14.320
length of the sequence but if we have a

0:38:12.720,0:38:16.839
really long sequence

0:38:14.320,0:38:19.839
can we model these long term

0:38:16.839,0:38:19.839
dependencies

0:38:21.920,0:38:25.839
yeah that's a really great question um i

0:38:24.240,0:38:32.960
actually meant to mention this point

0:38:25.839,0:38:34.640
so um

0:38:32.960,0:38:36.240
two things they want to say so firstly

0:38:34.640,0:38:39.680
you're absolutely right the

0:38:36.240,0:38:42.000
self tension is because of quadratic

0:38:39.680,0:38:43.040
the expense obviously grows super

0:38:42.000,0:38:46.800
linearly and that

0:38:43.040,0:38:50.480
is a problem in practice it means

0:38:46.800,0:38:53.440
um so mostly

0:38:50.480,0:38:55.119
transformers do 512 token contacts

0:38:53.440,0:38:57.680
windows which is fairly affordable for

0:38:55.119,0:38:57.680
gpus

0:38:58.160,0:39:00.800
i love these language models to do more

0:38:59.520,0:39:01.520
than that let me bottle a few thousand

0:39:00.800,0:39:03.520
tokens

0:39:01.520,0:39:05.680
um which is kind of limits what we can

0:39:03.520,0:39:08.320
do um

0:39:05.680,0:39:10.079
but it's definitely the case that a

0:39:08.320,0:39:14.000
vanilla transformer can't model say

0:39:10.079,0:39:18.560
a 50 000 word book at all

0:39:14.000,0:39:20.079
um there it's like this whole

0:39:18.560,0:39:22.240
cartridge industry recently building

0:39:20.079,0:39:25.440
various transformers which

0:39:22.240,0:39:27.200
can do long sequences um it's very hot

0:39:25.440,0:39:29.520
topic right now

0:39:27.200,0:39:31.040
um there's most things you can do but

0:39:29.520,0:39:31.520
one kind of thing you do is like if you

0:39:31.040,0:39:34.240
replace

0:39:31.520,0:39:35.119
self tension with something like nearest

0:39:34.240,0:39:38.400
neighbor search

0:39:35.119,0:39:42.000
uh you can do the self attention

0:39:38.400,0:39:43.599
uh subway driving time and that makes it

0:39:42.000,0:39:45.920
faster

0:39:43.599,0:39:45.920
um

0:39:47.040,0:39:50.640
there are also versions that try to do

0:39:48.960,0:39:52.000
kind of sparse attention where like you

0:39:50.640,0:39:53.040
can't attend to every previous word

0:39:52.000,0:39:57.280
directly but

0:39:53.040,0:39:58.960
you kind of have some dilated

0:39:57.280,0:40:01.119
uh set of previous words you can look at

0:39:58.960,0:40:02.320
and you don't get quite a direct

0:40:01.119,0:40:03.760
connection to every word but you can

0:40:02.320,0:40:06.000
sort of guarantee that you have short

0:40:03.760,0:40:08.400
paths across every word

0:40:06.000,0:40:10.800
um there are also things like compressed

0:40:08.400,0:40:14.640
transformers we try to um

0:40:10.800,0:40:17.440
multiple night and total and to sort of

0:40:14.640,0:40:18.079
uh compress the pre little distant past

0:40:17.440,0:40:21.839
into

0:40:18.079,0:40:21.839
shorter representations um

0:40:21.920,0:40:26.560
okay so you brought up the question of

0:40:23.760,0:40:28.079
rnn so at impress time absolutely in our

0:40:26.560,0:40:30.160
nanky model

0:40:28.079,0:40:31.119
infinite context where there absolutely

0:40:30.160,0:40:33.359
no additional cost

0:40:31.119,0:40:34.720
which is great i mean they can't put

0:40:33.359,0:40:38.400
like a million words and output

0:40:34.720,0:40:40.160
really first just fine

0:40:38.400,0:40:43.839
um well the question is actually isn't

0:40:40.160,0:40:43.839
using this context and um

0:40:46.079,0:40:49.520
that's probably it's not so at training

0:40:47.920,0:40:51.040
time

0:40:49.520,0:40:52.319
um you can't do this the training time

0:40:51.040,0:40:52.960
you actually have to back propagate

0:40:52.319,0:40:54.160
through

0:40:52.960,0:40:56.640
what's what's called back relations

0:40:54.160,0:40:58.960
through time where the lcm would

0:40:56.640,0:40:58.960
um

0:41:00.160,0:41:03.599
have to give modern line contacts like

0:41:02.319,0:41:04.960
grading will have to propagate all the

0:41:03.599,0:41:07.599
way back through the

0:41:04.960,0:41:11.200
sort of all the recurrent steps to make

0:41:07.599,0:41:11.200
a difference to the distant past there

0:41:11.440,0:41:15.200
uh in practice firstly the grading will

0:41:13.280,0:41:18.839
vanish like

0:41:15.200,0:41:20.480
well before you hit a thousand steps and

0:41:18.839,0:41:23.040
also

0:41:20.480,0:41:24.880
this is very expensive so this is a

0:41:23.040,0:41:26.640
training time system for free

0:41:24.880,0:41:28.319
and this back propagation operation will

0:41:26.640,0:41:28.960
get more and more expensive the longer

0:41:28.319,0:41:31.680
sequences

0:41:28.960,0:41:34.480
you're modeling so that means you can't

0:41:31.680,0:41:36.240
actually really learn to

0:41:34.480,0:41:38.319
uh well this is the past even

0:41:36.240,0:41:38.960
interesting it's not expensive you just

0:41:38.319,0:41:41.280
wouldn't

0:41:38.960,0:41:42.560
know what to do with this any practices

0:41:41.280,0:41:44.319
you probably just forget it anyway

0:41:42.560,0:41:46.839
because the

0:41:44.319,0:41:48.960
uh you can't remember that much data

0:41:46.839,0:41:52.000
once

0:41:48.960,0:41:52.640
um all right one more quick point in

0:41:52.000,0:41:55.200
that um

0:41:52.640,0:41:56.160
this is interesting uh i guess one case

0:41:55.200,0:41:57.839
where they'll

0:41:56.160,0:42:00.720
where the rnas do have an advantage is

0:41:57.839,0:42:02.319
on certain algorithmic tests

0:42:00.720,0:42:03.760
um so if you aren't linked language

0:42:02.319,0:42:05.040
let's say you're i'm doing something

0:42:03.760,0:42:08.560
like

0:42:05.040,0:42:10.720
edition or trying to like model a parody

0:42:08.560,0:42:11.920
of a string um

0:42:10.720,0:42:13.520
[Music]

0:42:11.920,0:42:15.520
so if you use string of like zeros and

0:42:13.520,0:42:16.000
ones and ask you either an even number

0:42:15.520,0:42:20.880
of

0:42:16.000,0:42:22.400
ones or not um in those cases

0:42:20.880,0:42:24.000
um you basically do actually want to

0:42:22.400,0:42:25.599
apply literally the same operation every

0:42:24.000,0:42:27.920
time step

0:42:25.599,0:42:29.359
and you can you don't actually have to

0:42:27.920,0:42:30.720
have much memory because i mean

0:42:29.359,0:42:32.960
your state really just needs to be a

0:42:30.720,0:42:35.119
zero or one

0:42:32.960,0:42:36.319
in this case the uh the rnas actually do

0:42:35.119,0:42:37.839
work very well because you can train

0:42:36.319,0:42:38.640
them on short sequences and then they'll

0:42:37.839,0:42:40.079
shoot

0:42:38.640,0:42:41.440
like great generalizations or long

0:42:40.079,0:42:42.960
sequences all these kinds of toy

0:42:41.440,0:42:45.520
problems

0:42:42.960,0:42:46.960
and actually on tray but i imagine the

0:42:45.520,0:42:47.760
transformer would actually find it much

0:42:46.960,0:42:49.920
harder to get that kind of

0:42:47.760,0:42:51.280
generalization

0:42:49.920,0:42:53.520
uh that only really applies to these

0:42:51.280,0:42:58.240
kind of algorithmic problems in terms of

0:42:53.520,0:43:00.000
modeling natural language then uh

0:42:58.240,0:43:01.520
yeah it seems like various transformers

0:43:00.000,0:43:04.319
are going to be much more effective than

0:43:01.520,0:43:04.319
recurrent nets

0:43:04.560,0:43:08.240
thank you that was really helpful

0:43:08.560,0:43:14.000
um any other questions

0:43:12.400,0:43:15.920
i've been addressing the questions i

0:43:14.000,0:43:17.680
could uh via text

0:43:15.920,0:43:19.119
so i think it's we are all good right

0:43:17.680,0:43:22.640
now

0:43:19.119,0:43:25.680
okay all right so

0:43:22.640,0:43:27.200
um next time we want to cover is uh

0:43:25.680,0:43:29.440
what's called decoding or interference

0:43:27.200,0:43:30.640
flying to models so

0:43:29.440,0:43:32.640
uh between this line as well the

0:43:30.640,0:43:34.319
slightest model puts a

0:43:32.640,0:43:36.240
hopefully probability maths on things

0:43:34.319,0:43:39.440
which good english and

0:43:36.240,0:43:42.800
uh their probability on grammatical and

0:43:39.440,0:43:44.079
nonsensical things um

0:43:42.800,0:43:45.680
but if you want to like create these

0:43:44.079,0:43:47.119
samples like i showed you before and how

0:43:45.680,0:43:49.920
do we actually

0:43:47.119,0:43:49.920
generate stacks

0:43:50.160,0:43:56.160
um so often we think about for inference

0:43:53.119,0:43:57.680
with the graphical model what we care

0:43:56.160,0:43:58.880
what we'd like to do is find the max

0:43:57.680,0:44:00.160
server by creating sensors which

0:43:58.880,0:44:03.200
maximizes

0:44:00.160,0:44:06.400
large world's probability um

0:44:03.200,0:44:07.520
unfortunately there's um as i mentioned

0:44:06.400,0:44:08.079
before there's quite a lot of english

0:44:07.520,0:44:09.680
sentences

0:44:08.079,0:44:12.960
that are possible and we can't just like

0:44:09.680,0:44:16.800
score them all to kind of max

0:44:12.960,0:44:16.800
um also these models don't really

0:44:17.280,0:44:20.960
uh there's not much to do with dynamic

0:44:18.880,0:44:23.040
programming here so

0:44:20.960,0:44:26.240
sometimes you can't find the max of

0:44:23.040,0:44:27.839
overexponential structures when you

0:44:26.240,0:44:30.800
have a model that factorizes somewhere

0:44:27.839,0:44:32.000
that lets you build a dynamic program

0:44:30.800,0:44:35.359
which lets you kind of share state

0:44:32.000,0:44:37.599
across different hypotheses um

0:44:35.359,0:44:40.319
but these molds don't be composed in a

0:44:37.599,0:44:40.319
friendly way so

0:44:40.480,0:44:44.000
kind of whatever choice make the first

0:44:42.240,0:44:46.800
word could affect all the other

0:44:44.000,0:44:46.800
other decisions

0:44:47.040,0:44:52.400
all right so must given that

0:44:50.319,0:44:54.000
uh one thing to do is do greedy decoding

0:44:52.400,0:44:56.800
um this is where we're just

0:44:54.000,0:44:58.079
gonna take the most likely the first

0:44:56.800,0:45:02.000
word and then given

0:44:58.079,0:45:05.680
that word pretty much like second word

0:45:02.000,0:45:09.119
uh guess was like a third word

0:45:05.680,0:45:11.040
um that's okay

0:45:09.119,0:45:12.319
but it's um there's no guarantee that's

0:45:11.040,0:45:15.200
actually gonna be the most likely

0:45:12.319,0:45:17.359
sequence you want to output because if

0:45:15.200,0:45:19.520
you have to make a

0:45:17.359,0:45:21.440
bad step at some point then you've got

0:45:19.520,0:45:25.760
no way of backtracking your search

0:45:21.440,0:45:28.800
to undo any previous decisions

0:45:25.760,0:45:30.839
um this ledger says that exhaustive

0:45:28.800,0:45:34.160
search is impossible

0:45:30.839,0:45:36.640
um and kind of hits middle ground of

0:45:34.160,0:45:38.400
what's called beam search

0:45:36.640,0:45:40.160
um so being searched is a way of trying

0:45:38.400,0:45:43.599
to keep track of

0:45:40.160,0:45:43.599
an n-best list of hypotheses

0:45:44.000,0:45:50.319
and then we're going to

0:45:48.560,0:45:53.200
uh just every time step try and keep

0:45:50.319,0:45:56.640
track update this list

0:45:53.200,0:45:58.560
with uh you as we've added

0:45:56.640,0:46:00.960
uh this may be easy to show you an

0:45:58.560,0:46:04.720
example um this slides from abigail c

0:46:00.960,0:46:06.960
at stanford um

0:46:04.720,0:46:06.960
so

0:46:08.000,0:46:13.280
uh we start we output let's say

0:46:11.760,0:46:15.040
we have the size of two well i'll put

0:46:13.280,0:46:18.160
these two possible words these are

0:46:15.040,0:46:19.359
these are two most likely words

0:46:18.160,0:46:21.440
now for each of these words we're going

0:46:19.359,0:46:23.599
to generate um

0:46:21.440,0:46:26.160
work out what our tumors like the next

0:46:23.599,0:46:26.160
words that

0:46:27.040,0:46:30.720
so obviously with io that does affect

0:46:29.520,0:46:32.160
what the next word should be

0:46:30.720,0:46:34.319
and we'll come with different hypotheses

0:46:32.160,0:46:36.560
for each of these

0:46:34.319,0:46:36.560
um

0:46:39.200,0:46:43.680
and then every time we're going to kind

0:46:40.480,0:46:45.520
of compress these down to

0:46:43.680,0:46:48.079
a list of uh two that we're going to

0:46:45.520,0:46:49.839
continue pressing

0:46:48.079,0:46:51.119
so we're looking for the lowest total

0:46:49.839,0:46:54.240
sum is it correct

0:46:51.119,0:46:54.240
uh yeah so these are

0:46:54.319,0:46:57.839
log likelihoods so

0:46:58.160,0:47:02.480
um we actually want the highest sum if

0:47:00.880,0:47:06.319
that makes sense which should be

0:47:02.480,0:47:06.319
where zero would be a probability one

0:47:06.640,0:47:11.839
oh yeah

0:47:12.880,0:47:19.440
so every score is going to be less than

0:47:16.000,0:47:21.599
zero but we're going to find the

0:47:19.440,0:47:22.960
secrets with the whether some of the

0:47:21.599,0:47:25.839
scores is

0:47:22.960,0:47:25.839
the highest

0:47:29.119,0:47:32.319
does that make sense it is so sorry yeah

0:47:31.599,0:47:34.400
i got the

0:47:32.319,0:47:36.160
the sign flipped i was many like in

0:47:34.400,0:47:38.079
magnitude we tried to get the smallest

0:47:36.160,0:47:41.280
number in magnitude uh

0:47:38.079,0:47:43.520
as well as the magnitude yeah sure sorry

0:47:41.280,0:47:45.520
sorry maybe this is not the most best

0:47:43.520,0:47:49.359
way to do this okay

0:47:45.520,0:47:52.880
how d does the um does this like tree

0:47:49.359,0:47:56.400
go into the beam search

0:47:52.880,0:47:59.920
when do you stop looking for um like

0:47:56.400,0:48:03.839
candidate sequences i guess

0:47:59.920,0:48:05.119
um all right so we basically

0:48:03.839,0:48:07.680
will detail our hepatologists we have

0:48:05.119,0:48:09.520
this like end of sentence token

0:48:07.680,0:48:11.119
and in the sense token means once you

0:48:09.520,0:48:15.200
once you output that then you

0:48:11.119,0:48:16.800
this hypothesis is finished um

0:48:15.200,0:48:18.800
and the aim is to find complete

0:48:16.800,0:48:20.160
hypotheses so from from a start to the

0:48:18.800,0:48:24.319
end token

0:48:20.160,0:48:27.599
that have the highest possible score

0:48:24.319,0:48:27.599
um so

0:48:29.040,0:48:33.680
um we'll just keep on generating you

0:48:31.520,0:48:35.920
hypotheses

0:48:33.680,0:48:35.920
um

0:48:38.800,0:48:41.920
uh there's no possible new words for

0:48:41.040,0:48:46.800
that that would be

0:48:41.920,0:48:50.160
the k complete hypothesis we have still

0:48:46.800,0:48:53.040
okay cool there's another question here

0:48:50.160,0:48:54.000
why do you think in nmt very very large

0:48:53.040,0:48:56.319
beam size

0:48:54.000,0:48:58.880
will most often result in empty

0:48:56.319,0:49:01.680
translations

0:48:58.880,0:49:02.079
ooh uh great question um i have opinions

0:49:01.680,0:49:05.440
on this

0:49:02.079,0:49:05.440
um so

0:49:06.720,0:49:09.040
um

0:49:11.119,0:49:14.640
the research is good and since it's

0:49:12.640,0:49:18.079
guaranteed to give you

0:49:14.640,0:49:22.240
a higher scoring hypothesis than

0:49:18.079,0:49:24.880
the uh greedy search i mentioned in the

0:49:22.240,0:49:24.880
previous slide

0:49:25.040,0:49:30.160
but it's kind of a catch here which is

0:49:26.480,0:49:32.640
that we're not actually

0:49:30.160,0:49:35.280
um at training time we're typically not

0:49:32.640,0:49:35.280
using a beam

0:49:35.440,0:49:37.680
so

0:49:39.920,0:49:43.839
um at training time we normally just use

0:49:42.880,0:49:45.760
kind of the ultra regressive

0:49:43.839,0:49:49.040
factorization i showed you before

0:49:45.760,0:49:49.440
where like given the sort of n previous

0:49:49.040,0:49:54.480
correct

0:49:49.440,0:49:57.520
outputs predict the n plus first word um

0:49:54.480,0:49:59.040
what we're not doing is

0:49:57.520,0:50:02.240
exposing the model to its own mistakes

0:49:59.040,0:50:05.280
in it so when you do beam search

0:50:02.240,0:50:06.559
um you can get all kinds of nonsense

0:50:05.280,0:50:07.040
showing up in your beam for whatever

0:50:06.559,0:50:11.119
reason

0:50:07.040,0:50:14.160
because if you have a very big beam then

0:50:11.119,0:50:15.920
probably some of it will be garbage and

0:50:14.160,0:50:17.440
in these garbage states the model has no

0:50:15.920,0:50:20.319
idea what to do because there's never

0:50:17.440,0:50:22.319
training the situation

0:50:20.319,0:50:23.760
um so it's kind of reasonable to expect

0:50:22.319,0:50:26.079
your model to generalize wealth like

0:50:23.760,0:50:28.319
making great predictions

0:50:26.079,0:50:29.760
for some completely nonsensical series

0:50:28.319,0:50:32.480
of words which is like

0:50:29.760,0:50:33.839
a very perfect training distribution and

0:50:32.480,0:50:37.280
in this case the model can

0:50:33.839,0:50:39.359
do all kinds of weird and uncerebral

0:50:37.280,0:50:41.440
things like maybe they put a very high

0:50:39.359,0:50:43.760
probability on something else

0:50:41.440,0:50:43.760
um

0:50:45.760,0:50:48.880
very kind of a classic example this i

0:50:47.200,0:50:49.359
don't know if he's i don't have one here

0:50:48.880,0:50:50.640
but

0:50:49.359,0:50:51.920
you may have seen his lines walls get

0:50:50.640,0:50:53.599
stuck in these feedback loops where they

0:50:51.920,0:50:56.319
end up just like repeating the same

0:50:53.599,0:50:57.599
word or phrase infinitely many times i

0:50:56.319,0:50:59.359
think it's kind of example this where

0:50:57.599,0:51:01.119
once the mods like start going into this

0:50:59.359,0:51:02.240
kind of loop then

0:51:01.119,0:51:03.599
it doesn't really know what to do and

0:51:02.240,0:51:04.319
the easiest thing for it to carry on

0:51:03.599,0:51:09.280
doing is

0:51:04.319,0:51:13.920
just keep on looping um

0:51:09.280,0:51:15.200
so yeah i think

0:51:13.920,0:51:17.839
at least you mentioned being searched is

0:51:15.200,0:51:20.240
one of uh

0:51:17.839,0:51:22.559
not exposing the model to its own

0:51:20.240,0:51:25.040
mistakes at training time

0:51:22.559,0:51:26.319
so it just it put actually puts a bunch

0:51:25.040,0:51:28.400
of probability amounts and all kinds of

0:51:26.319,0:51:30.000
things it shouldn't do

0:51:28.400,0:51:31.440
um kind of the obvious solution to that

0:51:30.000,0:51:33.220
is like why don't you

0:51:31.440,0:51:35.520
have a beam at training time um

0:51:33.220,0:51:39.599
[Music]

0:51:35.520,0:51:40.960
there's uh and the short answer that is

0:51:39.599,0:51:43.359
because it's expensive

0:51:40.960,0:51:44.480
uh if you guys go around this whole

0:51:43.359,0:51:46.640
inference procedure

0:51:44.480,0:51:48.319
a training time that firstly gets rid of

0:51:46.640,0:51:50.800
all the nice parallelism but we

0:51:48.319,0:51:51.599
have the transformer and introduces all

0:51:50.800,0:51:54.880
the search

0:51:51.599,0:51:57.359
and also gives you many more things to

0:51:54.880,0:51:57.359
score for

0:51:57.440,0:52:00.400
every trading example

0:52:00.640,0:52:09.040
so in practice people tend to just

0:52:05.680,0:52:09.040
ignore this problem and train

0:52:10.160,0:52:13.119
create a big model for as long as they

0:52:11.280,0:52:16.240
can like exposing like nice fast

0:52:13.119,0:52:16.240
parallels and you get from this

0:52:16.480,0:52:20.720
autoregressive version and then a test

0:52:19.359,0:52:22.079
site people will often

0:52:20.720,0:52:24.880
choose the size of their beam to get the

0:52:22.079,0:52:27.440
best performance so

0:52:24.880,0:52:28.480
uh i think that translation like

0:52:27.440,0:52:30.880
increasing the beam

0:52:28.480,0:52:32.240
normally helps up to a point then makes

0:52:30.880,0:52:33.040
basically worse again we started

0:52:32.240,0:52:36.480
covering

0:52:33.040,0:52:37.040
uh these weird degenerate degenerate

0:52:36.480,0:52:40.559
outputs

0:52:37.040,0:52:42.240
um but yeah that's just the unsatisfying

0:52:40.559,0:52:44.400
thing people

0:52:42.240,0:52:46.240
have to do sorry that's quite a long

0:52:44.400,0:52:49.280
answer that answer your question

0:52:46.240,0:52:51.839
i think uh i think this student i will

0:52:49.280,0:52:53.200
see now what the student says

0:52:51.839,0:52:55.440
like uh that was a question from a

0:52:53.200,0:52:55.440
student

0:52:56.079,0:52:59.680
and there is another question a small

0:52:58.000,0:53:04.160
one on this current slide

0:52:59.680,0:53:04.160
why the why is the a and one in green

0:53:04.319,0:53:07.119
on the right um

0:53:07.680,0:53:15.839
um i could admit i don't know

0:53:12.000,0:53:17.280
i stole this size from abby um

0:53:15.839,0:53:19.839
i'm not quite sure what point she was

0:53:17.280,0:53:22.240
trying to make there okay

0:53:19.839,0:53:22.240
it's okay

0:53:23.520,0:53:28.000
oh okay the point actually someone

0:53:25.280,0:53:30.400
answer because they are interchangeable

0:53:28.000,0:53:31.599
regardless of the the the the one you

0:53:30.400,0:53:35.440
pick you get

0:53:31.599,0:53:35.440
both outputs pie and tart

0:53:38.319,0:53:43.040
like either or you go for either you go

0:53:40.720,0:53:46.160
for a or one both of them will

0:53:43.040,0:53:50.559
tell you pie tart or pie dart

0:53:46.160,0:53:52.400
uh i'm not sure um i mean

0:53:50.559,0:53:54.000
even if you were to do that then you you

0:53:52.400,0:53:55.280
can't compress these it's not that you

0:53:54.000,0:53:58.240
could get a dynamic program where you

0:53:55.280,0:54:01.599
can sort of collapse these hypotheses

0:53:58.240,0:54:02.880
because the hidden states both these

0:54:01.599,0:54:04.800
those two hypotheses would still be

0:54:02.880,0:54:06.000
different um

0:54:04.800,0:54:08.319
depending on which path you took

0:54:06.000,0:54:10.480
together uh

0:54:08.319,0:54:11.680
so i don't know but hopefully this

0:54:10.480,0:54:14.559
illustrates might be in search

0:54:11.680,0:54:14.559
okay okay

0:54:16.800,0:54:24.820
okay any more questions on this

0:54:24.400,0:54:27.869
um

0:54:24.820,0:54:27.869
[Music]

0:54:27.920,0:54:32.640
okay this is a bit more description of

0:54:29.440,0:54:32.640
how the algorithm looks um

0:54:32.720,0:54:37.440
basically all you do is every time step

0:54:34.960,0:54:38.960
you generate

0:54:37.440,0:54:40.480
a distribution of next words three

0:54:38.960,0:54:44.319
hypotheses you have

0:54:40.480,0:54:45.920
and then you take the top k hypothesis

0:54:44.319,0:54:47.680
next words across all your hypotheses

0:54:45.920,0:54:50.000
and pull these before you go to the next

0:54:47.680,0:54:50.000
word

0:54:50.799,0:54:54.160
all right so

0:54:55.280,0:54:59.280
um all right so being said sometimes the

0:54:58.559,0:55:02.880
right thing to do

0:54:59.280,0:55:05.680
but um often it actually isn't

0:55:02.880,0:55:06.240
uh so this is the result of flying beam

0:55:05.680,0:55:07.839
search

0:55:06.240,0:55:09.599
to the example i showed you before so

0:55:07.839,0:55:10.799
this example from gpd2 about like

0:55:09.599,0:55:15.119
scientists finding

0:55:10.799,0:55:17.040
unicorns in the andes um

0:55:15.119,0:55:18.400
you can see here that the bottles

0:55:17.040,0:55:19.680
actually

0:55:18.400,0:55:21.599
it starts out putting some good stuff

0:55:19.680,0:55:22.160
and gets stuck in this weird feedback

0:55:21.599,0:55:24.480
loop

0:55:22.160,0:55:24.480
um

0:55:26.720,0:55:31.599
so i think yes we're just

0:55:30.160,0:55:32.799
gonna repeat the same phrase over and

0:55:31.599,0:55:34.000
over and over again i'll probably just

0:55:32.799,0:55:37.440
keep on repeating this phrase

0:55:34.000,0:55:38.720
forever i mean i guess kind of what's

0:55:37.440,0:55:39.680
going on here like once you said this

0:55:38.720,0:55:42.079
phrase

0:55:39.680,0:55:42.720
twice maybe it's just saying the third

0:55:42.079,0:55:45.200
time is

0:55:42.720,0:55:47.040
actually the most likely thing to do and

0:55:45.200,0:55:48.000
then all these other hypotheses get very

0:55:47.040,0:55:49.599
high prob

0:55:48.000,0:55:52.480
transitions get right have probability

0:55:49.599,0:55:52.480
even if they're not good

0:55:52.880,0:55:57.359
but there's also kind of a slightly

0:55:54.160,0:55:57.359
different problem which is like maybe

0:55:57.440,0:56:02.160
in some cases we don't actually want the

0:55:59.040,0:56:04.240
most likely sequence after all um

0:56:02.160,0:56:07.119
maybe what we want is something

0:56:04.240,0:56:07.119
interesting so

0:56:07.520,0:56:10.720
you see this problem also a lot in like

0:56:09.119,0:56:11.599
things like dialogue response generation

0:56:10.720,0:56:12.960
so

0:56:11.599,0:56:15.280
you're trying to build a world hold

0:56:12.960,0:56:16.640
conversation with someone and if you do

0:56:15.280,0:56:18.079
this kind of beam search often what

0:56:16.640,0:56:20.799
you'll get is it will just

0:56:18.079,0:56:21.440
give you the most generic response to

0:56:20.799,0:56:24.079
anything you say

0:56:21.440,0:56:25.280
so whatever you say it'll be like oh

0:56:24.079,0:56:28.480
that's interesting

0:56:25.280,0:56:29.520
thanks and maybe that actually genuinely

0:56:28.480,0:56:32.160
is the most likely thing

0:56:29.520,0:56:34.240
to do because these responses are good

0:56:32.160,0:56:34.240
in

0:56:34.720,0:56:38.960
most situations um however that's not

0:56:38.240,0:56:40.400
actually

0:56:38.960,0:56:42.720
a very good experience or a very good

0:56:40.400,0:56:42.720
system

0:56:43.440,0:56:50.319
so how about if instead of taking the um

0:56:48.079,0:56:53.200
max we're going to sample from the model

0:56:50.319,0:56:53.200
distribution instead

0:56:53.280,0:56:58.559
um so this is a

0:56:56.640,0:57:00.240
conceptually kind of appealing but it

0:56:58.559,0:57:02.079
doesn't actually give you very good

0:57:00.240,0:57:05.520
output so

0:57:02.079,0:57:07.440
uh this is again

0:57:05.520,0:57:09.680
the result sampling on that same input

0:57:07.440,0:57:09.680
um

0:57:10.559,0:57:14.400
i mean so this is kind of good but then

0:57:12.880,0:57:17.359
it goes kind of

0:57:14.400,0:57:18.079
uh it gets more weird and degenerate as

0:57:17.359,0:57:20.319
it goes on

0:57:18.079,0:57:20.319
um

0:57:21.440,0:57:26.079
and again you get to now problem where

0:57:23.359,0:57:27.760
like once you sample the bad choice

0:57:26.079,0:57:29.520
then the moles in state was never in

0:57:27.760,0:57:31.760
training

0:57:29.520,0:57:33.119
um and then once it's not stages in

0:57:31.760,0:57:34.640
during training it's more likely to give

0:57:33.119,0:57:35.680
you support bad output and you'll get

0:57:34.640,0:57:38.799
stuck in these

0:57:35.680,0:57:38.799
horrible feedback loops

0:57:39.440,0:57:42.480
okay um

0:57:43.520,0:57:46.480
all right so here's something that

0:57:44.480,0:57:47.119
actually does work because it was used

0:57:46.480,0:57:50.240
to get you those

0:57:47.119,0:57:52.319
uh beautiful outputs we had before

0:57:50.240,0:57:54.079
um unfortunately it's not very

0:57:52.319,0:57:57.359
satisfying technique but

0:57:54.079,0:57:58.240
it's a disclosure um so it's called top

0:57:57.359,0:58:00.960
pay sampling it's

0:57:58.240,0:58:02.400
used introduced by uh angela fan a

0:58:00.960,0:58:04.960
couple years ago

0:58:02.400,0:58:05.599
um basically top case sampling what

0:58:04.960,0:58:07.920
we're going to do

0:58:05.599,0:58:09.040
is truncate our distribution to just

0:58:07.920,0:58:12.880
taking the k best

0:58:09.040,0:58:12.880
and then sample from that

0:58:13.520,0:58:17.920
um so this advantage of giving us kind

0:58:15.599,0:58:22.319
of diversity like choosing randomly

0:58:17.920,0:58:26.079
amongst like good options but tries to

0:58:22.319,0:58:27.760
stop us kind of uh

0:58:26.079,0:58:29.839
falling off this kind of manifold and

0:58:27.760,0:58:32.480
actually good language but

0:58:29.839,0:58:34.319
when we sample something bad um so the

0:58:32.480,0:58:35.839
only basis just chop off the long tail

0:58:34.319,0:58:37.599
and just sample from the head of the

0:58:35.839,0:58:38.720
distribution and this is the sampling

0:58:37.599,0:58:40.400
for the beam search

0:58:38.720,0:58:43.520
is it uh sorry this is the beam switch

0:58:40.400,0:58:47.680
this is just um generation so

0:58:43.520,0:58:48.799
we're gonna um

0:58:47.680,0:58:50.720
there's not gonna be beam here this

0:58:48.799,0:58:54.160
could be one hypothesis

0:58:50.720,0:58:54.720
i guess you could it creates beam search

0:58:54.160,0:58:57.839
too but

0:58:54.720,0:59:00.319
uh this is actually pure sampling so

0:58:57.839,0:59:05.680
i can generate a word in this method

0:59:00.319,0:59:10.799
then use that to generate the next word

0:59:05.680,0:59:10.799
okay um so when you

0:59:13.440,0:59:17.440
uh do all that then this is finally the

0:59:16.079,0:59:19.040
technique that was used during this nice

0:59:17.440,0:59:20.640
sample

0:59:19.040,0:59:22.880
obviously this top case i'm playing it's

0:59:20.640,0:59:26.720
a bit of a hack it's not very satisfying

0:59:22.880,0:59:27.839
um i was um an author on my paper so i

0:59:26.720,0:59:33.359
can mean about the method

0:59:27.839,0:59:36.000
but um it does seem to work quite well

0:59:33.359,0:59:37.280
um i guess one thing to be aware of like

0:59:36.000,0:59:38.160
when you see these great samples and

0:59:37.280,0:59:40.079
things like this which

0:59:38.160,0:59:42.000
like openly i am very happy to put in

0:59:40.079,0:59:44.319
their publicity

0:59:42.000,0:59:45.040
uh it's kind of useful to know how it's

0:59:44.319,0:59:46.400
actually made

0:59:45.040,0:59:48.000
and this is like this is not like a real

0:59:46.400,0:59:50.640
sample from all distribution the model

0:59:48.000,0:59:54.319
is like not putting

0:59:50.640,0:59:56.480
uh and it must use probability mass on

0:59:54.319,0:59:59.839
this this is

0:59:56.480,1:00:01.119
generated by uh

0:59:59.839,1:00:04.160
doing this slightly weird inference

1:00:01.119,1:00:04.160
procedure with the model

1:00:05.119,1:00:09.520
um i just want to quickly cover like

1:00:08.160,1:00:11.040
all right so give us some text like this

1:00:09.520,1:00:13.040
how do we know if it's any good or not

1:00:11.040,1:00:16.640
like how do you evaluate this

1:00:13.040,1:00:18.240
um so like it's not

1:00:16.640,1:00:20.400
like evaluating launch model it's quite

1:00:18.240,1:00:22.799
easy i mean it's language modelling it's

1:00:20.400,1:00:24.319
task density estimation so you just

1:00:22.799,1:00:26.720
look at the look like here hold that

1:00:24.319,1:00:26.720
data

1:00:26.839,1:00:31.680
um if you want to do instead like

1:00:29.760,1:00:34.720
uh take some text to marvel and say if

1:00:31.680,1:00:34.720
it's any good or not then

1:00:35.040,1:00:41.440
uh this is not real and

1:00:38.079,1:00:42.880
uh it's kind of people tend to use like

1:00:41.440,1:00:44.400
these automated metrics like blue and

1:00:42.880,1:00:45.920
rouge which measure like

1:00:44.400,1:00:47.520
and grammar overlap with the reference

1:00:45.920,1:00:50.799
but

1:00:47.520,1:00:52.079
um they're not very satisfying

1:00:50.799,1:00:55.200
and this is recent research and trying

1:00:52.079,1:00:55.200
to do awesome asymmetrics

1:00:55.599,1:01:02.160
okay i should place me down for this

1:00:59.760,1:01:03.440
um all right so this is um that's

1:01:02.160,1:01:08.160
unconditional language models

1:01:03.440,1:01:09.839
um so they're generating samples of text

1:01:08.160,1:01:12.720
uh this actually isn't a very useful

1:01:09.839,1:01:14.559
thing to do what's much more useful is

1:01:12.720,1:01:16.640
uh conditional language models so models

1:01:14.559,1:01:18.160
which will give us a text

1:01:16.640,1:01:20.000
given some input generate use some

1:01:18.160,1:01:21.280
output so

1:01:20.000,1:01:24.880
for example you can think about things

1:01:21.280,1:01:27.599
like um

1:01:24.880,1:01:29.760
given a french sentence like translate

1:01:27.599,1:01:32.559
it into english i've given a document

1:01:29.760,1:01:34.240
generate a summary given a dialogue

1:01:32.559,1:01:36.799
generate the

1:01:34.240,1:01:39.280
next response or you can give it a

1:01:36.799,1:01:42.160
question i'll put the answer

1:01:39.280,1:01:42.720
so this is called sequence sequence

1:01:42.160,1:01:44.160
models

1:01:42.720,1:01:46.319
um because you get given some input

1:01:44.160,1:01:49.440
sequence and then you have to

1:01:46.319,1:01:51.119
generate some output sequence

1:01:49.440,1:01:53.280
um because the first models these are

1:01:51.119,1:01:55.359
introduced by elias giver

1:01:53.280,1:01:57.280
um look kind of like this with recurrent

1:01:55.359,1:01:58.880
neural networks where basically

1:01:57.280,1:02:00.319
you'd have some encoded network which

1:01:58.880,1:02:02.160
would read your inputs

1:02:00.319,1:02:03.359
produce some vector which you

1:02:02.160,1:02:05.839
marvelously called a

1:02:03.359,1:02:07.280
thought vector and then you'd use this

1:02:05.839,1:02:08.400
to initialize your decoder which would

1:02:07.280,1:02:11.680
generate tokens

1:02:08.400,1:02:12.240
by word again hopefully you get your

1:02:11.680,1:02:13.599
theme here

1:02:12.240,1:02:16.240
like carrying these kind of bottlenecks

1:02:13.599,1:02:17.599
and recurrence is not a good thing to do

1:02:16.240,1:02:21.039
uh you want to have expresso models

1:02:17.599,1:02:23.039
which you might see everything

1:02:21.039,1:02:25.599
uh so there's a variation transformer

1:02:23.039,1:02:28.400
for sequence sequence models

1:02:25.599,1:02:31.520
um here we're going to have a two stacks

1:02:28.400,1:02:33.680
an encoder stack and decode stack

1:02:31.520,1:02:35.039
uh basically the encoded stack is the

1:02:33.680,1:02:37.200
same as what i showed you before

1:02:35.039,1:02:39.119
apart from the self tension isn't masked

1:02:37.200,1:02:42.559
so every token the input can look at

1:02:39.119,1:02:42.559
every other token in the input

1:02:43.440,1:02:48.319
the decode stack will be similar except

1:02:46.559,1:02:49.200
that as well as doing the self tension

1:02:48.319,1:02:53.520
over itself

1:02:49.200,1:02:57.599
it's also going to do attention over

1:02:53.520,1:02:57.599
um the

1:02:58.319,1:03:02.160
complete inputs so this means that every

1:03:01.200,1:03:03.680
token output

1:03:02.160,1:03:05.520
has direct connection to every previous

1:03:03.680,1:03:10.880
token in the output

1:03:05.520,1:03:10.880
um and also to every word in the input

1:03:12.240,1:03:17.839
which makes these models very expressive

1:03:13.680,1:03:17.839
and powerful

1:03:22.319,1:03:28.839
translation scores over

1:03:25.520,1:03:30.720
the previous recurrent convolutional

1:03:28.839,1:03:31.760
models

1:03:30.720,1:03:33.839
so what we're trying these models

1:03:31.760,1:03:35.920
typically what we do is we rely on label

1:03:33.839,1:03:37.680
text so we

1:03:35.920,1:03:39.920
uh it's a string translation system for

1:03:37.680,1:03:41.359
example you

1:03:39.920,1:03:43.839
try and get lots of manually translated

1:03:41.359,1:03:45.280
text it turns out one of the best ways

1:03:43.839,1:03:46.640
to get this is things like parliament

1:03:45.280,1:03:48.079
proceedings because they always

1:03:46.640,1:03:49.440
translate

1:03:48.079,1:03:51.520
the european parliament or write

1:03:49.440,1:03:55.280
proceedings lots of different languages

1:03:51.520,1:03:58.640
um and then you just

1:03:55.280,1:03:59.599
use those as inputs and now however like

1:03:58.640,1:04:00.880
not all languages

1:03:59.599,1:04:03.440
are represented in the european

1:04:00.880,1:04:07.280
parliament um

1:04:03.440,1:04:08.880
so and these transformers are very data

1:04:07.280,1:04:11.680
hungry and like more texts can throw at

1:04:08.880,1:04:14.960
them the best they will do

1:04:11.680,1:04:19.200
um so this question like how we

1:04:14.960,1:04:22.720
use monolingual text to improve these so

1:04:19.200,1:04:23.760
this is actually saying it can we learn

1:04:22.720,1:04:27.280
without just having

1:04:23.760,1:04:29.520
input output pairs

1:04:27.280,1:04:30.960
uh the way we could do this is a

1:04:29.520,1:04:33.119
technique called back translation which

1:04:30.960,1:04:36.240
is

1:04:33.119,1:04:37.760
quite simple conceptually that's our

1:04:36.240,1:04:38.480
goal is to train a translation system

1:04:37.760,1:04:42.400
that

1:04:38.480,1:04:42.400
inputs german and we'll output english

1:04:42.880,1:04:46.160
um first of all we're going to actually

1:04:44.079,1:04:49.599
do the opposite we're going to train a

1:04:46.160,1:04:53.039
reverse translation model which will

1:04:49.599,1:04:53.039
give an english output german

1:04:53.839,1:04:59.359
then we can then run this model over

1:04:57.520,1:05:01.039
all the english texts we can find and we

1:04:59.359,1:05:02.240
can uh

1:05:01.039,1:05:06.480
find a lot of english text on the

1:05:02.240,1:05:06.480
internet and we'll translate it all in

1:05:06.839,1:05:09.760
german

1:05:08.079,1:05:11.359
um and that gives us like lots more

1:05:09.760,1:05:13.039
pairs of

1:05:11.359,1:05:14.480
english and german text and then we're

1:05:13.039,1:05:18.079
going to train a forward model or try

1:05:14.480,1:05:22.240
and translate this german into english

1:05:18.079,1:05:26.720
um the next thing to see here is

1:05:22.240,1:05:28.640
that it doesn't actually matter how good

1:05:26.720,1:05:29.920
the

1:05:28.640,1:05:32.000
initial model is right it doesn't matter

1:05:29.920,1:05:33.520
if the your reverse model is making

1:05:32.000,1:05:35.039
mistakes

1:05:33.520,1:05:36.880
um so if your reverse model makes

1:05:35.039,1:05:38.240
mistakes then your final train data will

1:05:36.880,1:05:40.799
contain kind of

1:05:38.240,1:05:42.000
noisy german translates to clean english

1:05:40.799,1:05:44.400
um

1:05:42.000,1:05:45.680
which might even help regularize your

1:05:44.400,1:05:47.760
model but probably

1:05:45.680,1:05:48.880
shouldn't pass its performance when you

1:05:47.760,1:05:53.280
show it

1:05:48.880,1:05:56.559
a clean german data what's a byte text

1:05:53.280,1:05:57.599
oh i'm sorry um a bitex just means a

1:05:56.559,1:06:01.119
parallel

1:05:57.599,1:06:04.319
text so the same sentences

1:06:01.119,1:06:06.559
in two different languages okay

1:06:04.319,1:06:06.559
thanks

1:06:08.319,1:06:12.640
okay um and the nice thing about

1:06:11.119,1:06:15.200
translation is that

1:06:12.640,1:06:16.400
the outputs you get are actually always

1:06:15.200,1:06:19.280
uh you know

1:06:16.400,1:06:20.400
high quality because these are the

1:06:19.280,1:06:23.039
outputs of the system

1:06:20.400,1:06:23.039
i think to you

1:06:24.240,1:06:28.160
uh sentences you found in the wild on

1:06:26.799,1:06:29.440
the internet

1:06:28.160,1:06:31.359
you're just going to create some noisy

1:06:29.440,1:06:34.240
inputs that you can use for these

1:06:31.359,1:06:34.240
pair of these outfits

1:06:34.799,1:06:41.119
um could you go back a slide

1:06:39.280,1:06:43.200
the third point translate billions of

1:06:41.119,1:06:45.440
words of english to german is that

1:06:43.200,1:06:48.480
through the reverse translation model

1:06:45.440,1:06:50.880
exactly yeah okay cool

1:06:48.480,1:06:51.520
uh and you're saying back translation

1:06:50.880,1:06:54.400
helps

1:06:51.520,1:06:56.480
uh generate higher quality translations

1:06:54.400,1:06:57.839
uh because of regularization

1:06:56.480,1:06:59.599
is that it ah it's not just

1:06:57.839,1:07:01.119
recognization it also the

1:06:59.599,1:07:04.720
really useful thing is it gives you lots

1:07:01.119,1:07:06.400
of clean output data

1:07:04.720,1:07:09.039
so let's say you ought to be a good

1:07:06.400,1:07:11.599
german between the translation model

1:07:09.039,1:07:12.319
you kind of need both to understand

1:07:11.599,1:07:14.960
german

1:07:12.319,1:07:16.319
we'll also be able to write lots of

1:07:14.960,1:07:18.559
fluent english as well and then

1:07:16.319,1:07:19.680
the english grammar team and the back

1:07:18.559,1:07:23.119
translation gives you a way of

1:07:19.680,1:07:23.119
incorporating tons of

1:07:23.359,1:07:29.520
additional language data beyond what you

1:07:24.960,1:07:33.359
have translations for

1:07:29.520,1:07:34.960
um okay so kind of

1:07:33.359,1:07:39.119
combines translation volatile language

1:07:34.960,1:07:39.119
model and you can also

1:07:39.839,1:07:47.359
um iterate this procedure too so you can

1:07:43.280,1:07:49.119
uh use it use that whole sense of

1:07:47.359,1:07:50.480
describe before to train a better model

1:07:49.119,1:07:52.799
and then

1:07:50.480,1:07:52.799
uh

1:07:54.400,1:07:57.440
do this to help you generate better

1:07:55.760,1:07:59.599
translate better back translations which

1:07:57.440,1:08:01.280
you can use to train again

1:07:59.599,1:08:02.640
and this can be really helpful i mean it

1:08:01.280,1:08:04.960
helps even in english german but it's

1:08:02.640,1:08:07.760
particularly helpful in cases

1:08:04.960,1:08:11.359
where you don't have much data so this

1:08:07.760,1:08:12.960
is on a bernie's to english translation

1:08:11.359,1:08:14.559
where there isn't a lot of parallel data

1:08:12.960,1:08:19.520
but you can

1:08:14.559,1:08:22.560
uh get really large improvements by

1:08:19.520,1:08:24.159
just iterating back translation uh this

1:08:22.560,1:08:27.279
was recent work from fair which i

1:08:24.159,1:08:27.279
forgot to reference for

1:08:28.239,1:08:33.600
um and again here are some results on uh

1:08:34.080,1:08:38.719
uh i think this is english german

1:08:35.600,1:08:40.480
showing some good improvements

1:08:38.719,1:08:42.080
uh one of the direction um in machine

1:08:40.480,1:08:42.880
translation people are exploring now is

1:08:42.080,1:08:45.120
a

1:08:42.880,1:08:46.080
massively multilingual mt so people are

1:08:45.120,1:08:47.759
trying to

1:08:46.080,1:08:49.920
not just translate between two languages

1:08:47.759,1:08:53.759
but trying to

1:08:49.920,1:08:55.120
take dozens of 100 languages and try and

1:08:53.759,1:08:57.440
train a single neural network that could

1:08:55.120,1:09:02.480
translate between all of these

1:08:57.440,1:09:02.480
um and if you do this you start see um

1:09:02.880,1:09:05.600
a big improvement particularly in

1:09:04.080,1:09:06.960
languages where you don't have much tags

1:09:05.600,1:09:08.480
presumably the model's learning some

1:09:06.960,1:09:10.799
kind of

1:09:08.480,1:09:13.279
more general language independent

1:09:10.799,1:09:13.279
information

1:09:13.600,1:09:18.719
okay so the last topic i want to cover

1:09:16.719,1:09:21.759
in this is a really important one which

1:09:18.719,1:09:24.480
is that self-supervised learning

1:09:21.759,1:09:26.719
um all right so um young is just seeing

1:09:24.480,1:09:29.140
this cake now but i think it's actually

1:09:26.719,1:09:31.759
a good image for this so the idea is

1:09:29.140,1:09:34.799
[Music]

1:09:31.759,1:09:36.080
um really that to

1:09:34.799,1:09:37.600
learn stuff like most of the information

1:09:36.080,1:09:40.400
we need is going to be most learning we

1:09:37.600,1:09:42.159
do has to be unsupervised so

1:09:40.400,1:09:43.440
we have huge amounts of text without any

1:09:42.159,1:09:47.279
labels on it

1:09:43.440,1:09:48.640
and we just have a little bit of um

1:09:47.279,1:09:50.960
sort of super frustrating data that's

1:09:48.640,1:09:52.960
represented by the cake here being the

1:09:50.960,1:09:54.159
unsupervised learning and the

1:09:52.960,1:09:56.320
supervised learning just being a little

1:09:54.159,1:09:59.440
bit of icing on top of the cake

1:09:56.320,1:10:00.800
i think actually um the recent person's

1:09:59.440,1:10:04.640
self-supervised learning from nlp has

1:10:00.800,1:10:07.920
really proved this metaphor to work

1:10:04.640,1:10:07.920
okay so

1:10:09.440,1:10:12.480
um i'm going to describe quite a few

1:10:10.800,1:10:14.480
methods for how you do self-supervised

1:10:12.480,1:10:15.920
learning for nlp um

1:10:14.480,1:10:18.320
just so you can try and get some ideas

1:10:15.920,1:10:22.400
as to what's actually working

1:10:18.320,1:10:24.800
uh so

1:10:22.400,1:10:27.520
uh the first one to describe is word to

1:10:24.800,1:10:27.520
back um

1:10:28.560,1:10:32.000
so the area of words back was trying to

1:10:30.480,1:10:33.920
i think it's really the first paper that

1:10:32.000,1:10:36.480
showed

1:10:33.920,1:10:38.560
uh got people excited about sales

1:10:36.480,1:10:40.239
surprise landing in lp

1:10:38.560,1:10:42.000
uh vern have his previous work from uh

1:10:40.239,1:10:46.320
culver and western which had

1:10:42.000,1:10:47.520
also shown some good gains um

1:10:46.320,1:10:49.040
so the goal here is going to be trying

1:10:47.520,1:10:52.400
to learn what's called word embedding so

1:10:49.040,1:10:57.120
brexit space recitations for words

1:10:52.400,1:10:58.800
and the hope is

1:10:57.120,1:11:00.159
by that by looking at unlabeled english

1:10:58.800,1:11:02.239
text we can learn something about what

1:11:00.159,1:11:03.600
these words mean

1:11:02.239,1:11:05.840
that's what the intuition behind all

1:11:03.600,1:11:08.320
this is that if two words are

1:11:05.840,1:11:09.520
ok close together in the text then

1:11:08.320,1:11:13.040
they're likely to have some kind of

1:11:09.520,1:11:14.560
relationship between each other

1:11:13.040,1:11:15.600
um so the pre-training task we're going

1:11:14.560,1:11:17.199
to do is going to be a filling in the

1:11:15.600,1:11:20.960
blanks task

1:11:17.199,1:11:22.159
so um in this sentence i'm going to

1:11:20.960,1:11:23.760
mask out this word in the middle which

1:11:22.159,1:11:24.640
is unicorns and try and predict what

1:11:23.760,1:11:27.679
this word should be

1:11:24.640,1:11:28.560
based on the surrounding context and

1:11:27.679,1:11:32.239
hope would be that

1:11:28.560,1:11:33.520
words like unknown silver hair and hand

1:11:32.239,1:11:35.040
will somehow

1:11:33.520,1:11:37.679
are more likely to occur in the context

1:11:35.040,1:11:41.840
of a unicorn than they are

1:11:37.679,1:11:41.840
i know a word like

1:11:43.600,1:11:46.320
some other animal

1:11:46.640,1:11:49.280
um so basically this is gonna be a very

1:11:48.159,1:11:50.719
simple model where basically we're gonna

1:11:49.280,1:11:52.880
take all these context words

1:11:50.719,1:11:54.239
we're gonna apply some linear projection

1:11:52.880,1:11:57.120
to these and

1:11:54.239,1:11:59.040
map the allowance of fixed size context

1:11:57.120,1:12:01.760
and then just do a softmax over our

1:11:59.040,1:12:03.679
vocabulary

1:12:01.760,1:12:05.120
uh so it looks a little bit like a

1:12:03.679,1:12:06.480
convolutional language model the only

1:12:05.120,1:12:10.000
difference is we're predicting the word

1:12:06.480,1:12:11.679
riddle not the word of the end um

1:12:10.000,1:12:14.000
any practice this model was um just a

1:12:11.679,1:12:17.120
shallow linear projection and didn't

1:12:14.000,1:12:17.120
was not a very deep model

1:12:18.320,1:12:23.520
okay um so

1:12:22.480,1:12:25.360
one of the things we find interesting

1:12:23.520,1:12:27.520
about this was these um wordy weddings

1:12:25.360,1:12:29.920
to show some

1:12:27.520,1:12:31.120
kind of surprising stretches to them uh

1:12:29.920,1:12:31.360
i'll show you how it was fun this is

1:12:31.120,1:12:32.880
like

1:12:31.360,1:12:34.560
people debated about how meaningful is

1:12:32.880,1:12:37.360
this um

1:12:34.560,1:12:39.040
but basically the claim was that if you

1:12:37.360,1:12:40.239
took you're invading the word

1:12:39.040,1:12:42.000
king which you train like this and you

1:12:40.239,1:12:43.840
subtract you're ready for word man then

1:12:42.000,1:12:45.920
you add the embedding of the word woman

1:12:43.840,1:12:48.159
you'll get something that's fairly close

1:12:45.920,1:12:53.120
to the embedding for the word queen

1:12:48.159,1:12:53.120
so somehow um

1:12:53.199,1:12:57.760
it's just this kind of unsupervised fill

1:12:54.960,1:12:58.960
in the blanks learning task

1:12:57.760,1:13:01.440
isn't using this kind of linear

1:12:58.960,1:13:05.840
structure with kind of meaningful

1:13:01.440,1:13:05.840
differences between vectors

1:13:06.320,1:13:11.440
okay so i mean this

1:13:10.159,1:13:13.760
was great and the really good thing

1:13:11.440,1:13:15.199
about this was that it's a really really

1:13:13.760,1:13:15.920
fast thing to do so you could train this

1:13:15.199,1:13:17.760
on

1:13:15.920,1:13:19.600
billions of words texts you back in

1:13:17.760,1:13:22.239
2013.

1:13:19.600,1:13:22.800
um but there's a big limitation which is

1:13:22.239,1:13:25.199
these word

1:13:22.800,1:13:26.640
writings are independent of the context

1:13:25.199,1:13:29.199
so

1:13:26.640,1:13:31.040
um you get like one vector per word in

1:13:29.199,1:13:33.840
your vocabulary

1:13:31.040,1:13:35.520
um but it doesn't know anything about

1:13:33.840,1:13:39.440
how that word relational works

1:13:35.520,1:13:42.480
and we know that to in language like

1:13:39.440,1:13:43.840
um a sentence is involved in just by

1:13:42.480,1:13:45.280
words it depends

1:13:43.840,1:13:47.199
each word interacts with other words

1:13:45.280,1:13:48.719
somehow

1:13:47.199,1:13:51.280
and these interactions are in some way

1:13:48.719,1:13:54.320
it's a really powerful thing

1:13:51.280,1:13:56.080
so in one example

1:13:54.320,1:13:57.760
obvious example is like ambiguous words

1:13:56.080,1:13:58.800
so lots of words can have many different

1:13:57.760,1:14:00.880
meanings

1:13:58.800,1:14:01.840
and these word vectors won't capture

1:14:00.880,1:14:03.679
that

1:14:01.840,1:14:06.080
or the best let's be superstition of all

1:14:03.679,1:14:06.080
the meanings

1:14:07.120,1:14:11.679
so how do we add context to these well

1:14:09.600,1:14:15.679
um

1:14:11.679,1:14:17.520
see the most obvious way is to

1:14:15.679,1:14:20.960
do a line as well i think i'm missing a

1:14:17.520,1:14:20.960
slide here uh basically

1:14:21.040,1:14:24.400
what we do is train a conditional

1:14:22.800,1:14:26.320
language model sorry an unconditional

1:14:24.400,1:14:27.840
language model this is going to

1:14:26.320,1:14:30.640
be exactly the kind of model i described

1:14:27.840,1:14:34.640
earlier in the talk

1:14:30.640,1:14:36.560
and then um

1:14:34.640,1:14:39.120
given this language model blindfold will

1:14:36.560,1:14:43.120
be outputting hidden states every

1:14:39.120,1:14:44.560
time step predicting the next word and

1:14:43.120,1:14:46.719
instead when we want to sell supervised

1:14:44.560,1:14:50.000
learning what we're going to do is

1:14:46.719,1:14:51.199
replace these outputs with um

1:14:50.000,1:14:54.400
some other output that depends on our

1:14:51.199,1:14:56.960
task so the pre-training phase is just

1:14:54.400,1:14:59.520
going to be predict the next word

1:14:56.960,1:15:02.239
but then kind of the icing on the cake

1:14:59.520,1:15:04.239
or supervised learning will be the

1:15:02.239,1:15:05.600
predicts some other property so i'll

1:15:04.239,1:15:06.159
show you an example here for a task

1:15:05.600,1:15:08.480
called

1:15:06.159,1:15:10.080
speech tagging which is trying to say

1:15:08.480,1:15:13.520
put some labels in every word here

1:15:10.080,1:15:15.520
so turn light label

1:15:13.520,1:15:16.960
scientists and noun and distinctive as

1:15:15.520,1:15:18.719
an adjective

1:15:16.960,1:15:21.920
um but you can actually fit all kinds of

1:15:18.719,1:15:24.880
tasks into this kind of framework

1:15:21.920,1:15:26.159
um so for example maybe you can fit

1:15:24.880,1:15:27.920
something like

1:15:26.159,1:15:29.679
this is a sentiment analysis task where

1:15:27.920,1:15:32.400
you're given some text to predict

1:15:29.679,1:15:33.440
like from an amazon review and predict

1:15:32.400,1:15:36.719
the

1:15:33.440,1:15:36.719
uh rating so

1:15:36.800,1:15:40.080
um this is a review that says what can i

1:15:38.400,1:15:41.440
say about its banana slicer that hasn't

1:15:40.080,1:15:44.880
already been said about the real

1:15:41.440,1:15:47.679
penicillin or the iphone and this review

1:15:44.880,1:15:47.679
got five stars

1:15:49.440,1:15:51.840
so here was you're going to predict one

1:15:50.560,1:15:53.520
output from this language model which is

1:15:51.840,1:15:57.120
going to be the

1:15:53.520,1:15:59.120
uh a token at the end

1:15:57.120,1:16:01.440
which you can some kind of test specific

1:15:59.120,1:16:01.440
label

1:16:02.000,1:16:07.600
so one of the really nice things about

1:16:04.840,1:16:11.679
this approach called gpt

1:16:07.600,1:16:13.840
was that it kind of eliminated tasks

1:16:11.679,1:16:16.080
specific modeling so now suddenly we

1:16:13.840,1:16:16.080
have

1:16:16.320,1:16:20.560
one model which you can pre-train and we

1:16:19.199,1:16:21.760
can that fine tune as well to do

1:16:20.560,1:16:25.280
basically

1:16:21.760,1:16:27.280
any task we want to do little

1:16:25.280,1:16:31.280
classification

1:16:27.280,1:16:32.960
um so before this

1:16:31.280,1:16:34.320
um there's actually a few years when

1:16:32.960,1:16:35.440
people were building all these crazy

1:16:34.320,1:16:37.600
architectures that you build

1:16:35.440,1:16:40.000
different architectures to do build a

1:16:37.600,1:16:41.679
quest answering model let's do a

1:16:40.000,1:16:44.159
sentiment analysis pro model or

1:16:41.679,1:16:46.320
something um now you train

1:16:44.159,1:16:47.840
creating one big model and then it's

1:16:46.320,1:16:49.199
really easy to find units do whatever

1:16:47.840,1:16:52.480
you like

1:16:49.199,1:16:56.239
so that was a really big step forward

1:16:52.480,1:16:58.480
um unfortunate model has kind of the

1:16:56.239,1:17:00.159
obvious limitation i said the important

1:16:58.480,1:17:03.040
thing to do was kind of contextualize

1:17:00.159,1:17:04.560
words so like let words know

1:17:03.040,1:17:06.719
build word recitations depend on the

1:17:04.560,1:17:09.199
context but

1:17:06.719,1:17:10.640
if you appreciate this language model

1:17:09.199,1:17:12.400
you can only really condition on your

1:17:10.640,1:17:14.960
left with context

1:17:12.400,1:17:16.400
so your expectations for each word

1:17:14.960,1:17:18.480
necessarily can't depend on the

1:17:16.400,1:17:21.440
representation for

1:17:18.480,1:17:21.440
any future words

1:17:21.679,1:17:23.920
um

1:17:25.199,1:17:28.400
and that kind of limits what the model

1:17:26.560,1:17:30.000
can do quite a lot

1:17:28.400,1:17:31.600
um there's one kind of obvious fix to

1:17:30.000,1:17:34.719
that which is um

1:17:31.600,1:17:37.360
the approach taken by elmo

1:17:34.719,1:17:38.800
um so elmo run the training one left to

1:17:37.360,1:17:41.040
right language model

1:17:38.800,1:17:42.400
um also train the second language model

1:17:41.040,1:17:45.679
which operates

1:17:42.400,1:17:46.400
in the reverse direction so this is like

1:17:45.679,1:17:48.000
um

1:17:46.400,1:17:51.040
so it's the last word in document and it

1:17:48.000,1:17:53.600
keeps trying to create the previous ones

1:17:51.040,1:17:55.840
and then you get word recitation by

1:17:53.600,1:17:57.920
concatenating the output layers of your

1:17:55.840,1:18:00.239
left right model and your right left

1:17:57.920,1:18:00.239
model

1:18:00.560,1:18:05.199
uh so this model is in some ways better

1:18:04.080,1:18:07.679
in that like now your word

1:18:05.199,1:18:09.280
representations

1:18:07.679,1:18:11.840
can't condition on local context and are

1:18:09.280,1:18:13.840
right with context

1:18:11.840,1:18:16.239
and that's really helpful for lots of

1:18:13.840,1:18:16.239
tasks

1:18:16.480,1:18:19.920
but it's still kind of limited and that

1:18:18.560,1:18:22.320
you don't really much like interactions

1:18:19.920,1:18:24.239
in these contexts so these

1:18:22.320,1:18:25.440
um you get this shallow kind of

1:18:24.239,1:18:27.760
concatenation of left

1:18:25.440,1:18:29.199
representation the right representation

1:18:27.760,1:18:30.719
and what you really do is having like

1:18:29.199,1:18:34.000
rich interactions between the left

1:18:30.719,1:18:34.000
context and the right context

1:18:34.239,1:18:38.159
right um and all this brings me to birth

1:18:37.120,1:18:41.199
which is

1:18:38.159,1:18:44.320
uh maybe you've heard of which has made

1:18:41.199,1:18:44.320
a very big difference in lp

1:18:45.520,1:18:49.679
um so

1:18:50.560,1:18:54.320
bit actually looks quite a lot like word

1:18:52.480,1:18:56.640
effect is basically a fillable blanks

1:18:54.320,1:18:59.199
task so you take some text

1:18:56.640,1:19:00.480
you hide some tokens by masking them out

1:18:59.199,1:19:01.520
and then you just try and fill it in the

1:19:00.480,1:19:04.159
mask so

1:19:01.520,1:19:05.040
here's text like something is a golden

1:19:04.159,1:19:09.840
something muppets

1:19:05.040,1:19:09.840
and you fill in there yeah

1:19:20.480,1:19:23.600
the thing i want you to notice is

1:19:21.760,1:19:24.480
firstly it actually looks quite a lot

1:19:23.600,1:19:27.440
like word to back

1:19:24.480,1:19:29.280
um wordsworth was also given some text

1:19:27.440,1:19:33.360
fill in the blanks

1:19:29.280,1:19:36.000
um the reasons works much better is that

1:19:33.360,1:19:37.840
in words event you would just had this

1:19:36.000,1:19:40.560
linear projection like

1:19:37.840,1:19:41.280
including the context words whereas you

1:19:40.560,1:19:43.520
have them

1:19:41.280,1:19:46.239
a very large transformer uh which look

1:19:43.520,1:19:50.159
in much more context and well much

1:19:46.239,1:19:52.560
lower interactions in that context

1:19:50.159,1:19:54.719
so there is a question here how are

1:19:52.560,1:19:58.800
contextual representations maintained

1:19:54.719,1:20:05.840
when fine-tuning for a specific task

1:19:58.800,1:20:05.840
um how are they maintained um

1:20:07.280,1:20:11.520
i guess um it's not clear they are

1:20:10.480,1:20:16.480
maintained um

1:20:11.520,1:20:16.480
so when you find your particular task

1:20:16.840,1:20:21.360
you kind of hook them all to learn

1:20:19.760,1:20:23.280
enough general stuff that language

1:20:21.360,1:20:25.199
the pre-trained task and then doing the

1:20:23.280,1:20:27.199
fine tuning probably i guess it's

1:20:25.199,1:20:29.679
forgetting a lot of stuff but it doesn't

1:20:27.199,1:20:32.719
need to solve this

1:20:29.679,1:20:34.960
particular task so

1:20:32.719,1:20:37.360
if you're fighting a sentiment analysis

1:20:34.960,1:20:38.400
or something it could probably

1:20:37.360,1:20:40.719
probably kind of lose a lot of this

1:20:38.400,1:20:47.679
information during fine tuning

1:20:40.719,1:20:50.719
that seems fine thanks

1:20:47.679,1:20:50.719
okay um

1:20:52.560,1:20:56.880
so but it worked very well um they gave

1:20:55.600,1:20:57.600
like quite large improvements on a bunch

1:20:56.880,1:20:59.440
of tasks

1:20:57.600,1:21:01.440
um it was actually achieving the

1:20:59.440,1:21:04.400
performance of humans or at least

1:21:01.440,1:21:05.360
humans approximated by amazon mechanical

1:21:04.400,1:21:08.400
tech

1:21:05.360,1:21:10.719
on a bunch of important uh questionnaire

1:21:08.400,1:21:12.239
benchmarks

1:21:10.719,1:21:14.560
but um burt was definitely not the end

1:21:12.239,1:21:16.000
of the story here um

1:21:14.560,1:21:18.719
but i've lots of people very excited

1:21:16.000,1:21:22.960
about self supervised training

1:21:18.719,1:21:25.360
um so just to quickly summarize details

1:21:22.960,1:21:25.360
there so

1:21:25.760,1:21:30.400
it's very simple model is just going to

1:21:27.760,1:21:33.760
mask out 15 of the tokens

1:21:30.400,1:21:33.760
and try and fill in the masks

1:21:34.880,1:21:43.600
um to build on that um doesn't work at

1:21:39.840,1:21:48.480
facebook uh yeah by led by year hanlon

1:21:43.600,1:21:48.480
which looked at scaling up birds um

1:21:49.040,1:21:53.679
so can you tell the combination actually

1:21:52.080,1:21:55.440
actually has second pre-training

1:21:53.679,1:21:56.719
objective which we showed didn't

1:21:55.440,1:21:58.800
actually help

1:21:56.719,1:22:00.000
so can i read can i ask a question for

1:21:58.800,1:22:02.080
the slide

1:22:00.000,1:22:03.280
so there there were three bars i think i

1:22:02.080,1:22:06.000
missed one point

1:22:03.280,1:22:08.239
the the dark blue what is the dark blue

1:22:06.000,1:22:10.320
so we have amazon twerk there

1:22:08.239,1:22:12.880
thank you sorry i said that um dark blue

1:22:10.320,1:22:16.080
hair is previously that so

1:22:12.880,1:22:18.000
okay which was um

1:22:16.080,1:22:19.679
these models were probably elmo which is

1:22:18.000,1:22:22.159
oh yeah okay

1:22:19.679,1:22:23.600
so previously i was definitely using

1:22:22.159,1:22:27.920
cell surprise training

1:22:23.600,1:22:29.040
but uh but improved relevant by having

1:22:27.920,1:22:32.719
this kind of like

1:22:29.040,1:22:34.639
i see and grew actually it's a benchmark

1:22:32.719,1:22:37.840
that we've been uh creating here at

1:22:34.639,1:22:38.480
nyu exactly some students were involved

1:22:37.840,1:22:40.880
yeah so

1:22:38.480,1:22:42.239
yeah glue is a big benchmark it's very

1:22:40.880,1:22:45.199
important

1:22:42.239,1:22:46.880
okay um so to beat but it turned out all

1:22:45.199,1:22:49.679
you had to do was firstly

1:22:46.880,1:22:50.800
simplify training objective then just

1:22:49.679,1:22:54.480
scale it up so

1:22:50.800,1:22:58.400
scaling up here means bigger batch sizes

1:22:54.480,1:22:58.400
uh huge numbers of gpus

1:22:58.480,1:23:04.560
more free training text and

1:23:01.679,1:23:06.639
then um you get very large gains on top

1:23:04.560,1:23:06.639
of

1:23:10.880,1:23:16.800
work so yellow here is then this new

1:23:14.000,1:23:16.800
reversal model

1:23:17.280,1:23:22.320
and uh actually roberta

1:23:21.199,1:23:25.120
the question answering is like

1:23:22.320,1:23:26.880
superhuman by quite a few points and

1:23:25.120,1:23:28.400
also on this blue benchmark from nyu is

1:23:26.880,1:23:31.199
also uh

1:23:28.400,1:23:31.199
outflowed people

1:23:31.679,1:23:34.719
and this isn't really about doing

1:23:32.880,1:23:36.400
anything smart it's just

1:23:34.719,1:23:39.040
taking self supervised training and

1:23:36.400,1:23:42.080
doing it more

1:23:39.040,1:23:44.159
alright um how why why do you say like

1:23:42.080,1:23:46.239
if you go on this slide here so there is

1:23:44.159,1:23:48.560
a very large improvement between

1:23:46.239,1:23:49.920
uh bert and then roberta in the gloom

1:23:48.560,1:23:52.639
but not such a

1:23:49.920,1:23:54.080
huge uh change maybe in the squad or is

1:23:52.639,1:23:58.239
it just a zooming factor

1:23:54.080,1:23:59.600
i'm like um

1:23:58.239,1:24:03.440
maybe it's just a zooming factor right

1:23:59.600,1:24:06.000
those bars on the left are taller maybe

1:24:03.440,1:24:06.000
yeah i think

1:24:06.960,1:24:10.320
maybe the scales distorting i think the

1:24:09.600,1:24:14.000
point is

1:24:10.320,1:24:14.000
if compared to human performance um

1:24:14.880,1:24:19.760
i know um but what 0.6 points best of

1:24:18.239,1:24:22.080
the people whereas

1:24:19.760,1:24:23.520
roberta is uh three and a half points

1:24:22.080,1:24:26.400
better

1:24:23.520,1:24:28.880
so by that metric is actually quite a

1:24:26.400,1:24:28.880
big jump

1:24:31.040,1:24:36.400
okay uh so

1:24:34.159,1:24:37.679
let's quickly discuss a few of the other

1:24:36.400,1:24:41.280
things people have

1:24:37.679,1:24:45.520
been doing still surprise training and

1:24:41.280,1:24:47.040
so there's one called excel now um

1:24:45.520,1:24:48.639
basically so input when you predict all

1:24:47.040,1:24:50.159
the mass tokens you predict

1:24:48.639,1:24:52.080
all the masks conditionally

1:24:50.159,1:24:54.000
independently

1:24:52.080,1:24:56.080
um excel net has a trick lets you

1:24:54.000,1:24:59.280
contact these mass tokens auto

1:24:56.080,1:25:00.480
regressively but in random order

1:24:59.280,1:25:02.400
and they claim some improvements from

1:25:00.480,1:25:05.840
doing that

1:25:02.400,1:25:07.280
it's also uh spam dirt which uh rather

1:25:05.840,1:25:07.760
than masking out words you're gonna mask

1:25:07.280,1:25:11.280
out

1:25:07.760,1:25:12.560
a sequence of consecutive words um there

1:25:11.280,1:25:16.080
is electron which

1:25:12.560,1:25:17.679
um rather than

1:25:16.080,1:25:19.360
masking words we're going to substitute

1:25:17.679,1:25:21.440
words with

1:25:19.360,1:25:23.120
sort of similar ones and then have a

1:25:21.440,1:25:24.000
binary classification problem to tell

1:25:23.120,1:25:27.280
you which

1:25:24.000,1:25:31.280
word's changed or not uh

1:25:27.280,1:25:34.639
it's albert which is um burt but you

1:25:31.280,1:25:37.280
title the weights across layers um also

1:25:34.639,1:25:39.040
um xlr and xlr which looking to

1:25:37.280,1:25:40.400
do this multilingually it turns out

1:25:39.040,1:25:42.560
basically you run the

1:25:40.400,1:25:44.320
pre-training objective but rather's

1:25:42.560,1:25:46.320
feeding in english text you

1:25:44.320,1:25:47.840
feed in text in every language you can

1:25:46.320,1:25:51.600
find it does a great job

1:25:47.840,1:25:51.600
learning cross-linked structure

1:25:52.840,1:25:58.480
um

1:25:55.360,1:26:00.960
the key point what you take from this is

1:25:58.480,1:26:02.560
really like these are all kind of

1:26:00.960,1:26:08.320
variation

1:26:02.560,1:26:09.920
um there's

1:26:08.320,1:26:11.840
but in the end like lots of different

1:26:09.920,1:26:12.560
things work and the important thing is

1:26:11.840,1:26:13.840
you have

1:26:12.560,1:26:15.920
big models you have bi-directional

1:26:13.840,1:26:19.120
interactions between the words

1:26:15.920,1:26:19.520
and you uh if anything the scale you do

1:26:19.120,1:26:23.840
this

1:26:19.520,1:26:23.840
is the most important thing

1:26:24.560,1:26:30.400
um so

1:26:27.600,1:26:31.760
one limitation these models i described

1:26:30.400,1:26:33.440
is they're only doing kind of text

1:26:31.760,1:26:37.840
classification problems

1:26:33.440,1:26:37.840
but often we'll want to do

1:26:38.960,1:26:41.280
problems where the output isn't the

1:26:40.080,1:26:43.120
classification problem is actually

1:26:41.280,1:26:45.199
output some more text

1:26:43.120,1:26:46.800
uh pre-training for sequence sequence

1:26:45.199,1:26:49.840
modeling

1:26:46.800,1:26:51.600
uh two papers came out about the same

1:26:49.840,1:26:52.960
time for this one which i was involved

1:26:51.600,1:26:57.600
in um

1:26:52.960,1:26:57.600
called birth and t5 um

1:26:58.159,1:27:01.760
so these models basically are going to

1:27:00.080,1:27:04.800
pre-train sequence sequence models by

1:27:01.760,1:27:06.880
denoising text

1:27:04.800,1:27:08.159
um the tree training objective looks

1:27:06.880,1:27:10.560
kind of like that basically all you're

1:27:08.159,1:27:14.560
going to do

1:27:10.560,1:27:15.199
is take some text corrupt it somehow by

1:27:14.560,1:27:17.760
applying

1:27:15.199,1:27:18.320
some kind of masking scheme and then

1:27:17.760,1:27:19.920
rather than

1:27:18.320,1:27:22.000
predict fill in the blanks you're going

1:27:19.920,1:27:25.280
to feed the corrupted text

1:27:22.000,1:27:28.480
into a cc model and try and predict

1:27:25.280,1:27:28.480
the complete outputs

1:27:28.560,1:27:34.800
and um

1:27:32.560,1:27:36.080
and this is kind of nice because then

1:27:34.800,1:27:37.840
you can actually go beyond just masking

1:27:36.080,1:27:41.040
text you can apply like any

1:27:37.840,1:27:42.000
random uh corruption thing that you want

1:27:41.040,1:27:43.679
so for example you can

1:27:42.000,1:27:45.280
shuffle sentences or delete whole

1:27:43.679,1:27:48.400
phrases or

1:27:45.280,1:27:50.320
it's a new phrases and the cc framework

1:27:48.400,1:27:52.639
is very flexible

1:27:50.320,1:27:53.520
um but it turns out just doing simple

1:27:52.639,1:27:56.880
masking actually

1:27:53.520,1:27:56.880
works about as well as anything else

1:27:57.920,1:28:01.760
um and then if you do this and as well

1:28:01.040,1:28:03.840
as like it

1:28:01.760,1:28:05.679
doing well things benchmarks like squad

1:28:03.840,1:28:07.280
and blue which classification benchmarks

1:28:05.679,1:28:10.639
you can also

1:28:07.280,1:28:14.159
get stage api results on um

1:28:10.639,1:28:17.440
tasks like summarization so um

1:28:14.159,1:28:17.440
where the output is attached so

1:28:19.840,1:28:22.480
on the left here we've got some length

1:28:20.960,1:28:24.400
of document we fight in we ask them all

1:28:22.480,1:28:27.600
to produce some kind of summary of this

1:28:24.400,1:28:28.960
and uh it is a great job like actually

1:28:27.600,1:28:30.239
uses context from across the whole

1:28:28.960,1:28:32.800
document and solves things like

1:28:30.239,1:28:33.920
co-reference and

1:28:32.800,1:28:37.360
generally as far as you can tell seems

1:28:33.920,1:28:37.360
to show some understanding of the inputs

1:28:38.320,1:28:46.080
um okay we're running out of time

1:28:42.800,1:28:48.880
um so briefly

1:28:46.080,1:28:50.400
um i don't think it's the end story like

1:28:48.880,1:28:52.960
the nlp is now solved

1:28:50.400,1:28:53.760
um a few open questions which i think

1:28:52.960,1:28:56.639
are interesting

1:28:53.760,1:28:58.000
including how do we integrate like

1:28:56.639,1:28:58.719
background knowledge into this do we

1:28:58.000,1:29:00.239
just want

1:28:58.719,1:29:02.800
these models to try and memorize the

1:29:00.239,1:29:06.320
whole internet or should we

1:29:02.800,1:29:06.320
build memory mechanisms somehow

1:29:06.400,1:29:10.239
uh as someone brought up earlier how do

1:29:08.239,1:29:12.080
we model long documents

1:29:10.239,1:29:13.440
we're typically doing 512 tokens here

1:29:12.080,1:29:17.199
how can we

1:29:13.440,1:29:20.000
do say a whole book at once

1:29:17.199,1:29:21.600
um one unsatisfying thing about this is

1:29:20.000,1:29:22.960
like we have like the same model

1:29:21.600,1:29:24.960
architecture can solve all kinds of

1:29:22.960,1:29:25.760
problems but it tends to not be able to

1:29:24.960,1:29:27.280
solve

1:29:25.760,1:29:28.880
all these problems at once and typically

1:29:27.280,1:29:30.000
you fine-tune a separate model for each

1:29:28.880,1:29:31.040
task

1:29:30.000,1:29:34.480
it would be great if you actually have

1:29:31.040,1:29:34.480
like one model solves everything

1:29:34.719,1:29:41.520
um and

1:29:38.400,1:29:42.880
um it's kind of related to that like we

1:29:41.520,1:29:44.960
basically get human level phones the

1:29:42.880,1:29:47.040
main task where you have say a hundred

1:29:44.960,1:29:49.120
thousand

1:29:47.040,1:29:50.239
uh labeled examples you're learning from

1:29:49.120,1:29:51.440
but

1:29:50.239,1:29:53.920
can we build miles will do well with

1:29:51.440,1:29:56.880
like 1000 or 10 or 1

1:29:53.920,1:29:56.880
labeled examples

1:29:57.280,1:29:59.760
and finally that people bring these

1:29:58.560,1:30:01.040
questions that's where these models are

1:29:59.760,1:30:02.560
just

1:30:01.040,1:30:06.719
actually understanding language i was

1:30:02.560,1:30:09.760
really good at breaking benchmarks

1:30:06.719,1:30:13.199
okay so to wrap up this

1:30:09.760,1:30:16.180
uh lecture um i think the main

1:30:13.199,1:30:18.480
takeaways from this uh um

1:30:16.180,1:30:20.239
[Music]

1:30:18.480,1:30:21.760
these kind of low bias models like

1:30:20.239,1:30:22.080
transformers work great we shouldn't try

1:30:21.760,1:30:24.000
to

1:30:22.080,1:30:25.120
explicitly model linguistic direction we

1:30:24.000,1:30:26.719
should have

1:30:25.120,1:30:28.400
very express models and show them lots

1:30:26.719,1:30:32.560
of text and let them

1:30:28.400,1:30:35.760
learn whatever structure they need um

1:30:32.560,1:30:39.199
predicting words and texts is a great uh

1:30:35.760,1:30:40.800
unsupervised learning objective um

1:30:39.199,1:30:42.239
but if you want to understand what's

1:30:40.800,1:30:42.800
crucial to like incorporate words in

1:30:42.239,1:30:46.239
context

1:30:42.800,1:30:48.000
in particular bi-directional context

1:30:46.239,1:30:50.719
okay so that's all i have to thank you

1:30:48.000,1:30:50.719
very much for listening

1:30:50.800,1:30:54.480
let's see if we have some questions now

1:30:52.400,1:30:59.600
i think there will be

1:30:54.480,1:30:59.600
several thank you mike

1:31:00.000,1:31:03.440
yeah there's a whole bunch of

1:31:01.840,1:31:06.560
discussions while we while you're

1:31:03.440,1:31:08.800
talking okay links to various papers

1:31:06.560,1:31:10.080
and explanations of various concepts in

1:31:08.800,1:31:13.600
the background

1:31:10.080,1:31:16.239
okay um any more questions uh yeah i

1:31:13.600,1:31:16.719
had one um on one of the open questions

1:31:16.239,1:31:18.719
it's

1:31:16.719,1:31:20.000
like understanding whether or not these

1:31:18.719,1:31:24.560
models are

1:31:20.000,1:31:26.639
actually uh understanding the language

1:31:24.560,1:31:28.639
what are some ways that exist right now

1:31:26.639,1:31:31.920
to quantify and measure that

1:31:28.639,1:31:37.199
um and how like how

1:31:31.920,1:31:37.199
how would we do that yeah okay so

1:31:38.960,1:31:43.199
what typically happens is someone says i

1:31:40.960,1:31:43.199
know

1:31:43.760,1:31:47.520
these models aren't signing language if

1:31:45.360,1:31:48.159
they could they'd be able to solve this

1:31:47.520,1:31:49.600
new task

1:31:48.159,1:31:51.760
that they're introducing then they

1:31:49.600,1:31:54.560
introduce some

1:31:51.760,1:31:55.040
new tasks which they can't do and then

1:31:54.560,1:31:57.199
say

1:31:55.040,1:31:58.639
bert isn't doing it then next week

1:31:57.199,1:32:00.000
someone trains a bigger model

1:31:58.639,1:32:01.920
and then actually gets human performance

1:32:00.000,1:32:05.440
on this task

1:32:01.920,1:32:05.440
and i think really

1:32:05.920,1:32:10.000
what's happening is like some people

1:32:07.040,1:32:10.000
just have intuitions that

1:32:10.639,1:32:15.840
this kind of these neural networks can't

1:32:14.159,1:32:17.840
be understanding language

1:32:15.840,1:32:19.040
and they must just be gaming data sets

1:32:17.840,1:32:21.360
somehow

1:32:19.040,1:32:23.120
and the extent that these models do well

1:32:21.360,1:32:24.480
there must be kind of weird biases in

1:32:23.120,1:32:26.080
our data sets and make

1:32:24.480,1:32:28.080
the moles can exploit without really

1:32:26.080,1:32:30.639
understanding anything

1:32:28.080,1:32:31.840
um and it's definitely true that like a

1:32:30.639,1:32:35.760
lot of my data sets

1:32:31.840,1:32:35.760
do have biases in them and like it's

1:32:37.679,1:32:42.639
kind of hard to make ones that don't do

1:32:38.880,1:32:44.480
it thanks a lot skill but

1:32:42.639,1:32:46.080
on the other hand it's like people are

1:32:44.480,1:32:48.080
failing to produce good cancer examples

1:32:46.080,1:32:51.679
so what these models can't do

1:32:48.080,1:32:53.679
like basically

1:32:51.679,1:32:55.280
sorry it's a good example in recent

1:32:53.679,1:32:58.480
times was the

1:32:55.280,1:32:59.840
winner glad schema results where

1:32:58.480,1:33:01.360
you know winograd schemas are those

1:32:59.840,1:33:03.280
sentences that are ambiguous and there

1:33:01.360,1:33:04.960
is a reference there is a

1:33:03.280,1:33:06.960
pronoun that refers to one of the words

1:33:04.960,1:33:08.719
and you can tell

1:33:06.960,1:33:10.239
which word the pronoun refers to unless

1:33:08.719,1:33:11.520
you know something about how the word

1:33:10.239,1:33:14.719
works right so

1:33:11.520,1:33:16.239
the standard example is uh the trophy

1:33:14.719,1:33:17.120
doesn't fit in the suitcase because it's

1:33:16.239,1:33:18.400
too large

1:33:17.120,1:33:20.560
or the trophy doesn't fit in the

1:33:18.400,1:33:23.360
suitcase because it's too small

1:33:20.560,1:33:24.000
and you know in in one case the the

1:33:23.360,1:33:26.239
trophy

1:33:24.000,1:33:27.520
refers to the the the pronoun refers to

1:33:26.239,1:33:27.920
the trophy in the other case it refers

1:33:27.520,1:33:30.639
to the

1:33:27.920,1:33:32.239
the suitcase and there was a list of

1:33:30.639,1:33:34.800
those and people

1:33:32.239,1:33:36.320
created a data set of those things and

1:33:34.800,1:33:39.520
until about two years ago

1:33:36.320,1:33:42.560
the best results were around 60

1:33:39.520,1:33:46.000
for computers humans do 95 or something

1:33:42.560,1:33:47.760
but um the best uh uh

1:33:46.000,1:33:49.040
the best you know artificial systems

1:33:47.760,1:33:51.679
were getting about 60

1:33:49.040,1:33:52.400
and now i think it's about 90 percent

1:33:51.679,1:33:54.080
yeah

1:33:52.400,1:33:55.280
right yeah something like that right you

1:33:54.080,1:33:55.679
don't even get any training dates for

1:33:55.280,1:33:59.199
these

1:33:55.679,1:34:02.400
this is just a purely unsupervised

1:33:59.199,1:34:04.320
problem right and so

1:34:02.400,1:34:05.920
so the question is you know it's clear

1:34:04.320,1:34:07.360
that those systems have learned

1:34:05.920,1:34:10.400
something about

1:34:07.360,1:34:11.679
uh the role of objects and you know

1:34:10.400,1:34:15.120
a little bit about how the world works

1:34:11.679,1:34:17.840
by just observing statistics about text

1:34:15.120,1:34:18.719
but it's relatively superficial it's not

1:34:17.840,1:34:21.280
um

1:34:18.719,1:34:23.679
i mean you know as it's pretty obvious

1:34:21.280,1:34:25.440
when you look at text that's generated

1:34:23.679,1:34:27.360
uh you know we're talking about unicorn

1:34:25.440,1:34:29.280
and then the first sentence is uh

1:34:27.360,1:34:30.159
unicorns has four horns right which of

1:34:29.280,1:34:31.679
course doesn't make sense because

1:34:30.159,1:34:32.880
unicorns have only one

1:34:31.679,1:34:34.800
that's kind of the point of being a

1:34:32.880,1:34:36.480
unicorn so um

1:34:34.800,1:34:39.199
so the whole idea of i mean the whole

1:34:36.480,1:34:41.520
con problem of learning common sense

1:34:39.199,1:34:42.719
uh has not been solved very far from it

1:34:41.520,1:34:44.239
but those systems but they work

1:34:42.719,1:34:46.239
surprisingly well i mean it's

1:34:44.239,1:34:47.280
surprisingly it's surprising how far you

1:34:46.239,1:34:49.490
can go with

1:34:47.280,1:34:50.800
just you know looking at text

1:34:49.490,1:34:52.239
[Music]

1:34:50.800,1:34:53.920
yeah i mean learning common sounds super

1:34:52.239,1:34:55.199
hard because in some sense the things

1:34:53.920,1:34:56.480
you want to learn

1:34:55.199,1:34:58.639
are things that aren't written down like

1:34:56.480,1:35:01.119
no one ever writes down

1:34:58.639,1:35:02.639
common sense knowledge yeah probably no

1:35:01.119,1:35:04.480
one ever writes down like a unicorn has

1:35:02.639,1:35:08.560
exactly one-on-one and not for i mean

1:35:04.480,1:35:10.560
it's just because everyone knows that um

1:35:08.560,1:35:12.080
so probably there are limitations to

1:35:10.560,1:35:14.800
what you can learn from just

1:35:12.080,1:35:15.679
looking at text but can you can you tell

1:35:14.800,1:35:17.360
us something about the

1:35:15.679,1:35:18.560
the word i mean about some of the work

1:35:17.360,1:35:20.560
you're doing on sort of grounded

1:35:18.560,1:35:24.880
language

1:35:20.560,1:35:26.560
uh sure yeah so i mean um

1:35:24.880,1:35:28.800
i put nothing back grounding in this um

1:35:26.560,1:35:31.840
but there's a whole

1:35:28.800,1:35:34.000
interesting topic and so i think it's

1:35:31.840,1:35:35.440
really interesting trying

1:35:34.000,1:35:37.280
no no i'm just like producing texts they

1:35:35.440,1:35:38.080
create people don't use text because

1:35:37.280,1:35:41.119
it's like

1:35:38.080,1:35:44.480
it's a recitation of the world um

1:35:41.119,1:35:46.080
so one type of guy's really interested

1:35:44.480,1:35:49.199
in like trying to like kind of

1:35:46.080,1:35:50.800
ground dialogue usage and goals so um

1:35:49.199,1:35:52.400
run some people like chit chat systems

1:35:50.800,1:35:54.080
that talk to each other

1:35:52.400,1:35:56.960
or talk to people to have a conversation

1:35:54.080,1:35:59.600
like can you build systems

1:35:56.960,1:36:00.719
where you try to achieve some goal um we

1:35:59.600,1:36:01.840
had some work a couple years ago and

1:36:00.719,1:36:03.920
doing a

1:36:01.840,1:36:05.679
this in the context of negotiations so

1:36:03.920,1:36:09.040
trying to

1:36:05.679,1:36:10.080
um there's two of you which are

1:36:09.040,1:36:11.520
trying to have a conversation just kind

1:36:10.080,1:36:12.560
of crank on some agreement with each

1:36:11.520,1:36:15.199
other

1:36:12.560,1:36:16.159
um and the only way you can come to

1:36:15.199,1:36:17.600
agreement is by

1:36:16.159,1:36:19.199
having a dialogue in natural language

1:36:17.600,1:36:20.639
and there's like some outcomes which are

1:36:19.199,1:36:22.880
good for use and what's good for them

1:36:20.639,1:36:26.159
you have to find some compromise

1:36:22.880,1:36:26.800
um and then yeah i'm kind of interested

1:36:26.159,1:36:29.119
in the setting

1:36:26.800,1:36:29.119
because

1:36:29.920,1:36:34.960
um yeah it seems like

1:36:33.520,1:36:36.400
you actually using length for a purpose

1:36:34.960,1:36:37.760
is gonna be really crucial to a really

1:36:36.400,1:36:41.199
understanding

1:36:37.760,1:36:42.320
things like i think

1:36:41.199,1:36:43.440
that's going to get hints like there's

1:36:42.320,1:36:45.280
limits to what we'll learn from just

1:36:43.440,1:36:47.760
like purely observational use language

1:36:45.280,1:36:49.440
and so just purely

1:36:47.760,1:36:51.119
seeing text out there in the world that

1:36:49.440,1:36:53.360
other people wrote like really

1:36:51.119,1:36:54.960
to understand things you want to be

1:36:53.360,1:36:56.159
agents which

1:36:54.960,1:36:57.840
are using language to try and choose

1:36:56.159,1:36:59.360
some goal and interact with people and

1:36:57.840,1:37:00.960
seeing what works and

1:36:59.360,1:37:03.199
learning from that kind of signal as

1:37:00.960,1:37:05.280
well um

1:37:03.199,1:37:06.639
maybe that's it's just the cherry on the

1:37:05.280,1:37:08.800
icing on the cake or whatever but i

1:37:06.639,1:37:13.760
think that's

1:37:08.800,1:37:13.760
it is that you need a cherry

1:37:17.520,1:37:22.560
more questions from the audience come on

1:37:19.360,1:37:26.080
guys don't be too shy

1:37:22.560,1:37:28.239
uh i have a question uh

1:37:26.080,1:37:29.199
the first point on the open questions

1:37:28.239,1:37:31.920
how should we

1:37:29.199,1:37:33.760
integrate world knowledge so uh the way

1:37:31.920,1:37:36.560
i i was thinking about is that

1:37:33.760,1:37:37.280
these billion parameter transformers

1:37:36.560,1:37:39.280
have

1:37:37.280,1:37:40.719
so much information about the world in

1:37:39.280,1:37:44.320
them and then if we

1:37:40.719,1:37:47.119
try to fine-tune or train this model

1:37:44.320,1:37:49.280
on some new data could we like forget

1:37:47.119,1:37:51.600
some of the earlier concepts that

1:37:49.280,1:37:53.199
uh this model had learnt and how would

1:37:51.600,1:37:56.400
we like quantify

1:37:53.199,1:37:59.119
what concepts like

1:37:56.400,1:38:00.719
has the model forgotten apart from the

1:37:59.119,1:38:03.920
validation set

1:38:00.719,1:38:05.360
does that make sense um

1:38:03.920,1:38:06.719
yeah so probably you will forget i mean

1:38:05.360,1:38:07.840
probably if you fine-tune this model to

1:38:06.719,1:38:08.639
do

1:38:07.840,1:38:11.280
something that doesn't need well

1:38:08.639,1:38:14.400
knowledgeable happily forget

1:38:11.280,1:38:15.600
all the knowledge you told it um

1:38:14.400,1:38:17.199
i mean there's some evidence these moles

1:38:15.600,1:38:19.920
are like memorizing quite a lot of facts

1:38:17.199,1:38:22.480
so there's a remarkable

1:38:19.920,1:38:24.080
uh result recently from this paper this

1:38:22.480,1:38:26.400
google system called t5 which i think is

1:38:24.080,1:38:27.280
12 billion parameters

1:38:26.400,1:38:28.719
and it's just trained in a

1:38:27.280,1:38:29.679
self-supervised way and if you have

1:38:28.719,1:38:33.520
people

1:38:29.679,1:38:34.320
and then you um just fine tune to answer

1:38:33.520,1:38:35.679
questions

1:38:34.320,1:38:37.760
which good questions about anything but

1:38:35.679,1:38:39.199
you don't show it any

1:38:37.760,1:38:40.560
you don't show up wikipedia or something

1:38:39.199,1:38:41.679
to let you know you just like see what's

1:38:40.560,1:38:43.360
memorized and

1:38:41.679,1:38:45.119
you can test how much knowledge is in

1:38:43.360,1:38:48.320
the model from that

1:38:45.119,1:38:48.800
and um it's not safety after that but it

1:38:48.320,1:38:52.320
like

1:38:48.800,1:38:53.840
it's kind of scarily good it's like

1:38:52.320,1:38:55.360
it turns out if you have 12 billion

1:38:53.840,1:38:57.360
parameters you train for a long time you

1:38:55.360,1:38:58.800
can't just

1:38:57.360,1:39:00.560
fit huge numbers of facts into these

1:38:58.800,1:39:01.520
levels

1:39:00.560,1:39:03.600
i'm not sure it's like the most

1:39:01.520,1:39:05.199
desirable way necessarily to memorize

1:39:03.600,1:39:08.800
knowledge but

1:39:05.199,1:39:13.840
um seems

1:39:08.800,1:39:13.840
somewhat effective

1:39:14.080,1:39:17.679
okay that was it thank you everyone for

1:39:17.040,1:39:21.040
attending

1:39:17.679,1:39:22.320
thank you so much mike for uh for giving

1:39:21.040,1:39:24.400
a guest lecture

1:39:22.320,1:39:26.560
um it's good to hear that stuff from the

1:39:24.400,1:39:29.920
horse's mouth

1:39:26.560,1:39:33.600
and we'll see

1:39:29.920,1:39:34.639
see everyone again next uh next week

1:39:33.600,1:39:35.440
we're gonna we'll actually tomorrow

1:39:34.639,1:39:36.880
right tomorrow we're gonna be

1:39:35.440,1:39:39.040
implementing everything from scratch

1:39:36.880,1:39:41.040
don't forget so tomorrow you get the

1:39:39.040,1:39:41.520
gory details from the code side of all

1:39:41.040,1:39:43.840
of this

1:39:41.520,1:39:45.199
and then uh monday you'll hear from

1:39:43.840,1:39:48.560
you'll hear about

1:39:45.199,1:39:50.400
graph neural nets from the vibration

1:39:48.560,1:39:52.000
actually about graph neural net and

1:39:50.400,1:39:53.920
graph knowledge is that

1:39:52.000,1:39:55.360
is graph knowledge used for language as

1:39:53.920,1:39:57.440
well somehow because

1:39:55.360,1:39:58.560
right i i don't know i have not really

1:39:57.440,1:40:00.320
uh

1:39:58.560,1:40:01.760
knowledgeable about this part of the

1:40:00.320,1:40:03.520
field well so

1:40:01.760,1:40:05.360
you can view to some extent you can view

1:40:03.520,1:40:06.080
all the those supervised training in

1:40:05.360,1:40:08.960
text

1:40:06.080,1:40:10.800
uh like what to vac uh bert et cetera

1:40:08.960,1:40:13.520
they use a graph and the graph is

1:40:10.800,1:40:15.119
how uh you know how often two words

1:40:13.520,1:40:17.760
appear next to each other

1:40:15.119,1:40:18.320
or some distance away from each other in

1:40:17.760,1:40:20.480
the text

1:40:18.320,1:40:22.480
that's you know the graph of similarity

1:40:20.480,1:40:24.960
between words basically is determined by

1:40:22.480,1:40:26.080
how far you know how often they're they

1:40:24.960,1:40:28.000
appear nearby

1:40:26.080,1:40:30.000
yeah that's that's when you decide to

1:40:28.000,1:40:31.920
put them in the input of a neural net

1:40:30.000,1:40:34.159
because they appear you know within the

1:40:31.920,1:40:36.719
sequence so you can think of

1:40:34.159,1:40:37.760
those those those are supervised

1:40:36.719,1:40:39.600
learning systems as

1:40:37.760,1:40:40.960
basically a very simple form of graph

1:40:39.600,1:40:42.159
neural net

1:40:40.960,1:40:44.239
well the graph always has the same

1:40:42.159,1:40:45.040
structure it's always linear but and it

1:40:44.239,1:40:47.280
always

1:40:45.040,1:40:49.600
uh indicates your your neighbors in a

1:40:47.280,1:40:49.600
text

1:40:50.719,1:40:55.000
all right thank you so much everyone

1:40:52.719,1:40:58.000
have a good evening

1:40:55.000,1:40:58.000
bye-bye

