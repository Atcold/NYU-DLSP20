0:00:00.030,0:00:04.920
all right so foundation of deep learning

0:00:01.860,0:00:07.109
me again all right

0:00:04.920,0:00:09.080
yeah so again do interrupt me is going

0:00:07.109,0:00:11.969
to be the last class we have in person

0:00:09.080,0:00:12.750
we have a very bad situation especially

0:00:11.969,0:00:14.639
in Italy

0:00:12.750,0:00:16.529
people are dying we don't have any more

0:00:14.639,0:00:18.930
beds in the hospitals we don't have

0:00:16.529,0:00:21.449
doctors doctor doctors are working like

0:00:18.930,0:00:23.580
24/7 and they are going home and they

0:00:21.449,0:00:25.260
are effecting their own families so it's

0:00:23.580,0:00:28.619
like a really bad situation right now

0:00:25.260,0:00:30.810
back home and it looks like we are two

0:00:28.619,0:00:34.950
weeks away from that situation under

0:00:30.810,0:00:38.129
here so just wash your hands try not to

0:00:34.950,0:00:42.950
go in very crowded places stay healthy

0:00:38.129,0:00:42.950
okay please a third class

0:00:43.550,0:00:49.260
all right self or unsupervised learning

0:00:46.789,0:00:50.520
generative models capabilities so here

0:00:49.260,0:00:52.710
I'm going to be giving you some eye

0:00:50.520,0:00:54.870
candies such that you can get hungry and

0:00:52.710,0:00:56.430
then I can feed you with the first part

0:00:54.870,0:00:58.199
of this lesson this lesson is gonna be

0:00:56.430,0:01:00.329
split in two parts half is gonna be

0:00:58.199,0:01:06.360
today hot is gonna be online through

0:01:00.329,0:01:13.250
zoom I think system so who hangs up who

0:01:06.360,0:01:13.250
thinks the picture on the left it's real

0:01:15.049,0:01:25.560
okay now hands up who thinks that the

0:01:18.299,0:01:29.970
picture on the right is real okay who

0:01:25.560,0:01:35.040
thinks that both of them are real who

0:01:29.970,0:01:37.290
think that this one is fake who thinks

0:01:35.040,0:01:42.030
that this one is fake who thinks that

0:01:37.290,0:01:44.299
both are fake okay you are right so

0:01:42.030,0:01:48.509
these two images have been generated by

0:01:44.299,0:01:51.210
modeling that we trained actually this

0:01:48.509,0:01:54.240
guy Cara's train so if you go on the

0:01:51.210,0:01:57.060
website this person does not exist you

0:01:54.240,0:02:01.200
can find several examples of very

0:01:57.060,0:02:02.310
good-looking non-existent people if you

0:02:01.200,0:02:03.659
keep clicking sometimes you're gonna

0:02:02.310,0:02:06.780
find some person with a hole in their

0:02:03.659,0:02:10.619
faces that's kind of very easy to

0:02:06.780,0:02:13.130
recognize that is not quite likely a

0:02:10.619,0:02:15.950
real person but otherwise

0:02:13.130,0:02:18.530
look pretty legit you can notice that

0:02:15.950,0:02:22.600
they have very nice teeth very nice

0:02:18.530,0:02:25.730
you know cheek you know chicken feet

0:02:22.600,0:02:27.680
like things or you call them you can

0:02:25.730,0:02:29.990
clearly tell here though that if you

0:02:27.680,0:02:31.400
check on the background behind the

0:02:29.990,0:02:33.440
network is not producing a very accurate

0:02:31.400,0:02:34.220
the ground although the faces looks very

0:02:33.440,0:02:36.920
good why is that

0:02:34.220,0:02:38.980
because the network has been provided

0:02:36.920,0:02:40.130
many samples and those samples are

0:02:38.980,0:02:44.270
refiguring

0:02:40.130,0:02:45.770
faces the thing that is not constant is

0:02:44.270,0:02:47.180
the background right so that the

0:02:45.770,0:02:49.880
background is the variable here and

0:02:47.180,0:02:53.420
therefore you can't learn any possible

0:02:49.880,0:02:55.580
background so the become the ground will

0:02:53.420,0:02:58.010
look like some weird stuff because there

0:02:55.580,0:03:01.520
is much more variability then what are

0:02:58.010,0:03:04.850
the possible appearances of a face how

0:03:01.520,0:03:07.370
many given a face how many in how many

0:03:04.850,0:03:09.620
way you can you distort her face a human

0:03:07.370,0:03:15.230
face like if your face how many degrees

0:03:09.620,0:03:16.850
of freedom does he have ah you know this

0:03:15.230,0:03:19.790
answer right we already covered this in

0:03:16.850,0:03:25.250
class eight

0:03:19.790,0:03:28.490
she said eight how much thousand and

0:03:25.250,0:03:30.320
fifty fifty yeah that's 50 correct so

0:03:28.490,0:03:32.480
you have roughly fifty a mass of

0:03:30.320,0:03:34.700
something less plus you know rotation

0:03:32.480,0:03:37.820
tilting and what so not what not so you

0:03:34.700,0:03:39.650
know all possible it's just a manifold

0:03:37.820,0:03:42.230
in 50 dimensions so everything nice

0:03:39.650,0:03:43.940
doesn't quite is outside that manifold

0:03:42.230,0:03:46.310
although this picture you know RF

0:03:43.940,0:03:48.920
several megapixel pictures so each point

0:03:46.310,0:03:50.330
here is living in this huge dimensional

0:03:48.920,0:03:52.760
space although all the possible

0:03:50.330,0:03:54.740
variations are restrained to a subspace

0:03:52.760,0:03:57.200
okay so that's the training manifold the

0:03:54.740,0:04:02.270
data manifold okay check out their

0:03:57.200,0:04:05.530
website okay so we have here a very cute

0:04:02.270,0:04:10.910
dog oh and on the other side less cute

0:04:05.530,0:04:13.490
bird sorry oh yeah if you do a linear

0:04:10.910,0:04:15.860
interpolation between the dog oh and the

0:04:13.490,0:04:18.560
bird what are you expecting to see in

0:04:15.860,0:04:19.760
the middle and for this one I'm gonna be

0:04:18.560,0:04:23.650
actually turning off the light not

0:04:19.760,0:04:28.129
turning it back on the next soon after

0:04:23.650,0:04:30.169
so again so a blurry image what do you

0:04:28.129,0:04:32.440
mean so what do you expect to get over

0:04:30.169,0:04:32.440
here

0:04:33.879,0:04:45.590
roughly yeah you can talk back so I'm

0:04:40.940,0:04:48.199
gonna be doing 100% DS 1 + 0 90 % D is

0:04:45.590,0:04:50.659
on Plus 10 percent 80 percent D is on +

0:04:48.199,0:04:54.379
20 % this one so what are you gonna be

0:04:50.659,0:04:56.300
seen here you should guess you're less

0:04:54.379,0:04:59.500
than usual so you actually have to talk

0:04:56.300,0:04:59.500
back more than usual

0:05:00.039,0:05:05.990
flying square no ok so you have a dog

0:05:03.710,0:05:07.699
you have a bird if I do like a linear

0:05:05.990,0:05:14.139
interpolation of these two images in

0:05:07.699,0:05:16.789
pixel space what do you get second sorry

0:05:14.139,0:05:17.990
yeah super super position right so

0:05:16.789,0:05:20.090
you're gonna get something that looks

0:05:17.990,0:05:22.129
like this you can get basically overlay

0:05:20.090,0:05:24.770
of the first image with a second image

0:05:22.129,0:05:27.139
alright so let's get back here and

0:05:24.770,0:05:28.849
instead let's do a interpolation in the

0:05:27.139,0:05:31.340
latent space of the network so I input

0:05:28.849,0:05:33.620
both those two guys I get a 2 and

0:05:31.340,0:05:35.240
representation those hidden layers then

0:05:33.620,0:05:37.490
I do a linear interpolation between the

0:05:35.240,0:05:43.789
hidden layers and then I do the decoding

0:05:37.490,0:05:46.909
part what do you expect to see here and

0:05:43.789,0:05:51.590
you still have to talk back to me you

0:05:46.909,0:05:53.090
have to shout the background feel a mess

0:05:51.590,0:05:57.889
but then what's gonna be this the

0:05:53.090,0:06:00.440
subject right right so you're gonna be

0:05:57.889,0:06:03.620
starting scene where the dog and then a

0:06:00.440,0:06:08.960
doggie bird okay and that's how it looks

0:06:03.620,0:06:10.430
birdie dog in a birdie birdie birdie dog

0:06:08.960,0:06:13.819
in a doggie bird okay

0:06:10.430,0:06:16.550
alright this is a network that did this

0:06:13.819,0:06:18.169
atrocious Frankie's blasphemy

0:06:16.550,0:06:21.400
you should watch full make a full metal

0:06:18.169,0:06:23.960
alchemist episode where the father takes

0:06:21.400,0:06:25.990
the daughter and the dog and makes

0:06:23.960,0:06:30.050
something similar it was so interesting

0:06:25.990,0:06:33.699
ok if you watch cartoons Brotherhood

0:06:30.050,0:06:33.699
right a second second season okay

0:06:34.240,0:06:38.750
aha

0:06:35.689,0:06:40.430
I don't know because it's a lot of green

0:06:38.750,0:06:43.000
so I guess it got rid of it I don't know

0:06:40.430,0:06:46.189
and I guess it yeah I don't know

0:06:43.000,0:06:47.659
good question though yeah good I so let

0:06:46.189,0:06:48.169
me show you a few more so this stuff

0:06:47.659,0:06:51.530
comes from

0:06:48.169,0:06:54.500
Brock's article and that you can you

0:06:51.530,0:06:56.780
have a smaller like so the first one you

0:06:54.500,0:06:58.490
have a small version of those images we

0:06:56.780,0:07:02.090
start from something like looks like a

0:06:58.490,0:07:04.879
shark or a monta I think is a name then

0:07:02.090,0:07:09.620
that stuff looks like a poly puss or how

0:07:04.879,0:07:11.599
do you call them again octopus right no

0:07:09.620,0:07:14.479
yeah it's something like octopus and

0:07:11.599,0:07:16.039
then the octopus becomes like monkey and

0:07:14.479,0:07:18.560
then it looks like a dog right so you

0:07:16.039,0:07:20.629
can see the shark becomes octopus that

0:07:18.560,0:07:22.460
becomes a monkey that becomes a dog so

0:07:20.629,0:07:24.529
interesting like how you can change

0:07:22.460,0:07:26.120
breeds by just having the final two

0:07:24.529,0:07:28.340
points fixed and then you walk through

0:07:26.120,0:07:31.310
the latent space so you have another one

0:07:28.340,0:07:33.969
here you go from these puppy here to our

0:07:31.310,0:07:36.710
bird so again you have a birdie squirrel

0:07:33.969,0:07:38.539
whatever and then you have a bird and

0:07:36.710,0:07:41.300
then the other side you have a doggie or

0:07:38.539,0:07:45.440
this one you have like the dismally guy

0:07:41.300,0:07:47.479
what's called a chunk skunk thank you

0:07:45.440,0:07:50.900
oh oh that's why you smell like a skunk

0:07:47.479,0:07:52.639
is the same right huh okay I see so that

0:07:50.900,0:07:55.159
if you have a skunk here and then you

0:07:52.639,0:07:58.490
get to a dog rabbit it actually looks a

0:07:55.159,0:08:03.319
lot of a dog after this thing here and

0:07:58.490,0:08:06.110
finally you get a bird turn into a fly I

0:08:03.319,0:08:08.419
think these are pretty awesome examples

0:08:06.110,0:08:10.789
so this should make you hungry such that

0:08:08.419,0:08:19.310
I can feed you with the second part of

0:08:10.789,0:08:20.990
the class right so you have this image

0:08:19.310,0:08:22.430
of one side you have this image on the

0:08:20.990,0:08:24.500
other side you get the embeddings and

0:08:22.430,0:08:25.699
you do some basically interpolation of

0:08:24.500,0:08:28.250
the embedding you can check out the

0:08:25.699,0:08:30.439
paper for more details the point here is

0:08:28.250,0:08:33.459
just to show you that the difference

0:08:30.439,0:08:35.120
between interpolation in pixel space

0:08:33.459,0:08:36.709
yeah what is the difference between

0:08:35.120,0:08:38.630
interpolation in pixel space in the

0:08:36.709,0:08:40.360
latent space so the latent space capture

0:08:38.630,0:08:43.090
what is the basic

0:08:40.360,0:08:45.010
semantics of an image and therefore you

0:08:43.090,0:08:48.250
you go from the pixel space which kind

0:08:45.010,0:08:52.960
of doesn't really play well with our

0:08:48.250,0:08:54.790
tools to kind of more well-behaved space

0:08:52.960,0:08:57.070
which is our internal hidden

0:08:54.790,0:08:59.050
representation of the data of the end of

0:08:57.070,0:09:01.360
the network again this is just to give

0:08:59.050,0:09:04.660
you some appetite right not I'm not

0:09:01.360,0:09:07.360
gonna be I'm not form a little what next

0:09:04.660,0:09:10.720
okay you can zoom on dogs you can shift

0:09:07.360,0:09:12.610
you can shift on the X on the Y you can

0:09:10.720,0:09:13.870
do change the brightness the interesting

0:09:12.610,0:09:16.260
part here is that when you change the

0:09:13.870,0:09:18.610
brightness actually you change day to

0:09:16.260,0:09:21.310
day to night or night today because

0:09:18.610,0:09:23.770
that's what the most normal brightness

0:09:21.310,0:09:24.880
change in pictures looks like okay so

0:09:23.770,0:09:26.830
whenever you change brightness you

0:09:24.880,0:09:29.530
actually change the time of the day or

0:09:26.830,0:09:31.510
you have a 2d rotation or even a 3d

0:09:29.530,0:09:34.450
rotation is so interesting means that

0:09:31.510,0:09:36.190
the network and somehow have a internal

0:09:34.450,0:09:38.560
representation of the 3d world

0:09:36.190,0:09:41.800
that's something yan was mentioning

0:09:38.560,0:09:44.200
yesterday if you shift you know a little

0:09:41.800,0:09:47.350
bit you see this kind of parallax then

0:09:44.200,0:09:49.330
the easiest way to express to basically

0:09:47.350,0:09:52.120
address this you know phenomenon is

0:09:49.330,0:10:00.460
actually to imply that there is a 3d war

0:09:52.120,0:10:02.430
okay so in this case they trained the

0:10:00.460,0:10:05.580
network in order to actually be able to

0:10:02.430,0:10:08.710
you know handle specific transformation

0:10:05.580,0:10:10.600
actually I have to put the reference on

0:10:08.710,0:10:16.210
this paper again I'm just giving you

0:10:10.600,0:10:17.740
some how to say I can this okay I'm not

0:10:16.210,0:10:21.220
giving you any more any formal thing

0:10:17.740,0:10:24.250
right now in this case actually I like

0:10:21.220,0:10:29.590
this on so much you can get the animal

0:10:24.250,0:10:31.090
version of your picture right so you

0:10:29.590,0:10:33.430
could try to stop by don't try with

0:10:31.090,0:10:37.330
hentai right we don't want to do those

0:10:33.430,0:10:38.590
things okay all right so some of you

0:10:37.330,0:10:40.889
actually know this stuff interesting

0:10:38.590,0:10:44.470
thank you

0:10:40.889,0:10:47.410
right the one that don't it's okay just

0:10:44.470,0:10:50.139
forget all right okay this is other

0:10:47.410,0:10:52.269
stuff which is pretty cool like you can

0:10:50.139,0:10:54.459
go from low resolution to high

0:10:52.269,0:10:56.619
resolution from the left hand side to

0:10:54.459,0:10:58.449
hide right hand side and here you have a

0:10:56.619,0:11:00.429
few examples but this is of course it's

0:10:58.449,0:11:01.839
black on white it's much easier to do

0:11:00.429,0:11:03.429
this stuff and the same for the zebra

0:11:01.839,0:11:05.230
and this is a pre deep learning

0:11:03.429,0:11:07.540
technique so they were just using some

0:11:05.230,0:11:09.879
hierarchical model nevertheless it works

0:11:07.540,0:11:12.819
pretty well and then a few years later

0:11:09.879,0:11:16.209
you've actually gave Garcia getting you

0:11:12.819,0:11:18.550
you know really high this is like the

0:11:16.209,0:11:20.619
hub sampling by doing like linear

0:11:18.550,0:11:23.110
interpolation by linear interpolation

0:11:20.619,0:11:24.879
and instead this one is gonna be the up

0:11:23.110,0:11:26.649
sampling down with the neural net and

0:11:24.879,0:11:29.679
the final one is actually the real image

0:11:26.649,0:11:34.179
you can see clearly on the third row how

0:11:29.679,0:11:39.759
these Asian dude became European white

0:11:34.179,0:11:41.709
that bias right correct so the network

0:11:39.759,0:11:43.899
has seen a lot of white dudes and

0:11:41.709,0:11:47.110
therefore the most the easiest way to

0:11:43.899,0:11:49.929
reconstruct a kind of unknown face

0:11:47.110,0:11:52.360
features it can be to plug there a white

0:11:49.929,0:11:55.299
dude face or this lady looks like she

0:11:52.360,0:11:57.610
has in she's having a stroke because she

0:11:55.299,0:12:00.910
we don't have many side views of these

0:11:57.610,0:12:04.089
images right these this lady became a

0:12:00.910,0:12:05.740
changed sex on the bottom side and then

0:12:04.089,0:12:08.679
this guy it looks like he had an

0:12:05.740,0:12:10.869
accident because again we didn't have

0:12:08.679,0:12:13.299
many glasses on the dataset therefore

0:12:10.869,0:12:15.369
the network you know so some very dark

0:12:13.299,0:12:20.319
thing and then you know implied someone

0:12:15.369,0:12:22.240
just punched him very hardly okay but

0:12:20.319,0:12:24.970
again this is very old stuff I mean we

0:12:22.240,0:12:26.290
are four years in the future now again

0:12:24.970,0:12:30.040
these are the first results and this

0:12:26.290,0:12:32.079
allows you to leverage you know actual

0:12:30.040,0:12:33.459
data in order to fill in the gaps and

0:12:32.079,0:12:36.360
the gaps are what are they actually

0:12:33.459,0:12:38.709
actual detail we have very very many new

0:12:36.360,0:12:40.509
results recently but these organ are the

0:12:38.709,0:12:44.160
kind of pioneering result and pioneering

0:12:40.509,0:12:47.230
examples one more here you basically

0:12:44.160,0:12:49.299
block the face with a gray square and

0:12:47.230,0:12:52.820
then you ask the network to reconstruct

0:12:49.299,0:12:55.850
the face such that it gives you

0:12:52.820,0:12:57.680
the best-looking closing point right so

0:12:55.850,0:13:01.160
you take an image which is staying on

0:12:57.680,0:13:03.950
the training manifold you put a patch on

0:13:01.160,0:13:06.530
the face this patch will make the image

0:13:03.950,0:13:08.210
go away from the training manifold now

0:13:06.530,0:13:10.910
you can do for example gradient descent

0:13:08.210,0:13:13.430
in this energy space such that you can

0:13:10.910,0:13:15.470
find what is the closest point like the

0:13:13.430,0:13:17.570
point with the lowest energy that is

0:13:15.470,0:13:19.100
associated to that specific initial

0:13:17.570,0:13:21.110
image okay so you get an image you

0:13:19.100,0:13:23.300
perturb the image you that makes it go

0:13:21.110,0:13:24.650
away from the training manifold and then

0:13:23.300,0:13:26.420
you can do great in the saint's in the

0:13:24.650,0:13:29.710
energy landscape such that you can pick

0:13:26.420,0:13:32.240
the whatever sample looks like the most

0:13:29.710,0:13:33.860
you know it's only the closest sample on

0:13:32.240,0:13:35.900
the training manifold and this is some

0:13:33.860,0:13:38.090
stuff yan was covering yesterday about

0:13:35.900,0:13:39.500
energy based model whenever you learn an

0:13:38.090,0:13:41.780
energy then you can actually use the

0:13:39.500,0:13:44.090
energy to do inference to do inference

0:13:41.780,0:13:45.740
you actually have to minimize the energy

0:13:44.090,0:13:47.720
right so energy minimization means

0:13:45.740,0:13:49.160
inference not training training

0:13:47.720,0:13:51.110
something else

0:13:49.160,0:13:52.850
again we're going to be covering more

0:13:51.110,0:13:55.340
detail energy based models in the

0:13:52.850,0:13:58.010
following classes here you have another

0:13:55.340,0:14:00.260
few examples one using a variational

0:13:58.010,0:14:04.460
encoder and another using generative

0:14:00.260,0:14:08.600
other cyanate this is also another

0:14:04.460,0:14:10.520
example from Reed this is crazy you can

0:14:08.600,0:14:13.580
go from English description to actual

0:14:10.520,0:14:15.980
drawing of what the English description

0:14:13.580,0:14:18.680
mean right so you go from a sequence I

0:14:15.980,0:14:20.600
guess to a vector which is like the

0:14:18.680,0:14:22.730
concept and then from the concept you

0:14:20.600,0:14:24.850
use a decoder so it's a generative net

0:14:22.730,0:14:29.060
which is going to be decoding your

0:14:24.850,0:14:33.800
specific output and that was pretty much

0:14:29.060,0:14:36.140
it for the eye candy so this should make

0:14:33.800,0:14:39.400
you very hungry for the second part of

0:14:36.140,0:14:41.660
the class are you hungry

0:14:39.400,0:14:48.230
yeah I didn't have dinner either either

0:14:41.660,0:14:49.850
okay all right so out encoders

0:14:48.230,0:14:51.470
what are these stuff I'm supervised

0:14:49.850,0:14:54.200
learning so this is our first model

0:14:51.470,0:14:55.760
we're going to be diving into in order

0:14:54.200,0:14:58.520
to see how we can train a network

0:14:55.760,0:15:03.440
without targets or labels what are

0:14:58.520,0:15:06.290
target's what was the difference between

0:15:03.440,0:15:09.860
target and labels

0:15:06.290,0:15:16.890
you already know everything someone else

0:15:09.860,0:15:18.480
prediction means both of them are

0:15:16.890,0:15:23.670
actually given both of them are

0:15:18.480,0:15:25.080
annotations thank you so labels are

0:15:23.670,0:15:26.700
going to be categorical you can label

0:15:25.080,0:15:29.970
things this is a chair that's a table

0:15:26.700,0:15:35.670
that doors targets are going to be you

0:15:29.970,0:15:37.230
know the target okay all right so we're

0:15:35.670,0:15:39.530
going to be observing how we can train

0:15:37.230,0:15:43.590
this model without actually having

0:15:39.530,0:15:46.440
targets or labels so this is the first

0:15:43.590,0:15:48.690
network which is the architecture we are

0:15:46.440,0:15:50.640
going to be playing with it's very

0:15:48.690,0:15:53.370
similar to what we observe so far but

0:15:50.640,0:15:55.590
the big difference is that we start from

0:15:53.370,0:15:58.200
the bottom we know already why it's pink

0:15:55.590,0:16:04.170
you got to intermediate hidden layer in

0:15:58.200,0:16:05.340
green then you get top two the input so

0:16:04.170,0:16:07.950
the output of the network is going to be

0:16:05.340,0:16:09.510
the prediction of the input okay so you

0:16:07.950,0:16:11.850
have also a different kind of

0:16:09.510,0:16:13.590
representation you may have so that

0:16:11.850,0:16:15.540
those are DEA questions the hidden

0:16:13.590,0:16:17.880
layers going to be the rotation squash

0:16:15.540,0:16:19.800
rotation on my input and then the final

0:16:17.880,0:16:22.830
output is going to be the I guess squash

0:16:19.800,0:16:24.420
version of the rotation of the hidden

0:16:22.830,0:16:27.450
okay where rotation means affine

0:16:24.420,0:16:29.640
transformations we have some

0:16:27.450,0:16:32.480
dimensionality so we shoot towards D but

0:16:29.640,0:16:34.710
then both X and X hat live in the RN

0:16:32.480,0:16:36.420
therefore the second part is going to be

0:16:34.710,0:16:39.300
our generative Network this one that

0:16:36.420,0:16:40.980
goes from h2x hots is going to be my

0:16:39.300,0:16:42.270
generative net and here you have a

0:16:40.980,0:16:44.850
different diagram which is basically

0:16:42.270,0:16:46.590
doing the same thing but this one is you

0:16:44.850,0:16:48.840
know some people prefer these diagrams

0:16:46.590,0:16:52.020
where the actual transformations are

0:16:48.840,0:16:53.550
made in boxes okay so you have people

0:16:52.020,0:16:57.060
saying this is a two layer neural net

0:16:53.550,0:17:01.680
although we know that is a how many

0:16:57.060,0:17:04.500
layer neural net how many balls you see

0:17:01.680,0:17:08.580
three layers neural network fantastic

0:17:04.500,0:17:12.150
that our my convention okay if we use

0:17:08.580,0:17:14.070
yawns notation then we also have okay

0:17:12.150,0:17:15.780
hold on so you actually can have some

0:17:14.070,0:17:17.620
tights weights in order to be trying to

0:17:15.780,0:17:20.890
reproduce somehow piece

0:17:17.620,0:17:24.970
although you don't have guarantees over

0:17:20.890,0:17:27.970
the order of the different weight all of

0:17:24.970,0:17:29.710
the different basis but if we use the

0:17:27.970,0:17:32.740
onion notation we are going to be also

0:17:29.710,0:17:34.690
adding those kind of little project is

0:17:32.740,0:17:37.960
there which are representing the

0:17:34.690,0:17:41.100
transformations okay so why are we using

0:17:37.960,0:17:47.620
out encoders what's the point of

0:17:41.100,0:17:51.940
predicting my input let's say I use a

0:17:47.620,0:17:53.140
identity matrix okay I provide input

0:17:51.940,0:17:56.170
which is a vector

0:17:53.140,0:17:58.929
I put apply this vector I do want my

0:17:56.170,0:18:04.720
identity matrix times my vector I get

0:17:58.929,0:18:08.230
the same vector this out encoder so you

0:18:04.720,0:18:18.760
get the same thing as you put in why the

0:18:08.230,0:18:20.530
hell are we doing this so you don't have

0:18:18.760,0:18:22.750
the input when you predict but then I

0:18:20.530,0:18:24.670
can just learn the identity matrix right

0:18:22.750,0:18:26.950
I have identity matrix I put some

0:18:24.670,0:18:29.590
thinning I get something out I put

0:18:26.950,0:18:31.630
something in I put something out I get

0:18:29.590,0:18:34.480
put same thing in I get the same thing

0:18:31.630,0:18:36.040
out so the most thing the most trivial

0:18:34.480,0:18:38.380
thing to learn for a network would be

0:18:36.040,0:18:40.870
the identity matrix right I thing I put

0:18:38.380,0:18:50.309
inside comes out and that's how we train

0:18:40.870,0:18:53.020
this stuff second sorry if d is

0:18:50.309,0:18:57.670
less right okay there is a first point

0:18:53.020,0:19:00.400
so if we have a weapon if you have

0:18:57.670,0:19:04.000
intermediate dimensionality D lower than

0:19:00.400,0:19:05.830
n therefore we can start seeing what

0:19:04.000,0:19:07.809
this guy this stuff can be used for for

0:19:05.830,0:19:09.429
example could be used for compression so

0:19:07.809,0:19:11.470
if I have an intermediate representation

0:19:09.429,0:19:13.900
which takes less space than my input

0:19:11.470,0:19:16.330
representation I can use this encoder is

0:19:13.900,0:19:18.940
a compressor then I have my hinny

0:19:16.330,0:19:21.400
representation my code which is you know

0:19:18.940,0:19:23.350
addressing what specific input is it

0:19:21.400,0:19:25.660
takes to this space so I can use a you

0:19:23.350,0:19:28.090
know image compressor for example for

0:19:25.660,0:19:30.550
example here so that was my initial idea

0:19:28.090,0:19:31.420
for out encoders but that's just one

0:19:30.550,0:19:34.300
type of

0:19:31.420,0:19:36.960
and it's kind of you know not the proper

0:19:34.300,0:19:41.110
way of thinking about these guys

0:19:36.960,0:19:44.760
so another encoder task is to be able to

0:19:41.110,0:19:48.850
reconstruct data that lives on the

0:19:44.760,0:19:51.970
manifold okay so we have a data manifold

0:19:48.850,0:19:54.220
we get some points we have data points I

0:19:51.970,0:19:57.070
use these points for training my system

0:19:54.220,0:19:59.800
and I'd like my out encoder to be able

0:19:57.070,0:20:01.600
to reconstruct only things that live on

0:19:59.800,0:20:03.910
the training manifold on the data

0:20:01.600,0:20:06.160
manifold okay so that's our that's

0:20:03.910,0:20:07.990
actually what the task what is the task

0:20:06.160,0:20:10.480
of these out encoders only to

0:20:07.990,0:20:13.380
reconstruct a small subset and I getting

0:20:10.480,0:20:17.230
tripped off by my microphone one sec I

0:20:13.380,0:20:19.240
only we should okay this is too short

0:20:17.230,0:20:21.640
okay we should be only able to

0:20:19.240,0:20:23.350
reconstruct we had to enforce only to be

0:20:21.640,0:20:26.140
able to reconstruct a small set of

0:20:23.350,0:20:27.910
possible inputs okay now it becomes

0:20:26.140,0:20:31.300
interesting because if you can only

0:20:27.910,0:20:33.160
reconstruct a small set of inputs then

0:20:31.300,0:20:36.400
you cannot reconstruct things that are

0:20:33.160,0:20:40.990
away right so for example like before I

0:20:36.400,0:20:44.110
show you I have put I put a picture I

0:20:40.990,0:20:46.600
have a picture and I have a gray box in

0:20:44.110,0:20:48.370
front of my face so I take my point and

0:20:46.600,0:20:51.460
I take it away from my training manifold

0:20:48.370,0:20:52.780
if I try to reconstruct it and I network

0:20:51.460,0:20:54.700
and only reconstruct things that are on

0:20:52.780,0:20:57.670
a manifold it will reconstruct something

0:20:54.700,0:21:01.180
that is here which doesn't have that

0:20:57.670,0:21:04.030
patch on the face okay you see this or

0:21:01.180,0:21:05.500
no so if you're only constrained to

0:21:04.030,0:21:08.140
reconstruct things that have been

0:21:05.500,0:21:10.570
observed during training any variation

0:21:08.140,0:21:12.850
that you apply to the you know new

0:21:10.570,0:21:14.320
inputs later on during when you can be

0:21:12.850,0:21:16.200
using this network is going to be read

0:21:14.320,0:21:18.270
removed because the network will be

0:21:16.200,0:21:21.570
insensitive to that kind of

0:21:18.270,0:21:23.620
perturbations so let's see a bit of more

0:21:21.570,0:21:25.110
details about this stuff is it clear so

0:21:23.620,0:21:30.940
far

0:21:25.110,0:21:33.340
yes no okay all right so let's figure

0:21:30.940,0:21:36.250
out what our D reconstruction losses we

0:21:33.340,0:21:38.590
have we can use so the first one we have

0:21:36.250,0:21:40.570
the classical you know loss for the

0:21:38.590,0:21:42.640
overall data set is going to be the

0:21:40.570,0:21:45.100
average between my per sample losses

0:21:42.640,0:21:47.890
okay and so there are two person

0:21:45.100,0:21:52.770
Nasus the first person per loss is going

0:21:47.890,0:21:55.720
to be the binary binary cross-entropy

0:21:52.770,0:21:57.070
which is going to be penalizing a lot if

0:21:55.720,0:21:59.350
you make a mistake

0:21:57.070,0:22:01.240
so the output the the targets are going

0:21:59.350,0:22:04.090
to be 0 or 1 so I have a categorical

0:22:01.240,0:22:06.070
distribution and then your input does

0:22:04.090,0:22:08.410
not be sorry you're out who's going to

0:22:06.070,0:22:10.450
be something that also leaves between 0

0:22:08.410,0:22:12.280
and 1 so you have a sigmoid network a

0:22:10.450,0:22:14.679
sigmoid a nonlinear function at the end

0:22:12.280,0:22:17.380
and then you get you try to minimize

0:22:14.679,0:22:20.169
this guy here otherwise if you have real

0:22:17.380,0:22:22.900
value inputs and outputs which are for

0:22:20.169,0:22:28.960
example images color images you may want

0:22:22.900,0:22:31.900
to use the MSC okay all right so as

0:22:28.960,0:22:34.570
someone yeah it's the your friend

0:22:31.900,0:22:37.030
they're mentioned before we have you

0:22:34.570,0:22:39.130
know pretty it's pretty obvious obvious

0:22:37.030,0:22:41.409
to think about like under complete

0:22:39.130,0:22:43.630
hidden layer a hundred complete hidden

0:22:41.409,0:22:48.280
layer has a dimensionality which is

0:22:43.630,0:22:51.730
smaller than the size of the input so in

0:22:48.280,0:22:54.400
this case the network not perhaps copy

0:22:51.730,0:22:55.720
or use the identity matrix because you

0:22:54.400,0:22:56.919
have an intermediate representation

0:22:55.720,0:22:59.200
which is smaller and then you had to

0:22:56.919,0:23:01.539
expand this one back to the original

0:22:59.200,0:23:04.210
dimensionality again you can use a under

0:23:01.539,0:23:06.309
complete hidden layer how to encoder for

0:23:04.210,0:23:08.980
doing compression for example ok so this

0:23:06.309,0:23:12.070
is pretty standard I would say does it

0:23:08.980,0:23:14.100
make sense so far ok so we're gonna play

0:23:12.070,0:23:17.380
with this in a second on the notebook

0:23:14.100,0:23:21.520
nevertheless I will say I actually like

0:23:17.380,0:23:24.880
this one more and you are gonna be

0:23:21.520,0:23:26.820
telling me why you should be able to I

0:23:24.880,0:23:29.440
mean you should have all the ingredients

0:23:26.820,0:23:31.360
it's gonna be what's this is the six

0:23:29.440,0:23:34.450
week I think seventh six

0:23:31.360,0:23:39.130
six week seventh week I think I'm not

0:23:34.450,0:23:41.730
sure why do I want a larger intermediate

0:23:39.130,0:23:41.730
representation

0:24:01.910,0:24:05.029
[Music]

0:24:19.240,0:24:22.329
[Music]

0:24:31.870,0:24:37.520
right so we always said that the larger

0:24:35.090,0:24:38.840
we go into intermediate presentation the

0:24:37.520,0:24:42.049
easiest is going to be the optimization

0:24:38.840,0:24:45.140
right and so although the information

0:24:42.049,0:24:47.000
that is contained in the first layer and

0:24:45.140,0:24:49.549
in the hidden layer is gonna be the same

0:24:47.000,0:24:51.620
I can't add information but it's much

0:24:49.549,0:24:54.289
easier now for the network to play with

0:24:51.620,0:24:57.919
a representation that has you know much

0:24:54.289,0:25:00.679
many more dimensions the point is that

0:24:57.919,0:25:01.820
we can simply learn now the identity

0:25:00.679,0:25:03.620
matrix and we're going to be just

0:25:01.820,0:25:06.409
copying everything you know you copy the

0:25:03.620,0:25:08.240
first guy in the first post post spot

0:25:06.409,0:25:09.740
the second guy you copy here the third

0:25:08.240,0:25:11.870
one you copied here now you copy

0:25:09.740,0:25:13.480
everything through you haven't learned

0:25:11.870,0:25:15.950
nothing have learned the identity

0:25:13.480,0:25:19.549
therefore we have to learn we have to

0:25:15.950,0:25:21.860
apply some other types of constraint for

0:25:19.549,0:25:24.320
the information and so we have to learn

0:25:21.860,0:25:26.510
how to introduce now we have to

0:25:24.320,0:25:29.330
introduce now a information bottleneck

0:25:26.510,0:25:31.370
okay although we enlarge the

0:25:29.330,0:25:33.500
intermediate representation we have to

0:25:31.370,0:25:36.230
constrain the representation we have to

0:25:33.500,0:25:40.640
constrain the possible configurations

0:25:36.230,0:25:42.980
that the hidden layer can take the input

0:25:40.640,0:25:45.110
layer can take as many configurations as

0:25:42.980,0:25:47.690
you want the hidden layer should be only

0:25:45.110,0:25:49.760
containing we represent the possible

0:25:47.690,0:25:51.799
configuration that the training data are

0:25:49.760,0:25:53.630
the data on that manifold can have okay

0:25:51.799,0:25:56.360
so the input can be everything you want

0:25:53.630,0:25:58.549
but you can be training only with data

0:25:56.360,0:25:59.580
that is on the manifold therefore the

0:25:58.549,0:26:03.270
hidden layer

0:25:59.580,0:26:06.060
only to be able to model to capture what

0:26:03.270,0:26:08.550
is develop ility within the training

0:26:06.060,0:26:10.080
data and be insensitive to anything that

0:26:08.550,0:26:11.970
is outside

0:26:10.080,0:26:15.090
okay such that we can have a selective

0:26:11.970,0:26:18.240
reconstruction of a subset of this in

0:26:15.090,0:26:26.280
very large input space are you with me

0:26:18.240,0:26:28.230
is no unless we are done see now how we

0:26:26.280,0:26:31.650
avoid overfitting on the training data

0:26:28.230,0:26:33.210
so a few there are a few ways to do this

0:26:31.650,0:26:35.790
make this stuff on the right-hand side

0:26:33.210,0:26:37.800
work and moreover you may want to have

0:26:35.790,0:26:40.710
you can have the same rationale also for

0:26:37.800,0:26:44.040
this less than side guy here so let's

0:26:40.710,0:26:46.800
say I have a super awesome decoder then

0:26:44.040,0:26:48.900
my encoder should could simply put all

0:26:46.800,0:26:51.510
my training data as you know first

0:26:48.900,0:26:52.830
training data is first point second

0:26:51.510,0:26:54.990
training data is gonna be number two

0:26:52.830,0:26:57.510
third training data same poles gonna be

0:26:54.990,0:27:00.600
number three so I can associate each of

0:26:57.510,0:27:02.760
my training data is one number one two

0:27:00.600,0:27:04.470
three four five six seven whatever and

0:27:02.760,0:27:06.390
now you have the decoder has memorized

0:27:04.470,0:27:08.370
all the training data points and then

0:27:06.390,0:27:11.400
you just output the training point that

0:27:08.370,0:27:14.340
you want from this kind of selector

0:27:11.400,0:27:17.190
right so you potentially may only need

0:27:14.340,0:27:19.080
only one ball here one only one neuron

0:27:17.190,0:27:21.120
in the hidden layer in order to have a

0:27:19.080,0:27:22.740
network that does overheat as long as

0:27:21.120,0:27:23.280
the decoder in the encoder are very

0:27:22.740,0:27:25.740
powerful

0:27:23.280,0:27:27.360
okay so the point is your colleague

0:27:25.740,0:27:30.440
mentioned yeah how do we avoid

0:27:27.360,0:27:33.270
overfitting this stuff can over fit to

0:27:30.440,0:27:35.670
this stuff will over fit unless we are

0:27:33.270,0:27:37.890
you know I'm kind of you know careful

0:27:35.670,0:27:39.420
about how we design these things so

0:27:37.890,0:27:42.510
there are a few different methods there

0:27:39.420,0:27:44.400
are contrastive methods in there are

0:27:42.510,0:27:46.770
there are regular ice metals and there

0:27:44.400,0:27:49.110
are architectural methods we have seen

0:27:46.770,0:27:53.460
yesterday as well something we can be

0:27:49.110,0:27:57.560
quarry now a few of these and we have 20

0:27:53.460,0:27:57.560
minutes left okay yeah

0:28:04.350,0:28:09.610
next slide

0:28:05.650,0:28:12.520
yeah so do you know is an alt encoder

0:28:09.610,0:28:16.630
how does it work I take my input the

0:28:12.520,0:28:22.210
pink one I put it away from my original

0:28:16.630,0:28:24.340
point so these are my training this is

0:28:22.210,0:28:26.530
my data manifold each of these points

0:28:24.340,0:28:28.900
are gonna be you know samples are gonna

0:28:26.530,0:28:32.890
be providing for the training I take my

0:28:28.900,0:28:35.350
point and I displace it okay how I just

0:28:32.890,0:28:37.810
add random crap okay cool

0:28:35.350,0:28:41.350
now I didn't force the network to be

0:28:37.810,0:28:42.730
reconstructing that initial point right

0:28:41.350,0:28:44.230
so this is the denoising auto-encoder

0:28:42.730,0:28:46.800
you take a point from your training

0:28:44.230,0:28:49.570
manifold you take it you move it away

0:28:46.800,0:28:52.780
and then you enforce the network to take

0:28:49.570,0:28:54.820
it back here I take the same point I

0:28:52.780,0:28:56.200
take it away on the other direction and

0:28:54.820,0:28:58.330
then I put it back here I take the same

0:28:56.200,0:29:00.400
point I put it another direction and I

0:28:58.330,0:29:03.190
put it down here okay so what are we

0:29:00.400,0:29:07.030
learning right now we will be learning a

0:29:03.190,0:29:10.210
vector field which has everything coming

0:29:07.030,0:29:12.550
back to this point then I start moving

0:29:10.210,0:29:14.920
around my training manifold and I have

0:29:12.550,0:29:17.020
all this kind of vector field like the

0:29:14.920,0:29:20.380
vector field is gonna be all pointing

0:29:17.020,0:29:21.790
towards the training sample right but if

0:29:20.380,0:29:23.710
you have a training sample here and a

0:29:21.790,0:29:25.690
training sample here this guy will try

0:29:23.710,0:29:27.850
to attract here these on tire tracks

0:29:25.690,0:29:30.070
there so things that are on a manifold

0:29:27.850,0:29:32.950
stay there things were outside manifold

0:29:30.070,0:29:41.110
will be you know collapsing towards the

0:29:32.950,0:29:44.500
manifold okay questions okay all right

0:29:41.110,0:29:48.640
so actually there is a caveat caveat or

0:29:44.500,0:29:51.340
a caveat caveat let me say Kavya

0:29:48.640,0:29:52.630
thank you all right we assume that we

0:29:51.340,0:29:54.910
are injecting the same noise

0:29:52.630,0:29:57.850
distribution we are going to observe in

0:29:54.910,0:30:01.510
reality in this way we can learn how

0:29:57.850,0:30:03.850
vastly recover from it right so if we

0:30:01.510,0:30:05.260
assume that we have access to the type

0:30:03.850,0:30:06.070
of cultivation we are going to be

0:30:05.260,0:30:08.140
observing

0:30:06.070,0:30:10.240
Ronit inference then we can train the

0:30:08.140,0:30:13.060
model to be insensitive deluded to those

0:30:10.240,0:30:15.090
kind of perturbations and this is a very

0:30:13.060,0:30:19.270
big if okay

0:30:15.090,0:30:21.880
therefore oh nice pictures okay all

0:30:19.270,0:30:24.670
right so this is my training data this

0:30:21.880,0:30:30.570
is my data pink points and I'm gonna be

0:30:24.670,0:30:34.540
turning off the lights so I have here my

0:30:30.570,0:30:36.160
pink points which look white to you then

0:30:34.540,0:30:38.140
I have the orange points with our which

0:30:36.160,0:30:40.690
are the displaced points against so they

0:30:38.140,0:30:42.340
are originated from these points here

0:30:40.690,0:30:44.260
and then I displace them in any very

0:30:42.340,0:30:47.110
dark mini directions then I train my

0:30:44.260,0:30:49.150
network to get all these orange points

0:30:47.110,0:30:52.750
back to original starting point right

0:30:49.150,0:30:55.240
and so this is the output of the network

0:30:52.750,0:30:57.160
I input this cloud of orange points in

0:30:55.240,0:31:00.160
the network I trained my network to

0:30:57.160,0:31:02.440
output the points on the actual spiral

0:31:00.160,0:31:04.390
and therefore these are the blue points

0:31:02.440,0:31:07.120
are going to be my reconstructions of

0:31:04.390,0:31:09.130
the network okay so if points were

0:31:07.120,0:31:12.160
already on the manifold they didn't move

0:31:09.130,0:31:15.040
in points are far away from the manifold

0:31:12.160,0:31:17.650
they moved a lot guess what I can

0:31:15.040,0:31:20.380
measure how much they moved and that's

0:31:17.650,0:31:22.960
gonna be your energy how cool is this

0:31:20.380,0:31:25.480
huh okay maybe you haven't understood

0:31:22.960,0:31:28.750
yet so in this case in order to be a bit

0:31:25.480,0:31:31.330
more thorough I just send every possible

0:31:28.750,0:31:33.250
XY combination on this plane inside my

0:31:31.330,0:31:35.410
network right so here you have this line

0:31:33.250,0:31:37.660
because because all these bottom left

0:31:35.410,0:31:40.270
corner got squashed down here and now

0:31:37.660,0:31:41.890
you can see here points are quite sparse

0:31:40.270,0:31:44.050
and then there are very very many of

0:31:41.890,0:31:45.670
them densely occupying manifold

0:31:44.050,0:31:49.900
nevertheless there are a few points here

0:31:45.670,0:31:52.990
right and so this is showing you with

0:31:49.900,0:31:55.570
colors what is the distance those points

0:31:52.990,0:31:57.730
have traveled so points over here in the

0:31:55.570,0:32:00.390
bottom left corner have traveled one

0:31:57.730,0:32:03.390
unit and they got down here I think

0:32:00.390,0:32:07.300
points over here and travel also like

0:32:03.390,0:32:10.780
0.9 something and they went down here as

0:32:07.300,0:32:15.970
you can tell points within these two

0:32:10.780,0:32:17.820
branches didn't go anywhere yeah why is

0:32:15.970,0:32:20.760
that

0:32:17.820,0:32:23.340
tracked by both points on this side and

0:32:20.760,0:32:26.430
both on this side you know on average

0:32:23.340,0:32:28.290
during training nevertheless if you

0:32:26.430,0:32:30.180
forget about you know having stuff that

0:32:28.290,0:32:34.560
is curling on its own you have

0:32:30.180,0:32:38.940
everything just drops down to here guess

0:32:34.560,0:32:41.520
what I can put the points that have just

0:32:38.940,0:32:43.740
moved a little bit again inside the out

0:32:41.520,0:32:45.840
encoder and I can keep doing this a few

0:32:43.740,0:32:49.680
times until these points collapse down

0:32:45.840,0:32:54.180
to the manifold okay all right

0:32:49.680,0:32:55.500
or I can do something good I'm cool that

0:32:54.180,0:32:57.780
is a trick right so what did I do here

0:32:55.500,0:33:00.120
this is my denoising auto-encoder where

0:32:57.780,0:33:02.460
I get to the initial point where did I

0:33:00.120,0:33:03.870
where I start from my displacement from

0:33:02.460,0:33:05.550
right so I got my initial point I

0:33:03.870,0:33:08.450
displaced and then they forced the

0:33:05.550,0:33:11.870
network to go back to the initial point

0:33:08.450,0:33:15.570
what happened here how did I fix this

0:33:11.870,0:33:23.580
how can you fix this Ridge here and this

0:33:15.570,0:33:27.150
black this dark region any guess you can

0:33:23.580,0:33:30.420
send them randomly or hold on someone

0:33:27.150,0:33:32.280
their top right push it up how do I push

0:33:30.420,0:33:32.940
it out oh okay pushing up would be also

0:33:32.280,0:33:34.950
very good

0:33:32.940,0:33:38.720
so I also try to push up everything that

0:33:34.950,0:33:38.720
is not on the manifold didn't quite work

0:33:39.140,0:33:45.480
what did I do here it's a very is a hack

0:33:42.960,0:33:48.000
okay it's not elegant it cannot be done

0:33:45.480,0:33:50.340
in a high dimensional space so what I've

0:33:48.000,0:33:52.920
done here is gonna be make your point

0:33:50.340,0:33:55.590
fall on the closest point on a manifold

0:33:52.920,0:33:57.000
it so I did an exhaustive search of the

0:33:55.590,0:33:58.890
closest point on the manifold and then I

0:33:57.000,0:34:01.230
enforce my network to always make my

0:33:58.890,0:34:02.700
points fall on the closest point

0:34:01.230,0:34:04.860
although they were may be generated from

0:34:02.700,0:34:08.700
another initial point right so if this

0:34:04.860,0:34:09.900
point over here initially originated

0:34:08.700,0:34:11.820
from here but it's gonna be always

0:34:09.900,0:34:14.310
falling down on this direction just a

0:34:11.820,0:34:16.410
few points will not be you know they are

0:34:14.310,0:34:21.530
just in there in the middle way and they

0:34:16.410,0:34:21.530
don't fall anywhere all right so

0:34:24.210,0:34:31.060
now in more dimensions everything is

0:34:26.919,0:34:32.589
Farah right so it doesn't quite work we

0:34:31.060,0:34:34.330
haven't covered that not work yet okay

0:34:32.589,0:34:39.070
and I show you next time I guess well

0:34:34.330,0:34:41.050
next next next time yeah so in this case

0:34:39.070,0:34:43.389
I've done the denoising auto-encoder in

0:34:41.050,0:34:45.730
this case I got the displace point to

0:34:43.389,0:34:48.089
fall on to the closest point on a

0:34:45.730,0:34:50.679
manifold so I did an exhaustive search

0:34:48.089,0:34:52.869
it's it's simple because I have hundred

0:34:50.679,0:34:57.730
and fifty points here but it's a hack

0:34:52.869,0:34:59.500
you cannot do that in reality anyhow the

0:34:57.730,0:35:02.080
point is that we kind of have developed

0:34:59.500,0:35:04.119
somehow kind of understanding and this

0:35:02.080,0:35:06.280
one instead that the unruly likes but I

0:35:04.119,0:35:11.250
am not yet able to make it work

0:35:06.280,0:35:13.720
so I guess I'm not that smart yet it's

0:35:11.250,0:35:18.099
regularized out encoder in this case I

0:35:13.720,0:35:20.859
have a l1 regularization term cost on my

0:35:18.099,0:35:22.390
hidden representation so I force my

0:35:20.859,0:35:25.630
network to come up with hidden

0:35:22.390,0:35:27.609
representations which are short and they

0:35:25.630,0:35:30.369
are like short of a few dimensions right

0:35:27.609,0:35:33.040
so if I have a one regularization of my

0:35:30.369,0:35:36.640
hidden representation I will only have a

0:35:33.040,0:35:38.560
few items active at a given time the

0:35:36.640,0:35:40.630
problem is that if you set all those

0:35:38.560,0:35:42.970
other elements to zero and then you have

0:35:40.630,0:35:45.070
zero gradients to send back okay and so

0:35:42.970,0:35:48.460
then you may want to use target prop and

0:35:45.070,0:35:50.230
other cute fancy things and I still am

0:35:48.460,0:35:52.060
working on this so I have no idea how to

0:35:50.230,0:35:54.580
make it work the point is that this is

0:35:52.060,0:35:56.830
the regularization term so this is the

0:35:54.580,0:35:59.859
l1 penalty on the hidden representation

0:35:56.830,0:36:02.020
and this black dark here the region

0:35:59.859,0:36:05.589
should be actually extending all around

0:36:02.020,0:36:07.960
again it's very hard for the moment for

0:36:05.589,0:36:09.339
me to get this to work not saying that

0:36:07.960,0:36:13.359
is impossible and just saying that I'm

0:36:09.339,0:36:14.619
not smart enough all right contract the

0:36:13.359,0:36:16.510
out encoder and then we going to be seen

0:36:14.619,0:36:19.359
the not works let me turn on the lights

0:36:16.510,0:36:25.990
such that or maybe not I don't know

0:36:19.359,0:36:28.710
shall I I like it so much dark okay

0:36:25.990,0:36:28.710
whatever

0:36:28.940,0:36:37.800
okay back on the camera right again data

0:36:34.859,0:36:39.780
manifold points training points what is

0:36:37.800,0:36:42.090
VI a contract adult encoder doing so

0:36:39.780,0:36:45.180
this guy here it simply have the

0:36:42.090,0:36:46.260
reconstruction term plus that thing here

0:36:45.180,0:36:49.260
what is it

0:36:46.260,0:36:54.540
gradient of my hidden representation

0:36:49.260,0:36:56.220
with respect to the input norm square in

0:36:54.540,0:36:59.609
the overall loss right

0:36:56.220,0:37:02.700
so my overall loss will try to minimize

0:36:59.609,0:37:05.430
the variation of my hidden layer given

0:37:02.700,0:37:07.109
variations on the input okay so here you

0:37:05.430,0:37:09.630
want to have a representation for the

0:37:07.109,0:37:12.630
input which is not changing that much is

0:37:09.630,0:37:16.980
I wiggled my input and so this one

0:37:12.630,0:37:21.170
basically makes makes you insensitive to

0:37:16.980,0:37:23.880
what makes you sorry insensitive to

0:37:21.170,0:37:26.700
reconstruction of analyzing sensitivity

0:37:23.880,0:37:28.290
to the reconstruction directions so you

0:37:26.700,0:37:31.470
actually will be able to reconstruct

0:37:28.290,0:37:35.400
things over the manifold but it will

0:37:31.470,0:37:38.280
make you otherwise insensitive to any

0:37:35.400,0:37:39.830
other possible direction and so this one

0:37:38.280,0:37:41.670
we don't have an assumption over the

0:37:39.830,0:37:43.589
perturbation I'm applying adjust

0:37:41.670,0:37:46.290
insensitive to everything but then I

0:37:43.589,0:37:49.980
still have many points here so you will

0:37:46.290,0:37:56.280
have to minimize the reconstruction as i

0:37:49.980,0:37:59.099
provide different samples okay and you

0:37:56.280,0:38:06.750
penalize incentivize as well and that's

0:37:59.099,0:38:07.050
just penalized finally okay ten minutes

0:38:06.750,0:38:09.950
left

0:38:07.050,0:38:13.440
finally what does this out in color tone

0:38:09.950,0:38:16.589
as you can see I can use matplotlib very

0:38:13.440,0:38:21.210
well here we have this training manifold

0:38:16.589,0:38:24.060
which is my single dimensional you know

0:38:21.210,0:38:27.750
thing going in three dimensions and here

0:38:24.060,0:38:35.310
I have all those data points okay cool

0:38:27.750,0:38:38.730
so the X lives on this set of data and

0:38:35.310,0:38:41.020
it lives in RN what an out encoder has

0:38:38.730,0:38:44.500
to do is going to be basically

0:38:41.020,0:38:46.720
getting that curly line stretched down

0:38:44.500,0:38:48.850
in one direction right and therefore you

0:38:46.720,0:38:51.190
have there your Z in this case is called

0:38:48.850,0:38:53.170
latent space and so you get the first

0:38:51.190,0:39:00.010
one there and then the second one over

0:38:53.170,0:39:02.590
there the point is that how do I know

0:39:00.010,0:39:04.930
how can I go from these back to here I

0:39:02.590,0:39:06.730
know if I'm in this first location I can

0:39:04.930,0:39:09.430
go back to this location I know if I'm

0:39:06.730,0:39:11.800
in this location I can go back there I'm

0:39:09.430,0:39:15.370
not entirely sure what's happening here

0:39:11.800,0:39:18.670
there is no I only have training samples

0:39:15.370,0:39:21.190
right so I only have the correspondence

0:39:18.670,0:39:24.580
between points in the input space and

0:39:21.190,0:39:27.130
points on the latent space I don't have

0:39:24.580,0:39:29.140
any correspondence between regions of

0:39:27.130,0:39:32.380
the input space and regions of the

0:39:29.140,0:39:37.320
latent space okay so as as of right now

0:39:32.380,0:39:39.760
you only know how to connect input to

0:39:37.320,0:39:41.770
regions here in the latent space and how

0:39:39.760,0:39:43.360
to get back then we have learned that

0:39:41.770,0:39:47.530
the denoising auto-encoder takes the

0:39:43.360,0:39:48.190
input shakes it but you enforced to go

0:39:47.530,0:39:50.170
back here

0:39:48.190,0:39:52.720
same point and then you go back to the

0:39:50.170,0:39:54.490
other location to define a location

0:39:52.720,0:39:56.410
right so you take this one you shake it

0:39:54.490,0:39:58.300
it's gonna be always going here and then

0:39:56.410,0:40:01.630
you'll get back to the correct location

0:39:58.300,0:40:03.700
or the Dino is in the contractive you're

0:40:01.630,0:40:06.190
going to be the input and every you try

0:40:03.700,0:40:08.890
to penalize any possible wiggling of

0:40:06.190,0:40:11.020
this one when you wiggle this okay this

0:40:08.890,0:40:15.990
is contractive out encoder nevertheless

0:40:11.020,0:40:18.190
how can I start from here move around

0:40:15.990,0:40:21.400
and get something that actually looks

0:40:18.190,0:40:24.940
like a decent output meaning if I

0:40:21.400,0:40:26.770
translate this one if I have a dog here

0:40:24.940,0:40:29.830
and a bird here the embedding speedy

0:40:26.770,0:40:33.070
latent space if I move on this line

0:40:29.830,0:40:35.730
how can I assure that the things on this

0:40:33.070,0:40:38.890
line here will actually look like

0:40:35.730,0:40:40.930
meaningful transformations in here we

0:40:38.890,0:40:42.850
don't know that right now we only know

0:40:40.930,0:40:44.980
that this image is connected to this

0:40:42.850,0:40:47.080
point this image is connected to this

0:40:44.980,0:40:51.220
point we don't have any knowledge about

0:40:47.080,0:40:54.220
what kind of behavior how well we have

0:40:51.220,0:40:56.950
the space is whenever I move

0:40:54.220,0:40:59.740
in this space convert to down here right

0:40:56.950,0:41:02.830
so we don't know how this decoder that

0:40:59.740,0:41:05.410
goes from the latent space to the input

0:41:02.830,0:41:07.510
space is behaving when we are not

0:41:05.410,0:41:10.150
exactly in the points right so right now

0:41:07.510,0:41:11.560
we have points mapping all day next time

0:41:10.150,0:41:15.910
we're gonna watching we're going to be

0:41:11.560,0:41:18.190
learning how to map regions of the input

0:41:15.910,0:41:21.700
space with regions of the hidden space

0:41:18.190,0:41:24.730
okay right now we have a point point all

0:41:21.700,0:41:28.950
right so not books in the last seven

0:41:24.730,0:41:36.700
minutes thank you for sticking with me

0:41:28.950,0:41:46.930
yeah I'm moving too much and I'm

0:41:36.700,0:41:55.650
painting they work it PDL Jupiter Conda

0:41:46.930,0:41:55.650
Conda the faith PDA Jupiter not pocus

0:41:56.040,0:42:03.460
okay so I'm gonna be using this out

0:41:59.410,0:42:05.170
encoder just the number ten okay over

0:42:03.460,0:42:09.670
there it's invisible I know but it's

0:42:05.170,0:42:14.580
gonna be number ten all right so I'm

0:42:09.670,0:42:14.580
gonna be just executing stuff through

0:42:15.900,0:42:24.339
okay all right so what are we doing here

0:42:20.650,0:42:26.920
let me see we import some random crap

0:42:24.339,0:42:29.290
can you see right yeah you can complain

0:42:26.920,0:42:31.510
if you don't see things right I can't

0:42:29.290,0:42:33.190
check too many things so we import some

0:42:31.510,0:42:39.700
stuff we have an image conversion

0:42:33.190,0:42:42.130
routine which is simply adding adding

0:42:39.700,0:42:44.800
one and then multiplying by zero half

0:42:42.130,0:42:47.109
because I have otherwise my data when I

0:42:44.800,0:42:49.270
get my data I try to get it to zero mean

0:42:47.109,0:42:52.000
and I have also in a range that is

0:42:49.270,0:42:54.849
between minus 0.5 to plus 5 so it is

0:42:52.000,0:42:56.830
centered then here to get it back by

0:42:54.849,0:43:00.580
someone so instead of being 0 meaning go

0:42:56.830,0:43:02.440
0.5 mean and then I actually have so it

0:43:00.580,0:43:05.080
goes from my it starts from minus 1 to

0:43:02.440,0:43:07.640
plus 1 then here I just someone so it

0:43:05.080,0:43:10.340
goes from 0 to 2 and then I get it 0

0:43:07.640,0:43:13.720
- one this is a some display in routines

0:43:10.340,0:43:18.260
and here okay I show you that I subtract

0:43:13.720,0:43:19.970
0.5 and I divide by 0.5 my data those

0:43:18.260,0:43:24.140
are the em nice digits from me on

0:43:19.970,0:43:26.420
website here we set the device if you

0:43:24.140,0:43:28.760
want to run on CP on GPU and in this

0:43:26.420,0:43:31.040
case we have images that are the digit

0:43:28.760,0:43:33.820
we saw that when we were training the

0:43:31.040,0:43:36.320
convolutional net which are 28 by 28

0:43:33.820,0:43:38.590
pixels and in this case I'm going to be

0:43:36.320,0:43:41.510
creating a note encoder which has a 30

0:43:38.590,0:43:44.660
dimensional intermediate layer right

0:43:41.510,0:43:48.980
hidden layer so we go from 784 to 30 and

0:43:44.660,0:43:51.290
time and then back to 784 so here is

0:43:48.980,0:43:53.500
gonna be my out encoder model just a

0:43:51.290,0:43:57.080
linear layer affine transformation like

0:43:53.500,0:43:58.610
228 square 2d hyperbolic tangent and

0:43:57.080,0:44:00.500
then I have the decoder which is my

0:43:58.610,0:44:03.280
generative model which goes from the

0:44:00.500,0:44:06.290
hidden space the latent space which is D

0:44:03.280,0:44:08.360
228 square and then I have again

0:44:06.290,0:44:11.800
hyperbolic tangent such that I limit my

0:44:08.360,0:44:15.470
output range to minus one to plus one

0:44:11.800,0:44:17.650
and my forward simply is gonna be send

0:44:15.470,0:44:19.850
things through the encoder and decoder I

0:44:17.650,0:44:21.520
created my model and then I create my

0:44:19.850,0:44:26.090
criterion which is gonna be the MSC loss

0:44:21.520,0:44:28.070
learning rate and atom optimizer and so

0:44:26.090,0:44:29.930
this is gonna be the training part so

0:44:28.070,0:44:32.260
you're gonna be having whatever 20

0:44:29.930,0:44:35.330
evokes the first part is going to be

0:44:32.260,0:44:38.000
sending the images through the model

0:44:35.330,0:44:40.270
this number one right number two is

0:44:38.000,0:44:47.300
going to be computation of the loss

0:44:40.270,0:44:48.830
which is line number 15 then third point

0:44:47.300,0:44:50.510
is going to be clearing the gradient

0:44:48.830,0:44:53.600
otherwise we accumulate so that's number

0:44:50.510,0:44:55.190
17 then we do back propagation

0:44:53.600,0:44:57.230
computation of the partial derivative or

0:44:55.190,0:44:59.810
the final loss with respect to the

0:44:57.230,0:45:02.420
weights that is number 18 and finally we

0:44:59.810,0:45:05.150
do a step backwards in the direction of

0:45:02.420,0:45:07.970
the easy depth direction of the gradient

0:45:05.150,0:45:11.330
you step backward I'm talking a lot

0:45:07.970,0:45:13.790
because the computer is just training ok

0:45:11.330,0:45:20.410
all right so you can see here we went

0:45:13.790,0:45:23.150
through 20 books and actually let me

0:45:20.410,0:45:24.470
okay let me show you how they look so

0:45:23.150,0:45:28.430
these are the reconstruction of my

0:45:24.470,0:45:30.200
network okay these are the output of the

0:45:28.430,0:45:32.480
network given that we compress them -

0:45:30.200,0:45:33.890
that's 30 dimensional intermediate

0:45:32.480,0:45:35.930
representation I'm gonna show you the

0:45:33.890,0:45:37.970
currents in a sec let me change this one

0:45:35.930,0:45:39.980
to a denoising auto-encoder so here I

0:45:37.970,0:45:42.620
create a drop out module which is

0:45:39.980,0:45:45.500
randomly turning off neurons

0:45:42.620,0:45:47.570
I create my nose mask noise mask and

0:45:45.500,0:45:50.090
then I create my dead images which are

0:45:47.570,0:45:52.880
multiplying those images to this binary

0:45:50.090,0:45:56.510
mask and then I send to the network

0:45:52.880,0:45:58.520
those bad images these I traded images

0:45:56.510,0:46:01.010
and I train this stuff again we also

0:45:58.520,0:46:03.770
like to get to 500 dimensions right so

0:46:01.010,0:46:06.560
it is owner complete hidden layer and

0:46:03.770,0:46:12.410
then we train again okay this is correct

0:46:06.560,0:46:14.780
and this is training okay all right so

0:46:12.410,0:46:16.640
just recap of what's the difference

0:46:14.780,0:46:19.040
between the previous training at the

0:46:16.640,0:46:21.920
current training alright so we were

0:46:19.040,0:46:24.590
saying that before we were just using a

0:46:21.920,0:46:28.100
under complete out encoder so we were

0:46:24.590,0:46:31.220
going from 784 dimensional is input to a

0:46:28.100,0:46:33.160
30 dimensional hidden layer but now we

0:46:31.220,0:46:36.680
are going to be using a over complete

0:46:33.160,0:46:41.330
still I use 500 here which is less than

0:46:36.680,0:46:46.160
a semi 784 so one proper question would

0:46:41.330,0:46:47.930
be why are 500 dimensions like why it

0:46:46.160,0:46:51.230
does a elting color with 500 Meg

0:46:47.930,0:46:53.840
dimensional hidden layer is consider or

0:46:51.230,0:46:56.090
can be considered over complete think

0:46:53.840,0:46:58.580
about the number of pixels that are

0:46:56.090,0:47:01.130
black for example on average in these

0:46:58.580,0:47:04.160
images alright so we actually already

0:47:01.130,0:47:06.500
run this part so we were down to the

0:47:04.160,0:47:09.440
training how does the training changes

0:47:06.500,0:47:12.500
right now I have a dropout mask here

0:47:09.440,0:47:14.120
which is allowing me to introduce some

0:47:12.500,0:47:17.660
kind of perturbation on the original

0:47:14.120,0:47:20.560
images then I have my noise which is

0:47:17.660,0:47:22.619
simply applying a drop of mask on a

0:47:20.560,0:47:24.380
vector of

0:47:22.619,0:47:27.479
is this going to be useful for later

0:47:24.380,0:47:30.269
visualizations then I create my images

0:47:27.479,0:47:32.009
bed the perturbed images which are

0:47:30.269,0:47:35.039
simply the multiplication of my image

0:47:32.009,0:47:38.429
times this noise so if we didn't have

0:47:35.039,0:47:40.769
any neuron dropped the noise would be

0:47:38.429,0:47:42.799
just those ones and that you get 1 times

0:47:40.769,0:47:45.329
image so you got the same image

0:47:42.799,0:47:47.640
otherwise when the neurons are dropping

0:47:45.329,0:47:50.429
set to 0 the image now is going to be

0:47:47.640,0:47:52.410
multiplied by 0 for no specific values

0:47:50.429,0:47:55.890
of the pixels so this image bed our

0:47:52.410,0:47:59.569
images with black dot then I input

0:47:55.890,0:48:04.049
inside my model this image pad ok and

0:47:59.569,0:48:06.739
then the criterion it's between like is

0:48:04.049,0:48:09.739
the distance between the output and the

0:48:06.739,0:48:12.449
original image man so before we were

0:48:09.739,0:48:14.849
like in here we are inputting these

0:48:12.449,0:48:16.650
perturbed images inside the model so

0:48:14.849,0:48:19.079
those are points that are outside the

0:48:16.650,0:48:21.390
training manifold but then I enforce

0:48:19.079,0:48:23.099
them to be the original point right so

0:48:21.390,0:48:25.140
you get the original point you perturb

0:48:23.099,0:48:27.479
it so you put it away and then you

0:48:25.140,0:48:28.919
enforce the network to actually I'll put

0:48:27.479,0:48:31.319
this on so it's going to be trying to

0:48:28.919,0:48:35.159
contrast any kind of perturbation that

0:48:31.319,0:48:37.679
happened to this original point ok all

0:48:35.159,0:48:40.499
right the rest is the same rank 0 guard

0:48:37.679,0:48:43.559
backwardness step so this is also train

0:48:40.499,0:48:47.130
and we can check how this reconstruction

0:48:43.559,0:48:50.059
look and if I can remember from the

0:48:47.130,0:48:52.679
previous iteration they look much more

0:48:50.059,0:48:56.279
actually clean because I guess we are

0:48:52.679,0:48:58.799
using a much larger hidden layer right

0:48:56.279,0:49:00.269
but before we couldn't use such a large

0:48:58.799,0:49:01.999
hidden layer because you would have been

0:49:00.269,0:49:04.019
overfitting right if you try to

0:49:01.999,0:49:05.669
reconstruct things that are always in

0:49:04.019,0:49:07.380
the same point we just can copy them

0:49:05.669,0:49:09.569
over in this case you can't copyright

0:49:07.380,0:49:11.609
because the input is not this point but

0:49:09.569,0:49:13.799
the input is actually the displace point

0:49:11.609,0:49:16.109
right so you learn a vector field that

0:49:13.799,0:49:20.039
is bringing you back to the original

0:49:16.109,0:49:22.949
position on the training manifold ok so

0:49:20.039,0:49:24.209
let's go down and let's visualize the

0:49:22.949,0:49:26.369
actually let's have a look to the

0:49:24.209,0:49:28.890
previous filters I didn't show you so

0:49:26.369,0:49:32.549
these are the filters of the outer

0:49:28.890,0:49:34.949
corner with a under complete hidden

0:49:32.549,0:49:35.480
layer ok and so you can see here there

0:49:34.949,0:49:37.850
are some

0:49:35.480,0:49:40.040
of patterns in this central area of

0:49:37.850,0:49:43.280
these filters so these are the filters

0:49:40.040,0:49:46.700
which are simply my rows of my W metrics

0:49:43.280,0:49:48.640
that have been reshaped in a basically

0:49:46.700,0:49:50.930
no image such that I can visualize

0:49:48.640,0:49:52.400
formula so in this case in this notebook

0:49:50.930,0:49:52.880
we are not using any convolutional

0:49:52.400,0:49:54.680
network

0:49:52.880,0:49:57.710
we are just using those images that have

0:49:54.680,0:49:59.210
been enrolled in protectors and they are

0:49:57.710,0:50:03.170
compared there and you know multiply it

0:49:59.210,0:50:05.420
like scalar product against the DD

0:50:03.170,0:50:07.040
vectors right of the of my matrix so

0:50:05.420,0:50:09.200
these are the rows of my matrix that

0:50:07.040,0:50:11.780
have been reshaped such that you can

0:50:09.200,0:50:13.430
make sense of what they represent so

0:50:11.780,0:50:16.850
here for example it looks like there is

0:50:13.430,0:50:18.470
like a loop upper loop detector or not a

0:50:16.850,0:50:20.600
detector because there are purple right

0:50:18.470,0:50:24.320
so these are would be negative the

0:50:20.600,0:50:26.359
output here you have like a C rule here

0:50:24.320,0:50:29.300
looks like some eight over three and

0:50:26.359,0:50:31.010
then you have this kind of right this

0:50:29.300,0:50:34.130
this this kernel over here and that has

0:50:31.010,0:50:36.410
basically learned nothing or well that's

0:50:34.130,0:50:39.320
the only one that didn't learn much

0:50:36.410,0:50:41.420
moreover you can notice that all those

0:50:39.320,0:50:43.490
points outside the region where the

0:50:41.420,0:50:45.619
number happened or any kind of

0:50:43.490,0:50:47.150
interesting thing happened all these

0:50:45.619,0:50:49.820
points are multiplied by a constant

0:50:47.150,0:50:52.150
right because it's outside a digit and

0:50:49.820,0:50:56.390
so things don't change there and

0:50:52.150,0:50:58.820
therefore these noisy kernels over there

0:50:56.390,0:51:00.710
you know the on average they will

0:50:58.820,0:51:03.109
produce a score of zero right and

0:51:00.710,0:51:06.080
therefore you're gonna have that the

0:51:03.109,0:51:08.300
network didn't care about giving any

0:51:06.080,0:51:11.840
specific value to these outstanding

0:51:08.300,0:51:13.850
without out there other points outer

0:51:11.840,0:51:16.130
pictures because I can on average they

0:51:13.850,0:51:19.300
will not contribute to the final score

0:51:16.130,0:51:24.010
what happened now when we are inputting

0:51:19.300,0:51:27.440
the data which have a variable amount of

0:51:24.010,0:51:29.570
like pixel set to zero now these points

0:51:27.440,0:51:32.930
will in matter right because it's not

0:51:29.570,0:51:35.619
longer continuous the value of the image

0:51:32.930,0:51:39.590
and so if I show you the new kernels

0:51:35.619,0:51:40.550
um how cool is this right this is

0:51:39.590,0:51:42.410
completely different

0:51:40.550,0:51:44.750
can you remember so here you can still

0:51:42.410,0:51:47.450
have some pattern right but then in the

0:51:44.750,0:51:48.990
majority of these kernels regardless

0:51:47.450,0:51:51.150
like if you don't consider the one that

0:51:48.990,0:51:53.550
did not did not learn anything so this

0:51:51.150,0:51:55.470
colonel here are didn't learn much but

0:51:53.550,0:51:57.300
all the other kernels that I have have

0:51:55.470,0:51:59.700
learned some kind of specific edge

0:51:57.300,0:52:02.580
filter or shape specific features

0:51:59.700,0:52:07.110
you know shape filter all the outside

0:52:02.580,0:52:08.880
pixels have now been set to some zero

0:52:07.110,0:52:11.940
value I think of some somebody that is

0:52:08.880,0:52:14.460
uniform right because again the input

0:52:11.940,0:52:17.250
images now are no longer constant in the

0:52:14.460,0:52:19.260
areas outside digit and therefore the

0:52:17.250,0:52:21.420
value of the pixels well the value of

0:52:19.260,0:52:23.280
the of the value of the kernel thing

0:52:21.420,0:52:26.540
though specifically specific regions now

0:52:23.280,0:52:30.210
do matter this is a big big difference

0:52:26.540,0:52:34.050
and again this this this maps here this

0:52:30.210,0:52:36.780
courier didn't learn anything okay so

0:52:34.050,0:52:38.610
let's now compare our denoising

0:52:36.780,0:52:41.450
auto-encoder we've failed

0:52:38.610,0:52:44.369
state-of-the-art algorithms for

0:52:41.450,0:52:46.470
denoising images so here we're going to

0:52:44.369,0:52:49.140
be importing some functions from the

0:52:46.470,0:52:51.960
opencv library there is the neighbor

0:52:49.140,0:52:55.650
strokes and then the tele algorithm so

0:52:51.960,0:52:59.130
it's imported and let's see how this

0:52:55.650,0:53:01.530
stuff look so here the first image is

0:52:59.130,0:53:03.630
the noise image the one we generated

0:53:01.530,0:53:05.630
before these are the maps of own ones

0:53:03.630,0:53:08.790
where we have dropped out some specific

0:53:05.630,0:53:11.700
values to set to 0 right so yellow is

0:53:08.790,0:53:14.310
one and purple is 0 in this case then

0:53:11.700,0:53:16.920
the second part is going to be the bed

0:53:14.310,0:53:20.400
images so these are the bed images

0:53:16.920,0:53:22.859
meaning purple is minus 1 yellow is plus

0:53:20.400,0:53:26.550
1 and then this green is the zero value

0:53:22.859,0:53:28.460
so all those black points like purple

0:53:26.550,0:53:31.170
points in the first row are here

0:53:28.460,0:53:32.940
represented in in green so those are the

0:53:31.170,0:53:36.210
values that are being set to 0 there are

0:53:32.940,0:53:40.650
mask value then we have the original

0:53:36.210,0:53:43.520
images and the reconstructions from our

0:53:40.650,0:53:46.230
you know is it not encoder which broke

0:53:43.520,0:53:48.420
reasonably okay if you think that half

0:53:46.230,0:53:51.390
of the pixels were actually nice right

0:53:48.420,0:53:53.070
so these are like half of the pixels are

0:53:51.390,0:53:54.660
provided to the network and then the

0:53:53.070,0:53:57.180
network actually reconstructed

0:53:54.660,0:54:00.119
both net and what look like the original

0:53:57.180,0:54:02.520
image more or less right cool Quan

0:54:00.119,0:54:06.510
so let's now have a look to what

0:54:02.520,0:54:10.110
the set of the art algorithms output are

0:54:06.510,0:54:13.130
so we can start with the Thalia and then

0:54:10.110,0:54:16.560
their strokes and so this is Thalia and

0:54:13.130,0:54:19.730
this is never stroke right so as you can

0:54:16.560,0:54:23.040
tell here the quality of our modern is

0:54:19.730,0:54:25.640
clearly a superior in terms of you know

0:54:23.040,0:54:28.080
qualitative qualitative output

0:54:25.640,0:54:30.360
nevertheless pay attention that this

0:54:28.080,0:54:32.160
modern works just for this kind of

0:54:30.360,0:54:33.660
specific perturbation that we have

0:54:32.160,0:54:39.030
introduced and then we haven't learned

0:54:33.660,0:54:41.070
how to counteract okay so again he note

0:54:39.030,0:54:42.990
encoder that we have trained in a in a

0:54:41.070,0:54:45.270
minute performs much better than

0:54:42.990,0:54:47.760
state-of-the-art computer vision

0:54:45.270,0:54:51.660
algorithms again when the ADA is

0:54:47.760,0:54:53.190
available okay and so I think that's it

0:54:51.660,0:54:55.500
for today thank you for listening

0:54:53.190,0:54:57.060
subscribe to my channel the non de

0:54:55.500,0:54:59.340
notification bed if you'd like to have

0:54:57.060,0:55:03.500
information about latest videos and

0:54:59.340,0:55:03.500
follow me on Twitter peace

