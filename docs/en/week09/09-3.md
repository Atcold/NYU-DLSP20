---
lang-ref: ch.09-3
title: Generative Adversarial Networks
authors: William Huang, Kunal Gadkar, Gaomin Wu, Lin Ye
date: 31 March 2020
---


## Kunal's Part

### Subtitle

[//]:# (Gaomin Wu)

## Difference between Generative Adversarial Network (GAN) and Variational Autoencoder (VAE)

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANvsVAE.jpg" height="300px" /><br>
<b>Fig. gan_v_vae</b>: GAN (left) vs. VAE (right)
</center>

Let's recall from Week 8 that a VAE (Fig. gan_v_vae right) uses an encoder to map the input $\vect{x}$ from the input space to latent space and adds some noise to get $\vect{z}$. Next, a decoder maps $\vect{z}$ from the latent space to output space to get $\vect{\hat{x}}$. In a VAE, we use reconstruction loss to measure the distance between the input $\vect{x}$ and output $\vect{\hat{x}}$. We minimize this loss through training, thereby forcing $\vect{\hat{x}}$ and $\vect{x}$ to be close.

For a GAN (Fig. gan_v_vae left), we start by sampling $\vect{z}$, similar to the latent space in a VAE. We then use a generative network to map $\vect{z}$ to $\vect{\hat{x}}$. This $\vect{\hat{x}}$ is then sent through a discriminator/cost network to evaluate how "real" it is. One of the main differences from VAE and GAN is that **we do not need to measure a direct relationship (i.e, reconstruction loss) between the output of the generative network $\vect{\hat{x}}$ and real data $\vect{x}$.** Instead, we force $\vect{\hat{x}}$ to be similar to $\vect{x}$ by training the generator to produce $\vect{\hat{x}}$ such that the discriminator/cost network produces scores that are similar to those of real data $\vect{x}$, or more "real".



## Major Pitfalls in GANs

While GANs can be powerful for building generators, they have some major pitfalls.

### 1. Unstable Convergence

As the generator improves with training, the discriminator performance gets worse because the discriminator can no longer easily tell the difference between real and fake data. If the generator is perfect, then the manifold of the real and fake data will be the same and the discriminator will create many misclassifications.

This progression poses a problem for convergence of the GAN: the discriminator feedback gets less meaningful over time. If the GAN continues training past the point when the discriminator is giving completely random feedback, then the generator starts to train on junk feedback and its quality may collapse. [Refer to [training convergence in GANs](https://developers.google.com/machine-learning/gan/training)]

As a result of this adversarial nature between the generator and discriminator there is a unstable equilibrium point rather than an equilibrium.

###  2. Vanishing Gradient

Let's consider we are using the binary cross entropy loss for a discriminator:

$$
\mathcal{L} = \mathbb{E}_\boldsymbol{x}[\log(D(\boldsymbol{x}))] + \mathbb{E}_\boldsymbol{\hat{x}}[\log(1-D(\boldsymbol{\hat{x}}))] \text{.}
$$


When the as the descriminator becomes more confident, $D(\vect{x})$ gets closer to $1$ and $D(\vect{\hat{x}})$ gets closer to $0$, where $D(\cdot)$ denotes the output of the discriminator. As we move into the flatter parts of the cost function, the gradients become more and more saturated. These flatter regions provide small, vanishing gradients that hinder the network's training. Thus, when training a GAN, you want to make sure that the cost gradually increases as you become more confident.

### 3. Mode Collapse

 If a generator maps all $\vect{z}$ from the sampler to a *single* $\vect{\hat{x}}$ that can fool the discriminator, then the generator will produce *only* that output. Eventually, the discriminator will learn to detect *specifically* this fake input. As a result, the generator simply finds the next most plausible $\vect{\hat{x}}$ and the cycle continues. As the cycle continues, the discriminator gets trapped in local minima to cycle through these fake $\vect{\hat{x}}$'s. A possible solution to this issue is to enfore some penalty to the generator for always giving the same output given different inputs.

[//]:# (Lin Ye)

## Source Code from PyTorch Examples: Deep Convolutional Generative Adversarial Network (DCGAN)

The source code of the example can be found at <https://github.com/pytorch/examples/blob/master/dcgan/main.py>

#### Generator

1. The generator upsamples the input using several `nn.ConvTranspose2d` modules seperated with `nn.BatchNorm2d` and `nn.ReLU`.
2. At the end of the sequential, the network uses `nn.Tanh()` to generate output from $-1$ to $1$.
3. The input is the latent vector of size $nz$. The output is of size $nc \times 64 \times 64$, where $nc$ is the number of channels.  

```python
class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        if input.is_cuda and self.ngpu > 1:
            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))
        else:
            output = self.main(input)
        return output
```

#### Discriminator

1. It's important to use `nn.LeakyReLU` as the activation function to avoid killing the gradient in negative regions. Without these gradients, the generator will not receive updates.
2. At the end of the sequential, the discriminator uses `nn.Sigmoid()` to generate an classify the input.

```python
class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        if input.is_cuda and self.ngpu > 1:
            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))
        else:
            output = self.main(input)

        return output.view(-1, 1).squeeze(1)
```

These two classes are initialized as `netG` and `netD`.

#### Loss function for GAN

We use Binary Cross Entropy (BCE) between target and output. 

```python
criterion = nn.BCELoss()
```

#### Setup

We set up `fixed_noise` of size `opt.batchSize' and length of latent vector `nz`. We also create labels for real data and fake data from the generator.

```python
fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)
real_label = 1
fake_label = 0
```

Then we set up optimizers for discriminator and generator networks.

```python
optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
```

#### Training

Each epoch of training is divided into two steps.

**Step 1** is to update the discriminator network. This is done in two parts. First, we feed the discriminator real data coming from dataloaders, compute the loss between the output and real labels, and then accumulate gradients with backpropagation. Second, we feed the discriminator data generated by the generator network using the fixed_noise, compute the loss between the output and fake labels, and then accumulate the gradient. Finally, we use the accumulated gradients to update the parameters for the discriminator network.

Note that we detach the fake data to stop gradients from propagating to the generator while we train the discriminator.

Also note that we only need to call `zero_grad()` once in the beginning to clear the gradients so the gradients from both the real and fake data can be used for the update. The two `.backward()` calls accumulate these gradients. We finally only need one call of `optimizerD.step()` to update the parameters.

```python
# train with real
netD.zero_grad()
real_cpu = data[0].to(device)
batch_size = real_cpu.size(0)
label = torch.full((batch_size,), real_label, device=device)

output = netD(real_cpu)
errD_real = criterion(output, label)
errD_real.backward()
D_x = output.mean().item()

# train with fake
noise = torch.randn(batch_size, nz, 1, 1, device=device)
fake = netG(noise)
label.fill_(fake_label)
output = netD(fake.detach())
errD_fake = criterion(output, label)
errD_fake.backward()
D_G_z1 = output.mean().item()
errD = errD_real + errD_fake
optimizerD.step()
```

**Step 2** is to update the Generator network. This time, we feed the discriminator the fake data, but compute the loss with the real labels! The purpose of doing this is to train the generator to make "realistic" $\vect{\hat{x}}$'s.

```python
netG.zero_grad()
label.fill_(real_label)  # fake labels are real for generator cost
output = netD(fake)
errG = criterion(output, label)
errG.backward()
D_G_z2 = output.mean().item()
optimizerG.step()
```
