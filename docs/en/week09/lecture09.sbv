0:00:00.000,0:00:03.280
all right so i guess we can get started

0:00:01.439,0:00:07.200
uh this is the third part of

0:00:03.280,0:00:09.599
uh the lecture on energy based models

0:00:07.200,0:00:11.120
uh which we are we're going to continue

0:00:09.599,0:00:11.599
a little bit what we talked about last

0:00:11.120,0:00:14.639
time

0:00:11.599,0:00:17.680
on sparse coding and

0:00:14.639,0:00:18.880
talk about gans very briefly you'll hear

0:00:17.680,0:00:22.000
more about it tomorrow

0:00:18.880,0:00:23.199
from alfredo and then talk about

0:00:22.000,0:00:27.279
learning world models

0:00:23.199,0:00:28.880
and similar things also about a bit of

0:00:27.279,0:00:30.320
a little bit about exotic

0:00:28.880,0:00:32.000
self-supervised and unsupervised

0:00:30.320,0:00:33.840
learning algorithms

0:00:32.000,0:00:35.680
that are kind of you know active

0:00:33.840,0:00:38.160
research topics at the moment

0:00:35.680,0:00:39.040
so one thing i talked about last time

0:00:38.160,0:00:42.719
was sparse coding

0:00:39.040,0:00:45.120
and i'm going to mention just a

0:00:42.719,0:00:47.280
very simple idea which consists in sort

0:00:45.120,0:00:47.280
of

0:00:47.600,0:00:52.239
combining uh sparse coding or the audio

0:00:51.039,0:00:55.199
sparsely encoder

0:00:52.239,0:00:56.239
with uh discriminative training so

0:00:55.199,0:00:58.960
imagine that

0:00:56.239,0:00:59.280
the architecture i'm showing you here uh

0:00:58.960,0:01:02.559
the

0:00:59.280,0:01:05.760
the encoder if you will the the first uh

0:01:02.559,0:01:09.119
part on the left is uh

0:01:05.760,0:01:11.680
mostly uh similar to the encoder i

0:01:09.119,0:01:14.000
talked about for the the lista method

0:01:11.680,0:01:16.080
so you start with the x variable you run

0:01:14.000,0:01:16.960
it through a matrix

0:01:16.080,0:01:19.119
then you run that through a

0:01:16.960,0:01:21.759
non-linearity it could be a value for

0:01:19.119,0:01:24.720
example this is the case here

0:01:21.759,0:01:25.600
and then you take the result multiplied

0:01:24.720,0:01:27.119
by

0:01:25.600,0:01:29.439
some matrix which we're going to learn

0:01:27.119,0:01:31.759
at this with the

0:01:29.439,0:01:33.280
product of the input by the encoding

0:01:31.759,0:01:34.880
matrix we

0:01:33.280,0:01:37.439
and then pass this to a non-linearity

0:01:34.880,0:01:39.920
and you can repeat this little block

0:01:37.439,0:01:42.079
this green block here multiple times

0:01:39.920,0:01:43.360
each of those is a layer basically that

0:01:42.079,0:01:46.000
consists in

0:01:43.360,0:01:46.880
a matrix or a bunch of convolutions uh

0:01:46.000,0:01:48.720
in addition with

0:01:46.880,0:01:50.720
uh some you know pre-existing variable

0:01:48.720,0:01:52.720
and a non-linearity

0:01:50.720,0:01:54.479
so this is you know a funny kind of

0:01:52.720,0:01:58.000
neural network where you have kind of

0:01:54.479,0:01:59.439
uh skipping connections

0:01:58.000,0:02:01.200
and then we're going to train this

0:01:59.439,0:02:02.880
neural network to do

0:02:01.200,0:02:04.560
uh three different things or with three

0:02:02.880,0:02:05.600
different criteria one criterion is

0:02:04.560,0:02:08.560
going to be

0:02:05.600,0:02:10.160
uh just reconstruct x okay so there's

0:02:08.560,0:02:14.400
going to be a decoding matrix that

0:02:10.160,0:02:16.480
is uh going to reproduce the input

0:02:14.400,0:02:19.440
on the output and we're going to do this

0:02:16.480,0:02:20.640
by just minimizing squared error

0:02:19.440,0:02:22.480
so this is what's indicated by the

0:02:20.640,0:02:23.840
decoding filters here

0:02:22.480,0:02:26.400
and again this could be convolutional or

0:02:23.840,0:02:28.800
not depending on which version you

0:02:26.400,0:02:29.599
you like there's going to be an l1

0:02:28.800,0:02:33.200
criterion

0:02:29.599,0:02:35.120
on the on the feature vector

0:02:33.200,0:02:37.360
that makes it sparse so this is very

0:02:35.120,0:02:38.800
much like a sparse auto encoder

0:02:37.360,0:02:41.040
of the type that we talked about last

0:02:38.800,0:02:42.879
week but then we're

0:02:41.040,0:02:44.319
also going to add a third term and this

0:02:42.879,0:02:48.080
third term is going to be

0:02:44.319,0:02:51.360
basically a a simple linear

0:02:48.080,0:02:53.920
classifier which is going to

0:02:51.360,0:02:54.560
try to predict a category okay and we're

0:02:53.920,0:02:56.640
going to

0:02:54.560,0:02:58.319
train the system to minimize all three

0:02:56.640,0:03:00.080
criteria at the same time

0:02:58.319,0:03:01.840
so this is a sparse autoencoder that

0:03:00.080,0:03:04.879
also tries to find codes that do a good

0:03:01.840,0:03:06.319
job at prediction

0:03:04.879,0:03:07.599
and this is sort of a good way you can

0:03:06.319,0:03:09.440
you can see this in two different ways

0:03:07.599,0:03:11.200
you can you can see this as

0:03:09.440,0:03:12.720
an auto encoder that is biased towards

0:03:11.200,0:03:14.560
producing good labels or you can see

0:03:12.720,0:03:16.560
this as a classifier

0:03:14.560,0:03:19.040
multi-layer classifier that is

0:03:16.560,0:03:20.400
regularized by an auto encoder

0:03:19.040,0:03:22.720
what's the advantage of this with the

0:03:20.400,0:03:24.080
advantage is that by

0:03:22.720,0:03:26.080
forcing the system to find

0:03:24.080,0:03:27.040
representations here at the second last

0:03:26.080,0:03:29.760
layer

0:03:27.040,0:03:31.360
that uh can reconstruct the input then

0:03:29.760,0:03:33.040
you're basically

0:03:31.360,0:03:34.400
biasing the system towards extracting

0:03:33.040,0:03:38.080
features that contain as much

0:03:34.400,0:03:38.080
information about the input as possible

0:03:38.159,0:03:41.200
so that sort of

0:03:41.280,0:03:45.519
makes the features richer if you want it

0:03:43.840,0:03:47.360
forces the system to

0:03:45.519,0:03:49.200
not generate degenerate features but to

0:03:47.360,0:03:50.799
generate features that contain as much

0:03:49.200,0:03:53.440
information as possible about

0:03:50.799,0:03:53.440
about the input

0:03:54.159,0:03:57.280
that works pretty well i think it's an

0:03:55.840,0:04:00.560
underexplored method

0:03:57.280,0:04:03.360
for training neural nets

0:04:00.560,0:04:03.920
um because very often we don't have

0:04:03.360,0:04:07.120
enough

0:04:03.920,0:04:09.280
uh label training data or when

0:04:07.120,0:04:10.879
the the training data is such that you

0:04:09.280,0:04:12.720
don't have a lot of categories

0:04:10.879,0:04:14.560
um to work with maybe it's a two or

0:04:12.720,0:04:17.120
three or ten classic problem

0:04:14.560,0:04:18.560
which we know tend to produce very

0:04:17.120,0:04:20.560
generic degenerate features

0:04:18.560,0:04:21.759
uh in a neural net as we discussed last

0:04:20.560,0:04:24.000
time

0:04:21.759,0:04:25.040
then forcing the system to reconstruct

0:04:24.000,0:04:27.040
basically

0:04:25.040,0:04:28.320
tells it you know you can't generate

0:04:27.040,0:04:31.120
features that are too

0:04:28.320,0:04:32.880
degenerate will sort of generate that uh

0:04:31.120,0:04:34.400
you can't reconstruct the input from it

0:04:32.880,0:04:37.440
so that's sort of a good you could think

0:04:34.400,0:04:39.120
of it as a good regularizer

0:04:37.440,0:04:41.120
okay group sparsity and structural

0:04:39.120,0:04:42.720
sparsity so there's some work

0:04:41.120,0:04:45.360
going back about 10 years maybe a little

0:04:42.720,0:04:47.040
more uh in fact the first work on this

0:04:45.360,0:04:48.800
are about 20 years old

0:04:47.040,0:04:50.479
on the idea of goose parsley what does

0:04:48.800,0:04:52.639
that mean

0:04:50.479,0:04:54.160
um here is here is the idea the idea is

0:04:52.639,0:04:57.440
to train a system to generate spice

0:04:54.160,0:04:59.840
features but not just

0:04:57.440,0:05:02.720
normal features that are extracted say

0:04:59.840,0:05:04.720
by a bunch of convolutions and values

0:05:02.720,0:05:06.080
but to basically produce part spot

0:05:04.720,0:05:08.960
features that are sparse

0:05:06.080,0:05:10.000
after the pooling okay so you

0:05:08.960,0:05:12.160
essentially have a system

0:05:10.000,0:05:13.520
that consists of convolutions

0:05:12.160,0:05:17.199
non-linearity and pooling

0:05:13.520,0:05:17.199
you try to make those features sparse

0:05:17.840,0:05:20.880
and there's a number of different work

0:05:19.360,0:05:24.160
the idea goes back to

0:05:20.880,0:05:26.080
ivarian and hoyer in 2001 uh in the

0:05:24.160,0:05:27.440
context of ica independent component

0:05:26.080,0:05:29.039
analysis

0:05:27.440,0:05:31.280
and then there were you know a few other

0:05:29.039,0:05:32.240
papers one by osindero in jeff eaton's

0:05:31.280,0:05:35.520
group

0:05:32.240,0:05:36.880
um and then karai uh truly was a student

0:05:35.520,0:05:40.000
of mine back in the

0:05:36.880,0:05:40.639
late 2000s uh carl greger who was posed

0:05:40.000,0:05:42.720
up with me

0:05:40.639,0:05:44.560
giuliana merrell who is in the in france

0:05:42.720,0:05:46.400
and a bunch of other people

0:05:44.560,0:05:47.759
on on this idea of structural space

0:05:46.400,0:05:51.440
coding so

0:05:47.759,0:05:53.759
the idea basically is you take um

0:05:51.440,0:05:54.960
uh so some of those uh models only have

0:05:53.759,0:05:56.479
an encoder some of them only have a

0:05:54.960,0:05:57.360
decoder and some of them are auto

0:05:56.479,0:05:58.800
encoders right

0:05:57.360,0:06:02.560
so the one on the left is in the airways

0:05:58.800,0:06:05.440
model is an encoder only model

0:06:02.560,0:06:07.759
julia alex model is a decoder only model

0:06:05.440,0:06:09.759
and choreographers model is

0:06:07.759,0:06:11.520
uh basically an autoencoder a space

0:06:09.759,0:06:13.520
autoencoder of the type that we talked

0:06:11.520,0:06:16.800
about last time

0:06:13.520,0:06:20.560
um so how does that work

0:06:16.800,0:06:22.319
uh let's take say an encoder only model

0:06:20.560,0:06:24.400
you have a feature extractor which

0:06:22.319,0:06:28.800
consists of convolutions or

0:06:24.400,0:06:31.520
maybe just uh fully connected uh

0:06:28.800,0:06:32.800
matrices over a patch an image patch for

0:06:31.520,0:06:34.960
example

0:06:32.800,0:06:36.000
and then instead of forcing the output

0:06:34.960,0:06:37.680
of this to be

0:06:36.000,0:06:39.360
after a non-linearity instead of forcing

0:06:37.680,0:06:41.840
that to be sparse

0:06:39.360,0:06:44.639
you you put a pulling layer and you you

0:06:41.840,0:06:46.880
force the pulling to be sparse

0:06:44.639,0:06:48.240
uh and this applies to uh all three of

0:06:46.880,0:06:51.520
those

0:06:48.240,0:06:52.639
um so here is a more specific example

0:06:51.520,0:06:55.599
this is the

0:06:52.639,0:06:57.440
the version that uh correct true uh did

0:06:55.599,0:07:00.319
for his phd this is where

0:06:57.440,0:07:02.400
he had a sparse auto encoder so you have

0:07:00.319,0:07:05.120
an encoding function g e of w

0:07:02.400,0:07:06.479
e y i it could be multiple layers in

0:07:05.120,0:07:07.599
this case it was basically just two

0:07:06.479,0:07:09.759
layers

0:07:07.599,0:07:12.000
uh with one non-linearity you have a

0:07:09.759,0:07:12.319
decoder which in this case was linear wd

0:07:12.000,0:07:15.360
times

0:07:12.319,0:07:17.919
e evaluating variable z and that agent

0:07:15.360,0:07:21.360
variable instead of going to an l1

0:07:17.919,0:07:23.280
it goes through uh basically an l2

0:07:21.360,0:07:26.479
but it's l2 over groups right so you

0:07:23.280,0:07:28.960
take a group of components of z

0:07:26.479,0:07:30.240
you compute the l2 norm not the square

0:07:28.960,0:07:31.919
to norm but the l2 norm

0:07:30.240,0:07:33.520
which means the square root of the sum

0:07:31.919,0:07:36.319
of the values

0:07:33.520,0:07:37.520
of those components uh of the square of

0:07:36.319,0:07:38.960
those components right

0:07:37.520,0:07:40.960
so take each component compute the

0:07:38.960,0:07:42.960
square and then compute the sum

0:07:40.960,0:07:44.240
of a group of those squares and then

0:07:42.960,0:07:46.400
compute the square root of that

0:07:44.240,0:07:47.759
so that's the l2 norm of that within

0:07:46.400,0:07:49.599
that group

0:07:47.759,0:07:50.800
and then you do this for multiple groups

0:07:49.599,0:07:52.479
the groups can be overlapping or

0:07:50.800,0:07:54.720
non-overlapping

0:07:52.479,0:07:56.240
and you compute the sum and that's your

0:07:54.720,0:07:58.319
regularizer that's your sparsity

0:07:56.240,0:08:01.759
regularizer so what does that

0:07:58.319,0:08:04.639
tend to do it tends to basically

0:08:01.759,0:08:06.160
turn off the maximum number of groups

0:08:04.639,0:08:09.039
okay the system basically

0:08:06.160,0:08:10.639
is sparsity on groups so it wants the

0:08:09.039,0:08:13.199
smallest number of groups to be on

0:08:10.639,0:08:15.520
at any one time but within a group

0:08:13.199,0:08:17.120
because it's an l2 norm within a group

0:08:15.520,0:08:19.199
it doesn't care how many units are on

0:08:17.120,0:08:21.919
within the group

0:08:19.199,0:08:23.520
so many units can be on within a group

0:08:21.919,0:08:26.960
so what does that do

0:08:23.520,0:08:30.319
it it forces the system basically

0:08:26.960,0:08:31.360
to group within a pool features that

0:08:30.319,0:08:33.279
turn on

0:08:31.360,0:08:34.560
simultaneously right so if you have

0:08:33.279,0:08:36.560
features that are very similar

0:08:34.560,0:08:38.399
feature extra extractors that are very

0:08:36.560,0:08:40.719
similar filters that are very similar in

0:08:38.399,0:08:41.919
a commercial net then those features

0:08:40.719,0:08:44.640
will tend to kind of

0:08:41.919,0:08:46.800
uh when you do the training they'll try

0:08:44.640,0:08:48.800
to group themselves within a group

0:08:46.800,0:08:51.040
because they will tend to be activated

0:08:48.800,0:08:52.480
together that's the best way to minimize

0:08:51.040,0:08:55.839
the number of groups that are activated

0:08:52.480,0:08:55.839
at any one time

0:08:56.399,0:09:01.360
so to get those those interesting kind

0:09:00.080,0:09:03.920
of

0:09:01.360,0:09:06.399
pictures here the way this was obtained

0:09:03.920,0:09:06.399
is by

0:09:06.640,0:09:09.680
here the groups so what you're looking

0:09:09.040,0:09:12.720
at here

0:09:09.680,0:09:15.120
are the either the uh i think it's the

0:09:12.720,0:09:18.399
decoding matrix so these are the

0:09:15.120,0:09:21.519
the the columns of the wd matrix um

0:09:18.399,0:09:24.720
that we can reconstruct an image patch

0:09:21.519,0:09:29.200
from the sparse code

0:09:24.720,0:09:29.200
by multiplying by that matrix

0:09:30.560,0:09:33.680
but what we do here is that we group

0:09:32.800,0:09:36.480
those features

0:09:33.680,0:09:38.240
into blocks of 36 so we arrange all the

0:09:36.480,0:09:39.839
features in a 2d map that has nothing to

0:09:38.240,0:09:41.760
do with the topology of the image we

0:09:39.839,0:09:43.360
could choose any topology we want

0:09:41.760,0:09:46.000
in fact this is not actually a 2d

0:09:43.360,0:09:47.600
topology it's a it's a toridol topology

0:09:46.000,0:09:50.720
so the left side touches the right side

0:09:47.600,0:09:52.720
on the top touches the bottom

0:09:50.720,0:09:55.120
so it's topologically identical to

0:09:52.720,0:09:55.120
taurus

0:09:55.440,0:10:04.800
and what we do is we regroup

0:10:00.720,0:10:07.839
sets of 36 features within a group okay

0:10:04.800,0:10:08.800
and those uh groups of 36 features

0:10:07.839,0:10:11.120
overlap by

0:10:08.800,0:10:13.040
by three columns and three rows okay so

0:10:11.120,0:10:14.480
we have multiple groups of 36 features

0:10:13.040,0:10:18.160
six by six

0:10:14.480,0:10:20.079
shifted by three you could think of this

0:10:18.160,0:10:21.600
as kind of pulling over

0:10:20.079,0:10:22.880
feature but not putting over space

0:10:21.600,0:10:25.519
because there's no space here it's a

0:10:22.880,0:10:27.279
free connected network

0:10:25.519,0:10:28.560
but it has a bit of the flavor the same

0:10:27.279,0:10:31.440
flavor as pooling

0:10:28.560,0:10:32.800
except here you pull over 36 features

0:10:31.440,0:10:36.240
you don't pull over space

0:10:32.800,0:10:36.240
all right so

0:10:37.760,0:10:41.040
so then you you compute the sum of the

0:10:40.240,0:10:43.920
l2

0:10:41.040,0:10:44.800
norm of the the features that are within

0:10:43.920,0:10:46.480
each group

0:10:44.800,0:10:49.279
and that's the regularizer you use when

0:10:46.480,0:10:51.920
you train your your sparse autoencoder

0:10:49.279,0:10:53.440
so the system uh wants to do is minimize

0:10:51.920,0:10:54.480
the number of groups that are on at any

0:10:53.440,0:10:58.000
one time

0:10:54.480,0:10:59.440
and so as i said before it basically

0:10:58.000,0:11:01.040
it regroups all the features that are

0:10:59.440,0:11:04.399
similar and likely to fire

0:11:01.040,0:11:06.320
simultaneously into into groups

0:11:04.399,0:11:09.040
and because the groups overlap then it

0:11:06.320,0:11:12.079
creates those kind of slowly evolving

0:11:09.040,0:11:12.959
sets of features that sort of uh seem to

0:11:12.079,0:11:17.120
kind of swirl

0:11:12.959,0:11:18.959
around a point

0:11:17.120,0:11:20.480
so the features you get as a result of

0:11:18.959,0:11:22.399
this have some sort of invariance and

0:11:20.480,0:11:25.120
they have some invariance not to

0:11:22.399,0:11:26.640
shift but to things like rotation and

0:11:25.120,0:11:29.680
scale and things like that

0:11:26.640,0:11:31.600
whatever the system decides so here the

0:11:29.680,0:11:34.399
reason for choosing a 2d topology

0:11:31.600,0:11:34.880
is basically just for you know to make

0:11:34.399,0:11:37.360
it look

0:11:34.880,0:11:38.959
beautiful but uh you could you could

0:11:37.360,0:11:40.959
choose any kind of topology

0:11:38.959,0:11:43.279
you want what is on the x-axis and the

0:11:40.959,0:11:45.360
y-axis here in this diagram so those are

0:11:43.279,0:11:48.720
arbitrary axes

0:11:45.360,0:11:50.079
i have i don't even remember how many

0:11:48.720,0:11:52.639
features there are here this

0:11:50.079,0:11:53.839
this might be 256 features i think it's

0:11:52.639,0:11:57.360
16 by 16.

0:11:53.839,0:11:59.040
so there's 256 uh hidden units right so

0:11:57.360,0:12:02.000
imagine a network that has

0:11:59.040,0:12:03.920
a 12 by 12 input patch okay an input

0:12:02.000,0:12:08.320
image it's a patch from an image

0:12:03.920,0:12:11.200
and 256 uh hidden units

0:12:08.320,0:12:12.800
with a fully connected full connection

0:12:11.200,0:12:16.000
uh non-linearity and there is

0:12:12.800,0:12:18.399
uh another layer on top

0:12:16.000,0:12:19.279
um then that's the encoder and then you

0:12:18.399,0:12:21.360
have uh

0:12:19.279,0:12:23.279
this group sparsity and then the the

0:12:21.360,0:12:26.079
decoder is linear

0:12:23.279,0:12:28.320
okay and what you're seeing here are the

0:12:26.079,0:12:31.120
columns of the decoder

0:12:28.320,0:12:32.480
and they are organized in a 2d topology

0:12:31.120,0:12:34.160
okay but it's arbitrary

0:12:32.480,0:12:36.079
each of these squares is a column of the

0:12:34.160,0:12:37.200
decoder each of these square is a column

0:12:36.079,0:12:39.440
of decoder that

0:12:37.200,0:12:41.200
also corresponds to a component of z

0:12:39.440,0:12:44.720
okay a component of the

0:12:41.200,0:12:46.880
for the feature the future vector

0:12:44.720,0:12:48.639
and so they are organized in a 16 by 16

0:12:46.880,0:12:49.519
matrix but it's kind of arbitrary we

0:12:48.639,0:12:51.600
just you know

0:12:49.519,0:12:52.639
put them in a in a matrix and then we

0:12:51.600,0:12:56.000
train

0:12:52.639,0:12:58.399
and because uh the groups take

0:12:56.000,0:12:59.360
kind of six by six neighborhoods in this

0:12:58.399,0:13:02.240
topology

0:12:59.360,0:13:03.760
the system naturally kind of learns

0:13:02.240,0:13:06.079
features that are similar when they're

0:13:03.760,0:13:08.720
nearby within this topology

0:13:06.079,0:13:10.959
all right but again i could have chosen

0:13:08.720,0:13:15.040
any kind of topology

0:13:10.959,0:13:15.040
1d2d 3d or even some graph

0:13:16.000,0:13:19.680
neighborhood of some kind as long as the

0:13:18.320,0:13:21.680
pooling is

0:13:19.680,0:13:24.800
you know between neighbors on the graph

0:13:21.680,0:13:24.800
that's that will work

0:13:28.079,0:13:32.839
so what i've done here is going to

0:13:30.240,0:13:35.440
repeat this this little

0:13:32.839,0:13:38.240
pattern um to kind of show

0:13:35.440,0:13:38.800
uh because it's you know it's historical

0:13:38.240,0:13:42.079
uh

0:13:38.800,0:13:44.160
to show the you know how those those

0:13:42.079,0:13:46.160
those patterns kind of repeat and are

0:13:44.160,0:13:48.560
sort of periodical

0:13:46.160,0:13:49.440
and the reason for visualizing it this

0:13:48.560,0:13:50.639
way is that

0:13:49.440,0:13:52.240
this is the kind of stuff that

0:13:50.639,0:13:53.519
neuroscientists observe when they poke

0:13:52.240,0:13:56.560
electrodes in the

0:13:53.519,0:13:58.800
usual primary visual cortex of

0:13:56.560,0:14:00.240
mammals but most most animals that have

0:13:58.800,0:14:02.079
good vision

0:14:00.240,0:14:04.639
they see kind of those kind of swirling

0:14:02.079,0:14:07.199
patterns where neighboring

0:14:04.639,0:14:09.360
neurons detect similar features which

0:14:07.199,0:14:12.000
means similar oriented edges they are

0:14:09.360,0:14:13.279
sensitive to oriented edges and and

0:14:12.000,0:14:15.360
neighboring

0:14:13.279,0:14:16.959
neurons are similar are sensitive to

0:14:15.360,0:14:19.920
similar angles

0:14:16.959,0:14:20.240
or the same angles that similar scale or

0:14:19.920,0:14:23.360
or

0:14:20.240,0:14:25.760
things like that and so

0:14:23.360,0:14:26.560
perhaps this is how you know the brain

0:14:25.760,0:14:29.519
organizes

0:14:26.560,0:14:31.519
its uh its neurons it's by kind of

0:14:29.519,0:14:32.000
basically having some sort of criterion

0:14:31.519,0:14:33.519
on the

0:14:32.000,0:14:35.680
complex cells which are the equivalent

0:14:33.519,0:14:37.920
of the pulling units that we're seeing

0:14:35.680,0:14:37.920
here

0:14:38.320,0:14:42.839
um here is the another example here so

0:14:41.199,0:14:46.560
this one is

0:14:42.839,0:14:47.760
uh not at the patch level but it uses

0:14:46.560,0:14:49.120
local connections

0:14:47.760,0:14:51.600
but it's not convolutional in the sense

0:14:49.120,0:14:53.040
that it doesn't use uh shared weights

0:14:51.600,0:14:55.600
the reason for doing this is to have

0:14:53.040,0:14:59.199
some you know a semi-realistic

0:14:55.600,0:15:02.399
uh sort of correspondence to

0:14:59.199,0:15:03.760
a uh uh sort of biological learning

0:15:02.399,0:15:04.720
where of course you know neurons in the

0:15:03.760,0:15:07.839
brain cancer

0:15:04.720,0:15:09.120
can't share weights right they um they

0:15:07.839,0:15:11.680
end up being similar because

0:15:09.120,0:15:14.240
you know they train using some sort of

0:15:11.680,0:15:15.600
unsupervised learning but

0:15:14.240,0:15:18.000
there is no such thing as as well

0:15:15.600,0:15:20.560
sharing in the brain as far as we know

0:15:18.000,0:15:22.480
so it was asked if the uh if you're a

0:15:20.560,0:15:24.560
similar similar strategy of the

0:15:22.480,0:15:26.320
training of the autoencoder with the

0:15:24.560,0:15:27.839
classifier and the regular

0:15:26.320,0:15:29.519
regularizer can be applied for a

0:15:27.839,0:15:31.680
variation of the encoder and

0:15:29.519,0:15:32.959
whether this has been explored if it

0:15:31.680,0:15:35.920
works as well

0:15:32.959,0:15:37.920
for the first slide you show yeah so um

0:15:35.920,0:15:40.480
you're basically

0:15:37.920,0:15:41.040
adding noise in a variation auto encoder

0:15:40.480,0:15:44.000
and

0:15:41.040,0:15:44.480
forcing sparsity are basically two ways

0:15:44.000,0:15:46.160
to

0:15:44.480,0:15:47.920
achieve the same purpose which is reduce

0:15:46.160,0:15:49.199
the capacity of the

0:15:47.920,0:15:51.040
of the legend variable reduce the

0:15:49.199,0:15:53.440
capacity of the of the code

0:15:51.040,0:15:54.959
that is extracted by the autoencoder and

0:15:53.440,0:15:56.880
this is what prevents the system from

0:15:54.959,0:15:58.000
running a trivial identity function

0:15:56.880,0:16:00.399
which would not be useful

0:15:58.000,0:16:01.360
right and what we talked about the last

0:16:00.399,0:16:03.360
couple times

0:16:01.360,0:16:05.040
is the fact that if you reduce the

0:16:03.360,0:16:07.759
information capacity

0:16:05.040,0:16:08.320
of the latent variable of the code you

0:16:07.759,0:16:10.959
uh

0:16:08.320,0:16:12.079
as a consequence you also minimize the

0:16:10.959,0:16:15.040
volume of

0:16:12.079,0:16:16.079
space that can take low energy okay

0:16:15.040,0:16:17.360
because you limit the number of

0:16:16.079,0:16:19.680
configurations

0:16:17.360,0:16:21.279
of the code and so as a consequence you

0:16:19.680,0:16:22.560
can limit the volume of space that can

0:16:21.279,0:16:25.839
take low energy

0:16:22.560,0:16:28.160
so essentially this idea of

0:16:25.839,0:16:29.920
regularizing with l1 or sparsity or

0:16:28.160,0:16:30.560
something like this or adding noise to a

0:16:29.920,0:16:33.839
code

0:16:30.560,0:16:35.279
where limiting the norm of the code

0:16:33.839,0:16:37.680
achieves the same purpose which is

0:16:35.279,0:16:40.480
limiting the capacity of the of the code

0:16:37.680,0:16:42.240
for the purpose of limiting the volume

0:16:40.480,0:16:44.959
of space that can take low energy

0:16:42.240,0:16:46.720
and as a consequence if you train part

0:16:44.959,0:16:48.399
of the space to have low energy by

0:16:46.720,0:16:50.480
minimizing the reconstruction error

0:16:48.399,0:16:52.000
on your training samples automatically

0:16:50.480,0:16:52.639
the rest of the space will have higher

0:16:52.000,0:16:54.160
energy

0:16:52.639,0:16:56.320
because the capacity the volume the

0:16:54.160,0:16:59.440
kentucky energy is limited

0:16:56.320,0:17:02.160
um so this is uh just to recap

0:16:59.440,0:17:03.519
uh we talked about last time and and a

0:17:02.160,0:17:05.919
couple weeks ago

0:17:03.519,0:17:06.959
this is to this is sort of the

0:17:05.919,0:17:08.880
alternative

0:17:06.959,0:17:10.480
so those kind of architectural methods

0:17:08.880,0:17:12.559
are alternatives to the

0:17:10.480,0:17:13.679
contrastive methods where you explicitly

0:17:12.559,0:17:16.720
push up

0:17:13.679,0:17:18.000
on the energy of bad samples

0:17:16.720,0:17:19.280
which means you have to come up with a

0:17:18.000,0:17:20.799
good idea you know a good way of

0:17:19.280,0:17:23.439
generating bad samples

0:17:20.799,0:17:23.919
in that case okay so again remember

0:17:23.439,0:17:26.240
those two

0:17:23.919,0:17:27.600
types of methods contractive methods you

0:17:26.240,0:17:29.600
push down the energy of the training

0:17:27.600,0:17:32.080
samples you push up the energy of stuff

0:17:29.600,0:17:33.280
outside either by corrupting the

0:17:32.080,0:17:36.720
original samples

0:17:33.280,0:17:37.919
or by doing uh uh gradient noisy

0:17:36.720,0:17:39.360
gradient descent you know contrast

0:17:37.919,0:17:41.039
divergence things like this

0:17:39.360,0:17:42.799
or by generating contrasting points in

0:17:41.039,0:17:44.000
some way um

0:17:42.799,0:17:45.760
we've seen a bunch of different

0:17:44.000,0:17:46.559
contrasting methods and then the

0:17:45.760,0:17:52.000
alternative

0:17:46.559,0:17:54.640
is limiting the capacity of a code

0:17:52.000,0:17:56.000
uh or or kind of limiting the volume of

0:17:54.640,0:17:56.799
stuff that can take low energy in the

0:17:56.000,0:17:58.799
context of

0:17:56.799,0:18:01.919
autoencoder or predictor this means

0:17:58.799,0:18:04.160
limiting the capacity of the code

0:18:01.919,0:18:05.679
and there are many ways to do this one

0:18:04.160,0:18:07.520
way is through sparsity

0:18:05.679,0:18:09.760
one way is through adding noise while

0:18:07.520,0:18:11.440
limiting the norm that's the a east

0:18:09.760,0:18:13.039
and there are other ways that we'll

0:18:11.440,0:18:14.640
we'll talk about in a minute whenever

0:18:13.039,0:18:15.600
you were talking before about the group

0:18:14.640,0:18:18.400
sparsity

0:18:15.600,0:18:19.600
uh you are summing just a few samples

0:18:18.400,0:18:21.760
like a few

0:18:19.600,0:18:22.880
indexes within a small range what is

0:18:21.760,0:18:25.679
that pj

0:18:22.880,0:18:26.000
maybe i didn't ej is a group it's a pool

0:18:25.679,0:18:27.440
so

0:18:26.000,0:18:29.200
imagine this is a pool like in a

0:18:27.440,0:18:30.160
convolutional net but the pool instead

0:18:29.200,0:18:32.320
of

0:18:30.160,0:18:33.520
putting just over space it pulls over

0:18:32.320,0:18:36.320
features as well

0:18:33.520,0:18:37.440
okay for a fully connected network it

0:18:36.320,0:18:40.480
just pulls over

0:18:37.440,0:18:44.000
components of the just features okay so

0:18:40.480,0:18:44.559
ppj is like a set of indexes pj is a

0:18:44.000,0:18:48.080
subset

0:18:44.559,0:18:51.280
of uh indices of z of components of z

0:18:48.080,0:18:54.960
yeah okay thanks

0:18:51.280,0:18:58.080
right so here pj is a group of six

0:18:54.960,0:19:02.000
components of z that happen to be

0:18:58.080,0:19:04.720
neighbors in this topology okay

0:19:02.000,0:19:05.440
and that's that's one p and the next p

0:19:04.720,0:19:08.000
is

0:19:05.440,0:19:09.520
a similar square six by six square

0:19:08.000,0:19:13.120
shifted by three pixels

0:19:09.520,0:19:17.200
to the left to the top or uh or bottom

0:19:13.120,0:19:19.120
okay okay bottom okay thanks

0:19:17.200,0:19:21.520
so the overlapping between the groups is

0:19:19.120,0:19:24.160
what kind of uh

0:19:21.520,0:19:26.400
represents this topology if you want

0:19:24.160,0:19:26.400
okay

0:19:30.320,0:19:32.559
okay

0:19:34.160,0:19:39.440
so in this this experiment you know is

0:19:36.960,0:19:40.080
is very similar to the one we just uh

0:19:39.440,0:19:43.360
talked about

0:19:40.080,0:19:44.240
except here um we have local connections

0:19:43.360,0:19:45.679
so we have an input it's a

0:19:44.240,0:19:49.280
two-dimensional input here we kind of

0:19:45.679,0:19:49.280
only represent a 1d version of it

0:19:49.520,0:19:54.640
and and we have units uh possibly

0:19:52.559,0:19:57.200
multiple units at one location

0:19:54.640,0:19:59.360
uh looking at a piece of the input kind

0:19:57.200,0:20:01.039
of a local patch on the input

0:19:59.360,0:20:03.200
and then those set of those sets of

0:20:01.039,0:20:05.679
units are

0:20:03.200,0:20:06.480
kind of you know replicated uh multiple

0:20:05.679,0:20:09.840
times but

0:20:06.480,0:20:10.960
there's no shared weights um so the the

0:20:09.840,0:20:12.480
units

0:20:10.960,0:20:14.080
these kind of units everywhere on the

0:20:12.480,0:20:14.480
input but they the weights are not

0:20:14.080,0:20:17.840
shared

0:20:14.480,0:20:17.840
okay they're just locally connected

0:20:18.640,0:20:23.360
so i guess i'm not quite understanding

0:20:21.600,0:20:27.360
the

0:20:23.360,0:20:30.559
overall concept of the of feature

0:20:27.360,0:20:31.679
pooling um i mean if i think about it in

0:20:30.559,0:20:34.240
terms of like

0:20:31.679,0:20:35.120
pooling that we used in in convolutional

0:20:34.240,0:20:38.400
networks

0:20:35.120,0:20:41.840
than it it straightforward but

0:20:38.400,0:20:46.960
i don't really understand how we how

0:20:41.840,0:20:48.320
feature pooling works okay

0:20:46.960,0:20:50.320
let me let me draw a picture maybe

0:20:48.320,0:20:52.880
that'll be clear okay so

0:20:50.320,0:20:54.400
you start with an input vector okay

0:20:52.880,0:20:56.960
multiply by

0:20:54.400,0:20:59.200
a matrix or pass it through uh some sort

0:20:56.960,0:21:02.320
of uh

0:20:59.200,0:21:06.880
encoder right which may have values

0:21:02.320,0:21:09.520
and whatever or multiple matrices inside

0:21:06.880,0:21:12.159
okay maybe multiple layers and you get a

0:21:09.520,0:21:12.159
future vector

0:21:13.120,0:21:18.960
okay so let's call that z

0:21:16.559,0:21:20.000
and now and now you do you do putting

0:21:18.960,0:21:23.280
essentially so

0:21:20.000,0:21:24.720
you divide this into groups in this case

0:21:23.280,0:21:27.919
are non-overlapping

0:21:24.720,0:21:30.159
and you compute the within

0:21:27.919,0:21:31.520
one of those groups you compute the

0:21:30.159,0:21:35.600
square root

0:21:31.520,0:21:39.200
of the sum of the squares of those zi's

0:21:35.600,0:21:44.080
where i belong to the group the pool

0:21:39.200,0:21:46.799
okay it's called p because it's a pool

0:21:44.080,0:21:47.440
okay and you do this for all the groups

0:21:46.799,0:21:50.400
right

0:21:47.440,0:21:51.840
so what you get here this output here

0:21:50.400,0:21:52.720
looks very much like the output of a

0:21:51.840,0:21:54.640
putting layer

0:21:52.720,0:21:56.400
in the conversion from that this is not

0:21:54.640,0:21:57.039
a conventional net okay it's a fully

0:21:56.400,0:22:02.799
connected

0:21:57.039,0:22:02.799
network here but the result is the same

0:22:03.360,0:22:07.679
and that's your that's your regularizer

0:22:05.280,0:22:10.320
now in the example i just showed

0:22:07.679,0:22:11.280
you take the z and this is what you send

0:22:10.320,0:22:15.840
to

0:22:11.280,0:22:19.120
a decoder matrix for me to reconstruct

0:22:15.840,0:22:19.919
the input okay so this is y this is y

0:22:19.120,0:22:20.880
bar

0:22:19.919,0:22:23.760
that's a prediction for the

0:22:20.880,0:22:26.880
reconstruction and this

0:22:23.760,0:22:28.480
this put this pooled layer here is is

0:22:26.880,0:22:31.520
only used

0:22:28.480,0:22:32.720
to compute the regularizer it's not

0:22:31.520,0:22:34.320
actually used as

0:22:32.720,0:22:36.480
uh for reconstruction you reconstruct

0:22:34.320,0:22:38.080
from the sparse code directly

0:22:36.480,0:22:41.120
but it is it looks very much like a

0:22:38.080,0:22:46.240
pulling layer now if this were

0:22:41.120,0:22:49.840
uh if this were a a convolutional net

0:22:46.240,0:22:50.400
then that that dimension or a feature

0:22:49.840,0:22:54.320
here

0:22:50.400,0:22:56.320
would be

0:22:54.320,0:22:58.640
features but you would have multiple

0:22:56.320,0:23:00.480
feature maps

0:22:58.640,0:23:02.480
okay so i'm representing the feature

0:23:00.480,0:23:04.000
dimension vertically

0:23:02.480,0:23:06.000
then the encoder would do multiple

0:23:04.000,0:23:07.840
convolutions and would also generate

0:23:06.000,0:23:10.159
multiple feature maps perhaps a larger

0:23:07.840,0:23:10.159
number

0:23:15.200,0:23:18.880
and then the kind of pulling we would do

0:23:16.640,0:23:18.880
here

0:23:20.400,0:23:25.360
is a pudding where so each

0:23:25.679,0:23:32.559
after pulling we would take

0:23:29.200,0:23:36.799
a window over space as well as

0:23:32.559,0:23:38.400
over features

0:23:36.799,0:23:40.799
and compute the square root of sum of

0:23:38.400,0:23:44.320
the square there and that gives us

0:23:40.799,0:23:45.760
one output in our pulling output

0:23:44.320,0:23:47.200
and then we have multiple groups of

0:23:45.760,0:23:49.039
features like this that go into

0:23:47.200,0:23:51.039
different

0:23:49.039,0:23:52.559
pulling so it doesn't matter whether

0:23:51.039,0:23:54.000
this is convolutional or not

0:23:52.559,0:23:55.840
in convolutions you would pull over

0:23:54.000,0:23:59.440
space as well as

0:23:55.840,0:24:00.559
feature type but um

0:23:59.440,0:24:02.559
if you don't have convolution you just

0:24:00.559,0:24:03.279
pull over features and that you know

0:24:02.559,0:24:06.320
builds

0:24:03.279,0:24:07.120
invariants to whatever it is that uh the

0:24:06.320,0:24:10.559
citizens think

0:24:07.120,0:24:10.559
uh thinks make sense

0:24:11.360,0:24:14.480
is that clear does that answer your

0:24:13.039,0:24:17.279
question

0:24:14.480,0:24:19.520
yeah i think it's it's more clear thank

0:24:17.279,0:24:23.039
you

0:24:19.520,0:24:24.000
um i have a question for when you do

0:24:23.039,0:24:26.000
when you split the z

0:24:24.000,0:24:28.559
into groups and do the cooling would

0:24:26.000,0:24:32.159
those groups overlap

0:24:28.559,0:24:35.279
right so uh in the example i showed here

0:24:32.159,0:24:36.159
they do not overlap but you can make

0:24:35.279,0:24:39.360
them overlap

0:24:36.159,0:24:42.559
okay so so let's say we have

0:24:39.360,0:24:42.559
a feature vector z

0:24:43.039,0:24:48.880
i can take a pool here and a pool here

0:24:46.720,0:24:50.799
and a pool here and here those groups

0:24:48.880,0:24:53.520
overlap and if i do this

0:24:50.799,0:24:54.400
and i do group sparsity where these

0:24:53.520,0:24:57.120
other groups

0:24:54.400,0:24:59.039
what's going to happen is that i'm going

0:24:57.120,0:25:01.039
to have sort of a continuously varying

0:24:59.039,0:25:02.559
set of features here that sort of vary

0:25:01.039,0:25:04.640
from one end to the other

0:25:02.559,0:25:05.919
because the system is going to want to

0:25:04.640,0:25:08.000
group within a pool

0:25:05.919,0:25:08.960
features that are similar and so because

0:25:08.000,0:25:10.640
of the overlap

0:25:08.960,0:25:13.039
it's going to sort of continuously vary

0:25:10.640,0:25:16.559
them so that they change slowly

0:25:13.039,0:25:18.240
over the over the vector now uh

0:25:16.559,0:25:20.880
in the pictures that i showed in the

0:25:18.240,0:25:23.760
slides uh instead of organizing the

0:25:20.880,0:25:25.679
the z features here in a 1d topology i

0:25:23.760,0:25:27.360
organized them in a 2d topology

0:25:25.679,0:25:28.960
and i made the groups 2-dimensional

0:25:27.360,0:25:32.240
right so i take a

0:25:28.960,0:25:34.240
six by six block uh that's one group

0:25:32.240,0:25:35.919
and then the next group will be another

0:25:34.240,0:25:37.440
six by six block with

0:25:35.919,0:25:39.039
some overlap and then the next group

0:25:37.440,0:25:42.000
will be

0:25:39.039,0:25:42.799
yet another six by six block okay and

0:25:42.000,0:25:44.799
maybe i have an

0:25:42.799,0:25:45.840
another one because i have a torito

0:25:44.799,0:25:48.880
topology that

0:25:45.840,0:25:49.919
takes these guys and these guys okay and

0:25:48.880,0:25:53.120
then there is you know the

0:25:49.919,0:25:55.679
similar thing kind of um

0:25:53.120,0:25:57.360
you know sliding up et cetera so the

0:25:55.679,0:25:59.279
groups basically

0:25:57.360,0:26:02.080
are those six by six windows that are

0:25:59.279,0:26:03.440
shifted by three and and overlapping

0:26:02.080,0:26:05.440
and so that's how you get those sort of

0:26:03.440,0:26:07.760
continuously varying uh

0:26:05.440,0:26:08.559
features uh along the along the

0:26:07.760,0:26:10.960
dimension

0:26:08.559,0:26:11.840
the two dimensions i could have equally

0:26:10.960,0:26:15.200
well

0:26:11.840,0:26:17.120
uh chosen to organize this into in a 3d

0:26:15.200,0:26:19.760
topology

0:26:17.120,0:26:21.679
or into some sort of tree right so i i

0:26:19.760,0:26:24.640
take all the components of z

0:26:21.679,0:26:25.360
and i organize them in some sort of

0:26:24.640,0:26:28.240
graph

0:26:25.360,0:26:28.240
perhaps a tree

0:26:28.559,0:26:32.799
so this is called structured structural

0:26:30.799,0:26:39.520
sparsity not gross parsley anymore well

0:26:32.799,0:26:42.320
depends how you do it i guess

0:26:39.520,0:26:42.960
and then the groups would be things like

0:26:42.320,0:26:45.679
uh

0:26:42.960,0:26:47.360
this would this would be a group and

0:26:45.679,0:26:49.200
then perhaps this would be a group as

0:26:47.360,0:26:52.159
well

0:26:49.200,0:26:53.679
uh and i can organize a group in sort of

0:26:52.159,0:26:56.960
uh

0:26:53.679,0:27:00.000
russian dolls like this uh and

0:26:56.960,0:27:03.200
uh what's gonna happen there is that the

0:27:00.000,0:27:05.039
the groups that um the units that are in

0:27:03.200,0:27:06.000
many groups will tend to be very sparse

0:27:05.039,0:27:08.240
whereas the groups the

0:27:06.000,0:27:09.760
units that are in a few groups will tend

0:27:08.240,0:27:11.200
to be less sparse

0:27:09.760,0:27:13.520
and so if you're if you do something

0:27:11.200,0:27:14.000
like this with a tree what happens here

0:27:13.520,0:27:16.559
is that

0:27:14.000,0:27:18.000
the the feature in the center tends to

0:27:16.559,0:27:19.520
be not sparse at all it's going to be

0:27:18.000,0:27:20.480
something that really sort of detects

0:27:19.520,0:27:23.200
just you know

0:27:20.480,0:27:24.880
very sort of generic features and then

0:27:23.200,0:27:26.080
at the first level in the tree

0:27:24.880,0:27:27.919
they're going to be a little sparse so

0:27:26.080,0:27:31.039
they're going to be sort of very sort of

0:27:27.919,0:27:31.760
smooth edge extractors or something like

0:27:31.039,0:27:33.440
that

0:27:31.760,0:27:35.039
and then the more you go inside of the

0:27:33.440,0:27:38.240
tree the more

0:27:35.039,0:27:38.960
each feature enters in a large number of

0:27:38.240,0:27:41.120
pools

0:27:38.960,0:27:42.799
and therefore they get more uh pressure

0:27:41.120,0:27:44.720
to be sparse and so they end up being

0:27:42.799,0:27:45.919
much sparser which means they end up

0:27:44.720,0:27:49.279
being more selective

0:27:45.919,0:27:50.240
for particular features and what happens

0:27:49.279,0:27:53.600
there is that

0:27:50.240,0:27:56.320
when you show an image it tends to favor

0:27:53.600,0:27:57.679
activating features that are along uh

0:27:56.320,0:28:00.159
one particular branch

0:27:57.679,0:28:02.000
in that tree because that's the best way

0:28:00.159,0:28:04.960
to sort of minimize the number of pools

0:28:02.000,0:28:08.159
that are on at any one time so that's

0:28:04.960,0:28:08.159
called structural sparsity

0:28:14.880,0:28:18.480
and there's a number of papers uh on

0:28:16.399,0:28:21.279
this by uh

0:28:18.480,0:28:21.840
uh julia merrell so this this goes back

0:28:21.279,0:28:26.640
about

0:28:21.840,0:28:26.640
about ten years ago and uh rodol

0:28:27.200,0:28:32.559
i mean they co-authored this senior

0:28:29.520,0:28:32.559
author was francis back

0:28:33.120,0:28:36.799
i really i put the reference in one of

0:28:34.960,0:28:39.520
the slides

0:28:36.799,0:28:41.279
and there's a paper by my group also by

0:28:39.520,0:28:44.480
arthur schlamm

0:28:41.279,0:28:46.320
which i'll i'll go to in a minute

0:28:44.480,0:28:48.320
can you explain why grouping

0:28:46.320,0:28:51.679
regularization actually helps

0:28:48.320,0:28:52.640
in grouping similar features well so

0:28:51.679,0:28:56.320
that's a good question

0:28:52.640,0:28:59.600
uh where first of all does it help

0:28:56.320,0:29:02.640
and uh and the answer is not clear

0:28:59.600,0:29:03.360
so those experiments were done uh quite

0:29:02.640,0:29:05.840
a while ago

0:29:03.360,0:29:07.840
before the computation was really

0:29:05.840,0:29:09.760
available and the data was available

0:29:07.840,0:29:11.039
uh for for this to really kind of work

0:29:09.760,0:29:14.320
at a big scale

0:29:11.039,0:29:15.279
this was mostly uh viewed as uh the

0:29:14.320,0:29:16.399
people interested in this were

0:29:15.279,0:29:17.760
interested in two things they were

0:29:16.399,0:29:19.120
either interested in

0:29:17.760,0:29:20.559
unsupervised running for things like

0:29:19.120,0:29:22.640
image restoration and stuff like that

0:29:20.559,0:29:26.080
this was what jeremiah was doing

0:29:22.640,0:29:27.919
um all they were interested in uh

0:29:26.080,0:29:29.679
uh unsupervised star supervised

0:29:27.919,0:29:30.880
pre-training because at the time the

0:29:29.679,0:29:33.679
data sets were very small

0:29:30.880,0:29:35.279
for for training uh uh convolutional

0:29:33.679,0:29:37.360
nets they were too small so they had to

0:29:35.279,0:29:40.480
be some sort of pre-training procedure

0:29:37.360,0:29:42.080
which is what i was interested in and so

0:29:40.480,0:29:44.640
it's the same motivation that we

0:29:42.080,0:29:46.559
now have again for self-supervised

0:29:44.640,0:29:49.840
garnie

0:29:46.559,0:29:53.279
but a lot of those methods haven't been

0:29:49.840,0:29:54.799
brought back to the fore they tended to

0:29:53.279,0:29:56.000
work very well when the data set was

0:29:54.799,0:29:57.520
small

0:29:56.000,0:29:59.120
um so they tended to kind of improve

0:29:57.520,0:30:00.559
performance of

0:29:59.120,0:30:02.799
uh let's say a compositional net if you

0:30:00.559,0:30:04.240
pre-trained this uh using a method

0:30:02.799,0:30:06.159
so using a method very similar to the

0:30:04.240,0:30:08.080
one i i uh

0:30:06.159,0:30:11.039
i showed earlier so something a bit like

0:30:08.080,0:30:14.159
this but convolutional

0:30:11.039,0:30:17.919
so make the the encoder and the decoder

0:30:14.159,0:30:21.120
convolutional and uh and and train with

0:30:17.919,0:30:22.720
good sparsity on complex cells and then

0:30:21.120,0:30:24.720
after you're you're done pre-training

0:30:22.720,0:30:26.640
this uh the system you get rid of the

0:30:24.720,0:30:27.760
decoder you only use the encoder as a

0:30:26.640,0:30:29.279
feature extractor

0:30:27.760,0:30:31.039
for uh say the first layer of a

0:30:29.279,0:30:32.799
conventional net

0:30:31.039,0:30:34.960
and you stick a second layer on top of

0:30:32.799,0:30:38.320
it okay so let me go through this

0:30:34.960,0:30:38.720
a little bit so you start you start with

0:30:38.320,0:30:43.120
a

0:30:38.720,0:30:43.120
with an image you

0:30:45.200,0:30:51.919
you have an encoder which is basically

0:30:48.399,0:30:54.320
a convolution uh

0:30:51.919,0:30:54.320
value

0:30:55.520,0:30:59.679
not much more than that okay just

0:30:57.200,0:31:01.360
combination value uh

0:30:59.679,0:31:03.120
there needs to be some sort of scaling

0:31:01.360,0:31:05.440
layer afterwards for for this particular

0:31:03.120,0:31:08.960
case

0:31:05.440,0:31:10.320
and you you train with group

0:31:08.960,0:31:12.799
groups positive so you have a linear

0:31:10.320,0:31:12.799
decoder

0:31:13.120,0:31:17.120
and you kind of reconstruct the input

0:31:15.519,0:31:19.840
and you have

0:31:17.120,0:31:19.840
a

0:31:23.120,0:31:27.600
you have a criterion here which is this

0:31:25.279,0:31:30.640
group l1

0:31:27.600,0:31:34.159
okay so it's sum of a group sorry

0:31:30.640,0:31:36.880
i call the good p right sum of a group a

0:31:34.159,0:31:40.080
square root of sum for

0:31:36.880,0:31:44.240
i in the group of

0:31:40.080,0:31:47.360
z i squared okay so that's good sparsity

0:31:44.240,0:31:50.399
so you train this little uh sparse uh

0:31:47.360,0:31:52.480
auto encoder with good sparsity

0:31:50.399,0:31:54.000
and then what you do is you you you take

0:31:52.480,0:31:57.519
the

0:31:54.000,0:31:58.320
the the the sparsity layer that you just

0:31:57.519,0:32:01.840
used as a

0:31:58.320,0:32:06.240
as a as a regularizer

0:32:01.840,0:32:09.360
and so you basically eliminate um

0:32:06.240,0:32:09.840
you cut this part out of the network you

0:32:09.360,0:32:12.240
take

0:32:09.840,0:32:13.120
the goosebumps d which is really a

0:32:12.240,0:32:18.080
pulling layer an

0:32:13.120,0:32:22.159
l2 pulling layer and you stick it here

0:32:18.080,0:32:22.159
okay so this is basically l2 pulling

0:32:23.440,0:32:26.960
but it has the same architecture as the

0:32:24.960,0:32:28.799
one you use for the

0:32:26.960,0:32:30.159
um you know for the groups the goose

0:32:28.799,0:32:31.440
part city

0:32:30.159,0:32:33.279
and then you use that as a feature

0:32:31.440,0:32:35.440
extractor

0:32:33.279,0:32:37.279
okay which is like it's like the first

0:32:35.440,0:32:39.440
pair of layers of a combinational net

0:32:37.279,0:32:42.240
composition value pulling okay with this

0:32:39.440,0:32:43.919
l2 pulling not max pulling and then you

0:32:42.240,0:32:47.200
can repeat the process you can train

0:32:43.919,0:32:50.320
another instance of this network

0:32:47.200,0:32:53.760
have a couple layers here

0:32:50.320,0:32:57.840
i'm going to and have a

0:32:53.760,0:33:01.200
decoder have this l2

0:32:57.840,0:33:04.320
uh pulling and sparsity criterion

0:33:01.200,0:33:07.039
train this to reconstruct its input

0:33:04.320,0:33:08.320
and then stick the pulling on top

0:33:07.039,0:33:09.840
eliminate this

0:33:08.320,0:33:11.840
and now we have you have a pre-trained

0:33:09.840,0:33:14.960
two-layer accomplishment

0:33:11.840,0:33:15.679
okay this is a procedure that some

0:33:14.960,0:33:17.679
people call

0:33:15.679,0:33:19.679
stacked audio encoder okay so you train

0:33:17.679,0:33:22.399
an auto encoder to extract features

0:33:19.679,0:33:24.240
and then you and then you generate

0:33:22.399,0:33:26.000
features with the encoder of that

0:33:24.240,0:33:27.760
part of that of the auto encoder and you

0:33:26.000,0:33:30.559
stick another layer on top train that

0:33:27.760,0:33:32.240
as another encoder and then keep going

0:33:30.559,0:33:33.760
and the only characteristic here is that

0:33:32.240,0:33:36.640
this autoencoder is trained

0:33:33.760,0:33:38.640
with uh you know to produce environment

0:33:36.640,0:33:41.519
features through

0:33:38.640,0:33:43.519
group sparsity essentially we use all

0:33:41.519,0:33:45.120
possible sub-trees as groups in the

0:33:43.519,0:33:48.880
previous example

0:33:45.120,0:33:50.480
uh no that's kind of up to you really

0:33:48.880,0:33:52.080
what structure you use here you can use

0:33:50.480,0:33:53.600
multiple trees you can use

0:33:52.080,0:33:55.279
if you want multiple features to kind of

0:33:53.600,0:33:57.600
be uh to represent

0:33:55.279,0:33:59.120
an input even at the low frequency so

0:33:57.600,0:34:01.919
that's really up to you

0:33:59.120,0:34:02.880
um you know it could be like what you

0:34:01.919,0:34:04.559
can afford

0:34:02.880,0:34:06.559
uh what you can do also is train the

0:34:04.559,0:34:08.079
system with you know a bigger tree than

0:34:06.559,0:34:08.800
necessary and then sort of prune the

0:34:08.079,0:34:10.480
tree

0:34:08.800,0:34:13.359
whenever there are branches that are not

0:34:10.480,0:34:15.679
used or used very rarely

0:34:13.359,0:34:16.879
okay so this is a the experiment i

0:34:15.679,0:34:18.480
showed here is uh

0:34:16.879,0:34:20.399
similar but there's only local

0:34:18.480,0:34:23.200
connections and no

0:34:20.399,0:34:23.200
no weight sharing

0:34:24.240,0:34:28.960
and what you see here is this again this

0:34:25.919,0:34:31.119
organization of the features

0:34:28.960,0:34:32.399
in terms of what neuroscientists call

0:34:31.119,0:34:34.000
pinwheel patterns

0:34:32.399,0:34:35.679
so pinwheel patterns are those patterns

0:34:34.000,0:34:37.200
where the uh

0:34:35.679,0:34:38.800
orientation selectivity varies

0:34:37.200,0:34:41.919
continuously as you

0:34:38.800,0:34:43.760
go around one of those red dots

0:34:41.919,0:34:45.919
so you take one of those red dots and if

0:34:43.760,0:34:47.280
you kind of do a little circle around

0:34:45.919,0:34:49.679
the the red dots

0:34:47.280,0:34:50.639
what you notice is that the orientation

0:34:49.679,0:34:52.480
of the feature

0:34:50.639,0:34:54.800
of the edge extractor kind of varies

0:34:52.480,0:34:56.639
continuously as you move around

0:34:54.800,0:34:58.320
and those are called pinwheel patterns

0:34:56.639,0:35:02.800
and they are observed in the

0:34:58.320,0:35:04.880
in the brain

0:35:02.800,0:35:07.119
in fact those pictures here on the right

0:35:04.880,0:35:09.280
come from neuroscience papers

0:35:07.119,0:35:11.280
that describe this where the the the

0:35:09.280,0:35:13.200
color here encodes the orientation set

0:35:11.280,0:35:16.960
activity

0:35:13.200,0:35:16.960
and the little stars indicate those

0:35:17.200,0:35:21.280
[Music]

0:35:18.960,0:35:22.800
kind of the singularities here the the

0:35:21.280,0:35:25.119
center of the pinwheels

0:35:22.800,0:35:26.960
is the group sparsity term trained uh to

0:35:25.119,0:35:30.560
have a small value

0:35:26.960,0:35:33.599
well it's a regularizer right let me

0:35:30.560,0:35:33.599
go back to the

0:35:33.920,0:35:39.599
um it's a it's it's a cost function

0:35:36.960,0:35:40.400
during training or during inference

0:35:39.599,0:35:43.119
depending on

0:35:40.400,0:35:43.119
whether you use the

0:35:43.760,0:35:46.640
the sort of predictive version of it

0:35:45.119,0:35:47.200
where you have latent variable or not

0:35:46.640,0:35:50.240
but

0:35:47.200,0:35:53.200
um but it's basically just a

0:35:50.240,0:35:55.119
it's basically just a term in the energy

0:35:53.200,0:35:58.640
right

0:35:55.119,0:35:59.200
so the term itself is not trained it's

0:35:58.640,0:36:00.960
fixed

0:35:59.200,0:36:03.680
right it's just the l2 norm over groups

0:36:00.960,0:36:05.920
and the groups are predetermined

0:36:03.680,0:36:06.720
uh but because it's a criterion it sort

0:36:05.920,0:36:08.560
of determines

0:36:06.720,0:36:10.240
what the what the encoder and the

0:36:08.560,0:36:12.400
decoders will do what type of features

0:36:10.240,0:36:15.599
will be extracted

0:36:12.400,0:36:19.119
here is um another example of

0:36:15.599,0:36:20.960
a sort of you know exotic way of doing

0:36:19.119,0:36:22.320
sparse coding through lateral inhibition

0:36:20.960,0:36:25.119
and there's a bunch of different ways to

0:36:22.320,0:36:28.160
do this that people are proposed

0:36:25.119,0:36:29.200
this one came came from uh uh carol

0:36:28.160,0:36:31.839
gregor and utter schlem

0:36:29.200,0:36:32.400
in my lab about 10 years ago and so here

0:36:31.839,0:36:34.240
there is

0:36:32.400,0:36:36.240
again a linear decoder with a square

0:36:34.240,0:36:39.280
reconstruction error this is wz minus

0:36:36.240,0:36:41.839
x where x is the input here in this case

0:36:39.280,0:36:42.800
and then there is a criterion in the

0:36:41.839,0:36:46.000
energy

0:36:42.800,0:36:48.240
which is uh the vector formed by the

0:36:46.000,0:36:50.240
absolute values of z

0:36:48.240,0:36:51.440
transpose times some matrix times the

0:36:50.240,0:36:55.040
vector itself so it's an

0:36:51.440,0:36:57.359
um a kind of a quadratic form

0:36:55.040,0:36:59.040
uh that involves z and this matrix s and

0:36:57.359,0:37:03.200
the matrix s is

0:36:59.040,0:37:03.200
either determined by hand or

0:37:03.280,0:37:07.520
learned so as to kind of maximize this

0:37:06.079,0:37:11.440
term

0:37:07.520,0:37:14.560
okay and

0:37:11.440,0:37:17.200
if the terms in uh in s

0:37:14.560,0:37:17.599
are positive and large if one particular

0:37:17.200,0:37:19.839
term

0:37:17.599,0:37:22.079
s i j is large what that means is that

0:37:19.839,0:37:23.839
the system does not want zi and zj to be

0:37:22.079,0:37:27.599
on at the same time

0:37:23.839,0:37:30.320
okay it wants the if zi is on

0:37:27.599,0:37:31.280
and s i j is large then it wants zj to

0:37:30.320,0:37:34.800
be off

0:37:31.280,0:37:36.000
and vice versa okay and so it's sort of

0:37:34.800,0:37:38.000
a mutual inhibition

0:37:36.000,0:37:39.440
people use people call this lateral

0:37:38.000,0:37:42.079
inhibition uh in uh

0:37:39.440,0:37:43.760
in neuroscience uh it's basically you

0:37:42.079,0:37:45.440
know all your feature vectors basically

0:37:43.760,0:37:46.480
inhibit other feature vectors through

0:37:45.440,0:37:47.920
this matrix s

0:37:46.480,0:37:49.680
you can decide that the matrix s a

0:37:47.920,0:37:51.680
priori is structured

0:37:49.680,0:37:53.599
so you can decide that only some terms

0:37:51.680,0:37:56.720
are nonzero you can decide that

0:37:53.599,0:37:57.680
some terms those terms are fixed or can

0:37:56.720,0:37:58.960
be trained

0:37:57.680,0:38:01.200
and the way you train them is by

0:37:58.960,0:38:03.040
actually maximizing uh so it's kind of

0:38:01.200,0:38:06.000
adversarial training a little bit you

0:38:03.040,0:38:06.800
you try to find the the value of s that

0:38:06.000,0:38:09.520
sort of

0:38:06.800,0:38:12.480
you know uh is as large as possible if

0:38:09.520,0:38:12.480
you want within limits

0:38:13.280,0:38:17.200
above a certain value of sij one of the

0:38:15.760,0:38:19.119
z

0:38:17.200,0:38:21.040
one of zi or zj is going to go to zero

0:38:19.119,0:38:24.480
and that term is gonna disappear

0:38:21.040,0:38:28.160
so the system is gonna you know

0:38:24.480,0:38:29.520
maximize the sijs until uh

0:38:28.160,0:38:32.800
it's large enough to kind of do the

0:38:29.520,0:38:34.000
mutual inhibition between z and zj

0:38:32.800,0:38:37.119
and it's not going to go any further

0:38:34.000,0:38:37.119
because it doesn't need to

0:38:37.920,0:38:44.839
and again if you organize s

0:38:41.520,0:38:47.839
in terms of a tree so so here

0:38:44.839,0:38:51.520
the the lines represent the

0:38:47.839,0:38:52.800
the zero terms uh in the s matrix

0:38:51.520,0:38:54.640
and whenever you don't have a line

0:38:52.800,0:38:56.480
between two features there's a

0:38:54.640,0:38:58.400
there's a non-zero term in the s matrix

0:38:56.480,0:39:00.000
right so every feature inhibits all

0:38:58.400,0:39:04.320
other features except the ones that are

0:39:00.000,0:39:05.920
up the tree or down the tree uh from it

0:39:04.320,0:39:08.240
uh and this is very much like lagroup's

0:39:05.920,0:39:11.119
sparsity a little bit it's kind of the

0:39:08.240,0:39:12.720
uh kind of the converse if you want of

0:39:11.119,0:39:15.359
ghost parsity instead of

0:39:12.720,0:39:15.839
saying features within a branch of the

0:39:15.359,0:39:18.720
tree

0:39:15.839,0:39:19.760
need to be activated together by

0:39:18.720,0:39:22.160
minimizing

0:39:19.760,0:39:23.599
you know l2 minimizing the number of

0:39:22.160,0:39:26.480
such groups that are on

0:39:23.599,0:39:27.520
here you explicitly have a sort of

0:39:26.480,0:39:30.560
inhibition

0:39:27.520,0:39:32.800
term that for every

0:39:30.560,0:39:33.760
every feature inhibits all other

0:39:32.800,0:39:36.880
features in

0:39:33.760,0:39:38.640
all the other branches of the tree

0:39:36.880,0:39:40.240
and what you see again is that you see

0:39:38.640,0:39:42.240
this

0:39:40.240,0:39:44.640
systems are organizing the features in a

0:39:42.240,0:39:48.079
more or less so continuous fashion

0:39:44.640,0:39:50.079
um and in such a way that

0:39:48.079,0:39:51.760
features along a branch of the tree

0:39:50.079,0:39:52.079
correspond to basically the same feature

0:39:51.760,0:39:54.160
but

0:39:52.079,0:39:55.359
with uh sort of different levels of

0:39:54.160,0:39:57.520
selectivity

0:39:55.359,0:39:59.040
and then features along the periphery

0:39:57.520,0:39:59.680
sort of vary more or less continuously

0:39:59.040,0:40:02.240
because

0:39:59.680,0:40:03.599
there is you know in addition not just

0:40:02.240,0:40:10.560
at the bottom level but also at the

0:40:03.599,0:40:13.200
middle level

0:40:10.560,0:40:14.319
okay so to uh to go back to this the way

0:40:13.200,0:40:16.800
you train the system

0:40:14.319,0:40:18.720
is uh at each iteration you give an x

0:40:16.800,0:40:19.839
you find the z that minimizes this

0:40:18.720,0:40:21.680
energy function

0:40:19.839,0:40:24.319
so you find a z that reconstructs but

0:40:21.680,0:40:26.400
also minimizes the second term

0:40:24.319,0:40:27.839
which means that if you have an sij term

0:40:26.400,0:40:30.880
that is nonzero

0:40:27.839,0:40:33.119
it wants either zi or zj to be zero or

0:40:30.880,0:40:34.720
at least very small

0:40:33.119,0:40:36.960
you do one step a great in descent now

0:40:34.720,0:40:36.960
to

0:40:37.280,0:40:42.160
uh turn to kind of update uh w so as to

0:40:40.640,0:40:44.000
minimize the construction error

0:40:42.160,0:40:46.720
and you do also if you want you can do

0:40:44.000,0:40:50.079
one step of gradient ascent to make the

0:40:46.720,0:40:51.440
terms in s larger

0:40:50.079,0:40:53.280
by kind of computing the gradient of

0:40:51.440,0:40:56.560
this energy with respect to s but then

0:40:53.280,0:40:56.560
going up the energy not down

0:40:59.200,0:41:03.119
uh again if you use a not a tree but

0:41:01.520,0:41:04.839
sort of some sort of 2d topology you

0:41:03.119,0:41:07.839
also get those kind of those kind of

0:41:04.839,0:41:07.839
patterns

0:41:12.000,0:41:16.880
and more complex ones if there are kind

0:41:14.240,0:41:19.040
of multiple scales for the features

0:41:16.880,0:41:20.720
okay so so much for sparse coding and

0:41:19.040,0:41:22.240
structure space coding

0:41:20.720,0:41:23.920
and the reason i'm i'm telling you about

0:41:22.240,0:41:25.920
this is because

0:41:23.920,0:41:27.760
uh although those don't have a huge

0:41:25.920,0:41:31.200
amount of practical applications the

0:41:27.760,0:41:31.200
sparsely instructions passcoding

0:41:31.280,0:41:36.560
they in my opinion uh

0:41:34.480,0:41:38.480
will be the basis for kind of

0:41:36.560,0:41:40.560
self-supervised running methods

0:41:38.480,0:41:41.920
of the next few years as i told you i

0:41:40.560,0:41:42.240
think south surprise running right now

0:41:41.920,0:41:44.800
is

0:41:42.240,0:41:45.680
the hottest topic in nlp uh and it's

0:41:44.800,0:41:47.920
becoming kind of

0:41:45.680,0:41:48.960
a bit of a hot topic in computer vision

0:41:47.920,0:41:50.400
as well

0:41:48.960,0:41:53.119
and it's mostly now dominated by

0:41:50.400,0:41:54.640
contrasting methods but i think uh

0:41:53.119,0:41:56.000
the architectural methods are going to

0:41:54.640,0:41:58.400
take over because contrasting methods

0:41:56.000,0:42:01.119
don't scale very well

0:41:58.400,0:42:02.160
so this is sort of you know giving you

0:42:01.119,0:42:04.880
weapons for the future

0:42:02.160,0:42:06.640
if you want understanding what this is

0:42:04.880,0:42:08.480
all about

0:42:06.640,0:42:10.160
um okay now for something completely

0:42:08.480,0:42:11.680
different this is something that alfredo

0:42:10.160,0:42:13.839
will like because he works on this

0:42:11.680,0:42:16.880
project

0:42:13.839,0:42:18.480
and it's one of the users

0:42:16.880,0:42:21.119
probably one of the most important users

0:42:18.480,0:42:24.800
of star supervisor learning is the

0:42:21.119,0:42:29.119
idea of learning world models

0:42:24.800,0:42:32.319
for control systems or for other purpose

0:42:29.119,0:42:35.520
so um

0:42:32.319,0:42:36.960
when we when humans or animals learn a

0:42:35.520,0:42:39.359
task

0:42:36.960,0:42:40.560
we quite obviously have a kind of good

0:42:39.359,0:42:42.880
internal model

0:42:40.560,0:42:44.240
of how the world works of intuitive

0:42:42.880,0:42:46.480
physics of

0:42:44.240,0:42:47.760
the fact that when an object is not

0:42:46.480,0:42:49.599
supported it falls

0:42:47.760,0:42:51.200
we've learned gravity when we were

0:42:49.599,0:42:53.200
babies probably around the age of

0:42:51.200,0:42:55.760
nine months or so eight or nine months

0:42:53.200,0:42:57.760
that's when it pops up in babies

0:42:55.760,0:42:59.520
um and we learned this mostly about

0:42:57.760,0:43:00.079
observation so how is it that we can

0:42:59.520,0:43:02.079
learn

0:43:00.079,0:43:03.359
how the world works and all the concepts

0:43:02.079,0:43:06.400
about the world

0:43:03.359,0:43:07.040
by observation and there are there are

0:43:06.400,0:43:08.640
two

0:43:07.040,0:43:10.480
reasons for this right so one i already

0:43:08.640,0:43:11.440
explained is the idea of supervised

0:43:10.480,0:43:14.319
learning if you can

0:43:11.440,0:43:15.920
train yourself to predict maybe you will

0:43:14.319,0:43:18.640
spontaneously kind of learn

0:43:15.920,0:43:20.400
abstract concepts about the world that

0:43:18.640,0:43:22.000
might be useful

0:43:20.400,0:43:25.599
in preparation for running a particular

0:43:22.000,0:43:27.599
task or a set of tasks

0:43:25.599,0:43:29.200
but there's another reason which is that

0:43:27.599,0:43:30.560
you actually want to build models of the

0:43:29.200,0:43:31.760
world if you want to be able to act on

0:43:30.560,0:43:35.359
the world

0:43:31.760,0:43:38.400
right so i'm holding this pen

0:43:35.359,0:43:40.400
and i know that if i move my hand up

0:43:38.400,0:43:41.520
the the pen will move with it because

0:43:40.400,0:43:43.760
you know

0:43:41.520,0:43:44.800
it's between my fingers i know that if i

0:43:43.760,0:43:46.880
open my fingers

0:43:44.800,0:43:48.240
the pen will fall i know by gravity i

0:43:46.880,0:43:49.839
know by grasping

0:43:48.240,0:43:51.200
uh i've learned all that stuff and i've

0:43:49.839,0:43:52.720
learned mostly about observation i've

0:43:51.200,0:43:53.920
learned also by experimentation

0:43:52.720,0:43:56.079
but a lot of what i learned i learned

0:43:53.920,0:43:58.079
just by observation so the big question

0:43:56.079,0:44:00.160
is can we learn can we

0:43:58.079,0:44:01.920
use what we've learned about

0:44:00.160,0:44:06.960
self-supervised learning to

0:44:01.920,0:44:06.960
train a system to learn world models

0:44:07.280,0:44:11.520
um and what is a well model okay so if

0:44:09.520,0:44:13.920
you if you want to sort of

0:44:11.520,0:44:14.800
give the an idea of the architecture of

0:44:13.920,0:44:17.680
an autonomous

0:44:14.800,0:44:17.680
intelligence system

0:44:18.079,0:44:21.119
it would be a system that is composed of

0:44:20.160,0:44:22.800
essentially four

0:44:21.119,0:44:24.240
major blocks here that are represented

0:44:22.800,0:44:26.480
on the left so

0:44:24.240,0:44:28.480
it's an intelligent agent or maybe not

0:44:26.480,0:44:29.920
so intelligent we'll see

0:44:28.480,0:44:31.839
it has a perception module and the

0:44:29.920,0:44:33.280
perception module basically observes the

0:44:31.839,0:44:35.440
world and then

0:44:33.280,0:44:36.640
computes a representation of the state

0:44:35.440,0:44:40.480
of the world

0:44:36.640,0:44:43.680
okay called st at time t

0:44:40.480,0:44:45.440
s of t is the the

0:44:43.680,0:44:46.880
idea that the system has of the state of

0:44:45.440,0:44:47.599
the world this is necessarily an

0:44:46.880,0:44:49.520
incomplete

0:44:47.599,0:44:50.960
representation of the world because we

0:44:49.520,0:44:51.520
can't observe the entire universe at

0:44:50.960,0:44:53.040
once

0:44:51.520,0:44:54.720
we only observe what's immediately

0:44:53.040,0:44:57.040
around us and even that we can't

0:44:54.720,0:44:58.000
see through occlusions and there is a

0:44:57.040,0:44:59.200
lot of

0:44:58.000,0:45:01.680
you know internal states about the world

0:44:59.200,0:45:03.680
that we can't observe well enough

0:45:01.680,0:45:04.880
even if you can observe your accuracy or

0:45:03.680,0:45:07.040
observation may not be

0:45:04.880,0:45:09.040
good enough so if i put this pen in my

0:45:07.040,0:45:10.160
in my hand and it appears to be vertical

0:45:09.040,0:45:11.359
and let it go

0:45:10.160,0:45:12.800
it's going to fall but you can't really

0:45:11.359,0:45:14.480
predict in what direction i've used that

0:45:12.800,0:45:18.319
example before

0:45:14.480,0:45:21.440
to describe the problem of

0:45:18.319,0:45:23.119
alliatoric uh uncertainty which is the

0:45:21.440,0:45:24.720
world is non-deterministic and you can't

0:45:23.119,0:45:26.319
predict exactly what's going to happen

0:45:24.720,0:45:28.400
because you don't have a perfect reading

0:45:26.319,0:45:30.839
of the state of the world

0:45:28.400,0:45:32.240
and maybe the world is intrinsically

0:45:30.839,0:45:35.040
stochastic

0:45:32.240,0:45:36.319
we don't know that actually okay so a

0:45:35.040,0:45:39.440
forward model

0:45:36.319,0:45:40.480
is a model that given the current state

0:45:39.440,0:45:41.839
of the world s of t

0:45:40.480,0:45:43.520
or your idea of your current state of

0:45:41.839,0:45:45.359
the world and

0:45:43.520,0:45:46.960
an action that you're taking or that

0:45:45.359,0:45:49.520
someone else is taking

0:45:46.960,0:45:51.680
something that you can choose or at

0:45:49.520,0:45:53.839
least observe

0:45:51.680,0:45:55.680
and perhaps an auxiliary latent variable

0:45:53.839,0:45:57.760
z of t which represents

0:45:55.680,0:45:59.599
what you don't know about the world okay

0:45:57.760,0:46:00.400
so the part of the world the state of

0:45:59.599,0:46:02.319
the world that

0:46:00.400,0:46:03.920
you don't know or the thing that's

0:46:02.319,0:46:04.240
unpredictable about what's going to go

0:46:03.920,0:46:06.880
and

0:46:04.240,0:46:08.319
go on in the world the forward model

0:46:06.880,0:46:11.920
predicts the next state of the world

0:46:08.319,0:46:15.920
st plus one okay you discretized uh

0:46:11.920,0:46:20.160
time in in some way so if you have

0:46:15.920,0:46:22.720
a model of the world of that type

0:46:20.160,0:46:24.240
you can simulate in your head what's

0:46:22.720,0:46:24.960
going to happen as a consequence of your

0:46:24.240,0:46:28.319
actions

0:46:24.960,0:46:29.760
okay so you have this uh this model in

0:46:28.319,0:46:31.520
your head

0:46:29.760,0:46:32.880
uh you know the current state of the

0:46:31.520,0:46:34.079
world was

0:46:32.880,0:46:35.839
some idea of the current state of the

0:46:34.079,0:46:37.599
world you run your internal model of the

0:46:35.839,0:46:39.920
world forward

0:46:37.599,0:46:41.920
with a sequence of a of t which is a

0:46:39.920,0:46:43.839
sequence of action that you imagine

0:46:41.920,0:46:45.599
taking

0:46:43.839,0:46:46.880
and your model of the world as you

0:46:45.599,0:46:50.640
imagine it will predict

0:46:46.880,0:46:50.640
what's going to happen in the world okay

0:46:52.079,0:46:56.560
if you could do this then you could plan

0:46:54.720,0:46:58.880
a sequence of actions that will arrive

0:46:56.560,0:47:01.359
at a particular goal

0:46:58.880,0:47:02.640
okay so for example what sequence of

0:47:01.359,0:47:05.760
action should i

0:47:02.640,0:47:07.839
uh should i do to grab this pen

0:47:05.760,0:47:09.359
um you know i should you know follow a

0:47:07.839,0:47:10.800
particular trajectory

0:47:09.359,0:47:14.720
you know actuate my muscles in a

0:47:10.800,0:47:14.720
particular way so i grab this pen

0:47:15.040,0:47:19.440
and the criterion the the the cost

0:47:18.319,0:47:21.359
function i can measure is

0:47:19.440,0:47:23.359
is whether i've grabbed the pen okay

0:47:21.359,0:47:24.800
whether the pen is in my grasp

0:47:23.359,0:47:27.760
i could measure this with some some

0:47:24.800,0:47:29.839
function perhaps

0:47:27.760,0:47:31.520
and the question is can i plan a

0:47:29.839,0:47:32.240
sequence of action that given my model

0:47:31.520,0:47:33.520
of the world

0:47:32.240,0:47:35.520
which in this case is the model of my

0:47:33.520,0:47:38.640
hand and the model of where the pen

0:47:35.520,0:47:40.319
is will allow me to grab it okay

0:47:38.640,0:47:41.680
it's a little more complicated if i

0:47:40.319,0:47:42.480
throw the pen and i have to catch it in

0:47:41.680,0:47:43.839
the air

0:47:42.480,0:47:45.839
okay because i have to predict the

0:47:43.839,0:47:48.960
trajectory of the pen so i have to have

0:47:45.839,0:47:51.200
uh an intuitive model of physics

0:47:48.960,0:47:52.480
to be able to uh grab that pen which of

0:47:51.200,0:47:53.119
course i've learned through experience

0:47:52.480,0:47:54.720
as well

0:47:53.119,0:47:56.400
people are surprised you like so much

0:47:54.720,0:47:57.040
reinforcement learning this is not

0:47:56.400,0:47:58.400
reinforcement

0:47:57.040,0:48:00.240
it has absolutely nothing to do with

0:47:58.400,0:48:02.160
reinforcement learning maybe

0:48:00.240,0:48:04.160
be very clear this has nothing to do

0:48:02.160,0:48:05.680
with reinforcement learning

0:48:04.160,0:48:08.000
uh this may have to do in the future

0:48:05.680,0:48:10.960
okay but right now it doesn't

0:48:08.000,0:48:12.160
um model-based reinforcement learning no

0:48:10.960,0:48:13.200
it doesn't has nothing to do with

0:48:12.160,0:48:14.880
refreshment running

0:48:13.200,0:48:16.079
let me okay let me let me go through

0:48:14.880,0:48:16.800
this a little bit can you explain the

0:48:16.079,0:48:20.000
difference then

0:48:16.800,0:48:23.280
someone asking um in a minute okay

0:48:20.000,0:48:25.200
so now uh

0:48:23.280,0:48:26.559
so on the left here you have this little

0:48:25.200,0:48:28.400
agent it has this model of the world

0:48:26.559,0:48:31.760
that you can run forward

0:48:28.400,0:48:33.680
okay uh it can it has an actor or you

0:48:31.760,0:48:36.000
can think of it as a policy that

0:48:33.680,0:48:38.000
produces a sequence of actions which is

0:48:36.000,0:48:39.359
going to feed to the model

0:48:38.000,0:48:41.520
and then a critic which is going to

0:48:39.359,0:48:44.559
predict what the

0:48:41.520,0:48:46.559
cost of the

0:48:44.559,0:48:48.319
final state or the trajectory is going

0:48:46.559,0:48:51.839
to be according to the criterion so

0:48:48.319,0:48:54.480
the critic here computes the

0:48:51.839,0:48:56.720
basically the cost of not fulfilling the

0:48:54.480,0:48:59.839
goal that i set myself

0:48:56.720,0:49:01.599
okay so if i if my task is to reach for

0:48:59.839,0:49:03.280
the span and i kind of miss the pen by a

0:49:01.599,0:49:06.400
few centimeters

0:49:03.280,0:49:07.839
my cost is a few centimeters if i grab

0:49:06.400,0:49:09.440
it the cost is zero

0:49:07.839,0:49:12.800
if i miss it by a lot the cost is higher

0:49:09.440,0:49:12.800
okay that would be an example of a cost

0:49:13.760,0:49:19.359
now okay so there there is

0:49:17.839,0:49:21.119
a number of different things you can do

0:49:19.359,0:49:24.000
with uh this sort of basic

0:49:21.119,0:49:25.280
uh model of uh intelligent agent so the

0:49:24.000,0:49:27.200
first one is

0:49:25.280,0:49:28.720
uh you start from an initial state that

0:49:27.200,0:49:31.839
you observe in the world

0:49:28.720,0:49:33.839
you run your forward model you give a

0:49:31.839,0:49:35.200
a proposal for a sequence of actions you

0:49:33.839,0:49:37.119
measure the cost

0:49:35.200,0:49:39.760
and what you can do here ignoring the

0:49:37.119,0:49:43.119
the p here which represents a policy

0:49:39.760,0:49:45.520
um let's let's imagine it doesn't exist

0:49:43.119,0:49:47.119
by gradient descent or by some sort of

0:49:45.520,0:49:48.800
optimization algorithm you could

0:49:47.119,0:49:51.440
you could try to find the sequence of

0:49:48.800,0:49:52.079
actions that will minimize the overall

0:49:51.440,0:49:54.240
cost

0:49:52.079,0:49:55.280
over the trajectory i start from the

0:49:54.240,0:49:58.960
state

0:49:55.280,0:50:02.480
i run my forward model

0:49:58.960,0:50:02.480
and it it takes an action

0:50:02.800,0:50:09.599
okay let me just call this a1 this is s1

0:50:05.839,0:50:13.440
or s1

0:50:09.599,0:50:15.599
and this is going to give me s2

0:50:13.440,0:50:18.640
and i'm going to measure the cost of s2

0:50:15.599,0:50:18.640
through some cost function

0:50:18.720,0:50:20.880
see

0:50:22.800,0:50:28.720
okay the next time step running my

0:50:25.920,0:50:28.720
forward model again

0:50:30.400,0:50:34.000
make an action action proposal a2 this

0:50:32.559,0:50:34.720
is all simulated this is all in my head

0:50:34.000,0:50:36.559
right

0:50:34.720,0:50:40.160
because this model this forward model is

0:50:36.559,0:50:41.599
in my head see my frontal cortex

0:50:40.160,0:50:43.920
so i'm not actually doing this in the

0:50:41.599,0:50:43.920
world

0:50:45.839,0:50:53.920
etc right so i can unroll this for a few

0:50:49.440,0:50:55.599
time steps those time steps can be

0:50:53.920,0:50:57.280
milliseconds if i control muscles they

0:50:55.599,0:50:59.040
can be

0:50:57.280,0:51:01.119
seconds if i control high level actions

0:50:59.040,0:51:02.400
they can be hours okay so if i want to

0:51:01.119,0:51:04.880
plan how to

0:51:02.400,0:51:08.000
i don't know go to san francisco you

0:51:04.880,0:51:10.319
know i need to

0:51:08.000,0:51:11.200
to the airports and then catch a plane

0:51:10.319,0:51:14.400
and then

0:51:11.200,0:51:15.280
when i arrive there catch a taxi or

0:51:14.400,0:51:19.119
something

0:51:15.280,0:51:20.000
etc okay so this is independent at the

0:51:19.119,0:51:24.319
the level of which

0:51:20.000,0:51:26.240
level description of the of the thing

0:51:24.319,0:51:28.480
okay so what i can do with this is i can

0:51:26.240,0:51:36.240
do a very classical

0:51:28.480,0:51:41.200
method called model predictive control

0:51:36.240,0:51:41.200
so it's a classical method of

0:51:41.680,0:51:44.720
optimal control which is a whole

0:51:43.760,0:51:46.559
discipline

0:51:44.720,0:51:50.160
that has been around since the the 50s

0:51:46.559,0:51:51.359
if not if not earlier

0:51:50.160,0:51:53.280
and some of the methods are method

0:51:51.359,0:51:55.280
predictive controls goes go back to the

0:51:53.280,0:51:58.319
the 1960s there's something called the

0:51:55.280,0:51:58.319
kelly bison algorithm

0:51:58.400,0:52:01.839
i think it's kelly with an e i'm not

0:52:02.839,0:52:08.319
sure

0:52:05.119,0:52:09.839
um so this is the

0:52:08.319,0:52:12.240
method very similar to the one i'm

0:52:09.839,0:52:16.160
describing at the moment

0:52:12.240,0:52:17.839
and this was used primarily by

0:52:16.160,0:52:19.599
nasa let's say to compute trajectories

0:52:17.839,0:52:21.920
for rockets okay so when they started

0:52:19.599,0:52:25.040
having computers in the 60s

0:52:21.920,0:52:26.559
uh at nasa they they started computing

0:52:25.040,0:52:28.960
trajectories with computers and they

0:52:26.559,0:52:30.839
were basically using things like this

0:52:28.960,0:52:32.960
before that they had to do it by hand

0:52:30.839,0:52:35.280
okay

0:52:32.960,0:52:36.640
and if you haven't seen the movie uh

0:52:35.280,0:52:38.640
hidden figures i

0:52:36.640,0:52:40.079
um it describes how people were

0:52:38.640,0:52:42.240
competing this by hand this was

0:52:40.079,0:52:43.839
mostly due mostly done by black women

0:52:42.240,0:52:46.960
black mathematicians

0:52:43.839,0:52:48.960
uh women mathematicians who also ended

0:52:46.960,0:52:51.839
up kind of programming those computers

0:52:48.960,0:52:52.960
watch that movie is it's really great um

0:52:51.839,0:52:55.839
okay so here is a

0:52:52.960,0:52:56.880
basic idea here um this looks very much

0:52:55.839,0:52:58.160
like a recurrent net

0:52:56.880,0:53:00.319
okay because your ford model is

0:52:58.160,0:53:00.960
basically the same network replicated

0:53:00.319,0:53:03.280
over

0:53:00.960,0:53:05.119
over time and this is like an unworld

0:53:03.280,0:53:08.160
recurrent network

0:53:05.119,0:53:09.440
and so well what you do here is you back

0:53:08.160,0:53:11.839
propagate

0:53:09.440,0:53:13.760
the value of the cost through this

0:53:11.839,0:53:17.200
entire network all the way to the

0:53:13.760,0:53:20.240
actions and you don't use this for

0:53:17.200,0:53:21.200
training you use this for inference you

0:53:20.240,0:53:24.319
think of the actions

0:53:21.200,0:53:25.520
as latent variables and you basically by

0:53:24.319,0:53:27.119
gradient descent or some other

0:53:25.520,0:53:29.040
optimization method

0:53:27.119,0:53:31.440
you find a sequence of actions that will

0:53:29.040,0:53:32.480
minimize the sum of the cost over the

0:53:31.440,0:53:34.720
trajectory

0:53:32.480,0:53:34.720
okay

0:53:36.800,0:53:43.920
so basically you have

0:53:39.920,0:53:45.839
an overall cost um

0:53:43.920,0:53:48.240
i'm going to call it big c and that's

0:53:45.839,0:53:51.520
going to be the sum or the time step

0:53:48.240,0:53:55.359
time steps of the little c of

0:53:51.520,0:53:58.960
st okay

0:53:55.359,0:54:01.200
uh and what you're going to do is

0:53:58.960,0:54:02.800
big a which is the sequence of a is

0:54:01.200,0:54:06.480
going to be replaced by

0:54:02.800,0:54:09.440
its own value minus some

0:54:06.480,0:54:10.720
step size times the gradient of big c

0:54:09.440,0:54:13.839
with respect to

0:54:10.720,0:54:15.599
a okay so as long as you can compute the

0:54:13.839,0:54:17.280
gradient of the sum of those costs over

0:54:15.599,0:54:18.559
the trajectory with respect to all of

0:54:17.280,0:54:21.599
the components of a

0:54:18.559,0:54:23.440
which means the a the trajectories of a

0:54:21.599,0:54:24.800
you can do this optimization you don't

0:54:23.440,0:54:25.520
have to do it necessarily for gradient

0:54:24.800,0:54:26.880
descent

0:54:25.520,0:54:28.720
in some cases there are more efficient

0:54:26.880,0:54:31.599
ways to do this optimization

0:54:28.720,0:54:32.800
um using dynamic programming for example

0:54:31.599,0:54:34.880
if a is discrete

0:54:32.800,0:54:36.559
that might be more efficient but but if

0:54:34.880,0:54:37.760
a is continuous and high dimensional you

0:54:36.559,0:54:39.119
basically have no choice but to use

0:54:37.760,0:54:40.559
gradient based methods

0:54:39.119,0:54:42.960
okay so this is inference it's not

0:54:40.559,0:54:46.079
there's no learning yet what is a

0:54:42.960,0:54:50.640
big a is the sequence a1

0:54:46.079,0:54:50.640
a2 a3 etc

0:54:51.280,0:54:54.960
okay so you have a differentiable

0:54:54.000,0:54:56.559
objective function

0:54:54.960,0:54:57.839
and you can minimize it with respect to

0:54:56.559,0:54:59.440
the variables you're interested in so

0:54:57.839,0:55:01.520
what do you get out of this

0:54:59.440,0:55:02.480
there are no weights in a a is a vector

0:55:01.520,0:55:04.240
right so

0:55:02.480,0:55:05.599
a is a vector yeah yeah so that was

0:55:04.240,0:55:07.839
actually because we never use

0:55:05.599,0:55:09.520
uh we never minimize vectors so far we

0:55:07.839,0:55:11.200
always been minimizing

0:55:09.520,0:55:12.799
we are always being optimizing weights

0:55:11.200,0:55:14.720
so people are oh we have

0:55:12.799,0:55:16.559
for latent variables like the z

0:55:14.720,0:55:18.400
variables the latent variables of the

0:55:16.559,0:55:20.000
energy-based models the latent variables

0:55:18.400,0:55:21.680
we do minimize the energy

0:55:20.000,0:55:23.200
with respect to z so this is the same

0:55:21.680,0:55:25.119
problem here we're solving

0:55:23.200,0:55:26.960
i think yeah i think not everyone

0:55:25.119,0:55:28.079
understood that the latent variables are

0:55:26.960,0:55:30.160
actually inputs

0:55:28.079,0:55:31.920
so that was i think like also

0:55:30.160,0:55:33.680
misunderstanding with the

0:55:31.920,0:55:35.359
question we had on piazza about training

0:55:33.680,0:55:37.599
these these

0:55:35.359,0:55:38.480
uh latent variable models yeah you don't

0:55:37.599,0:55:40.240
want to use the word

0:55:38.480,0:55:42.160
training for literal variables or for

0:55:40.240,0:55:45.200
things like this

0:55:42.160,0:55:46.559
because uh you want to use inference

0:55:45.200,0:55:49.520
okay you want to use the word

0:55:46.559,0:55:50.079
to infer or to not to train i want to

0:55:49.520,0:55:52.720
use

0:55:50.079,0:55:53.839
the word inference not training what's

0:55:52.720,0:55:55.680
the difference between inference and

0:55:53.839,0:55:58.960
training

0:55:55.680,0:56:02.720
training with training you

0:55:58.960,0:56:04.960
learn a a parameter

0:56:02.720,0:56:06.559
uh that is the same for a large number

0:56:04.960,0:56:10.240
of samples

0:56:06.559,0:56:11.839
okay for inference you find the value of

0:56:10.240,0:56:14.640
some variable a latent variable

0:56:11.839,0:56:16.720
a in this case z in the case of a latent

0:56:14.640,0:56:20.319
variable energy-based model

0:56:16.720,0:56:22.319
uh that is specific to one sample

0:56:20.319,0:56:23.359
okay you change the sample the written

0:56:22.319,0:56:24.640
variable changes

0:56:23.359,0:56:26.480
so you don't learn it because you don't

0:56:24.640,0:56:29.680
remember it from one once when

0:56:26.480,0:56:30.079
one time to the next you know there's no

0:56:29.680,0:56:34.079
memory

0:56:30.079,0:56:34.079
for it right um

0:56:34.240,0:56:36.960
so that's the difference you know

0:56:35.440,0:56:38.400
conceptually you're doing the same kind

0:56:36.960,0:56:39.520
of operation where you do learning and

0:56:38.400,0:56:41.359
inference

0:56:39.520,0:56:42.799
and so at some level of abstraction

0:56:41.359,0:56:46.400
they're the same

0:56:42.799,0:56:50.079
but uh inference you do it per sample

0:56:46.400,0:56:50.720
learning you do it uh over a bunch of

0:56:50.079,0:56:53.040
samples

0:56:50.720,0:56:54.079
and you the parameter is shared across

0:56:53.040,0:56:55.760
the samples

0:56:54.079,0:56:57.599
when we have an energy based model and

0:56:55.760,0:56:59.280
we'd like to do inference we still have

0:56:57.599,0:57:02.480
a minimization to do at

0:56:59.280,0:57:05.040
every time we perform this uh

0:57:02.480,0:57:06.799
we use it right so that was a big

0:57:05.040,0:57:08.240
difference between after you

0:57:06.799,0:57:10.319
after you've trained the model when you

0:57:08.240,0:57:11.760
use it you you still have to do

0:57:10.319,0:57:12.559
minimization with respect to the latent

0:57:11.760,0:57:15.280
variables

0:57:12.559,0:57:16.480
okay so that's the big difference same

0:57:15.280,0:57:18.400
here

0:57:16.480,0:57:19.680
here uh there may or may not be any

0:57:18.400,0:57:21.200
training your forward model may be built

0:57:19.680,0:57:23.760
by hand or maybe trained but

0:57:21.200,0:57:25.200
by the time we're here it's trained

0:57:23.760,0:57:26.240
we're not training anything here

0:57:25.200,0:57:27.760
we're just doing inference we're

0:57:26.240,0:57:29.359
figuring out what is the optimal value

0:57:27.760,0:57:30.640
of the sequence of a is that we'll

0:57:29.359,0:57:34.160
minimize our

0:57:30.640,0:57:34.960
uh for cost overall cost and this is an

0:57:34.160,0:57:36.799
inference problem

0:57:34.960,0:57:38.000
just like energy-based models for

0:57:36.799,0:57:40.480
example the fm

0:57:38.000,0:57:42.079
the four model can be just a one line of

0:57:40.480,0:57:43.920
equation of physics right it can be just

0:57:42.079,0:57:46.000
a deterministic equation

0:57:43.920,0:57:47.359
so imagine the forward model is the few

0:57:46.000,0:57:50.960
equations that describe the

0:57:47.359,0:57:54.160
the uh the the physics of a rocket

0:57:50.960,0:57:56.079
and a is basically the action on the

0:57:54.160,0:57:59.599
the steering you know how you orient the

0:57:56.079,0:57:59.599
nozzles and then the the thrust

0:58:00.000,0:58:02.480
so that would be the the collection of a

0:58:01.599,0:58:03.680
would be the collection of those

0:58:02.480,0:58:05.200
variables and then there is you know

0:58:03.680,0:58:06.240
very simple physics newtonian physics

0:58:05.200,0:58:08.160
basically

0:58:06.240,0:58:09.280
uh you can write the equations it will

0:58:08.160,0:58:12.799
give you the state of the

0:58:09.280,0:58:14.000
racket at the next uh time step uh as a

0:58:12.799,0:58:15.520
function of state of arc at the previous

0:58:14.000,0:58:16.880
time step and the actions you're taking

0:58:15.520,0:58:20.640
that's how you do simulations that's how

0:58:16.880,0:58:20.640
every simulator works

0:58:20.720,0:58:24.000
and then your cost function if you want

0:58:22.240,0:58:25.920
to shoot a rocket would be

0:58:24.000,0:58:27.359
maybe a combination of two things one uh

0:58:25.920,0:58:30.319
would be the

0:58:27.359,0:58:30.880
the uh energy spent during that time

0:58:30.319,0:58:32.880
step

0:58:30.880,0:58:34.160
okay the amount of fuel you spent

0:58:32.880,0:58:35.920
something like that

0:58:34.160,0:58:37.440
and the second term might be the

0:58:35.920,0:58:38.400
distance to a target you want to reach

0:58:37.440,0:58:42.000
maybe you want to

0:58:38.400,0:58:43.680
rendezvous with a space station and uh

0:58:42.000,0:58:45.200
the the second term in the cost would be

0:58:43.680,0:58:47.119
the distance to the space station

0:58:45.200,0:58:48.720
okay square distance to the space

0:58:47.119,0:58:51.599
station uh

0:58:48.720,0:58:53.040
if you measure the um the sum over the

0:58:51.599,0:58:53.920
entire trajectory of the distance to the

0:58:53.040,0:58:56.160
space station

0:58:53.920,0:58:57.599
the system will try to minimize the time

0:58:56.160,0:58:59.200
it will take to get to the space station

0:58:57.599,0:59:00.720
because they will want to minimize

0:58:59.200,0:59:02.799
the sum of the square of the distances

0:59:00.720,0:59:03.680
to the space station over the trajectory

0:59:02.799,0:59:06.079
but at the same time it wants to

0:59:03.680,0:59:07.599
minimize fuel so you have to balance

0:59:06.079,0:59:08.640
those two terms right so that's a

0:59:07.599,0:59:10.000
classical way

0:59:08.640,0:59:12.079
of doing optimal control and that's

0:59:10.000,0:59:14.640
called model predictive control

0:59:12.079,0:59:16.000
is model is kalman filtering one type of

0:59:14.640,0:59:19.440
model predictive control

0:59:16.000,0:59:20.960
no camera filtering is a particular uh

0:59:19.440,0:59:23.680
forward model if you want it's a way of

0:59:20.960,0:59:27.040
estimating the state of the world

0:59:23.680,0:59:28.720
okay but um

0:59:27.040,0:59:30.559
it's you know basically given your

0:59:28.720,0:59:32.160
observation of the state of the world

0:59:30.559,0:59:33.520
through a perception system there's

0:59:32.160,0:59:34.960
going to be some uncertainty about the

0:59:33.520,0:59:36.880
state of the world

0:59:34.960,0:59:38.160
and the command filter basically assumes

0:59:36.880,0:59:39.920
a gaussian distribution on this

0:59:38.160,0:59:41.200
uncertainty

0:59:39.920,0:59:43.760
and now when you run through your

0:59:41.200,0:59:45.200
forward model

0:59:43.760,0:59:46.880
you're going to have a resulting

0:59:45.200,0:59:48.799
uncertainty about the state of the world

0:59:46.880,0:59:52.000
at the next time step

0:59:48.799,0:59:54.880
because it wasn't certain to start with

0:59:52.000,0:59:56.799
okay so given the uncertainty when you

0:59:54.880,0:59:59.119
started from where you started from

0:59:56.799,1:00:01.839
what's the uncertainty after one step of

0:59:59.119,1:00:04.000
physics if you want

1:00:01.839,1:00:04.880
and if you assume linearity of all those

1:00:04.000,1:00:06.799
steps

1:00:04.880,1:00:09.280
and gaussianity of the uncertainty

1:00:06.799,1:00:14.000
that's what uh that's what the

1:00:09.280,1:00:16.240
common filter is um

1:00:14.000,1:00:18.720
most of the uncertainty comes from okay

1:00:16.240,1:00:20.640
so now now your forward model produces

1:00:18.720,1:00:21.920
a prediction and then the next time step

1:00:20.640,1:00:22.799
you might get another reading of the

1:00:21.920,1:00:24.720
state of the world

1:00:22.799,1:00:27.599
because your sensors are still working

1:00:24.720,1:00:29.119
so now you have two gaussians one is

1:00:27.599,1:00:30.640
your new perception of the world tells

1:00:29.119,1:00:32.559
you here is where i think

1:00:30.640,1:00:34.079
the state of the world is and your ford

1:00:32.559,1:00:35.520
model also predicted here is why i think

1:00:34.079,1:00:37.119
it what where i think it is

1:00:35.520,1:00:38.960
and you have to combine those two that's

1:00:37.119,1:00:40.160
where the comp the complexity of common

1:00:38.960,1:00:43.280
filtering comes in

1:00:40.160,1:00:44.319
which is uh i've got two gaussian

1:00:43.280,1:00:45.520
predictions

1:00:44.319,1:00:47.040
so the resulting probability

1:00:45.520,1:00:48.960
distribution is also a gaussian if you

1:00:47.040,1:00:50.880
compute the covariance matrix and

1:00:48.960,1:00:52.079
et cetera and that's where the the

1:00:50.880,1:00:55.280
formulas for

1:00:52.079,1:00:57.280
um common filters come from

1:00:55.280,1:00:58.880
okay so game filter is a way to deal

1:00:57.280,1:01:01.599
with the uncertainty

1:00:58.880,1:01:02.000
in the reading your perception of the

1:01:01.599,1:01:06.079
world

1:01:02.000,1:01:06.079
and in the uh uh

1:01:06.640,1:01:11.839
when you propagate this uncertainty in

1:01:08.640,1:01:11.839
your forward model

1:01:13.599,1:01:17.040
uh i think there was still a main

1:01:15.520,1:01:18.000
difference i think you wanted to address

1:01:17.040,1:01:20.720
the point that

1:01:18.000,1:01:22.799
the this is different from already okay

1:01:20.720,1:01:26.319
so what is rl in that context

1:01:22.799,1:01:28.000
okay so okay i need i need i need one

1:01:26.319,1:01:33.760
more step before i talk about rl

1:01:28.000,1:01:33.760
okay and here is that step

1:01:36.240,1:01:42.640
okay so what we had uh just a minute ago

1:01:39.520,1:01:45.599
was a forward model that's

1:01:42.640,1:01:45.599
enrolled in time

1:01:48.160,1:01:53.839
and the system has

1:01:54.240,1:02:02.480
takes a sequence of actions a1

1:01:58.240,1:02:02.480
a2 a3

1:02:04.839,1:02:10.000
s1 s2 and then we have the cost function

1:02:08.559,1:02:12.559
here

1:02:10.000,1:02:12.559
coming up

1:02:13.200,1:02:19.680
okay and this this could go on right

1:02:16.400,1:02:21.440
now what we'd like to be able to do

1:02:19.680,1:02:24.160
is not have to do this optimization with

1:02:21.440,1:02:26.400
respect to a1 a2 a3 a4

1:02:24.160,1:02:28.400
uh every time every time we need to do a

1:02:26.400,1:02:30.640
planning we don't want to have to

1:02:28.400,1:02:31.839
do to go through this complex process of

1:02:30.640,1:02:34.000
back propagating

1:02:31.839,1:02:35.200
a gradient through this entire system to

1:02:34.000,1:02:39.599
do model predictive

1:02:35.200,1:02:42.400
uh control

1:02:39.599,1:02:43.680
and so a simple simple way to get rid of

1:02:42.400,1:02:46.079
that step

1:02:43.680,1:02:47.680
is the same trick that we use in auto

1:02:46.079,1:02:48.720
encoders versus passcoding so remember

1:02:47.680,1:02:51.599
it's passcoding

1:02:48.720,1:02:52.880
we wanted to reconstruct but then we had

1:02:51.599,1:02:54.880
to do inference with respect to the

1:02:52.880,1:02:56.640
latent variable by optimization

1:02:54.880,1:02:58.720
and that turned out to be to be

1:02:56.640,1:03:00.400
expensive so we talked about last week

1:02:58.720,1:03:01.920
was the idea of using an encoder

1:03:00.400,1:03:03.440
that we trained to predict the optimal

1:03:01.920,1:03:05.760
value directly

1:03:03.440,1:03:07.280
okay and we're going to do the same here

1:03:05.760,1:03:09.039
that resulted in the idea as part of the

1:03:07.280,1:03:11.520
encoder we're going to do the same here

1:03:09.039,1:03:13.119
i'm going to train a network to take the

1:03:11.520,1:03:16.880
state

1:03:13.119,1:03:18.799
and directly predict what the optimal

1:03:16.880,1:03:20.079
value of the action is

1:03:18.799,1:03:30.799
and this network of course we're going

1:03:20.079,1:03:32.880
to apply every time step

1:03:30.799,1:03:35.280
and this is going to be called a policy

1:03:32.880,1:03:35.280
network

1:03:37.039,1:03:40.240
okay so the policy network takes the

1:03:38.640,1:03:43.520
state

1:03:40.240,1:03:44.880
and produces a guess about the best

1:03:43.520,1:03:47.920
action

1:03:44.880,1:03:49.680
to take at at this time so as to

1:03:47.920,1:03:52.319
minimize the overall cost

1:03:49.680,1:03:53.520
okay and this is going to be a trainable

1:03:52.319,1:03:55.280
neural net

1:03:53.520,1:03:56.559
or whatever model parametrized model

1:03:55.280,1:03:58.799
that we want the way we're going to

1:03:56.559,1:03:59.760
train this model is basically just back

1:03:58.799,1:04:02.960
back propagation

1:03:59.760,1:04:04.960
okay so we're going to uh using our

1:04:02.960,1:04:08.319
perception module this is this is the

1:04:04.960,1:04:10.079
this is the world here and

1:04:08.319,1:04:11.839
we're looking at the world with a camera

1:04:10.079,1:04:13.359
and there's a perception module that

1:04:11.839,1:04:14.880
gives us a guess as to what the state of

1:04:13.359,1:04:18.240
the world is

1:04:14.880,1:04:18.240
okay this is perception

1:04:19.599,1:04:27.200
and this is a forward model applied

1:04:21.440,1:04:30.160
multiple time steps

1:04:27.200,1:04:30.160
and this is all cost

1:04:30.240,1:04:37.760
okay so what we can do

1:04:33.359,1:04:41.839
is run the system

1:04:37.760,1:04:41.839
and to run the system we first

1:04:42.640,1:04:48.480
run through the perception we compute

1:04:46.400,1:04:49.920
an action we run this action through the

1:04:48.480,1:04:50.160
forward model this forward model gives

1:04:49.920,1:04:51.920
us

1:04:50.160,1:04:53.760
here is the next state we're going to be

1:04:51.920,1:04:57.359
in compute the cost

1:04:53.760,1:04:59.520
and then keep going okay keep doing this

1:04:57.359,1:05:00.799
just forward pop through this entire

1:04:59.520,1:05:01.599
system which is really kind of an

1:05:00.799,1:05:04.319
unrolled

1:05:01.599,1:05:04.880
recurrent net if you want and once

1:05:04.319,1:05:07.920
you're done

1:05:04.880,1:05:10.079
you back propagate gradient gradients

1:05:07.920,1:05:11.839
from the all the terms in the cost

1:05:10.079,1:05:13.680
function

1:05:11.839,1:05:16.000
all the way through the network all the

1:05:13.680,1:05:20.720
way through the parameters

1:05:16.000,1:05:20.720
of that policy network

1:05:20.799,1:05:27.280
okay so basically you compute uh

1:05:24.240,1:05:28.880
d of big c so big c remember is the sum

1:05:27.280,1:05:33.119
of all the c's

1:05:28.880,1:05:34.640
a long time with respect to d w

1:05:33.119,1:05:36.640
okay and that's just going to be the sum

1:05:34.640,1:05:41.119
of a time

1:05:36.640,1:05:43.680
of the big c over

1:05:41.119,1:05:43.680
dw

1:05:44.799,1:05:51.920
sorry yeah big c over d

1:05:48.000,1:05:55.200
a t d a t

1:05:51.920,1:05:55.680
or d w okay i've just applied chain rule

1:05:55.200,1:05:58.000
right but

1:05:55.680,1:05:59.520
i don't need to right if i just you know

1:05:58.000,1:06:00.240
define this function in python and just

1:05:59.520,1:06:03.440
do backward

1:06:00.240,1:06:04.960
it'll just do the right thing um so

1:06:03.440,1:06:06.640
i can compute the gradient of the

1:06:04.960,1:06:09.359
overall cost with respect to the

1:06:06.640,1:06:12.160
parameters of that policy network and so

1:06:09.359,1:06:14.480
if i train this over sufficiently many

1:06:12.160,1:06:16.079
uh samples if my forward model is

1:06:14.480,1:06:16.720
correct if my cost function does what i

1:06:16.079,1:06:18.880
want

1:06:16.720,1:06:20.559
then my policy network is going to learn

1:06:18.880,1:06:22.319
a good policy that

1:06:20.559,1:06:25.200
just looking at the state will minimize

1:06:22.319,1:06:28.319
the expected cost over trajectory

1:06:25.200,1:06:29.599
okay the average cost over a trajectory

1:06:28.319,1:06:32.160
there's no reinforcement running here

1:06:29.599,1:06:34.640
this is all background

1:06:32.160,1:06:36.240
okay now we can talk about the

1:06:34.640,1:06:37.520
difference with refreshment running

1:06:36.240,1:06:39.359
the main difference with reinforcement

1:06:37.520,1:06:43.280
running here

1:06:39.359,1:06:46.880
is uh is is twofold the first one is in

1:06:43.280,1:06:48.799
reinforcement learning

1:06:46.880,1:06:50.799
in most reinforcement training scenarios

1:06:48.799,1:06:54.000
at least

1:06:50.799,1:06:56.160
the the c

1:06:54.000,1:07:01.839
function is a black box well it's a

1:06:56.160,1:07:01.839
black box not a red box

1:07:07.119,1:07:11.599
okay that's the first difference the

1:07:09.760,1:07:12.880
second difference is that this is not a

1:07:11.599,1:07:15.839
forward model of the world this is the

1:07:12.880,1:07:15.839
real world

1:07:23.039,1:07:26.640
and your measure of the state of the

1:07:24.799,1:07:28.160
world is imperfect so

1:07:26.640,1:07:31.920
inside of this policy network you might

1:07:28.160,1:07:34.960
have a perception network here

1:07:31.920,1:07:36.480
that estimates the state of the world so

1:07:34.960,1:07:40.160
you have no control over

1:07:36.480,1:07:43.039
the real world and your cost function

1:07:40.160,1:07:44.480
is not known you can you can just get

1:07:43.039,1:07:45.200
the output of the cost function by just

1:07:44.480,1:07:46.960
trying something

1:07:45.200,1:07:48.559
right you take an action you see the

1:07:46.960,1:07:52.160
effect on the world

1:07:48.559,1:07:53.599
and that gives you uh what reinforcement

1:07:52.160,1:07:55.280
running people call a reward but it's

1:07:53.599,1:07:57.359
just a negative cost

1:07:55.280,1:07:59.520
okay is the value of negative value of

1:07:57.359,1:08:01.039
your cost

1:07:59.520,1:08:02.400
but the cost is not differentiable you

1:08:01.039,1:08:03.920
don't know the function of the cost you

1:08:02.400,1:08:09.119
have to go through the world

1:08:03.920,1:08:09.119
to figure out the value of the cost okay

1:08:09.200,1:08:12.799
um and that's the that's that's the main

1:08:11.680,1:08:14.000
issue with reinforcement running which

1:08:12.799,1:08:16.640
is that the cost function is not

1:08:14.000,1:08:16.640
differentiable

1:08:16.799,1:08:19.920
uh it's it's unknown the only way to

1:08:18.880,1:08:21.359
estimate it is by

1:08:19.920,1:08:23.600
trying something and then observing the

1:08:21.359,1:08:26.319
value which is what the reward is

1:08:23.600,1:08:28.719
really it's a negative the negative of

1:08:26.319,1:08:32.239
the reward is basically your your cost

1:08:28.719,1:08:35.359
okay so in that situation since you

1:08:32.239,1:08:36.960
cannot evaluate gradients

1:08:35.359,1:08:38.480
to minimize your cost you have to try

1:08:36.960,1:08:40.480
multiple things you have to

1:08:38.480,1:08:42.319
try an action see the result and then

1:08:40.480,1:08:43.199
try another action see if the result is

1:08:42.319,1:08:44.560
better

1:08:43.199,1:08:46.560
and then try another action see if the

1:08:44.560,1:08:48.640
result is better and

1:08:46.560,1:08:50.080
if your cost function is very flat you

1:08:48.640,1:08:52.239
have to try many many things before you

1:08:50.080,1:08:55.359
get a non-zero reward

1:08:52.239,1:08:57.040
or you know a non-high cost

1:08:55.359,1:08:59.120
and so that's that's where the the

1:08:57.040,1:09:00.400
complexity goes there is the additional

1:08:59.120,1:09:03.520
problem of

1:09:00.400,1:09:05.759
exploration so um

1:09:03.520,1:09:07.679
you know you because you don't know the

1:09:05.759,1:09:09.279
the form of the of the cost and because

1:09:07.679,1:09:11.679
it's non-differentiable

1:09:09.279,1:09:13.520
uh you might need to kind of try many

1:09:11.679,1:09:15.120
actions in kind of a smart way to figure

1:09:13.520,1:09:16.400
out in which part of the space to go to

1:09:15.120,1:09:19.679
be able to sort of figure out

1:09:16.400,1:09:22.799
how can i improve my uh my performance

1:09:19.679,1:09:25.839
okay so that's the the main issue uh of

1:09:22.799,1:09:26.480
uh uh exploration and then there is the

1:09:25.839,1:09:29.440
issue of

1:09:26.480,1:09:30.560
uh exploration versus exploitation so

1:09:29.440,1:09:32.960
the fact that

1:09:30.560,1:09:34.000
um when you're on a situation you don't

1:09:32.960,1:09:35.520
want to take completely random

1:09:34.000,1:09:37.199
actions because they're likely to not

1:09:35.520,1:09:38.480
result in anything interesting so you

1:09:37.199,1:09:39.359
want to take actions that are kind of

1:09:38.480,1:09:42.319
close to

1:09:39.359,1:09:43.520
what you think might work uh and sort of

1:09:42.319,1:09:46.000
you know

1:09:43.520,1:09:46.960
occasionally kind of try something else

1:09:46.000,1:09:49.600
while you're learning

1:09:46.960,1:09:50.400
and learn your policy as you go what i'm

1:09:49.600,1:09:53.199
describing

1:09:50.400,1:09:54.480
what i was describing just before is a

1:09:53.199,1:09:56.000
situation where

1:09:54.480,1:09:59.040
you can do all of this in your head

1:09:56.000,1:10:00.800
because you have a model of the world

1:09:59.040,1:10:02.480
and you can optimize your sequence of

1:10:00.800,1:10:03.920
action very efficiently

1:10:02.480,1:10:06.159
because you have a differentiable cost

1:10:03.920,1:10:06.640
function your cost function is computed

1:10:06.159,1:10:09.120
by your

1:10:06.640,1:10:10.640
your own brain if you want inside of

1:10:09.120,1:10:12.719
your agent

1:10:10.640,1:10:14.400
you can tell if you grab the if you go

1:10:12.719,1:10:15.199
out the pen you can tell the distance

1:10:14.400,1:10:17.040
between your

1:10:15.199,1:10:19.520
hand and the pen so you can compute your

1:10:17.040,1:10:20.880
own cost function and it is kind of

1:10:19.520,1:10:22.640
in your internal world model is

1:10:20.880,1:10:23.679
differentiable in the real world it's

1:10:22.640,1:10:24.960
not

1:10:23.679,1:10:27.760
in the real world you don't know the

1:10:24.960,1:10:29.760
derivative of the distance of your hand

1:10:27.760,1:10:30.960
to the pen unless you have some model of

1:10:29.760,1:10:33.440
that in your head

1:10:30.960,1:10:34.800
but by default you don't but because

1:10:33.440,1:10:35.920
everything is in your head everything is

1:10:34.800,1:10:37.600
differentiable everything is

1:10:35.920,1:10:38.960
implemented by neural net and everything

1:10:37.600,1:10:40.080
you can back properly gradient to

1:10:38.960,1:10:41.760
everything

1:10:40.080,1:10:43.199
so that's the big advantage of this kind

1:10:41.760,1:10:44.000
of approach versus reinforcement

1:10:43.199,1:10:46.719
planning

1:10:44.000,1:10:48.239
okay make everything differentiable so

1:10:46.719,1:10:50.080
there's two problems with the world

1:10:48.239,1:10:52.320
so there's one big advantage in this

1:10:50.080,1:10:55.040
kind of this kind of scenario

1:10:52.320,1:10:56.560
uh which is you can run this faster than

1:10:55.040,1:10:59.840
real time because your forward model

1:10:56.560,1:11:01.280
inside of your agent can run as fast as

1:10:59.840,1:11:03.600
you want you don't need to

1:11:01.280,1:11:05.600
run through the world okay that's one

1:11:03.600,1:11:08.000
advantage second advantage is

1:11:05.600,1:11:09.199
the actions you're taking will not kill

1:11:08.000,1:11:12.080
you

1:11:09.199,1:11:12.960
because you can predict uh using your

1:11:12.080,1:11:14.880
forward model

1:11:12.960,1:11:15.920
you know maybe you'll predict that the

1:11:14.880,1:11:17.760
action will kill you but you're not

1:11:15.920,1:11:19.679
going to take it in the real world so

1:11:17.760,1:11:22.560
it won't kill you if you have an

1:11:19.679,1:11:22.560
accurate forward model

1:11:23.360,1:11:26.560
third advantage because everything takes

1:11:25.760,1:11:27.840
place in your head

1:11:26.560,1:11:29.600
everything is internet everything is

1:11:27.840,1:11:30.480
differentiable you can use all kinds of

1:11:29.600,1:11:33.679
efficient

1:11:30.480,1:11:33.679
uh learning or

1:11:33.760,1:11:38.239
inference algorithms to figure out a

1:11:36.239,1:11:41.920
good course of actions

1:11:38.239,1:11:43.199
okay so that's the difference with with

1:11:41.920,1:11:44.800
reinforcement training in refreshment

1:11:43.199,1:11:47.120
running

1:11:44.800,1:11:48.800
you're telling yourself i have to go

1:11:47.120,1:11:51.440
through the real world

1:11:48.800,1:11:51.920
uh i don't have a model of the real

1:11:51.440,1:11:53.520
world

1:11:51.920,1:11:55.280
i don't know how to compute the cost

1:11:53.520,1:11:56.880
function in a differentiable way

1:11:55.280,1:11:58.320
that said a lot of reinforcement

1:11:56.880,1:12:00.960
learning methods

1:11:58.320,1:12:02.560
actually work by training a model of the

1:12:00.960,1:12:06.560
cost function

1:12:02.560,1:12:10.000
okay so actor critic methods basically

1:12:06.560,1:12:13.120
the role of the critic uh is to learn

1:12:10.000,1:12:13.760
to evaluate to kind of predict the value

1:12:13.120,1:12:15.600
of the

1:12:13.760,1:12:17.520
overall objective function the expected

1:12:15.600,1:12:19.760
value of the objective function

1:12:17.520,1:12:20.719
and because it's a it's a neural net

1:12:19.760,1:12:22.080
that you're going to train you can back

1:12:20.719,1:12:23.040
backpropagate gradient to it so you're

1:12:22.080,1:12:24.560
basically

1:12:23.040,1:12:26.480
learning an approximation of the cost

1:12:24.560,1:12:28.640
function of the real world

1:12:26.480,1:12:32.000
of the real world using using a neural

1:12:28.640,1:12:36.480
net that's that's the role of a critic

1:12:32.000,1:12:39.360
okay why is it so good to have models

1:12:36.480,1:12:39.360
when you're learning a

1:12:39.840,1:12:46.719
skill like learning to drive for example

1:12:44.320,1:12:48.400
it's basically what allows you to learn

1:12:46.719,1:12:49.360
quickly and to learn without killing

1:12:48.400,1:12:50.880
yourself

1:12:49.360,1:12:52.159
so if you don't have a good model of the

1:12:50.880,1:12:54.239
world you don't know about gravity you

1:12:52.159,1:12:57.360
don't know about the dynamics of objects

1:12:54.239,1:12:58.159
uh you don't know anything and you put

1:12:57.360,1:13:00.480
an agent

1:12:58.159,1:13:02.000
at the at the wheel of a car the agent

1:13:00.480,1:13:04.320
has no idea what the physics of a car

1:13:02.000,1:13:05.360
is okay and you put the car next to a

1:13:04.320,1:13:07.120
cliff

1:13:05.360,1:13:08.480
the car is driving at you know 30 miles

1:13:07.120,1:13:11.679
an hour next to

1:13:08.480,1:13:13.520
next to a cliff the agent

1:13:11.679,1:13:15.040
doesn't have a model of the world has no

1:13:13.520,1:13:15.840
idea that by turning the wheel to the

1:13:15.040,1:13:18.000
right

1:13:15.840,1:13:20.960
the car will run off the cliff and will

1:13:18.000,1:13:22.880
fall into the into the ravine

1:13:20.960,1:13:25.120
it has to actually try it to figure it

1:13:22.880,1:13:27.280
out it has to fall into the ravine to

1:13:25.120,1:13:29.840
figure out that this is a bad idea

1:13:27.280,1:13:30.880
okay and maybe just from one sample it's

1:13:29.840,1:13:32.080
not going to be able to learn it so it's

1:13:30.880,1:13:33.280
going to have to run into the ravine

1:13:32.080,1:13:34.640
like thousands of times before it

1:13:33.280,1:13:35.920
figures out

1:13:34.640,1:13:37.440
the model of the world that first

1:13:35.920,1:13:38.719
turning the wheel to the right makes the

1:13:37.440,1:13:40.960
car go to the right

1:13:38.719,1:13:42.400
and second that when the car goes above

1:13:40.960,1:13:44.400
a raven it falls into a ravine and

1:13:42.400,1:13:46.239
destroys itself

1:13:44.400,1:13:47.760
okay if you have a model of the world

1:13:46.239,1:13:48.719
that understands about gravity and

1:13:47.760,1:13:50.159
things like this

1:13:48.719,1:13:51.679
then you know that turning the wheel to

1:13:50.159,1:13:52.320
the right is going to make the caveat to

1:13:51.679,1:13:53.360
the ravine

1:13:52.320,1:13:55.440
and you don't do it because you know

1:13:53.360,1:13:56.560
it's going to kill you okay so it allows

1:13:55.440,1:13:59.120
humans and animals

1:13:56.560,1:14:00.880
to learn quickly much much quicker than

1:13:59.120,1:14:02.880
any uh

1:14:00.880,1:14:04.480
model-free reinforcement running methods

1:14:02.880,1:14:06.560
that has ever been devised

1:14:04.480,1:14:07.920
is is the fact that we have very very

1:14:06.560,1:14:12.320
good word models

1:14:07.920,1:14:12.320
in our head okay

1:14:12.840,1:14:18.080
now what does that tell us

1:14:14.960,1:14:19.199
um okay so here is the problem with

1:14:18.080,1:14:21.600
with the world the world is not

1:14:19.199,1:14:24.640
deterministic or

1:14:21.600,1:14:25.600
if it is deterministic it's so complex

1:14:24.640,1:14:26.840
that

1:14:25.600,1:14:28.480
it equally well could be

1:14:26.840,1:14:29.199
non-deterministic it doesn't make any

1:14:28.480,1:14:32.640
difference for it

1:14:29.199,1:14:34.159
for us there's two problems with

1:14:32.640,1:14:35.840
predicting the next state of the world

1:14:34.159,1:14:37.120
the first problem is

1:14:35.840,1:14:39.679
that the world is not entirely

1:14:37.120,1:14:41.199
predictable and it could be not entirely

1:14:39.679,1:14:42.239
predictable for two reasons those are

1:14:41.199,1:14:45.360
called

1:14:42.239,1:14:47.679
electoric uncertainty and epistemic

1:14:45.360,1:14:49.040
uncertainty auditory uncertainty

1:14:47.679,1:14:52.000
is due to the fact that the world is

1:14:49.040,1:14:53.679
intrinsically unpredictable

1:14:52.000,1:14:55.040
or the fact that we don't have full

1:14:53.679,1:14:56.320
information about the state of the world

1:14:55.040,1:14:57.679
so we cannot predict exactly what's

1:14:56.320,1:14:59.840
going to happen next

1:14:57.679,1:15:01.360
so you're looking at me right now you're

1:14:59.840,1:15:02.320
a pretty good model of the immediate

1:15:01.360,1:15:04.480
environment of

1:15:02.320,1:15:05.920
of me okay but you cannot exactly

1:15:04.480,1:15:07.040
predict in which way i'm going to move

1:15:05.920,1:15:08.400
my head next

1:15:07.040,1:15:10.320
because you don't have an accurate model

1:15:08.400,1:15:12.719
of what's inside my skull

1:15:10.320,1:15:14.880
okay your perceptual system does not

1:15:12.719,1:15:19.360
give you a full model of

1:15:14.880,1:15:19.360
how my brain functions uh unfortunately

1:15:20.000,1:15:24.159
so so you cannot exactly predict what

1:15:22.800,1:15:25.360
i'm you know what i'm going to do next

1:15:24.159,1:15:26.080
what i'm going to say i'm going to move

1:15:25.360,1:15:30.239
my head

1:15:26.080,1:15:33.360
et cetera so that's

1:15:30.239,1:15:34.880
elatoric uncertainty there is also

1:15:33.360,1:15:36.080
epistemic uncertainty epistemic

1:15:34.880,1:15:38.080
uncertainty is

1:15:36.080,1:15:39.679
the fact that you can't completely

1:15:38.080,1:15:42.159
predict the next

1:15:39.679,1:15:43.440
uh state of the world because the amount

1:15:42.159,1:15:45.280
of training data you've had

1:15:43.440,1:15:46.560
is not was not enough your model hasn't

1:15:45.280,1:15:47.679
been trained enough to really kind of

1:15:46.560,1:15:50.560
figure it out

1:15:47.679,1:15:50.880
okay that's kind of a different uh type

1:15:50.560,1:15:54.080
of

1:15:50.880,1:15:55.360
uncertainty so the big question now is

1:15:54.080,1:15:57.679
though how do we train models of the

1:15:55.360,1:16:01.920
world under a certainty i give you

1:15:57.679,1:16:03.360
an st can you predict st plus one

1:16:01.920,1:16:04.960
and it's the same problem we encountered

1:16:03.360,1:16:07.280
before we start supervising i give you

1:16:04.960,1:16:08.560
an x can you predict why

1:16:07.280,1:16:10.400
but the problem is that there are now

1:16:08.560,1:16:12.239
multiple y's that are compatible with x

1:16:10.400,1:16:14.320
the multiple st plus ones are compatible

1:16:12.239,1:16:16.719
with s even for a given

1:16:14.320,1:16:16.719
action

1:16:18.840,1:16:24.000
so what does that mean

1:16:21.840,1:16:26.640
that means that our model here or

1:16:24.000,1:16:26.640
forward model

1:16:28.880,1:16:34.480
may take the state to the world and an

1:16:32.840,1:16:37.840
action

1:16:34.480,1:16:37.840
but it will also have to take

1:16:38.880,1:16:46.400
a little variable which we don't know

1:16:42.480,1:16:46.400
the value of to predict the next state

1:16:46.960,1:16:50.640
okay and this looks very much like what

1:16:49.040,1:16:52.960
we talked about earlier

1:16:50.640,1:16:54.560
where we had i'm going to draw this in a

1:16:52.960,1:16:56.800
different topology but it's the same

1:16:54.560,1:17:02.080
idea

1:16:56.800,1:17:05.199
so we had x and it was going through

1:17:02.080,1:17:08.000
a predictor

1:17:05.199,1:17:10.239
computing h and then that was going

1:17:08.000,1:17:10.239
through

1:17:12.400,1:17:16.159
a decoder that will take into account a

1:17:14.400,1:17:18.719
latent variable

1:17:16.159,1:17:18.719
to predict

1:17:20.080,1:17:24.080
y-bar and then we observe y

1:17:24.320,1:17:27.760
okay this is a prediction for s and

1:17:26.320,1:17:30.800
maybe

1:17:27.760,1:17:32.320
at some time we might be able to

1:17:30.800,1:17:33.840
actually take the action and observe the

1:17:32.320,1:17:34.719
next state of the world while we are

1:17:33.840,1:17:36.320
training our model

1:17:34.719,1:17:38.239
we'll actually be observing the next

1:17:36.320,1:17:40.960
state of the world

1:17:38.239,1:17:40.960
t plus one

1:17:42.640,1:17:45.679
okay so to train a forward model here we

1:17:44.960,1:17:48.239
we take

1:17:45.679,1:17:49.760
the state st we take an action if we

1:17:48.239,1:17:52.480
have an action

1:17:49.760,1:17:55.760
uh we have a latent variable and our

1:17:52.480,1:17:58.080
prediction goes into a cost function

1:17:55.760,1:18:00.800
that diagram is exactly identical to the

1:17:58.080,1:18:00.800
one on the right

1:18:03.840,1:18:07.040
right it's the same it's exactly the

1:18:05.440,1:18:10.320
same diagram

1:18:07.040,1:18:13.760
except i split the

1:18:10.320,1:18:15.760
fm into two modules okay i get i've

1:18:13.760,1:18:18.800
given it a particular

1:18:15.760,1:18:22.159
architecture in fact i could make this

1:18:18.800,1:18:22.159
uh more explicit

1:18:22.480,1:18:25.840
i think you have the super thick marker

1:18:24.719,1:18:29.840
selected i do

1:18:25.840,1:18:29.840
yes you don't like that huh

1:18:29.920,1:18:36.320
so this would be my forward model

1:18:33.280,1:18:39.280
okay so that's what inside this box

1:18:36.320,1:18:41.840
uh inside of the ford model box here is

1:18:39.280,1:18:41.840
this

1:18:42.560,1:18:46.239
and you know i renamed uh

1:18:47.600,1:18:50.800
st is now called x and s c plus one is

1:18:49.920,1:18:53.360
not called y bar

1:18:50.800,1:18:54.880
but i mean it's not for y but it's the

1:18:53.360,1:18:56.400
same thing otherwise right so it's the

1:18:54.880,1:18:57.040
same scenario that we talked about

1:18:56.400,1:18:59.520
before

1:18:57.040,1:19:00.560
in late and variable energy-based models

1:18:59.520,1:19:02.159
essentially

1:19:00.560,1:19:04.080
but now we're going to use this to train

1:19:02.159,1:19:07.120
uh a forward model to predict

1:19:04.080,1:19:07.120
what's going to happen in the world

1:19:07.360,1:19:09.840
so

1:19:10.719,1:19:15.760
um we may have to play the same tricks

1:19:14.640,1:19:19.360
that that we played

1:19:15.760,1:19:23.280
uh that we talked about last week

1:19:19.360,1:19:27.040
which is that um

1:19:23.280,1:19:27.040
last week what we explained was that

1:19:27.120,1:19:29.760
we can take

1:19:30.400,1:19:37.840
okay the way i drew this last week was

1:19:32.400,1:19:37.840
slightly different

1:19:43.199,1:19:47.199
um what explained last week is that we

1:19:45.760,1:19:49.120
can

1:19:47.199,1:19:53.199
if we have while we are training our

1:19:49.120,1:19:55.440
forward model we have a pair x and y

1:19:53.199,1:19:57.440
and the way we find the value of z is by

1:19:55.440,1:19:58.000
minimizing the energy with respect to z

1:19:57.440,1:20:01.040
right

1:19:58.000,1:20:05.679
so we basically find z

1:20:01.040,1:20:08.800
star which is the argument

1:20:05.679,1:20:11.440
of c of y and

1:20:08.800,1:20:12.239
y-bar y-bar being the output of our of

1:20:11.440,1:20:15.199
our predictor

1:20:12.239,1:20:15.199
of our system

1:20:15.360,1:20:19.520
okay and then we do one step of gradient

1:20:18.480,1:20:21.920
descent so we

1:20:19.520,1:20:22.800
change the parameters of our entire

1:20:21.920,1:20:25.840
system

1:20:22.800,1:20:28.480
according to the gradient of uh

1:20:25.840,1:20:29.920
that cost but for this to work we had to

1:20:28.480,1:20:33.840
regularize the

1:20:29.920,1:20:33.840
limit its information content

1:20:34.320,1:20:37.520
and we have to do the same here

1:20:37.600,1:20:42.480
why is that well here we're

1:20:41.280,1:20:44.840
we're trying to solve a prediction

1:20:42.480,1:20:47.280
problem but

1:20:44.840,1:20:49.280
imagine and we talked about this a

1:20:47.280,1:20:51.199
couple weeks ago

1:20:49.280,1:20:53.120
i give you an x and a y and you find the

1:20:51.199,1:20:54.880
z that minimizes the overall energy and

1:20:53.120,1:20:57.280
the z is not regularized

1:20:54.880,1:20:59.120
if z is the same dimension as y the

1:20:57.280,1:21:01.840
there's probably going to be

1:20:59.120,1:21:03.679
a z for any y that makes the cost

1:21:01.840,1:21:06.400
function zero

1:21:03.679,1:21:07.840
right if there's enough capacity in z

1:21:06.400,1:21:10.159
there's always going to be

1:21:07.840,1:21:12.719
a value of z that makes the cost

1:21:10.159,1:21:14.239
function zero

1:21:12.719,1:21:15.120
and that's bad because that means my

1:21:14.239,1:21:16.480
energy function is going to be

1:21:15.120,1:21:18.080
completely flat

1:21:16.480,1:21:20.080
it's going to be zero everywhere and i

1:21:18.080,1:21:20.800
need it to be small on the training

1:21:20.080,1:21:23.679
samples

1:21:20.800,1:21:25.920
and high outside of the region of high

1:21:23.679,1:21:28.159
data density

1:21:25.920,1:21:29.760
and what we saw in the last couple weeks

1:21:28.159,1:21:33.199
is that by regularizing z

1:21:29.760,1:21:35.120
limiting its capacity either by

1:21:33.199,1:21:38.080
making its farce for example or making

1:21:35.120,1:21:38.080
it discrete or by

1:21:39.040,1:21:42.800
making it noisy then we can limit this

1:21:41.840,1:21:46.960
capacity

1:21:42.800,1:21:50.400
why do we need zt if you already have 80

1:21:46.960,1:21:54.000
well so 80 is the action you take right

1:21:50.400,1:21:56.960
um okay

1:21:54.000,1:21:58.960
i'm going to tell you i'm going to i'm

1:21:56.960,1:22:00.719
going to let this pen go

1:21:58.960,1:22:02.159
okay but you don't know which direction

1:22:00.719,1:22:04.000
it's going to

1:22:02.159,1:22:05.440
it's going to go right so let's say it

1:22:04.000,1:22:07.120
goes this way

1:22:05.440,1:22:08.560
but i have to predict in advance which

1:22:07.120,1:22:11.280
way it's going to go it's like

1:22:08.560,1:22:13.520
okay here's a better situation you are

1:22:11.280,1:22:13.520
uh

1:22:13.840,1:22:20.000
uh you're a goalie playing soccer

1:22:17.040,1:22:22.000
okay and it's a penalty kick so you're

1:22:20.000,1:22:24.080
in front of the

1:22:22.000,1:22:25.360
you know the kicker in front of you and

1:22:24.080,1:22:26.639
the guy is going to kick the ball

1:22:25.360,1:22:28.480
and you're going to have to jump one way

1:22:26.639,1:22:30.880
or the other and you have to make a

1:22:28.480,1:22:32.880
choice am i jumping left or right

1:22:30.880,1:22:34.719
and you have to make that decision based

1:22:32.880,1:22:36.000
on what you observe from the person but

1:22:34.719,1:22:38.480
you don't know exactly

1:22:36.000,1:22:39.840
what the ball is going to do a is which

1:22:38.480,1:22:42.880
direction you do you jump in

1:22:39.840,1:22:45.520
i mean it's basically how you jump z

1:22:42.880,1:22:46.800
is what you don't know about the player

1:22:45.520,1:22:48.159
in front of you doing

1:22:46.800,1:22:49.040
okay you don't know the state of the

1:22:48.159,1:22:50.000
world you don't know the state of the

1:22:49.040,1:22:51.120
brain of this guy

1:22:50.000,1:22:54.800
and so you don't know if he's going to

1:22:51.120,1:22:58.239
shoot left or right or up or down

1:22:54.800,1:23:01.520
okay that's the difference right

1:22:58.239,1:23:02.159
z is what you cannot know about the

1:23:01.520,1:23:04.239
world

1:23:02.159,1:23:08.880
that is necessary to make the prediction

1:23:04.239,1:23:10.320
the next state a is the action you take

1:23:08.880,1:23:11.760
which in this case has very little

1:23:10.320,1:23:12.239
influence on the immediate state of the

1:23:11.760,1:23:15.120
world

1:23:12.239,1:23:15.520
yeah it seems it seems to be clear now

1:23:15.120,1:23:18.560
right

1:23:15.520,1:23:20.239
so you need to regularize z and then one

1:23:18.560,1:23:23.920
of the tricks we uh

1:23:20.239,1:23:25.920
we described um

1:23:23.920,1:23:27.840
so so the one of the things we described

1:23:25.920,1:23:31.199
to regularize he was was passivity

1:23:27.840,1:23:31.199
another one was adding noise

1:23:32.840,1:23:36.880
um

1:23:35.440,1:23:39.840
but the other trick we described is this

1:23:36.880,1:23:42.880
idea of having an encoder right so

1:23:39.840,1:23:46.080
you have x or st

1:23:42.880,1:23:48.000
run through the predictor the predictor

1:23:46.080,1:23:50.880
goes into

1:23:48.000,1:23:51.840
the decoder which makes a prediction

1:23:50.880,1:23:55.040
about

1:23:51.840,1:23:59.040
y let's call it y bar

1:23:55.040,1:23:59.040
and you compare oops sorry

1:24:00.960,1:24:06.159
you compare y bar to y

1:24:07.360,1:24:10.400
and here you have z and what we talked

1:24:10.000,1:24:14.239
about

1:24:10.400,1:24:14.239
is the idea of using an encoder here

1:24:15.040,1:24:19.679
to predict the optimal value of z

1:24:18.320,1:24:22.080
and then basically having a cost

1:24:19.679,1:24:23.679
function that

1:24:22.080,1:24:25.360
is determining the energy that measures

1:24:23.679,1:24:26.880
the discrepancy between the

1:24:25.360,1:24:29.440
value of z you actually use and the

1:24:26.880,1:24:32.800
value of z predicted by the encoder

1:24:29.440,1:24:35.040
and perhaps this is regularized in some

1:24:32.800,1:24:35.040
way

1:24:37.040,1:24:41.600
and the predictor also has to influence

1:24:38.960,1:24:41.600
the encoder

1:24:41.920,1:24:45.040
so it's pretty clear that you need uh an

1:24:44.159,1:24:48.639
information

1:24:45.040,1:24:50.239
bottleneck uh between the encoder the

1:24:48.639,1:24:52.000
decoder otherwise the system will cheat

1:24:50.239,1:24:54.320
it will completely ignore x

1:24:52.000,1:24:55.920
you will be able to predict why exactly

1:24:54.320,1:24:56.480
by just cheating by looking at the value

1:24:55.920,1:24:58.000
of y

1:24:56.480,1:24:59.520
running it through the encoder and then

1:24:58.000,1:25:01.360
running it through the decoder and then

1:24:59.520,1:25:03.520
predicting why right that's just a

1:25:01.360,1:25:05.199
very simple encoder so unless you

1:25:03.520,1:25:06.800
restrict the capacity of z

1:25:05.199,1:25:09.199
the system will just cheat and not

1:25:06.800,1:25:10.840
actually train itself to predict

1:25:09.199,1:25:12.560
you have to push down on the information

1:25:10.840,1:25:16.719
content

1:25:12.560,1:25:20.880
of z so as to force the system to use

1:25:16.719,1:25:27.040
uh the information from x

1:25:20.880,1:25:31.199
okay to make the the best prediction

1:25:27.040,1:25:34.800
okay now we can use that trick to to uh

1:25:31.199,1:25:36.800
uh to train or forward model

1:25:34.800,1:25:38.960
because again a ford model is basically

1:25:36.800,1:25:42.320
just an instance of this

1:25:38.960,1:25:45.520
and and this is uh the

1:25:42.320,1:25:46.320
project that uh uh for autonomous

1:25:45.520,1:25:49.120
driving that

1:25:46.320,1:25:49.679
uh performance student michael enough uh

1:25:49.120,1:25:52.320
worked on

1:25:49.679,1:25:54.880
and uh alfredo has worked on this and is

1:25:52.320,1:25:58.320
still working on this project

1:25:54.880,1:26:01.120
and so here you're trying to train a car

1:25:58.320,1:26:01.120
to drive itself

1:26:01.600,1:26:06.320
and what's difficult to predict what

1:26:04.960,1:26:08.800
is what the car around you are going to

1:26:06.320,1:26:11.760
do so you place a camera

1:26:08.800,1:26:14.239
above a highway and you watch the the

1:26:11.760,1:26:17.280
cars kind of go by

1:26:14.239,1:26:18.080
and you can track every car and then

1:26:17.280,1:26:19.760
extract

1:26:18.080,1:26:21.520
the immediate neighborhood of the car

1:26:19.760,1:26:22.000
basically a little rectangle around

1:26:21.520,1:26:23.760
every car

1:26:22.000,1:26:25.120
that indicates where the other cars are

1:26:23.760,1:26:27.840
relative to the

1:26:25.120,1:26:29.440
to your car and this is what represents

1:26:27.840,1:26:31.920
represented at the bottom

1:26:29.440,1:26:33.440
um so at the bottom you you have a

1:26:31.920,1:26:34.719
little rectangle that's centered around

1:26:33.440,1:26:38.239
a given car

1:26:34.719,1:26:39.920
and then all the cars around are the uh

1:26:38.239,1:26:41.920
you know a little rectangular centered

1:26:39.920,1:26:44.480
on that car where the car is

1:26:41.920,1:26:45.040
in a standardized location in the middle

1:26:44.480,1:26:47.679
of that

1:26:45.040,1:26:49.840
rectangle you do this for every car what

1:26:47.679,1:26:51.280
it gives you is for every car a sequence

1:26:49.840,1:26:52.480
of what the cars around it are going to

1:26:51.280,1:26:54.960
do

1:26:52.480,1:26:56.000
and we can use this to train a forward

1:26:54.960,1:26:57.520
model

1:26:56.000,1:26:59.600
that will predict what the cars run us

1:26:57.520,1:27:01.520
are going to do

1:26:59.600,1:27:03.920
the question is if this forward model is

1:27:01.520,1:27:06.560
predicting all possible futures uh

1:27:03.920,1:27:09.600
irrespective of the action taken

1:27:06.560,1:27:12.560
yeah where we predict

1:27:09.600,1:27:14.880
a set of futures so given one action and

1:27:12.560,1:27:14.880
even

1:27:15.520,1:27:19.440
so given one initial state one action

1:27:17.679,1:27:20.080
and one cent one particular value of the

1:27:19.440,1:27:22.000
latent variable

1:27:20.080,1:27:23.440
will make a single prediction and then

1:27:22.000,1:27:24.960
you can vary the latent variable and you

1:27:23.440,1:27:27.199
will make multiple predictions

1:27:24.960,1:27:28.080
you can change the action of course

1:27:27.199,1:27:31.280
right

1:27:28.080,1:27:33.360
so i've redrawn the little diagram

1:27:31.280,1:27:35.360
i drew previously here here the the

1:27:33.360,1:27:37.280
state basically is a sequence of three

1:27:35.360,1:27:39.679
frames from this video

1:27:37.280,1:27:40.880
um there's no abstract state here it's

1:27:39.679,1:27:44.080
just the

1:27:40.880,1:27:45.679
the picture itself the blue car is is

1:27:44.080,1:27:46.320
our car and the green cars are the other

1:27:45.679,1:27:47.760
cards

1:27:46.320,1:27:49.679
so you take kind of three frames from

1:27:47.760,1:27:52.880
the past run this through this

1:27:49.679,1:27:53.920
uh neural net which attempts to predict

1:27:52.880,1:27:58.400
the next

1:27:53.920,1:28:01.040
uh the next frame okay using a

1:27:58.400,1:28:02.480
basically a big convolutional net as a

1:28:01.040,1:28:04.880
predictor and a big commercial

1:28:02.480,1:28:06.159
net as a decoder but there's a latent

1:28:04.880,1:28:08.159
variable here there's also an action

1:28:06.159,1:28:11.040
here which is not drawn

1:28:08.159,1:28:11.040
that gets into this

1:28:11.840,1:28:18.400
and the system also has an encoder

1:28:15.360,1:28:19.920
so it looks more like this

1:28:18.400,1:28:21.679
there's a and again the action here is

1:28:19.920,1:28:24.800
not represented but

1:28:21.679,1:28:26.159
imagine there is one so x is the

1:28:24.800,1:28:27.760
the past frames it goes through a

1:28:26.159,1:28:29.360
predictor that predicts a representation

1:28:27.760,1:28:32.480
of the input

1:28:29.360,1:28:35.520
and then that representation goes into

1:28:32.480,1:28:36.400
a convolutional net that the decoder

1:28:35.520,1:28:39.760
that predicts

1:28:36.400,1:28:41.920
it basically is combined additively

1:28:39.760,1:28:44.320
with a latent variable so it's added to

1:28:41.920,1:28:46.400
a latent variable

1:28:44.320,1:28:49.520
before going into a decoder that makes a

1:28:46.400,1:28:49.520
prediction for the next state

1:28:49.760,1:28:53.920
and the latent variable itself is

1:28:51.600,1:28:57.360
isolating variable but

1:28:53.920,1:28:59.199
is being predicted by by an encoder

1:28:57.360,1:29:01.440
which itself is also a convolutional net

1:28:59.199,1:29:03.520
it takes the past and the

1:29:01.440,1:29:05.600
and the future and tries to predict the

1:29:03.520,1:29:06.800
ideal value of the latent variable

1:29:05.600,1:29:08.800
now of course you have to restrict the

1:29:06.800,1:29:10.480
information content here and this is

1:29:08.800,1:29:11.840
done in this particular project using

1:29:10.480,1:29:15.120
sort of a vae like

1:29:11.840,1:29:18.159
approach where the um

1:29:15.120,1:29:20.159
i mean it's basically a vie with a few a

1:29:18.159,1:29:22.000
few tricks

1:29:20.159,1:29:23.920
so this is sampled from a distribution

1:29:22.000,1:29:25.360
that is obtained

1:29:23.920,1:29:26.960
from the output of the encoder the

1:29:25.360,1:29:28.320
output of the encoder outputs a

1:29:26.960,1:29:30.719
prediction for z bar

1:29:28.320,1:29:31.840
as well as prediction for variances and

1:29:30.719,1:29:33.120
z is sampled from the

1:29:31.840,1:29:36.080
from that distribution so it's not

1:29:33.120,1:29:36.080
optimized it's sampled

1:29:36.400,1:29:40.239
but there's also a term that tries to

1:29:38.000,1:29:43.280
kind of minimize the sum of the square

1:29:40.239,1:29:46.320
of disease over time uh which is the

1:29:43.280,1:29:48.960
standard uh technique for vae

1:29:46.320,1:29:50.400
and that goes into the decoder and so

1:29:48.960,1:29:52.239
this is trend as a conditional

1:29:50.400,1:29:54.000
autoencoder basically

1:29:52.239,1:29:55.520
there's another trick that's added to

1:29:54.000,1:29:58.560
this which is that

1:29:55.520,1:30:00.320
half the time z is simply set to zero so

1:29:58.560,1:30:01.840
half the time the system is told you're

1:30:00.320,1:30:03.920
not allowed to use z

1:30:01.840,1:30:06.560
just make your backs guess as the

1:30:03.920,1:30:08.639
prediction without a z

1:30:06.560,1:30:10.320
and that drives the system to sort of

1:30:08.639,1:30:13.120
really kind of use the past in sort of a

1:30:10.320,1:30:14.960
bigger way than if you just uh

1:30:13.120,1:30:17.679
have a noisy z if you just use the

1:30:14.960,1:30:18.560
standard the ie type training the system

1:30:17.679,1:30:20.960
basically ignores

1:30:18.560,1:30:22.080
the the past it just cheats it looks at

1:30:20.960,1:30:24.960
the

1:30:22.080,1:30:26.880
the answer why i will cover the rest in

1:30:24.960,1:30:28.639
a greater detail in a lab in a future

1:30:26.880,1:30:32.400
lab uh perhaps you want to

1:30:28.639,1:30:32.400
say something about the guns

1:30:32.960,1:30:36.880
because i will be actually going over

1:30:34.800,1:30:40.719
this the whole presentation as well

1:30:36.880,1:30:42.639
you are so gans are a particular form of

1:30:40.719,1:30:45.040
contrastive learning

1:30:42.639,1:30:47.840
okay so remember that uh when we talked

1:30:45.040,1:30:52.159
about energy-based learning

1:30:47.840,1:30:52.159
have data points

1:30:55.600,1:31:00.000
and our model

1:31:00.159,1:31:03.840
which i'm going to

1:31:04.000,1:31:06.719
draw like this

1:31:10.239,1:31:15.600
with a cost function it could have any

1:31:13.679,1:31:17.199
kind of

1:31:15.600,1:31:19.600
structure but i'm just going to draw it

1:31:17.199,1:31:19.600
like this

1:31:27.440,1:31:31.600
so this would be sort of a

1:31:28.639,1:31:33.920
reconstruction type

1:31:31.600,1:31:35.679
model right so imagine that the model

1:31:33.920,1:31:36.560
here is an auto encoder or something

1:31:35.679,1:31:38.080
like this

1:31:36.560,1:31:40.560
but you can imagine just about just

1:31:38.080,1:31:42.320
about anything

1:31:40.560,1:31:44.639
a simplified version i mean a more

1:31:42.320,1:31:47.679
general version of this would be just

1:31:44.639,1:31:48.960
y goes into a cost function and i'm not

1:31:47.679,1:31:54.159
specifying

1:31:48.960,1:31:54.159
what the cost function looks like okay

1:31:54.960,1:32:01.040
so what the cost function computes

1:31:58.719,1:32:03.760
is a in the space of y so let's say y is

1:32:01.040,1:32:03.760
two dimensional

1:32:07.840,1:32:15.920
is an energy that we want to be low

1:32:11.679,1:32:15.920
on the data and high outside the data

1:32:16.400,1:32:20.080
and here i deliberately drew a bad

1:32:18.400,1:32:21.520
energy function right so this energy

1:32:20.080,1:32:24.000
function is bad

1:32:21.520,1:32:24.000
because

1:32:24.560,1:32:28.800
it should be low around this region

1:32:27.360,1:32:30.320
where we have data

1:32:28.800,1:32:32.719
and it should be higher outside and

1:32:30.320,1:32:36.719
right now it's it's pretty low

1:32:32.719,1:32:36.719
in in this region right here

1:32:38.840,1:32:44.080
so we talked about contrastive methods

1:32:41.840,1:32:47.280
and contrastive methods consist in

1:32:44.080,1:32:48.800
taking a sample and pushing down on its

1:32:47.280,1:32:52.560
energy

1:32:48.800,1:32:52.560
and then taking a contrastive sample

1:32:52.960,1:32:58.239
which i'm going to draw in purple so

1:32:56.080,1:33:00.080
contrastive sample should be

1:32:58.239,1:33:02.000
a sample that our model already gives

1:33:00.080,1:33:03.040
low energy to but should not give low

1:33:02.000,1:33:06.400
energy to

1:33:03.040,1:33:09.679
we're going to push that up okay so

1:33:06.400,1:33:12.480
push up on the energy of this guy

1:33:09.679,1:33:13.120
push down on the energy of that guy and

1:33:12.480,1:33:14.639
if you keep

1:33:13.120,1:33:17.840
picking those samples and those

1:33:14.639,1:33:17.840
contrastive samples well

1:33:18.639,1:33:21.840
by minimizing some objective function

1:33:20.320,1:33:24.239
that wants to make the energy of the

1:33:21.840,1:33:28.239
blue point small and the energy of the

1:33:24.239,1:33:31.600
pink points high then the system will

1:33:28.239,1:33:33.120
will learn properly so

1:33:31.600,1:33:34.800
we've seen several ways of generating

1:33:33.120,1:33:36.159
contrasting samples the idea of

1:33:34.800,1:33:38.159
denoising autoencoder

1:33:36.159,1:33:40.320
which is to take a sample and basically

1:33:38.159,1:33:43.520
corrupt it in some way

1:33:40.320,1:33:43.520
we've seen the idea of

1:33:43.679,1:33:48.880
contrasting divergence which takes a

1:33:45.520,1:33:50.400
sample and then you go down the energy

1:33:48.880,1:33:53.199
with some noise and that gives you a

1:33:50.400,1:33:56.480
contracting sample to push up

1:33:53.199,1:33:57.920
um and you know we've seen

1:33:56.480,1:33:59.679
a number of other methods that are based

1:33:57.920,1:34:00.159
on prior knowledge about similarity

1:33:59.679,1:34:02.560
between

1:34:00.159,1:34:03.199
between samples but here is here is

1:34:02.560,1:34:05.040
another idea

1:34:03.199,1:34:06.560
the other idea is to use is to train a

1:34:05.040,1:34:08.800
neural net to produce

1:34:06.560,1:34:10.719
those contracted samples intelligently

1:34:08.800,1:34:13.280
and that's the basic idea of gans

1:34:10.719,1:34:14.719
at least in a form of gants that would

1:34:13.280,1:34:16.560
be called energy-based gans

1:34:14.719,1:34:18.159
you can do several formulations against

1:34:16.560,1:34:18.560
in fact there's an entire laundry list

1:34:18.159,1:34:21.840
of

1:34:18.560,1:34:23.040
various types of gans but the basic idea

1:34:21.840,1:34:25.600
of gans is is that

1:34:23.040,1:34:26.320
you you train your energy model so the

1:34:25.600,1:34:28.000
energy model

1:34:26.320,1:34:30.000
in the context of gann is called a

1:34:28.000,1:34:32.080
discriminator or sometimes a critic

1:34:30.000,1:34:33.840
but it's basically just very similar to

1:34:32.080,1:34:35.760
an energy model

1:34:33.840,1:34:37.120
and you try need to take low energy on

1:34:35.760,1:34:40.480
the data points

1:34:37.120,1:34:42.960
and then you train another net

1:34:40.480,1:34:45.600
neural net to generate contrastive data

1:34:42.960,1:34:48.639
points and you move their energy up

1:34:45.600,1:34:52.480
okay so the overall

1:34:48.639,1:34:52.480
diagram is something like this

1:34:53.199,1:34:57.920
you have a discriminator and the

1:34:55.600,1:34:59.840
discriminator really should be

1:34:57.920,1:35:01.199
not drawn this way it could be a large

1:34:59.840,1:35:04.880
neural net

1:35:01.199,1:35:04.880
but in the end oops sorry

1:35:07.280,1:35:15.840
in the end it's just a cost function

1:35:16.239,1:35:21.280
okay so it takes it takes a variable y

1:35:21.600,1:35:24.880
and it tells you it's good or bad low

1:35:23.440,1:35:27.119
energy if it's good high energy if it's

1:35:24.880,1:35:27.119
bad

1:35:27.679,1:35:33.199
so in one phase you collect

1:35:30.800,1:35:35.600
a piece of data from the from your data

1:35:33.199,1:35:38.800
set and just give it to

1:35:35.600,1:35:39.440
your discriminator okay so this is a

1:35:38.800,1:35:43.840
real y

1:35:39.440,1:35:43.840
coming from data

1:35:45.360,1:35:49.840
that's a training sample and you say the

1:35:48.080,1:35:52.480
output of

1:35:49.840,1:35:56.880
of that should go down okay i should

1:35:52.480,1:35:59.280
really write this as f

1:35:56.880,1:36:02.000
because after all it's just it's an

1:35:59.280,1:36:02.000
energy function

1:36:05.679,1:36:13.280
okay so make f of y

1:36:09.360,1:36:15.119
go down of course by changing the

1:36:13.280,1:36:20.800
parameters right

1:36:15.119,1:36:20.800
so you do w replace by w minus eta

1:36:20.960,1:36:26.560
df so f is a neural net

1:36:24.080,1:36:28.000
f is a neural net okay some primary

1:36:26.560,1:36:29.440
choice function but probably a neural

1:36:28.000,1:36:31.679
net probably a pretty complicated neural

1:36:29.440,1:36:31.679
net

1:36:32.159,1:36:36.880
okay that's the first uh first thing

1:36:35.280,1:36:38.960
and that will make the energy of data

1:36:36.880,1:36:40.400
points small okay

1:36:38.960,1:36:41.840
now there's a form of this that's

1:36:40.400,1:36:43.119
conditional so the form of this as

1:36:41.840,1:36:46.000
conditional you have

1:36:43.119,1:36:46.719
an extra input here which is an

1:36:46.000,1:36:48.880
observation

1:36:46.719,1:36:50.320
okay but you can have this or not that's

1:36:48.880,1:36:54.719
called conditional again

1:36:50.320,1:36:58.320
it doesn't matter okay second phase

1:36:54.719,1:37:01.040
or for contrastive samples uh

1:36:58.320,1:37:01.600
you have a latent variable z that you

1:37:01.040,1:37:03.760
sample

1:37:01.600,1:37:05.199
from some distribution a distribution

1:37:03.760,1:37:05.800
that's easy to sample from let's say a

1:37:05.199,1:37:08.960
gaussian

1:37:05.800,1:37:12.159
multi-multivariate gaussian

1:37:08.960,1:37:15.360
or uniform or something you run this

1:37:12.159,1:37:15.360
through what's called a generator

1:37:16.000,1:37:21.840
so this is a neural net and that neural

1:37:18.080,1:37:21.840
net produces

1:37:22.000,1:37:25.679
something similar to white okay it just

1:37:23.760,1:37:28.080
produces an image let's say for ir

1:37:25.679,1:37:28.080
images

1:37:29.360,1:37:35.840
and again you run this through your

1:37:32.840,1:37:35.840
discriminator

1:37:36.960,1:37:43.520
but now you want to make that

1:37:40.080,1:37:45.679
large okay

1:37:43.520,1:37:47.360
so in fact what i told you before is a

1:37:45.679,1:37:52.000
lie

1:37:47.360,1:37:52.000
uh you don't do this update like that

1:37:54.560,1:37:59.119
okay but here what you want is you want

1:37:57.280,1:38:03.840
to make

1:37:59.119,1:38:03.840
fw of this y bar high

1:38:04.159,1:38:06.400
okay

1:38:08.960,1:38:12.560
and what you're going to do now is train

1:38:11.280,1:38:14.840
the

1:38:12.560,1:38:16.480
discriminator and the generator

1:38:14.840,1:38:18.480
simultaneously

1:38:16.480,1:38:22.159
so you're going to first have to come up

1:38:18.480,1:38:24.960
with a cost function a loss function

1:38:22.159,1:38:26.560
and this loss function is going to be

1:38:24.960,1:38:30.800
you know some

1:38:26.560,1:38:35.920
um you know a summer sample

1:38:30.800,1:38:35.920
of a per sample loss function that

1:38:37.600,1:38:46.560
basically is a function of

1:38:40.960,1:38:48.400
f of y and f of y bar

1:38:46.560,1:38:52.159
where y bar of course is generated from

1:38:48.400,1:38:52.159
the randomly sampled latent variable z

1:38:52.320,1:38:58.400
now this cost function needs to be

1:38:55.360,1:39:01.360
a decreasing function of f of y and

1:38:58.400,1:39:01.920
an increasing function of f of y bar

1:39:01.360,1:39:03.520
okay

1:39:01.920,1:39:05.679
you can use just about any cost function

1:39:03.520,1:39:07.520
you want as long as

1:39:05.679,1:39:09.040
it makes for y decrease and it makes f

1:39:07.520,1:39:12.480
of y bar increase

1:39:09.040,1:39:15.440
or as long as it makes a difference

1:39:12.480,1:39:17.600
decrease f of y minus f of y bar good

1:39:15.440,1:39:18.960
example of this

1:39:17.600,1:39:21.679
would be kind of a hinge loss for

1:39:18.960,1:39:25.040
example okay

1:39:21.679,1:39:27.840
so something that says my loss function

1:39:25.040,1:39:27.840
is going to be

1:39:28.880,1:39:40.159
f of y plus

1:39:33.760,1:39:43.119
some margin minus f of y bar

1:39:40.159,1:39:45.520
positive part okay so this is a this is

1:39:43.119,1:39:45.520
a hinge

1:39:46.800,1:39:52.840
and it says i want to make f of y bar

1:39:50.480,1:39:56.000
smaller than

1:39:52.840,1:39:59.440
m um

1:39:56.000,1:39:59.920
other than that i don't care uh bigger

1:39:59.440,1:40:08.960
than m

1:39:59.920,1:40:12.159
i'm sorry i drew this backwards

1:40:08.960,1:40:15.679
so overall as a function of f

1:40:12.159,1:40:18.000
of y bar this function looks like this

1:40:15.679,1:40:23.199
okay so it wants to make f of y bar

1:40:18.000,1:40:25.360
larger than m okay so that's an example

1:40:23.199,1:40:27.920
the the actual cost function that most

1:40:25.360,1:40:31.040
uh the original formulation of gans used

1:40:27.920,1:40:32.080
basically plugs uh each of those terms

1:40:31.040,1:40:35.679
into a sigmoid

1:40:32.080,1:40:37.440
and tries to make the you know the the

1:40:35.679,1:40:39.199
sigmoid applied to f of y as close to

1:40:37.440,1:40:42.159
one as possible and sigma applied to f

1:40:39.199,1:40:43.840
uh y bar as close to zero as possible

1:40:42.159,1:40:46.159
it's you know it's basically that

1:40:43.840,1:40:48.800
nothing more than that so it's sigmoid

1:40:46.159,1:40:48.800
of f of y

1:40:49.440,1:40:56.800
plus one minus sigma eight of

1:40:53.440,1:41:00.159
uh f of y bar and

1:40:56.800,1:41:01.520
you you you take logs because um

1:41:00.159,1:41:03.360
i mean this is not the last function

1:41:01.520,1:41:05.520
this is kind of because before

1:41:03.360,1:41:07.360
the before the last function so this is

1:41:05.520,1:41:09.840
kind of like a cross entropy but

1:41:07.360,1:41:11.280
you have cross entropy that's positive

1:41:09.840,1:41:14.159
for the

1:41:11.280,1:41:15.600
the positive phase and sort of the the

1:41:14.159,1:41:19.840
target is negative for the negative

1:41:15.600,1:41:19.840
phase um

1:41:20.880,1:41:26.159
yeah i shouldn't write it this way this

1:41:22.159,1:41:26.159
is wrong actually sorry about that

1:41:27.280,1:41:32.560
but you put it the largest class for

1:41:29.600,1:41:36.719
each of those

1:41:32.560,1:41:36.719
so it's technically

1:41:37.520,1:41:41.520
you know log log of 1 plus exponential f

1:41:39.920,1:41:46.000
of y

1:41:41.520,1:41:50.320
for the correct one and

1:41:46.000,1:41:54.719
minus for that log f1 plus

1:41:50.320,1:41:58.000
e to the f of y

1:41:54.719,1:42:03.040
plus log

1:41:58.000,1:42:03.040
one plus e to the minus f of y bar

1:42:06.480,1:42:14.880
but you could imagine a large number of

1:42:10.000,1:42:18.480
objective functions of this type

1:42:14.880,1:42:19.760
okay so this is

1:42:18.480,1:42:22.080
the last function you're going to use to

1:42:19.760,1:42:24.880
train the discriminator

1:42:22.080,1:42:26.800
but the generator this is for the

1:42:24.880,1:42:28.080
discriminator

1:42:26.800,1:42:30.000
but it's going to be a loss function for

1:42:28.080,1:42:31.600
the generator and that's a different

1:42:30.000,1:42:33.360
loss function

1:42:31.600,1:42:35.440
and you're going to optimize those two

1:42:33.360,1:42:38.880
loss functions the same way

1:42:35.440,1:42:42.480
the one for the generator is is one that

1:42:38.880,1:42:43.760
basically wants to make the generator

1:42:42.480,1:42:46.800
produce

1:42:43.760,1:42:50.080
outputs that the discriminator thinks

1:42:46.800,1:42:54.840
are good but they're not

1:42:50.080,1:42:57.679
okay so basically the generator

1:42:54.840,1:43:02.400
um

1:42:57.679,1:43:06.239
uh wants to

1:43:02.400,1:43:07.199
adapt its its weight so that the output

1:43:06.239,1:43:10.800
that it produces y

1:43:07.199,1:43:15.119
bar produces a low energy

1:43:10.800,1:43:18.320
for f y okay

1:43:15.119,1:43:19.840
so you sample a random variable z you

1:43:18.320,1:43:20.960
run it through the generator it produces

1:43:19.840,1:43:22.400
a y bar you run through the

1:43:20.960,1:43:24.239
discriminator the f of y

1:43:22.400,1:43:26.400
you get some value and then you back

1:43:24.239,1:43:28.639
propagate the value

1:43:26.400,1:43:31.920
through the generator and adapt the

1:43:28.639,1:43:34.400
weights to the generator so that

1:43:31.920,1:43:36.080
this energy goes down okay so basically

1:43:34.400,1:43:36.560
the generator is trying to find a white

1:43:36.080,1:43:39.920
bar

1:43:36.560,1:43:42.080
that has low energy as low as possible

1:43:39.920,1:43:43.280
okay and it trains itself to kind of

1:43:42.080,1:43:45.440
produce wise

1:43:43.280,1:43:48.000
to have low energy again if if we're

1:43:45.440,1:43:52.480
talking about

1:43:48.000,1:43:54.400
conditional gains there's going to be

1:43:52.480,1:43:56.000
an x variable that's going to enter

1:43:54.400,1:43:59.679
those two modules

1:43:56.000,1:43:59.679
but that makes no difference in the end

1:44:01.040,1:44:06.719
so lg is maybe simply an increasing

1:44:04.840,1:44:11.119
function

1:44:06.719,1:44:11.119
of f y bar

1:44:11.280,1:44:16.000
i think we are kind of running out of

1:44:12.960,1:44:21.840
time we are

1:44:16.000,1:44:21.840
we have run out of time

1:44:22.880,1:44:26.320
so this would be uh some objective

1:44:25.760,1:44:30.159
function

1:44:26.320,1:44:32.800
of f of

1:44:30.159,1:44:35.840
g if g is the generator of z where z is

1:44:32.800,1:44:35.840
sample randomly

1:44:36.159,1:44:40.239
okay so you just do back up to this and

1:44:38.960,1:44:43.280
you change the parameters

1:44:40.239,1:44:46.239
of g let's call them u

1:44:43.280,1:44:47.280
so that this goes down now this is gold

1:44:46.239,1:44:48.719
this is called a game

1:44:47.280,1:44:49.760
in a sense that you have two objective

1:44:48.719,1:44:51.280
functions that you need to minimize

1:44:49.760,1:44:52.880
simultaneously and they are incompatible

1:44:51.280,1:44:54.639
with each other

1:44:52.880,1:44:56.639
and so it's not a gradient descent

1:44:54.639,1:44:58.239
problem you have to find

1:44:56.639,1:45:00.560
what's called a nash equilibrium between

1:44:58.239,1:45:04.320
those two functions

1:45:00.560,1:45:06.880
and gradient descent will not do it uh

1:45:04.320,1:45:08.320
by default so that leads to

1:45:06.880,1:45:10.480
instabilities and there is

1:45:08.320,1:45:11.360
tons of papers on how to make guns

1:45:10.480,1:45:13.360
actually work

1:45:11.360,1:45:15.119
that's kind of a complicated part but

1:45:13.360,1:45:17.199
alfredo will tell you all about this

1:45:15.119,1:45:18.560
uh tomorrow maybe you also you want to

1:45:17.199,1:45:20.000
mention the uh

1:45:18.560,1:45:21.679
the one with the sigmoid that creates

1:45:20.000,1:45:23.520
some issues uh

1:45:21.679,1:45:25.520
if we have like samples that are close

1:45:23.520,1:45:28.719
to the true manifold

1:45:25.520,1:45:31.280
yes and then i think we can close the

1:45:28.719,1:45:32.000
conclusion okay so let me mention that

1:45:31.280,1:45:35.440
so

1:45:32.000,1:45:35.440
let's imagine that your data

1:45:37.440,1:45:41.440
so again uh energy-based framework

1:45:42.159,1:45:47.199
your data is around some manifold

1:45:45.440,1:45:49.199
but it's a thin manifold so it's an

1:45:47.199,1:45:51.920
infinitely thin

1:45:49.199,1:45:51.920
distribution

1:45:52.960,1:46:01.360
okay in the original formulation of gan

1:45:58.159,1:46:03.679
the the gan the discriminator would need

1:46:01.360,1:46:08.159
to produce

1:46:03.679,1:46:09.440
zero probability outside of this

1:46:08.159,1:46:11.600
okay so it needs to produce zero

1:46:09.440,1:46:14.800
probability here

1:46:11.600,1:46:16.320
and it needs to produce on the manifold

1:46:14.800,1:46:19.280
in eastwood to produce

1:46:16.320,1:46:19.280
infinite probability

1:46:19.360,1:46:23.760
in such a way that the integral if this

1:46:21.920,1:46:25.760
is really a density estimation

1:46:23.760,1:46:27.280
in such a way that the integral of this

1:46:25.760,1:46:32.480
density over the entire space

1:46:27.280,1:46:34.480
is one and this is of course very hard

1:46:32.480,1:46:35.920
so gans basically abandoned the idea of

1:46:34.480,1:46:38.320
actually learning a distribution

1:46:35.920,1:46:39.840
what they want to do is produce zero the

1:46:38.320,1:46:41.760
original formulation produce zero

1:46:39.840,1:46:45.119
outside the manifold of data

1:46:41.760,1:46:45.920
and produce one here it's the output of

1:46:45.119,1:46:47.280
the sigmoid that

1:46:45.920,1:46:49.199
needs to be one which means the weighted

1:46:47.280,1:46:50.719
sum going into that sigma it needs to be

1:46:49.199,1:46:52.840
infinite essentially so it's not that

1:46:50.719,1:46:56.800
different

1:46:52.840,1:47:00.000
um and the problem with this is that

1:46:56.800,1:47:01.520
if you train the system successfully

1:47:00.000,1:47:03.840
and you get that energy function which

1:47:01.520,1:47:05.360
is zero outside the data manifold and

1:47:03.840,1:47:06.960
one on the data manifold

1:47:05.360,1:47:08.480
your energy function is completely

1:47:06.960,1:47:11.360
useless

1:47:08.480,1:47:11.679
it's useless because it's a golf course

1:47:11.360,1:47:13.920
right

1:47:11.679,1:47:15.280
it's flat so the energy function

1:47:13.920,1:47:16.000
basically that corresponds to this would

1:47:15.280,1:47:18.080
be the

1:47:16.000,1:47:20.239
negative log of that right so it would

1:47:18.080,1:47:20.239
be

1:47:20.480,1:47:25.600
it would be infinity here and

1:47:23.679,1:47:27.199
the minimum value of your cost function

1:47:25.600,1:47:28.320
on the manifold which for example could

1:47:27.199,1:47:30.159
be zero if it

1:47:28.320,1:47:32.239
if it's if it's an auto encoder the

1:47:30.159,1:47:35.600
energy gonna be smaller than zero

1:47:32.239,1:47:38.239
right um and so

1:47:35.600,1:47:39.760
it's a it's a it's a golf course of

1:47:38.239,1:47:42.159
infinite altitude

1:47:39.760,1:47:43.040
which is really not that useful what you

1:47:42.159,1:47:44.880
want

1:47:43.040,1:47:46.239
as i said before for every energy-based

1:47:44.880,1:47:47.199
model if you want an energy-based model

1:47:46.239,1:47:49.199
to be useful

1:47:47.199,1:47:50.320
you want the energy function to be

1:47:49.199,1:47:52.400
smooth

1:47:50.320,1:47:53.840
you don't want it to go to infinity in

1:47:52.400,1:47:55.920
sort of

1:47:53.840,1:47:57.600
a very small step you want it to be

1:47:55.920,1:47:58.159
smooth so that you can do inference so

1:47:57.600,1:48:00.080
that if

1:47:58.159,1:48:01.280
you start from a point here it's easy to

1:48:00.080,1:48:02.639
find

1:48:01.280,1:48:04.400
a point on the manifold that's nearby

1:48:02.639,1:48:07.280
using and descent for example

1:48:04.400,1:48:09.600
right so the original formulation of gan

1:48:07.280,1:48:10.960
leads to

1:48:09.600,1:48:13.600
first of all infinite weights in the

1:48:10.960,1:48:15.360
discriminator instabilities

1:48:13.600,1:48:18.239
something called mode collapse which

1:48:15.360,1:48:21.280
alfredo will tell you about

1:48:18.239,1:48:22.400
and in the end a contrast function an

1:48:21.280,1:48:23.920
energy function that's essentially

1:48:22.400,1:48:26.719
useless

1:48:23.920,1:48:27.440
so it's not ideally formulated so people

1:48:26.719,1:48:29.920
have

1:48:27.440,1:48:31.520
proposed ways to fix it by regularizing

1:48:29.920,1:48:33.280
the

1:48:31.520,1:48:35.119
energy function basically forcing it to

1:48:33.280,1:48:39.199
be smooth so one good example of this

1:48:35.119,1:48:39.199
is something called vessel steingans

1:48:43.280,1:48:50.639
proposed by martin arjoski who

1:48:46.480,1:48:54.480
just graduated from nyu

1:48:50.639,1:48:54.480
and leonardo 2 and a few other people

1:48:58.000,1:49:01.679
and and the idea of of that is to

1:49:00.080,1:49:02.960
basically limit the size of the weights

1:49:01.679,1:49:03.760
of the discriminator so that the

1:49:02.960,1:49:05.360
function

1:49:03.760,1:49:07.199
is smooth and there is you know various

1:49:05.360,1:49:08.400
mathematical arguments uh

1:49:07.199,1:49:09.760
in probabilistic framework but that's

1:49:08.400,1:49:10.800
the basic idea and there's lots of

1:49:09.760,1:49:14.159
variations of this

1:49:10.800,1:49:16.480
also questions about today class

1:49:14.159,1:49:18.159
it was dense but at least we were you

1:49:16.480,1:49:20.639
know answering every question

1:49:18.159,1:49:22.000
it was coming right through so i think

1:49:20.639,1:49:24.800
we

1:49:22.000,1:49:25.760
we follow along today um i wasn't sure

1:49:24.800,1:49:29.040
if maybe you

1:49:25.760,1:49:31.280
like explained it in a different form

1:49:29.040,1:49:32.719
and i didn't realize it's the same thing

1:49:31.280,1:49:37.199
but i was a little

1:49:32.719,1:49:40.400
um lost on what the policy network is

1:49:37.199,1:49:42.719
okay what that does

1:49:40.400,1:49:44.400
so the policy network takes the

1:49:42.719,1:49:46.560
estimation of the state of the world and

1:49:44.400,1:49:49.440
produces an action

1:49:46.560,1:49:51.520
and it's trained to minimize the

1:49:49.440,1:49:54.719
expected cost

1:49:51.520,1:49:56.800
of uh the state over the over a

1:49:54.719,1:49:59.040
trajectory but it takes just one action

1:49:56.800,1:49:59.040
okay

1:49:59.920,1:50:04.239
so right and there was a there was a

1:50:02.639,1:50:07.360
part towards the end where

1:50:04.239,1:50:10.400
i guess you drew a new connection

1:50:07.360,1:50:13.760
um right that uh from like

1:50:10.400,1:50:17.280
s to uh

1:50:13.760,1:50:20.400
where it goes down to

1:50:17.280,1:50:23.280
like connected through some module to

1:50:20.400,1:50:24.320
a so what is happening there so the

1:50:23.280,1:50:27.280
policy network

1:50:24.320,1:50:28.719
is the indicated by pi here on the

1:50:27.280,1:50:31.840
screen

1:50:28.719,1:50:35.040
so it takes s the state

1:50:31.840,1:50:35.040
and it produces an action

1:50:36.400,1:50:41.760
okay okay okay that's what a policy is

1:50:39.679,1:50:44.880
right you observe the state of the world

1:50:41.760,1:50:47.119
and you take an action i see okay

1:50:44.880,1:50:48.400
in fact a probabilistic policy is you

1:50:47.119,1:50:50.080
don't take an action you

1:50:48.400,1:50:52.000
give a distribution over actions and

1:50:50.080,1:50:53.199
then you pick the action in some way and

1:50:52.000,1:50:55.679
perform that distribution

1:50:53.199,1:50:57.599
but here you know you just have to take

1:50:55.679,1:50:59.199
an action

1:50:57.599,1:51:01.440
if the number of actions is discrete

1:50:59.199,1:51:02.880
then uh this this pi network

1:51:01.440,1:51:06.159
is this policy network is basically a

1:51:02.880,1:51:08.159
classifier and it produces a bunch of

1:51:06.159,1:51:10.239
scores for each possible action

1:51:08.159,1:51:11.760
and then you take one of the actions

1:51:10.239,1:51:13.040
probabilistically or deterministically

1:51:11.760,1:51:15.199
deterministically you

1:51:13.040,1:51:16.400
just take the action with the highest

1:51:15.199,1:51:18.320
score

1:51:16.400,1:51:19.440
uh probabilistically you can sample

1:51:18.320,1:51:21.199
according to

1:51:19.440,1:51:23.840
to the score and then you run through

1:51:21.199,1:51:26.239
your phone model and you keep going

1:51:23.840,1:51:27.440
okay so without the policy connection

1:51:26.239,1:51:30.000
then

1:51:27.440,1:51:32.159
then the action is just kind of it's a

1:51:30.000,1:51:34.239
related variable so you have to optimize

1:51:32.159,1:51:36.159
with respect to the latent variable to

1:51:34.239,1:51:36.960
find the to find its optimal value so

1:51:36.159,1:51:40.239
you have this

1:51:36.960,1:51:43.760
this kind of uh diagram now

1:51:40.239,1:51:44.480
where the actions are not produced by a

1:51:43.760,1:51:46.639
neural net

1:51:44.480,1:51:47.679
they there are latent variables that you

1:51:46.639,1:51:49.679
have to figure out

1:51:47.679,1:51:50.800
for every new every every time you run

1:51:49.679,1:51:52.320
your model you

1:51:50.800,1:51:54.480
you have to figure out what's the best

1:51:52.320,1:51:57.280
sequence of action to minimize my cost

1:51:54.480,1:51:57.920
and so you have to basically uh do do

1:51:57.280,1:51:59.520
this

1:51:57.920,1:52:01.119
for example by grading descent figuring

1:51:59.520,1:52:02.639
out the sequence of a that will minimize

1:52:01.119,1:52:05.360
the sum of the c's

1:52:02.639,1:52:06.880
over the trajectory that's that's called

1:52:05.360,1:52:09.599
model predictive control

1:52:06.880,1:52:10.880
and then um the one with the policy

1:52:09.599,1:52:14.639
network

1:52:10.880,1:52:18.480
um is is called uh

1:52:14.639,1:52:21.840
you know direct uh control essentially

1:52:18.480,1:52:24.159
um professor uh

1:52:21.840,1:52:26.560
you say that during insurance we need to

1:52:24.159,1:52:30.400
uh minimize

1:52:26.560,1:52:32.639
the energy to get the final value but

1:52:30.400,1:52:34.320
uh okay there are two questions one

1:52:32.639,1:52:35.520
won't it take too much time during

1:52:34.320,1:52:39.199
inference and

1:52:35.520,1:52:42.080
would be useful for real-time systems

1:52:39.199,1:52:44.000
and the second one is since it's

1:52:42.080,1:52:46.960
unrolled and you have to back propagate

1:52:44.000,1:52:48.560
all the way through the beginning yeah

1:52:46.960,1:52:51.440
have all the problems

1:52:48.560,1:52:52.960
that we face in uh recurrent neural

1:52:51.440,1:52:55.360
networks

1:52:52.960,1:52:56.960
exactly so presumably you're not going

1:52:55.360,1:52:58.400
to get the same problems as you have

1:52:56.960,1:52:59.280
with current nets because your forward

1:52:58.400,1:53:01.199
model

1:52:59.280,1:53:02.480
you know presumably implements the

1:53:01.199,1:53:06.320
dynamics of some real

1:53:02.480,1:53:08.159
systems so it might not have the issues

1:53:06.320,1:53:09.760
of sort of non-invertibility that you

1:53:08.159,1:53:10.800
have if it's a physical system it's

1:53:09.760,1:53:13.440
probably going to be

1:53:10.800,1:53:15.599
reversible so you may not have the same

1:53:13.440,1:53:17.280
issue as with regular recurrent nets but

1:53:15.599,1:53:19.040
uh but yeah you're facing this in the

1:53:17.280,1:53:22.159
same problems now

1:53:19.040,1:53:25.679
uh in real time situations

1:53:22.159,1:53:30.000
you you use a form of this called

1:53:25.679,1:53:30.000
reseeding horizon planning

1:53:35.199,1:53:37.599
planning

1:53:38.480,1:53:42.639
okay so receding horizon planning uh is

1:53:41.280,1:53:45.760
when you are in a

1:53:42.639,1:53:46.719
it's a real time situation uh your your

1:53:45.760,1:53:49.040
system will

1:53:46.719,1:53:50.080
run its forward model for a few steps in

1:53:49.040,1:53:51.840
the future

1:53:50.080,1:53:54.000
i don't know let's say a few seconds

1:53:51.840,1:53:57.679
okay sufficiently many steps to predict

1:53:54.000,1:53:59.840
for a few seconds that's your horizon

1:53:57.679,1:54:01.040
uh then you do this uh model predictive

1:53:59.840,1:54:03.440
control you know

1:54:01.040,1:54:04.880
by optimizing finding the optimal air

1:54:03.440,1:54:06.800
that minimizes your cost

1:54:04.880,1:54:08.719
your estimated cost according to your

1:54:06.800,1:54:09.679
model okay you know you haven't taken an

1:54:08.719,1:54:11.760
action yet

1:54:09.679,1:54:13.760
okay you've just run your internal model

1:54:11.760,1:54:16.639
to make that prediction

1:54:13.760,1:54:18.800
um so through optimization with respect

1:54:16.639,1:54:20.560
to a you find the sequence of a that

1:54:18.800,1:54:22.639
optimizes your cost and then you take

1:54:20.560,1:54:26.159
the first action

1:54:22.639,1:54:28.800
in that a and then you do it again okay

1:54:26.159,1:54:30.639
so with the a you talk observe the state

1:54:28.800,1:54:34.000
of the world now you have a new

1:54:30.639,1:54:36.800
state okay which you observe from your

1:54:34.000,1:54:38.000
your sensors and now repeat the process

1:54:36.800,1:54:40.880
run your forward model

1:54:38.000,1:54:42.480
a number of steps in the future optimize

1:54:40.880,1:54:43.040
the sequence of actions to minimize your

1:54:42.480,1:54:46.560
cost

1:54:43.040,1:54:49.119
take the first action and do it again

1:54:46.560,1:54:50.800
so it can be expensive if your horizon

1:54:49.119,1:54:52.239
is long if your forward model is

1:54:50.800,1:54:55.840
complicated

1:54:52.239,1:54:56.320
um and so that's when you need a forward

1:54:55.840,1:54:58.400
model

1:54:56.320,1:55:00.000
the the for a policy network so the

1:54:58.400,1:55:02.159
policy network basically

1:55:00.000,1:55:04.239
compiles this whole process into a

1:55:02.159,1:55:06.960
neural net that directly produces

1:55:04.239,1:55:08.320
the best action from the state okay

1:55:06.960,1:55:11.760
which may or may not be possible

1:55:08.320,1:55:14.239
but it gives you a good guess now

1:55:11.760,1:55:16.480
to give you a concrete example this is

1:55:14.239,1:55:18.800
an interesting series of books by

1:55:16.480,1:55:19.920
a nobel prize-winning economist that

1:55:18.800,1:55:22.480
lives in new york called

1:55:19.920,1:55:23.440
danny kahneman and he talks about two

1:55:22.480,1:55:26.719
systems in the

1:55:23.440,1:55:27.280
human mind called system one and system

1:55:26.719,1:55:30.960
two

1:55:27.280,1:55:32.960
so system one is the process by which

1:55:30.960,1:55:36.880
you take an action without thinking

1:55:32.960,1:55:38.480
okay um you're a very experienced driver

1:55:36.880,1:55:40.159
and you can drive your car without even

1:55:38.480,1:55:41.760
paying attention by you know talking to

1:55:40.159,1:55:42.880
someone next to you

1:55:41.760,1:55:44.880
you don't actually need to think about

1:55:42.880,1:55:47.840
it okay

1:55:44.880,1:55:48.400
system two is more sort of deliberate

1:55:47.840,1:55:50.719
planning

1:55:48.400,1:55:52.320
so system two is when you use your

1:55:50.719,1:55:54.080
internal model of the world

1:55:52.320,1:55:55.599
to kind of predict in advance what's

1:55:54.080,1:55:57.440
gonna happen ahead

1:55:55.599,1:55:58.840
sort of foresee what's gonna happen and

1:55:57.440,1:56:01.840
then take a deliberate

1:55:58.840,1:56:03.360
uh action that you think is gonna be

1:56:01.840,1:56:05.199
the right one according to your model so

1:56:03.360,1:56:07.760
it's more like reasoning

1:56:05.199,1:56:09.599
okay you can think of this you know

1:56:07.760,1:56:11.599
optimization with respect to actions

1:56:09.599,1:56:13.440
to minimize an objective as a form of

1:56:11.599,1:56:14.639
reasoning and we talked about this

1:56:13.440,1:56:18.719
before

1:56:14.639,1:56:20.080
so uh basically model predictive control

1:56:18.719,1:56:21.360
is when you don't have a policy you

1:56:20.080,1:56:22.960
haven't learned the skill

1:56:21.360,1:56:24.560
you know what your cost function is you

1:56:22.960,1:56:27.840
have a pretty good model of the world

1:56:24.560,1:56:28.960
but you don't know how to react okay so

1:56:27.840,1:56:32.400
a beginner

1:56:28.960,1:56:33.840
chess player would be like that you

1:56:32.400,1:56:35.280
you look at the the chase game and you

1:56:33.840,1:56:36.480
have to think about all possibilities

1:56:35.280,1:56:38.800
before you play

1:56:36.480,1:56:40.480
because you know you don't know where to

1:56:38.800,1:56:42.560
play so you have to kind of imagine all

1:56:40.480,1:56:44.639
the possibilities

1:56:42.560,1:56:45.599
if you are an expert player and you play

1:56:44.639,1:56:48.960
against a

1:56:45.599,1:56:50.239
a beginner you know immediately what to

1:56:48.960,1:56:51.440
play you don't have to think about it

1:56:50.239,1:56:53.520
i don't know if you've played

1:56:51.440,1:56:56.000
simultaneous games against

1:56:53.520,1:56:57.280
a master or grandmaster at chess

1:56:56.000,1:57:00.560
grandmaster can play

1:56:57.280,1:57:02.880
against 50 people and beat them in a few

1:57:00.560,1:57:05.520
minutes

1:57:02.880,1:57:06.960
because the player can go from just you

1:57:05.520,1:57:08.800
know one

1:57:06.960,1:57:11.360
opponent to another and just immediately

1:57:08.800,1:57:13.599
play just it's completely reactive

1:57:11.360,1:57:15.199
um you actually doesn't need to to think

1:57:13.599,1:57:17.199
because

1:57:15.199,1:57:18.960
you know they've kind of compiled that

1:57:17.199,1:57:20.639
if you if you want in their

1:57:18.960,1:57:22.639
in their knowledge of chess that they

1:57:20.639,1:57:25.360
don't need to think when you see this

1:57:22.639,1:57:27.360
kind of type of easy situation so that's

1:57:25.360,1:57:29.920
going from system two to system one

1:57:27.360,1:57:31.119
and uh when you learn the skill at first

1:57:29.920,1:57:31.920
you're hesitant and you have to think

1:57:31.119,1:57:33.119
about it

1:57:31.920,1:57:34.560
you know you're heads-up when you drive

1:57:33.119,1:57:36.239
you drive slowly and you look at

1:57:34.560,1:57:39.840
everything and you pay attention

1:57:36.239,1:57:42.080
and then when you are uh experimented

1:57:39.840,1:57:44.080
you you can just react really quickly

1:57:42.080,1:57:46.960
basically you've gone from

1:57:44.080,1:57:48.800
model predictive control to basically

1:57:46.960,1:57:49.440
training your own policy network if you

1:57:48.800,1:57:52.159
will

1:57:49.440,1:57:52.880
okay and in the process of doing this

1:57:52.159,1:57:55.520
your

1:57:52.880,1:57:56.400
uh your skill has gone from a sort of

1:57:55.520,1:58:00.080
deliberate

1:57:56.400,1:58:02.000
planned conscious uh

1:58:00.080,1:58:03.199
decision mechanism to a sort of

1:58:02.000,1:58:06.159
subconscious

1:58:03.199,1:58:09.840
automatic uh decision mechanism that's

1:58:06.159,1:58:09.840
what sort of acquiring expertise does

1:58:11.679,1:58:15.679
and that's that's how you go from this

1:58:13.599,1:58:17.679
diagram to that diagram where you have a

1:58:15.679,1:58:20.960
policy that directly predicts the action

1:58:17.679,1:58:25.920
without having to plan

1:58:20.960,1:58:25.920
okay got it thanks

