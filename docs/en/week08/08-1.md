---
lang-ref: ch.08-1
lecturer: Yann LeCun
title: Contrastive Methods in Energy-Based Models

عنوان: روش های مقابله ای در مدل های مبتنی بر انرژی

authors: Vishwaesh Rajiv, Wenjun Qu, Xulai Jiang, Shuya Zhao
date: 23 Mar 2020
---


## [Recap](https://www.youtube.com/watch?v=ZaVP2SY23nc&t=5s)

Dr. LeCun spent the first ~15 min giving a review of energy-based models. Please refer back to last week (Week 7 notes) for this information, especially the concept of contrastive learning methods.

دکتر لوکان اولین پانزده دقیقه را صرف بررسی مدل های مبتنی بر انرژی کرد. لطفاً برای این اطلاعات، به ویژه مفهوم روش های یادگیری مقابله ای، به هفته گذشته (یادداشت های هفته هفتم) مراجعه کنید

As we have learned from the last lecture, there are two main classes of learning methods:
1. Contrastive Methods that push down the energy of training data points, $F(x_i, y_i)$, while pushing up energy on everywhere else, $F(x_i, y’)$.
2. Architectural Methods that build energy function $F$ which has minimized/limited low energy regions by applying regularization.

همانطور که از آخرین سخنرانی یاد گرفته ایم، دو کلاس اصلی روش های یادگیری وجود دارد:
1. روش های مقابله ای که انرژی نقاط آموزش را کاهش می دهد، $F(x_i، y_i)$ ،در حالی که انرژی را در هرجای دیگر افزایش می دهید، $F(x_i،y')$.
2. روش های معماری که تابع انرژی $F$ را میسازد که با استفاده از منظم سازی مناطق کم انرژی به حداقل می رساند یا محدود می کند

To distinguish the characteristics of different training methods, Dr. Yann LeCun has further summarized 7 strategies of training from the two classes mention before. One of which is methods that are similar to Maximum Likelihood method, which push down the energy of data points and push up everywhere else.

برای متمایز کردن ویژگی های روش های مختلف آموزشی، دکتر یان لوکان 7 راهبرد آموزش را از دو کلاس ذکر شده در قبل خلاصه کرده است. یکی از آنها روش هایی است که مشابه روش حداکثر احتمال است، که انرژی نقاط داده را پایین آورده و در جاهای دیگر بالا می برد

Maximum Likelihood method probabilistically pushes down energies at training data points and pushes everywhere else for every other value of $y’\neq y_i$. Maximum Likelihood doesn't “care” about the absolute values of energies but only “cares” about the difference between energy. Because the probability distribution is always normalized to sum/integrate to 1, comparing the ratio between any two given data points is more useful than simply comparing absolute values.

روش حداکثر احتمال بطور احتمالی انرژی را در نقاط داده آموزش کاهش می دهد و در هر جای دیگر برای هر مقدار دیگر  $y'\neq y_i$ کاهش می دهد
حداکثر احتمال برای مقادیر مطلق انرژی "اهمیتی" ندارد بلکه فقط به تفاوت انرژی اهمیت می دهد. از آنجا که توزیع احتمال همیشه به جمع یا ترکیب با 1 نرمال می شود، مقایسه نسبت بین هر دو نقطه داده داده شده مفیدتر از مقایسه ساده مقادیر مطلق است

## [Contrastive methods in self-supervised learning](https://www.youtube.com/watch?v=ZaVP2SY23nc&t=613s)

## [روشهای مقابله ای در یادگیری خود نظارت شده]

In contrastive methods, we push down on the energy of observed training data points ($x_i$, $y_i$), while pushing up on the energy of points outside of the training data manifold.

در روش های مقابله ای، ما انرژی نقاط مشاهده شده آموزش را کاهش می دهیم ($x_i$، $ y_i$)، در حالی که انرژی نقاط خارج از منیفولد داده آموزش را افزایش می دهیم

In self-supervised learning, we use one part of the input to predict the other parts. We hope that our model can produce good features for computer vision that rival those from supervised tasks.

در یادگیری خود نظارتی، ما از یک قسمت ورودی برای پیش بینی قسمت های دیگر استفاده می کنیم. ما امیدواریم که مدل ما بتواند ویژگی های خوبی برای بینایی ماشین تولید کند که با وظایف نظارت شده رقابت می کند

Researchers have found empirically that applying contrastive _embedding_ methods to self-supervised learning models can indeed have good performances which rival that of supervised models. We will explore some of these methods and their results below.

محققان به طور تجربی دریافته اند که استفاده از روش های مقابله ای _ تعبیه شده_ در مدل های یادگیری خود نظارتی می تواند عملکرد خوبی داشته باشد که با مدلهای تحت نظارت رقابت کند. در زیر برخی از این روش ها و نتایج آنها را بررسی خواهیم کرد

### Contrastive embedding

Consider a pair ($x$, $y$), such that $x$ is an image and $y$ is a transformation of $x$ that preserves its content (rotation, magnification, cropping, *etc.*). We call this a **positive** pair.

یک جفت ($x$, $y$)، را در نظر بگیرید، به عنوان مثال $x$ یک تصویر است و $y$ یک تغییر شکل از $x$ است که محتوای آن را حفظ می کند (چرخش، بزرگنمایی، برش، *و غیره*). ما این را یک جفت **مثبت** می نامیم

<center>
<img src="{{site.baseurl}}/images/week08/08-1/fig1.png" width="50%"/><br>
<b>Fig. 1</b>: Positive Pair
</center>

Conceptually, contrastive embedding methods take a convolutional network, and feed $x$ and $y$ through this network to obtain two feature vectors: $h$ and $h'$. Because $x$ and $y$ have the same content (*i.e.* a positive pair), we want their feature vectors to be as similar as possible. As a result, we choose a similarity metric (such as cosine similarity) and a loss function that maximizes the similarity between $h$ and $h'$. By doing this, we lower the energy for images on the training data manifold.

از نظر مفهومی، روش های تعبیه مقابله ای یک شبکه کانولوشن را می گیرد و $x$ و $y$  را از طریق این شبکه تغذیه می کند تا دو بردار ویژگی $h$ و $h'$ را بدست آورد.
از آنجا که $x$ و $y$ محتوای یکسانی دارند (*یعنی* یک جفت مثبت) ، ما می خواهیم بردارهای ویژگی آنها تا حد ممکن مشابه باشد. در نتیجه، ما یک معیار تشابه (مانند تشابه کسینوس) و یک تابع اتلاف را انتخاب می کنیم که شباهت بین $h$ و $h'$ را ماکزیمم نماید.
با این کار، انرژی تصاویر روی منیفولد آموزش را کاهش می دهیم.

<center>
<img src="{{site.baseurl}}/images/week08/08-1/fig2.png" width="50%"/><br>
<b>Fig. 2</b>: Negative Pair
</center>

However, we also have to push up on the energy of points outside this manifold. So we also generate **negative** samples ($x_{\text{neg}}$, $y_{\text{neg}}$), images with different content (different class labels, for example). We feed these to our network above, obtain feature vectors $h$ and $h'$, and now try to minimize the similarity between them.

با این حال، ما همچنین باید انرژی نقاط خارج از این منیفولد را افزایش دهیم. بنابراین ما همچنین نمونه های **منفی** تولید می کنیم ($x_{\text{neg}}$, $y_{\text{neg}}$)،
تصاویر با محتوای متفاوت (به عنوان مثال، برچسب های کلاس مختلف).
ما شبکه خود در بالا را با اینها تغذیه می کنیم، بردارهای ویژگی $h$ و $h'$ را بدست می آوریم، و سعی می کنیم شباهت بین آنها را به حداقل برسانیم.

This method allows us to push down on the energy of similar pairs while pushing up on the energy of dissimilar pairs.

این روش به ما امکان می دهد تا انرژی جفت های مشابه را کاهش دهیم در حالی که انرژی جفت های غیر مشابه را افزایش می دهیم

Recent results (on ImageNet) have shown that this method can produce features that are good for object recognition that can rival the features learned through supervised methods.

نتایج اخیر (در ایمج نت) نشان داده است که این روش می تواند ویژگی های مناسب برای تشخیص شی را ایجاد کند که می تواند با ویژگی های یاد گرفته شده از طریق روش های نظارتی رقابت کند

### Self-Supervised Results (MoCo, PIRL, SimCLR)

<center>
<img src="{{site.baseurl}}/images/week08/08-1/fig3.png" height="75%" width="75%"/><br>
<b>Fig. 3</b>: PIRL and MoCo on ImageNet
</center>

As seen in the figure above, MoCo and PIRL achieve SOTA results (especially for lower-capacity models, with a small number of parameters). PIRL is starting to approach the top-1 linear accuracy of supervised baselines (~75%).

همانطور که در شکل بالا مشاهده می شود، MoCo  و PIRL نتایج SOTA را به دست می آورند (به ویژه برای مدل های با ظرفیت پایین ، با تعداد کمی پارامتر).
 PIRLشروع به نزدیک شدن به رتبه اول دقت خطی در میان خطوط پایه نظارت شده می کند. 

We can understand PIRL more by looking at its objective function: NCE (Noise Contrastive Estimator) as follows.
ما می توانیم PIRL را با نگاهی به تابع هدف آن بیشتر درک کنیم:
NCE (برآورد كننده نویز) به شرح زیر است

$$
h(v_I,v_{I^t})=\frac{\exp\big[\frac{1}{\tau}s(v_I,v_{I^t})\big]}{\exp\big[\frac{1}{\tau}s(v_I,v_{I^t})\big]+\sum_{I'\in D_{N}}\exp\big[\frac{1}{\tau}s(v_{I^t},v_{I'})\big]}
$$

$$
L_{\text{NCE}}(I,I^t)=-\log\Big[h\Big(f(v_I),g(v_{I^t})\Big)\Big]-\sum_{I'\in D_N}\log\Big[1-h\Big(g(v_{I^t}),f(v_{I'})\Big)\Big]
$$

Here we define the similarity metric between two feature maps/vectors as the cosine similarity.

در اینجا ما معیار تشابه بین دو نقشه یا بردار ویژگی را به عنوان شباهت کسینوس تعریف می کنیم

What PIRL does differently is that it doesn't use the direct output of the convolutional feature extractor. It instead defines different _heads_ $f$ and $g$, which can be thought of as independent layers on top of the base convolutional feature extractor.

کاری که PIRL بطور متفاوتی انجام می دهد این است که از خروجی مستقیم استخراج کننده ویژگی های کانولوشن استفاده نمی کند.
در عوض،_heads_  مختلف $f$ و $g$ را تعریف می کند، که می تواند به عنوان لایه های مستقل در بالای استخراج کننده ویژگی کانولوشنی پایه در نظر گرفته شود.

Putting everything together, PIRL's NCE objective function works as follows. In a mini-batch, we will have one positive (similar) pair and many negative (dissimilar) pairs. We then compute the similarity between the transformed image's feature vector ($I^t$) and the rest of the feature vectors in the minibatch (one positive, the rest negative). We then compute the score of a softmax-like function on the positive pair. Maximizing a softmax score means minimizing the rest of the scores, which is exactly what we want for an energy-based model. The final loss function, therefore, allows us to build a model that pushes the energy down on similar pairs while pushing it up on dissimilar pairs.

با قرار دادن همه چیز در کنار هم، تابع هدف PIRL’s NCE به شرح زیر عمل می کند. در یک مینی بچ، یک جفت مثبت (مشابه) و بسیاری از جفت های منفی (غیر مشابه) خواهیم داشت. سپس شباهت بین بردار ویژگی تصویر تبدیل شده ($I^t$) و بقیه بردارهای ویژگی در مینی بچ را محاسبه می کنیم (یک مثبت، بقیه منفی). سپس امتیاز یک تابعsoftmax مانند را بر روی جفت مثبت محاسبه می کنیم. به حداکثر رساندن امتیاز softmax به معنای به حداقل رساندن بقیه امتیازات است، که دقیقاً همان چیزی است که ما برای یک مدل مبتنی بر انرژی می خواهیم. بنابراین، تابع اتلاف نهایی به ما امکان می دهد مدلی بسازیم که انرژی را روی جفت های مشابه به کاهش دهد در حالی که آن را روی جفت های غیرمشابه افزایش می دهد. 

Dr. LeCun mentions that to make this work, it requires a large number of negative samples. In SGD, it can be difficult to consistently maintain a large number of these negative samples from mini-batches. Therefore, PIRL also uses a cached memory bank.

دکتر لوکان اشاره می کند که برای این کار، به تعداد زیادی نمونه منفی نیاز دارد. درSGD ، نگهداری مداوم تعداد زیادی از این نمونه های منفی از مینی بچ ها دشوار است. بنابراین، PIRL همچنین از یک بانک حافظه پنهان استفاده می کند.

**Question**: Why do we use cosine similarity instead of L2 Norm?
Answer: With an L2 norm, it's very easy to make two vectors similar by making them "short" (close to centre) or make two vectors dissimilar by making them very "long" (away from the centre). This is because the L2 norm is just a sum of squared partial differences between the vectors. Thus, using cosine similarity forces the system to find a good solution without "cheating" by making vectors short or long.
**سوال**:
چرا به جای L2 Norm از شباهت کسینوس استفاده می کنیم؟
پاسخ:
با L2 Norm، ساخت دو بردار مشابه با "کوتاه" کردنشان (نزدیک به مرکز) یا غیرمشابه کردن دو بردار با بسیار "طولانی" کردنشان (دور از مرکز) ، بسیار آسان است. این بدان دلیل است که L2 Norm فقط مجموع اختلاف جزئی مربع بردارها است. بنابراین، استفاده از تشابه کسینوس سیستم را مجبور می کند بدون "تقلب" با کوتاه یا بلند کردن بردارها، راه حل خوبی پیدا کند.

### SimCLR

<center>
<img src="{{site.baseurl}}/images/week08/08-1/fig5.png" height="75%" width="75%"/><br>
<b>Fig. 4</b>: SimCLR Results on ImageNet
</center>

SimCLR shows better results than previous methods. In fact, it reaches the performance of supervised methods on ImageNet, with top-1 linear accuracy on ImageNet. The technique uses a sophisticated data augmentation method to generate similar pairs, and they train for a massive amount of time (with very, very large batch sizes) on TPUs. Dr. LeCun believes that SimCLR, to a certain extend, shows the limit of contrastive methods. There are many, many regions in a high-dimensional space where you need to push up the energy to make sure it's actually higher than on the data manifold. As you increase the dimension of the representation, you need more and more negative samples to make sure the energy is higher in those places not on the manifold.

SimCLR نتایج بهتری نسبت به روش های قبلی نشان می دهد. در واقع، با بالاترین دقت خطی ایمج نت ، به عملکرد روشهای نظارت شده در ایمج نت می رسد. این روش برای تولید جفت های مشابه از یک روش افزایش داده پیچیده استفاده می کند، و آنها برای مدت زمان زیادی (با اندازه های بچ بسیار زیاد) روی TPU تمرین می کنند. دکتر لوکان معتقد است که SimCLR تا حدودی محدودیت روش های انقباضی را نشان می دهد. مناطق بسیار زیاد در یک فضا با ابعاد بالا وجود دارد که لازم است انرژی را بالا ببرید تا مطمئن شوید در واقع بیشتر از انرژی روی منیفولد داده است. همانطور که ابعاد نمایش را افزایش می دهید، به نمونه های منفی بیشتر و بیشتری نیاز دارید تا اطمینان حاصل کنید که انرژی در آن مکان ها بیشتر از انرژی روی منیفولد است.

## [Denoising autoencoder](https://www.youtube.com/watch?v=ZaVP2SY23nc&t=1384s)

In [week 7's practicum](https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-3/), we discussed denoising autoencoder. The model tends to learn the representation of the data by reconstructing corrupted input to the original input. More specifically, we train the system to produce an energy function that grows quadratically as the corrupted data move away from the data manifold.

در [جلسه هفتم هفتم]، ما در مورد نویززدایی اتوانکودر بحث کردیم. این مدل تمایل دارد تا با بازسازی ورودی خراب به ورودی اصلی، نمایش داده ها را بیاموزد. بطور خاص، ما سیستم را برای تولید یک تابع انرژی آموزش می دهیم که با دور شدن داده های خراب از منیفولد داده، درجه دوم رشد می کند

<center>
<img src="{{site.baseurl}}/images/week08/08-1/fig6.png" height="75%" width="75%"/><br>
<b>Fig. 5</b>: Architecture of denoising autoencoder
</center>


### Issues

However, there are several problems with denoising autoencoders. One problem is that in a high dimensional continuous space, there are uncountable ways to corrupt a piece of data. So there is no guarantee that we can shape the energy function by simply pushing up on lots of different locations. Another problem with the model is that it performs poorly when dealing with images due to the lack of latent variables. Since there are many ways to reconstruct the images, the system produces various predictions and doesn't learn particularly good features. Besides, corrupted points in the middle of the manifold could be reconstructed to both sides. This will create flat spots in the energy function and affect the overall performance.

با این حال، مشکلات زیادی در زمینه نویززدایی اتوانکودر وجود دارد. یک مشکل این است که در یک فضای پیوسته با ابعاد بالا، روش های بی شماری برای خراب کردن یک داده وجود دارد. بنابراین هیچ تضمینی وجود ندارد که بتوانیم تابع انرژی را فقط با افزایش دادن روی موقعیت های مختلف، شکل دهیم. مشکل دیگر مدل این است که هنگام کار با تصاویر به دلیل کمبود متغیرهای نهفته، عملکرد ضعیفی دارد. از آنجا که روش های زیادی برای بازسازی تصاویر وجود دارد، سیستم پیش بینی های مختلفی را ایجاد می کند و ویژگی های منحصرا خوبی را نمی آموزد. علاوه بر این، نقاط خراب در وسط منیفولد می تواند از هر دو طرف بازسازی شود. این باعث ایجاد لکه های مسطح در تابع انرژی می شود و عملکرد کلی آن را تحت تأثیر قرار می دهد.

## Other Contrastive Methods
## روش های مقابله ای دیگر

There are other contrastive methods such as contrastive divergence, Ratio Matching, Noise Contrastive Estimation, and Minimum Probability Flow. We will briefly discuss the basic idea of contrastive divergence.

روشهای مقابله ای دیگری نیز وجود دارد مانند واگرایی مقابله ای (انقباضی)، تطبیق نسبت، برآورد ضد نویز و حداقل جریان احتمال. ما به طور خلاصه در مورد ایده اصلی واگرایی انقباضی بحث خواهیم کرد


### Contrastive Divergence
### واگرایی مقابله ای (انقباضی)

Contrastive divergence (CD) is another model that learns the representation by smartly corrupting the input sample. In a continuous space, we first pick a training sample $y$ and lower its energy. For that sample, we use some sort of gradient-based process to move down on the energy surface with noise. If the input space is discrete, we can instead perturb the training sample randomly to modify the energy. If the energy we get is lower, we keep it. Otherwise, we discard it with some probability. Keep doing so will eventually lower the energy of $y$. We can then update the parameter of our energy function by comparing $y$ and the contrasted sample $\bar y$ with some loss function.

واگرایی مقابله ای (CD) مدل دیگری است که با خراب کردن هوشمندانه نمونه ورودی، نمایش را فرا می گیرد. در یک فضای پیوسته، ابتدا یک نمونه آموزشی $y$ انتخاب کرده و انرژی آن را کاهش می دهیم. برای آن نمونه، ما از نوعی فرایند مبتنی بر شیب (گرادیان) استفاده می کنیم تا با نویز روی سطح انرژی به پایین حرکت کنیم. اگر فضای ورودی گسسته باشد، می توانیم نمونه آموزشی را به طور تصادفی مختل کنیم تا انرژی را اصلاح کنیم. اگر انرژی که می گیریم کمتر باشد، آن را حفظ می کنیم. در غیر این صورت، ما آن را با احتمال زیاد کنار می گذاریم. ادامه این کار در نهایت باعث کاهش انرژی $y$  می شود. سپس می توانیم پارامتر تابع انرژی خود را با مقایسه کردن $y$ و نمونه متضاد $\ bar y$ با تابع اتلاف به روز کنیم.

### Persistent Contrastive Divergence
### واگرایی مقابله ای پایدار

One of the refinements of contrastive divergence is persistent contrastive divergence. The system uses a bunch of "particles" and remembers their positions. These particles are moved down on the energy surface just like what we did in the regular CD. Eventually, they will find low energy places in our energy surface and will cause them to be pushed up. However, the system does not scale well as the dimensionality increases.

یکی از اصلاحات واگرایی مقابله ای، واگرایی مقابله ای پایدار است. این سیستم از یک دسته "ذرات" استفاده می کند و موقعیت آنها را به خاطر دارد. این ذرات درست مانند آنچه در واگرایی مقابله ای معمولی انجام دادیم روی سطح انرژی به پایین منتقل می شوند. در نهایت، آنها مکان های کم انرژی را در سطح انرژی مان پیدا می کنند و باعث می شوند که آنها افزایش یابند. اما، سیستم با افزایش ابعاد مقیاس خوبی ندارد.
