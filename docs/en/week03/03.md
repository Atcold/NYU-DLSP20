---
lang-ref: ch.03
title: Week 3
---


## Lecture part A

We first see a visualization of 6-layer neural network. Next we begin to the topic of Convolution and Convolution Neural Networks (CNN). We review several types of parameter transformation in CNN and introduce the idea of a kernel, used to learn features in a hierarchical manner, and to classify our input data is the basic idea of a CNN.


## Lecture part B

We give an introduction on CNN evolutions. We discuss in detail on architectures of CNN with modern implementation of LeNet5, exemplified by the task of digit recognition on MNIST. Based on its design principles, we expand on the advantages of CNN which fully explores compositionality, stationarity, and locality features of natural images.


## Practicum

Properties of signals that are most relevant to CNNs are discussed, namely:- Locality, Stationarity, and Compositionality. How a kernel exploits these features by using Sparsity, Weight sharing and Stacking of layers is explored next, along with the concepts of padding and pooling. A performance comparison between FCN and CNN for different data modalities was also made.
