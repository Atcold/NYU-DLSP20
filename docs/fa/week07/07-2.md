---
lang-ref: ch.07-2
lecturer: Yann LeCun
title: SSL, EBM with details and examples
authors: Ravi Choudhary， B V Nithish Addepalli, Syed Rahman，Jiayi Du
date: 9 Mar 2020
---


<!--## [Self supervised learning](https://www.youtube.com/watch?v=tVwV14YkbYs&t=2683s)-->
##[یادگیری خودنظارتی](https://www.youtube.com/watch?v=tVwV14YkbYs&t=2683s)
<!--Self Supervised Learning (SSL) encompasses both supervised and unsupervised learning. The objective of the SSL pretext task is to learn a good representation of the input so that it can subsequently be used for supervised tasks. In SSL, the model is trained to predict one part of the data given other parts of the data. For example, BERT was trained using SSL techniques and the Denoising Auto-Encoder (DAE) has particularly shown state-of-the-art results in Natural Language Processing (NLP).-->
&#x202b; یادگیری خودنظارتی (SSL) شامل هر دوی یادگیری‌های بانظارت و بی‌نظارت می‌شود. هدف از کارایی اصلی SSL یادگیری نمایش درستی از ورودی است، به گونه‌ای که بتواند متعاقبا برای کارهای بانظارت استفاده شود. در SSL، مدل برای پیش‌بینی یک قسمت از داده با توجه به قسمت‌های دیگر آموزش داده شده است. برای مثال، BERT با استفاده از آموزش‌هایی که از روش‌های SSL و Denoising Auto-Encoder (DAE) گرفت، نتایج درخشانی در پردازش زبان طبیعی از خود نشان داد.
<center>
<img src="{{site.baseurl}}/images/week07/07-2/1_ssl.png"/><br>
<!--<b>Fig. 1</b>: Self Supervised Learning-->
<b>شکل. ۱:</b> يادگیری خودنظارتی
</center>

<!--Self Supervised Learning task can be defined as the following:-->
&#x202b; وظایف عمده‌ی یادگیری خودنظارتی به صورت زیر دسته‌بندی می‌شوند:
<!--* Predict the future from the past.-->
* پیش‌بینی آینده با استفاده از گذشته&#x202b;
<!--* Predict the masked from the visible.-->
* &#x202b; پیش‌بینی نهان، با استفاده از چیز‌های آشکار
<!--* Predict any occluded parts from all available parts.-->
* پیش‌بینی بخش‌های مسدود از طریق بخش‌های در دسترس &#x202b;


<!--For example, if a system is trained to predict the next frame when the camera is moved, the system will implicitly learn about the depth and parallax. This will force the system to learn that objects occluded from its vision do not disappear but continue to exist and the distinction between animate, inanimate objects, and the background. It can also end up learning about intuitive physics like gravity.-->
&#x202b; برای مثال، اگر یک سیستم برای پیش‌بینی چارچوب بعدی زمانی که دوربین‌ حرکت می‌کند آموزش دیده است، سیستم به طور ضمنی درمورد عمق و اختلاف منظر یاد خواهد گرفت. این سیستم را مجبور می‌کند تا اشیای دور از دسترس و فاصله‌ی بین اشیای زنده و غیره زنده و تصاویر پس‌زمینه، ناپدید نمی‌شوند و همچنان وجود دارند. همچنین می‌تواند منجر به یادگیری فیزیک شهودی مانند جاذبه شود.

<!--State-of-the-art NLP systems (BERT) pre-train a giant neural network on an SSL task. You remove some of the words from a sentence and make the system predict the missing words. This has been very successful. Similar ideas were also tried out in computer vision realm. As shown in the image below, you can take an image and remove a portion of the image and train the model to predict the missing portion.-->
&#x202b; سیستم‌های پیشرفته‌ی NLP (BERT)، یک شبکه‌ی عصبی غول‌آسا را به عنوان یک تکلیف SSL از قبل آموزش می‌دهند. چند کلمه را از یک جمله حذف می‌کنید و باعث می‌شوید سیستم کلمه‌های مفقود را پیش‌بینی کند. این امر بسیار موفقی بوده است. ایده‌های مشابه همچنین در حیطه‌ی بینایی کامپیوتر بررسی شده‌اند. مانند تصویر زیر، شما می‌توانید بخشی از یک تصویر را حذف کنید و مدل را برای پیش‌بینی بخش حذف شده آموزش دهید.

<center>
<img src="{{site.baseurl}}/images/week07/07-2/2_cv_eg.png"/><br>
<!--<b>Fig. 2</b>: Corresponding results in computer vision-->
<b>شکل.۲</b> : نتایج متناظر در بینایی کامپیوتر
</center>

<!--Although the models can fill in the missing space they have not shared the same level of success as NLP systems. If you were to take the internal representations generated by these models, as input to a computer vision system, it is unable to beat a model that was pre-trained in a supervised manner on ImageNet. The difference here is that NLP is discrete whereas images are continuous. The difference in success is because in the discrete domain we know how to represent uncertainty, we can use a big softmax over the possible outputs, in the continuous domain we do not.-->
&#x202b; با اینکه این سیستم‌ها هم می‌توانند بخش‌های مفقود را بیابند و جایگزین کنند، اما هیچ‌کدام به موفقیت NLP نیستند. اگر شما می‌خواستید تصویر داخلی این مدل‌ها را به عنوان ورودی به سیستم‌های بینایی کامپیوتر داشته باشید، توجه داشته باشید که نمی‌توان مدلی را که به صورت یک مسئله‌ی بانظارت در ImageNet از پیش‌آموزش داده است را نمی‌توان شکست داد. تفاوت اینجا در آن است که NLP در جاهایی که تصاویر پیوسته است، گسسته می‌باشد. تفاوت در میزان موفقیت به خاطر این است که چون در دامنه‌ی گسسته می‌دانیم عدم قطعیت را چگونه نمایش دهیم، می‌توانیم از یک softmax بزرگ در خروجی‌های ممکن استفاده کنیم، اما در دامنه‌ی پیوسته این امکان وجود ندارد.


<!--An intelligent system (AI agent) needs to be able to predict the results of its own action on the surroundings and itself to make intelligent decisions. Since the world is not completely deterministic and there is not enough compute power in a machine/human brain to account for every possibility, we need to teach AI systems to predict in the presence of uncertainty in high dimensional spaces. Energy-based models (EBMs) can be extremely useful for this.-->

&#x202b; یک سیستم هوشمند (دستیار AI) نیاز دارد تا بتواند نتایج حاصل از حرکات خودش در محیط پیرامون و خود را پیش‌بینی کند. تا زمانی که دنیا به صورت کلی قابل پیش‌بینی و دارای نتایج قطعی نیست و توان کافی محاسباتی در مغز ماشین/انسان برای هر احتمالی وجود ندارد، نیاز است تا سیستم‌های هوش مصنوعی را با توجه به عدم قطعیت ممکن در فضاهای با ابعاد بالا، آموزش دهیم.
<!--A neural network trained using Least Squares to predict the next frame of a video will result in blurry images because the model cannot exactly predict the future so it learns to average out all possibilities of the next frame from the training data to reduce the loss.-->
&#x202b;یک شبکه‌ی عصبی که توسط مربع حداقل‌ها برای پیش‌بینی چارچوب بعدی یک ویدیو آموزش دیده‌است، منجر به نمایش تصاویر تار می‌شود، چرا که مدل به صورت دقیق نمی‌تواند آینده را پیش‌بینی کند و بنابراین تنها برای نمایش میانگین احتمالات ممکن در چارچوب‌های بعدی با توجه به دیتای آموزش دیده، آموزش می‌بیند تا تلفات را کم کند.  

<!--### Latent variable energy-based models as a solution to make predictions for next frame:-->
###&#x202b; مدل‌های متغیر پنهان مبتنی بر انرژی، به عنوان یک راهکار برای پیش‌بینی چارچوب بعدی:

<!--Unlike linear regression, Latent variable energy-based models take what we know about the world as well as a latent variable which gives us information about what happened in reality. A combination of those two pieces of information can be used to make a prediction that will be close to what actually occurs.-->
&#x202b; بر خلاف رگرسیون خطی، مدل‌های متغیر پنهان مبتنی بر انرژی آنچه که ما درباره‌ی دنیا می‌دانیم را مانند اطلاعاتی که در مورد رخداد‌های دنیای به ما می‌دهند، از ما می‌گیرند. ترکیبی از دو بخش از اطلاعات می‌تواند به عنوان یک پیش‌بینی نزدیک به رخداد واقعی استفاده شود.

<!--These models can be thought of as systems that rate compatibility between the input $x$ and actual output $y$ depending on the prediction using the latent variable that minimizes the energy of the system. You observe input $x$ and produce possible predictions $\bar{y}$ for different combinations of input $x$ and latent variables $z$ and choose the one that minimizes the energy, prediction error, of the system.-->
&#x202b; از این مدل‌ها می‌توان برای برسی میزان تطبیق ورودی X و خروجی حقیقی y با توجه به پیش‌بینی مبتنی بر استفاده از متغیر پنهان که انرژی سیستم را کمینه می‌کند، استفاده کرد. ورودی x را مشاهده می‌کنید و پیش‌بینی ممکن y برای ترکیب‌های مخلفی از ورودی x و متغیر پنهان z را تولید می‌کنید، سپس آن پارامتری که انرژی خطای پیش‌بینی، سیستم را کمینه می‌کند، انتخاب می‌کنید.
<!--Depending upon the latent variable we draw, we can end up with all the possible predictions. The latent variable could be thought of as a piece of important information about the output $y$ that is not present in the input $x$.-->
&#x202b; با توجه به متغیر پنهانی که ما ترسیم کردیم، می‌توانیم همه‌ی احتمالات ممکن را پیش‌بینی کنیم. متغیر پنهان می‌تواند به عنوان بخشی از یک سری اطلاعات مهم درباره‌ی خروجی y که ممکن است در ورودی x وجود نداشته باشند، باشد.

<!--Scalar-valued energy function can take two versions:-->
&#x202b; توابع انرژی با مقادیر اسکالر می‌توانند دو نوع باشند:

<!--1. Conditional $F(x, y)$ - measure the compatibility between $x$ and $y$-->
&#x202b; ۱. F(x,y) شرطی- انطباق بین x و y را اندازه‌گیری می‌کند
<!--2. Unconditional $F(y)$ -  measure the compatibility between the components of $y$-->
&#x202b; ۲. F(y) غیرشرطی-  انطباق بین بخش‌های y را اندازه‌گیری می‌کند


<!--## [Training an Energy-Based Model](https://www.youtube.com/watch?v=tVwV14YkbYs&t=3957s)-->
## &#x202b; [آموزش یک مدل مبتنی بر انرژی](https://www.youtube.com/watch?v=tVwV14YkbYs&t=3957s)

<!--There are two classes of learning models to train an Energy-Based Model to parametrize $F(x, y)$.-->
&#x202b; دو کلاس از مدل‌های یادگیری برای آموزش یک مدل مبتنی بر انرژی برای پارامتریزه کردن F(x, y) وجود دارد.
<!--1. **Contrastive methods:** Push down on $F(x[i], y[i])$, push up on other points $F(x[i], y')$-->
&#x202b; ۱. 	روش‌های انقباضی: F(x[i], y[i]) را به پایین هل دهید و نقاط دیگر F(x[i], y’) را به بالا.
<!--2. **Architectural Methods:** Build $F(x, y)$ so that the volume of low energy regions is limited or minimized through regularization-->
&#x202b; ۲. 	روش‌های معماری: F(x, y) را چنان بسازید که حجم نواحی کم‌انرژی، با مرتب کردن آن‌ها محدود و کمینه شود.
<!--There are seven strategies to shape the energy function. The contrastive methods differ in the way they pick the points to push up. While the architectural methods differ in the way they limit the information capacity of the code.-->
&#x202b; هفت راه برای شکل دادن به تابع انرژی وجود دارد. روش‌های انقباضی در نحوه‌ی انتخاب نقاطی که به بالا هل داده‌ می‌شوند متفاوتند. اما روش‌های معماری در  نحوه‌ی محدود کردن ظرفیت اطلاعات روی کد با یکدیگر متفاوتند.
<!--An example of the contrastive method is Maximum Likelihood learning. The energy can be interpreted as an unnormalised negative log density. Gibbs distribution gives us the likelihood of $y$ given $x$. It can be formulated as follows:-->
&#x202b; یک مثال از روش انقباضی یادگیری Maximum Likelihood است. انرژی می‌تواند به صورت چگالی لگاریتم منفی نرمالیزه نشده نمایش داده شود. توزیع Gibbs، likelihood خروجی y که توسط x داده شده است را به ما می‌دهد، که به صورت زیر بیان می‌شود.
$$
P(Y \mid W) = \frac{e^{-\beta E(Y,W)}}{\int_{y}e^{-\beta E(y,W)}}
$$

<!--Maximum likelihood tries to make the numerator big and the denominator small to maximize the likelihood. This is equivalent to minimizing $-\log(P(Y \mid W))$ which is given below-->
&#x202b; Maximum Likelihood تلاش می‌کند تا مقسوم را بزرگ و مقسوم علیه را کوچک نگه دارد تا likelihood را بیشینه کند. این معادل با کمینه کردن – که در زیر نشان‌ داده شده است، می‌باشد:

$$
L(Y, W) = E(Y,W) + \frac{1}{\beta}\int_{y}e^{-\beta E(y,W)}
$$

<!--Gradient of the negative log likelihood loss for one sample Y is as follows:-->
&#x202b; گرادیان تلفات لگاریتم Likelihood منفی برای نمونه‌ی y به صورت زیر است:

$$
\frac{\partial L(Y, W)}{\partial W} = \frac{\partial E(Y, W)}{\partial W} - \int_{y} P(y\mid W) \frac{\partial E(y,W)}{\partial W}
$$

<!--In the above gradient, the first term of the gradient at the data point $Y$ and the second term of the gradient gives us the expected value of the gradient of the energy over all $Y$s. Hence, when we perform gradient descent the first term tries to reduce energy given to the data point $Y$ and the second term tries to increase the energy given to all other $Y$s.-->
&#x202b; در گرادیان بالا، اولین بخش از گرادیان در نقاط داده y و بخش دوم گرادیان مقدار قابل انتظاری از گرادیان انرژی در کل y را به ما می‌دهد. از این رو، وقتی که ما وقتی که ما گرادیان نزولی را محاسبه می‌کنیم، اولین بخش تلاش می‌کند تا انرژی داده شده به نقاط داده y را کاهش دهد و بخش دوم تلاش می‌کند تا انرژی داده شده به همه‌ی y‌های دیگر را افزایش دهد.

<!--The gradient of the energy function is generally very complex and hence computing, estimating or approximating the integral is a very interesting case as it is intractable in most of the cases.-->
&#x202b; گرادیان تابع انرژی به صورت کلی خیلی پیچیده و دارای محاسبات زیاد است، محاسبه و یا تقریب زدن انتگرال از آن جایی که یک مورد غیر قابل حل در بیشتر موارد است، بسیار جالب به نظر می‌رسد.

<!--## [Latent variable energy-based model](https://www.youtube.com/watch?v=tVwV14YkbYs&t=4767s)-->
## &#x202b; [ مدل متغیر پنهان مبتنی بر انرژی](https://www.youtube.com/watch?v=tVwV14YkbYs&t=4767s)

<!--The main advantage of Latent variable models is that they allow multiple predictions through the latent variable. As $z$ varies over a set, $y$ varies over the manifold of possible predictions. Some examples include:-->
&#x202b; مزیت اصلی مدل‌های متغیر پنهان در پذیرفتن پیش‌بینی‌های متعدد از طریق متغیر‌های پنهان است. در همان حین که Z بر روی یک مجموعه تغییرمی‌کند، y بر روی یک بستر گوناگونی از احتمالات ممکن تغییر می‌کند. برخی از مثال‌ها شامل:

<!--1. K-means-->
&#x202b; ۱. K-means

<!--2. Sparse modelling-->
&#x202b; ۲. مدل‌سازی پراکنده
<!--3. [GLO](https://arxiv.org/abs/1707.05776)-->
&#x202b; ۳. [GLO](https://arxiv.org/abs/1707.05776)

<!--These can be of two types:-->
&#x202b; این‌ها می‌توانند از دو گونه باشند:

<!--1. Conditional models where $y$ depends on $x$-->
&#x202b; ۱.	مدل‌های شرطی که $y$ مبتنی بر $X$ است

    1. $$F(x,y) = \text{min}_{z} E(x,y,z)$$
    2. $$F_\beta(x,y) = -\frac{1}{\beta}\log\int_z e^{-\beta E(x,y,z)}$$
    
<!--2. Unconditional models that have scalar-valued energy function, $F(y)$ that measures the compatibility between the components of $y$-->
&#x202b; ۲. مدل‌های غیر شرطی که تابع انرژی با مقدار اسکالر دارند، F(y) که تطابق بین بخش‌های y را اندازه‌گیری می‌کند.

    1. $$F(y) = \text{min}_{z} E(y,z)$$
    2. $$F_\beta(y) = -\frac{1}{\beta}\log\int_z e^{-\beta E(y,z)}$$

<center>
<img src="{{site.baseurl}}/images/week07/07-2/3_lv_ebm.png" width="50%"/><br>
<!--<b>Fig. 3</b>: Latent Variable EBM-->
&#x202b; <b>شکل. ۳</b>: متغیر پنهان EBM
</center>


<!--## Latent variable EBM example: $K$-means-->
## &#x202b; مثال EBM متغیر پنهان: K-means 

<!--K-means is a simple clustering algorithm that can also be considered as an energy-based model where we are trying to model the distribution over $y$. The energy function is $E(y,z) = \Vert y-Wz \Vert^2$ where $z$ is a $1$-hot vector.-->
&#x202b; K-means یک الگوریتم خوشه‌بندی ساده است که می‌توان آن را به صورت یک مدل مبتنی بر انرژی در جایی که ما در تلاشیم تا توزیع را بر روی y مدل کنیم نیز، در نظر گرفت. تابع انرژی E(y,z) است.= \Vert y-Wz \Vert^2$ در جایی که $z$ یک $1$-hot vector است.
<center>
<img src="{{site.baseurl}}/images/week07/07-2/4_kmeans.png" width="50%"/><br>
<!--<b>Fig. 4</b>: K-means example-->
<b> شکل. ۴</b> : مثال K-means
</center>

<!--Given a value of $y$ and $k$, we can do inference by figuring out which of the $k$ possible columns of $W$ minimizes the reconstruction error or energy function. To train the algorithm, we can adopt an approach where we can find $z$ to choose the column of $W$ closest to $y$ and then try to get even closer by taking a gradient step and repeat the process. However, coordinate gradient descent actually works better and faster.-->
&#x202b; با داشتن مقادیر $y$ و $k$، می‌توانیم از طریق فهمیدن اینکه کدام یک از ستون‌‌های ممکن $k$ از $w$، خطای بازسازی یا تابع انرژی را کمینه می‌کنند، استنباط انجام دهیم. برای آموزش الگوریتم، می‌توانیم روشی را به کار گیریم که در آن $z$  را برای اننتخاب نزدیک‌ترین ستون $W$ به $y$ و سپس تلاش برای نزدیک تر شدن با استفاده از گرادیان گرفتن و تکرار روند، بهره گیریم. به هرحال استفاده از گرادیان نزولی قطعا باعث سرعت و نتایج بهتر گرفتن می‌شود.
<!--In the plot below we can see the data points along the pink spiral. The black blobs surrounding this line corresponds to quadratic wells around each of the prototypes of $W$.-->
&#x202b; در تصویر زیر، می‌توانیم نقاط داده را در طول مارپیچ صورتی ببینیم. حباب‌های مشکی اطراف این خط مربوط به چا‌ه‌های درجه‌دوم در اطراف هریک از نمونه‌های اولیه W هستند.

<center>
<img src="{{site.baseurl}}/images/week07/07-2/5_spiral.png" width="50%"/><br>
<!--<b>Fig. 5</b>: Spiral plot-->
<b> شکل. ۵</b>: پلات مارپیچ

</center>

<!--Once we learn the energy function, we can begin to address questions like:-->
&#x202b; وقتی که تابع انرژی را یاد گرفتیم، می‌توانیم به سوال‌هایی مانند زیر پاسخ دهیم:

<!--1. Given a point $y_1$, can we predict $y_2$?-->
&#x202b; ۱. 	با داشتن یک نقطه‌ی y1 می‌توانیم y2 را پیش‌بینی کنیم؟
<!--2. Given $y$, can we find the closest point on the data manifold?-->
&#x202b; ۲. 	با داشتن y، آیا می‌توانیم نزدیک‌ترین تقطه بر روی گوناگونی داده را بیابیم؟


<!--K-means belongs to architectural methods (as opposed to contrastive methods). Hence we do not push up the energy anywhere, all we do is push the energy down in certain regions. One disadvantage is that once the value of $k$ has been decided, there can only be $k$ points that have $0$ energy, and every other point will have higher energy that grows quadratically as we move away from them.-->
&#x202b; K-means به روش‌های معماری مربوط است (بر خلاف روش‌های انقباضی). از این رو، ما همه‌جا انرژی را بالا نمی‌بریم، تنها کاری که می‌کنیم به عقب راندن انرژی در نواحی مشخص است. یکی از معایب آن این است که وقتی یک بار مقدار k تعیین شد، تنها k نقطه با انرژی ۰ می‌تواند داشته باشد و هر نقطه‌ی دیگری انرژی بالاتری که با هرچه دورتر شدن ما از‌ آن‌ها به صورت درجه‌ی دو رشد می‌کنند، خواهد داشت.

<!--## Contrastive methods-->
##روش‌های انقباضی

<!--According to Dr Yann LeCun, everyone will be using architectural methods at some point, but at this moment, it is contrastive methods that work for images. Consider the figure below which shows us some data points and contours of the energy surface. Ideally, we want the energy surface to have the lowest energy on the data manifold. Hence what we would like to do is lower the energy (*i.e.* the value of $F(x,y)$) around the training example, but this alone may not be enough. Hence we also raise it for the $y$'s in the region that should have high energy but has low energy.-->
&#x202b; با توجه به صحبت‌های دکتر Yann LeCun، همه مجبور به استفاده از روش‌های معماری در برخی موارد خواهند شد، اما در این لحظه، روش‌های انقباضی برای تصاویر پاسخگو هستند. تصویر بالا را که برخی از نقاط داده و خطوطی از سطح انرژی به ما را نشان می‌دهد، را در نظر بگیرید. به صورت ایده‌آل، توقع داریم که سطح انرژی کمترین انرژی بر روی گوناگونی داده را داشته باشد. از این رو، تمایل داریم تا انرژی را حول و حوش نمونه‌ی آموزش، کم کنیم ( برای مثال مقدار F(x, y)) اما این به تنهایی ممکن است کافی نباشد. بنابراین همچنین مقدار آن را برای y’ در نواحی که باید انرژی بالایی داشته باشند اما انرژی کمی دارند، بالا می‌بریم.

<center>
<img src="{{site.baseurl}}/images/week07/07-2/6_contrastive_1.png" width="50%"/><br>
<!--<b>Fig. 6</b>: Contrastive methods-->
<b>شکل. ۶</b>: روش‌های انقباضی

</center>

<!--There are several ways to find these candidates $y$'s that we want to raise energy for. Some examples are:-->
&#x202b; راه‌های متعددی برای پیدا کردن این کاندیداهای $y$’ که انرژی را برای آن‌ها می‌خواهیم افزایش دهیم وجود دارد. برای مثال:
<!--1. Denoising Autoencoder-->
&#x202b; ۱. 	Denoising Autoencoder
<!--2. Contrastive Divergence-->
&#x202b; ۲.	واگرایی انقباضی
<!--3. Monte Carlo-->
&#x202b; ۳. مونت کارلو
<!--4. Markov Chain Monte Carlo-->
&#x202b; ۴.	مونت کارلوی زنجیره‌ی مارکوف
<!--5. Hamiltonian Monte Carlo-->
&#x202b; ۵. مونت کارلوی همیلتونی

<!--We will briefly discuss denoising autoencoders and contrastive divergence.-->
&#x202b; به صورت مختصر دو مورد اول را توضیح می‌دهیم.


### Denoising autoencoder (DAE)

<!--One way of finding $y$'s to increase energy for it is by randomly perturbing the training example as shown by the green arrows in the plot below.-->
&#x202b; یکی از راه‌های پیدا کردن $y$ ها برای افزایش انرژی برای آن‌ها، اختلال تصادفی در نمونه‌های آموزش آن‌ها ایجاد کردن، همانند آنچه توسط فلش‌های سبز در تصویر زیر نمایش داده شده است، می‌باشد.
<center>
<img src="{{site.baseurl}}/images/week07/07-2/7_contrastive_2.png" width="50%"/><br>
<!--<b>Fig. 7</b>: Topographic map-->
<b>شکل. ۷</b>: نقشه‌ی توپوگرافی
</center>

<!--Once we have a corrupted data point, we can push the energy up here. If we do this sufficiently many times for all the data points, the energy sample will curl up around the training examples. The following plot illustrates how training is done.-->
&#x202b; وقتی که یک نقطه داده خراب شده داشتیم، می‌توانیم در اینجا انرژی را بالا ببریم. اگر این‌کار را چند بار برای دیتاهای مختلف انجام دهیم، نمونه‌ی انرژی در اطراف نمونه‌ی آموزش دیده حلقه می‌زند. تصویر زیر نشان‌دهنده نحوه‌ی آموزش آن است.
<center>
<img src="{{site.baseurl}}/images/week07/07-2/8_training.png" width="50%"/><br>
<!--<b>Fig. 8</b>: Training-->
<b> شکل. ۸</b>: آموزش
</center>

<!--Steps for training:-->
&#x202b; گام‌های آموزش
<!--1. Take a point $y$ and corrupt it-->
&#x202b;۱.  یک نقطه از y را انتخاب و آن را مخدوش کنید
<!--2. Train the Encoder and Decoder to reconstruct the original data point from this corrupted data point-->
&#x202b; ۲. انکودر و دیکورد را برای بازسازی نقاط داده اصلی از داده‌ی مخدوش شده، آموزش دهید.

<!--If the DAE is properly trained, the energy grows quadratically as we move away from the data manifold.-->
&#x202b; اگر DAE به صورت کلی آموزش دید، انرژی به صورت درجه‌ی دو وقتی که از گوناگونی داده دور می‌شویم، افزایش می‌یابد. 
<!--The following plot illustrates how we use the DAE.-->
&#x202b; تصویر زیر نشان می‌دهد چگونه از DAE استفاده می‌کنیم.
<center>
<img src="{{site.baseurl}}/images/week07/07-2/9_dae_use.png" width="50%"/><br>
<!--<b>Fig. 9</b>: How DAE is used-->
<b> ؤکل. ۹</b>: DAE چگونه استفاده می‌شود
</center>


### BERT

<!--BERT is trained similarly, except that the space is discrete as we are dealing with text. The corruption technique consists of masking some of the words and the reconstruction step consists of trying to predict these. Hence, this is also called a masked autoencoder.-->
&#x202b; BERT به طرز مشابهی آموزش می‌بیند، به جز اینکه چون با متن سر و کار داریم، فضای ما گسسته است. تکنیک اختلال شامل پوشش برخی از کلمات و گام‌های بازسازی شما تلاش برای پیش‌بینی آن‌ها می‌شود. بنابراین، به این اتوانکودر، اتوانکدور نقاب‌دار نیز گفته می‌شود.

<!--### Contrastive divergence-->
### واگرایی انقباضی

<!--Contrastive Divergence presents us with a smarter way to find the $y$ point that we want to push up the energy for. We can give a random kick to our training point and then move down the energy function using gradient descent. At the end of the trajectory, we push up the energy for the point we land on. This is illustrated in the plot below using the green line.-->
&#x202b; واگرایی انقباضی راه هوشمندانه تری برای یافتن نقاط $y$ که می‌خواهیم سطوح انرژی آن‌ها را بالا ببریم به ما ارائه می‌کند. می‌توانیم یک ضربه‌ی تصادفی به نمونه‌ی آموزش بزنیم و سپس با استفاده از گرادیان نزلی، تابع انرژی را کاهش دهیم. در انتهای این مسیر، انرژی را در نقاطی که بر آن‌ها حضور داریم بالا می‌بریم. این مسئله در تصویر زیر با استفاده از خط سبز نشان داده شده است.
<center>
<img src="{{site.baseurl}}/images/week07/07-2/10_contrastive_div.png" width="50%"/><br>
<!--<b>Fig. 10</b>: Contrastive Divergence-->
<b>شکل. ۱۰</b>: واگرایی انقباضی
</center>
