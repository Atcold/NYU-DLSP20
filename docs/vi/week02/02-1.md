---
lang-ref: ch.02-1
lecturer: Yann LeCun
title: Giới thiệu Giảm dần độ dốc (Gradient Descent) và Thuật toán lan truyền ngược (Backpropagation Algorithm)
authors: Amartya Prasad, Dongning Fang, Yuxin Tang, Sahana Upadhya
date: 3 Feb 2020
translator: Huynh Nguyen
lang: vi
translator-date: 15 Apr 2020
---

## [Thuật toán tối ưu hóa Gradient Descent](https://www.youtube.com/watch?v=d9vdh3b787Y&t=29s)

### Các mô hình tham số

$$
\bar{y} = G(x,w)
$$

Các mô hình tham số chỉ đơn giản là các hàm phụ thuộc vào các đầu vào và các tham số có thể đào tạo được. Không có sự khác biệt giữa hai mẫu, ngoại trừ việc các thông số có thể đào tạo được chia sẻ trên các mẫu đào tạo trong khi đầu vào thay đổi theo từng mẫu. Trong hầu hết các khuôn khổ học sâu, các tham số là ẩn, nghĩa là chúng không được chuyển đổi khai hàm được gọi ra. Nói cách khác chúng được lưu bên trong hàm, ít nhất là một trong các phiên bản hướng đối tượng của các mô hình.
Mô hình tham số (hàm) nhận một đầu vào, có một véc-tơ tham số và tạo ra một đầu ra. Trong học giám sát, đầu ra này đi vào hàm chi phí (cost function)($C(y,\bar{y}$)) so sánh đầu ra thực (${y}$) với đầu ra của mô hình ($\bar{y}$). Đồ thị tính toán mô hình này được thế hiện trong hình 01.

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure1.jpg" alt="Figure1" style="zoom: 33%;" /></center> |
| <center>Hình 1: Biểu diễn đồ thị tính toán của mô hình tham số </center>|

Ví dụ của các hàm tham số:

Mô hình hồi quy tuyến tính - Tổng trọng số thành phần  của các véc-tơ đầu vào:

$$
\bar{y} = \sum_i w_i x_i, C(y,\bar{y}) = \Vert y - \bar{y}\Vert^2
$$

Hàng xóm láng giềng (Nearest Neighbour) - Có một đầu vào $\vect{x}$ và một ma trận trọng số $\matr{W}$ với mỗi hàng của ma trận được lập chỉ mục bởi $k$. Đầu ra là giá trị của $k$ tương chứng với hàng $\matr{W}$ gần nhất với $\vect{x}$.

$$
\bar{y} = \underset{k}{\arg\min} \Vert x - w_{k,.} \Vert^2
$$

Các mô hình tham số cũng có liên quan đến các hàm phức tạp.

#### Ký hiệu sơ đồ khối cho đồ thị tính toán

- Các biến (tensor, scala, continuous, discrete)
  - <img src="{{site.baseurl}}/images/week02/02-1/x.PNG" alt="x" style="zoom:50%;" /> là một đầu vào được quan sát cho hệ thống.
  - <img src="{{site.baseurl}}/images/week02/02-1/y.PNG" alt="y" style="zoom:50%;" /> là một biến tính toán được tạo ra bởi một hàm xác định.

- Hàm xác định

<img src="{{site.baseurl}}/images/week02/02-1/deterministic_function.PNG" alt="deterministic_function" style="zoom:50%;" />

  - Dùng để biểu diễn các hàm chi phí.
  - Nó có một biến tham số (${w}$).
  - Mặt tròn cho biết hướng dễ tính toán. Trong sơ đồ trên, việc tính ${\bar{y}}$ từ ${x}$ dễ dàng hơn so với cách khác.

- Hàm có giá trị vô hướng - Scala

<img src="{{site.baseurl}}/images/week02/02-1/scalar-valued.PNG" alt="scalar-valued" style="zoom:50%;" />

  - Dùng để biểu diễn các hàm chi phí.
  - Có đầu ra vô hướng.
  - Sử dụng nhiều đầu vào và đầu ra một giá trị duy nhất (thường là khoảng các giữa các đầu vào).

#### Hàm mất mát

Hàm mất mát là một hàm được giảm thiểu trong quá trình đào tạo. Có hai loại mất mát:

1) Mất mát mỗi mẫu

$$
 L(x,y,w) = C(y, G(x,w))
$$

2) Mất mát trung bình

Đối với bất kỳ bộ mẫu nào:

$$S = \lbrace(x[p],y[p]) \mid p \in \lbrace 0, \cdots, P-1 \rbrace \rbrace$$

Khoản mất mát trung bình trên bộ $S$ được chia ra bởi:

$$L(S,w) = \frac{1}{P} \sum_{(x,y)} L(x,y,w)$$

| <center><img src="{{site.baseurl}}/images/week02/02-1/Average_Loss.png" alt="Average_Loss" style="zoom:33%;" /></center> |
| <center>Hình 2: Đồ thị tính toán cho mô hình có mất mát trung bình</center>|

Trong các mô hình học giám sát tiêu chuẩn, mất mát (trên mỗi mẫu) chỉ đơn giản là đầu ra của hàm chi phí. Máy học chủ yếu là tối ưu hóa các hàm (thường là giảm thiểu chúng). Nó cũng có thể liên quan đến việc tìm Nash Equilibria giữa hai hàm như với GAN. Điều này được thực hiện bằng cách sử dụng các phương pháp dựa trên độ dốc, mặc dù không nhất thiết phải là giảm dần độc dốc.

### Độ dốc

**Phương pháp dựa trên độ dốc** là một phương pháp/ thuật toán tìm cực tiểu của một hàm, giả sử rằng người ta dễ dàng tính toán độ dốc của một hàm. Nó được giả định rằng hàm là liên tục và có thể phân biệt hầu hết ở mọi nơi (nó không phải khác biệt ở mọi nơi).

**Trực giác giảm dần độ dốc** - Hãy tưởng tượng bạn đang ở trên núi vào giữa đêm đầy sương mù. Bạn phải đi xuống ngôi làng gần đó nhất với tầm nhìn hạn chế, bạn nhìn xung quanh vùng lân cận của mình để tìm hướng đi xuống dốc nhất và thực hiện một bước theo hướng đó.

**Các phương pháp khác nhau của giảm dần độc dốc**
- Quy tắc cập nhật độ dốc đầy đủ (the full batch)

 $$
 w \leftarrow w - \eta \frac{\partial L(S,w)}{\partial w}
 $$
  
- Đối với SGD (Stochastic Gradient Descent), quy tắc cập nhật trở thành:

Chọn $p \in \lbrace 0, \cdots, P-1 \rbrace$, sau đó cập nhật

$$
w \leftarrow w - \eta \frac{\partial L(x[p], y[p],w)}{\partial w}
$$

Trong đó:

${w}$ đại diện cho thông số cần tối ưu hóa.
$\eta$ ở đây là một hằng số, nhưng trong các thuật toán phức tạp hơn, nó có thể là một ma trận.

Nếu đó là một ma trận bán xác định dương, chúng ta sẽ vẫn di chuyển xuống dốc nhưng không nhất thiết phải đi theo hướng dốc xuống nhất. Trên thực tế, hướng dốc xuống nhất có thể không phải lúc nào cũng là hướng chúng ta muốn di chuyển.

Nếu một hàm không thể phân biệt được, tức là nó có một lỗ (hole) hoặc một cầu thang giống như hoặc bằng phẳng, trong đó độ dốc không cung cấp cho bạn bất kỳ thông tin nào, người ta phải sử dụng các phương pháp khác - được gọi là Phương thức thứ tự 0 hoặc Phương thức không có độ dốc. Học sâu là tất cả phương pháp dự trên độ dốc.

Tuy nhiên, Học tăng cường (RL - Reinforcement Learning) liên quan đến **ước tính độ dốc** mà không có dạng rõ ràng cho độ dốc. Một ví dụ là một Robot học cách đi xe đạp, thỉnh thoảng Robot bị ngã. Hàm mục tiêu đo thời gian chiếc xe đạp đứng vững mà không bị ngã. Thật không may, không có độ dốc cho hàm mục tiêu. Robot cần thử những cái khác nhau.

Hầu hết thời gian, hàm chi phí của RL không thể phân biệt được nhưng mang tính toán đầu ra dựa trên độ dốc. Đây là sự khác biệt chính giữa học giám sát và học tăng cường. Với cái sau, hàm chi phí $C$ không thể phân biệt được. Trong thực tế nó hoàn toàn không biết. Nó chỉ trả về một đầu ra khi các đầu vào được cung cấp cho nó, giống như một hộp đen (blackbox). Điều này làm cho nó không hiệu quả cao và là một trong những nhược điểm của RL - đặc biệt là khi véc-tơ tham số có chiều cao (nghĩa là một không gian giải pháp khổng lồ để tìm kiếm, khiến cho nó khó tìm thấy nơi để di chuyển).

Một kỹ thuật rất phổ biến trong RL là phương pháp Actor Critic. Phương pháp Actor Critic về cơ bản bao gồm một mô-đun C được biết trước, có thể đào tạo được. Người ta có thể đào tạo mô-đun C, có thể phân biệt được để gần đúng với hàm chi phí/ hàm reward. Reward là một chi phí tiêu cực, giống như một hình phạt hơn. Đó là một cách để cho hàm chi phí có thể phân biệt được hoặc ít nhất là xấp xỉ nó bằng bằng một hàm có thể phân biệt để người ta nhân rộng.

## [Ưu điểm của giảm dần độ dốc ngẫu nhiên (SGD) và Lan truyền ngược (Backpropagation) với mạng lưới thần kinh truyền thống](https://www.youtube.com/watch?v=d9vdh3b787Y&t=1036s)

### Ưu điểm của SGD

Trong thực tế, tôi chỉ sử dụng giảm dần độ dốc ngẫu nhiên (stochastic gradient descent) để tính toán độ dốc của hàm mục tiêu với các tham số. Thay vì tính toán độ đốc đầy đủ (the full gradient) của hàm mục tiêu, là giá trị trung bình của tất cả các mẫu, Stochastic gradient (SD) chỉ lấy một mẫu, tính toán tổn thất, $L$ và tổn thất độ dốc với các tham số w.r.t, sau đó thực hiện một bước hướng độ dốc âm (the negative gradient direction).

$$
w \leftarrow w - \eta \frac{\partial L(x[p], y[p],w)}{\partial w}
$$

Trong công thức trên, $w$ được tiếp cận bằng $w$ trừ đi kích thước bước (step - size), nhân với độ dốc của hàm mất mát trên mỗi mẫu với các tham số cho một mẫu nhất định ($x[p]$,$y[p]$).

Nếu chúng ta làm điều này trên một mẫu duy nhất, chúng ta sẽ nhận được một quỹ đạo rất lộn xộn như trong Hình 3. Thay vì mất mát (loss) sẽ trực tiếp xuống dốc, đó được gọi là ngẫu nhiên. Mỗi mẫu sẽ kéo loss theo một hướng khác nhau. Nó chỉ là mức trung bình kéo chúng ta đến mức tối thiểu của mức trung bình. Mặc dù nó trong không hiệu quả, nhưng nó quá nhanh hơn nhiều so với giảm độ dốc toàn bộ theo batch, ít nhất là trong bối cảnh máy học khi các mẫu có một số dư thừa.

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure2.png" alt="Figure2" style="zoom:80%;" /></center> |
| <center>Hình 3: Quỹ đạo SGD cho mỗi bản cập nhật mẫu </center>|

Trong thực tế, chúng tôi sử dụng các batch thay vì thực hiện SG trên một mẫu duy nhất. Chúng tôi tính giá trị trung bình của độ dốc qua một loạt mẫu, không phải một mẫu đơn lẻ, rồi thực hiện một bước. Lý do duy nhất để làm điều này là chúng ta có thể sử dụng hiệu quả hơn phần cứng (ví dụ như GPU, đa GPU), chúng ta sử dụng theo batch vì dễ dàng ghép song song hơn. Batch là cách đơn giả nhất để ghép song song.

### Mạng nơ-ron truyền thống

Mạng nơ-ron truyền thống về cơ bản là các lớp xen kẽ của các hoạt động tuyến tính và các hoạt động phi tuyến tính theo point-wise. Đối với các phép toán tuyến tính, về mặt khái niệm nó chỉ là một phép nhân véc-tơ ma trận. Chúng tôi lấy véc-tơ đầu vào nhân với một ma trận được tạo thành bởi các trọng số. Loại hoạt động thứ 02 là lấy tất cả các thành phần của các véc-tơ tổng có trọng số và chuyển nó sang một số phi tuyến tính đơn giản (ví dụ như: $\texttt{ReLU}(\cdot)$, $\tanh(\cdot)$, …).

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure3.png" alt="Figure3" style="zoom:30%;" /></center> |
| <center>Hình 4: Mạng nơ-ron truyền thống</center>|

Hình 4 là một ví dụ về mạng 02 lớp, bởi vì điều quan trọng là các cặp (tuyến tính + phi tuyến tính). Một số người gọi nó là mạng 03 lớp vì họ đếm các biến. Lưu ý rằng nếu không có bất kỳ tuyến tính nào ở giữa, chúng ta cũng có thể có một lớp duy nhất vì tích của hai hàm tuyến tính là một hàm tuyến tính.

Hình 5 cho thấy cách các khối hàm tuyến tính và phi tuyến tính của ngăn xếp mạng:

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure4.png" alt="Figure4" style="zoom:30%;" /></center> |
|  <center>Hình 5: Nhìn vào bên trong các khối tuyến tính và phi tuyến tính</center>|

Trong hình trên, $s[i]$ là tổng trọng số của đơn vị ${i}$ được tính như sau:

$$
s[i]=\sum_{j \in UP(i)}w[i,j]\cdot z[j]
$$

Trong đó $UP(i)$ được biểu thị các tiền thân của $i$ và $z[j]$ là đầu ra thứ $j$ từ lớp trước đó

Đầu ra $z[i]$ được tính như sau:

$$
z[i]=f(s[i])
$$

Trong đó $f$ là một hàm phi tuyến tính.

### Lan truyền ngược thông qua một hàm phi tuyến tính

Cách đầu tiên để thực hiện lan truyền ngược là sao chép ngược thông qua một hàm phi tuyến tính. Chúng tôi lấy một hàm phi tuyến tính cụ thể $h$ từ mạng và để mọi thứ khác trong hộp đen (blackbox).

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure5.png" alt="Figure5" style="zoom: 25%;" /></center> |
|    <center>Hình 6: Lan truyền ngược thông qua hàm phi tuyến tính</center>|

Chúng tôi sẽ sử dụng quy tắc chuỗi để tính toán độ dốc:

$$
g(h(s))' = g'(h(s))\cdot h'(s)
$$

Trong đó $h'(s)$ là đạo hàm của $z$ w.r.t $s$ được biểu diễn bởi $\frac{\mathrm{d}z}{\mathrm{d}s}$.
Để làm rõ ràng mối liên hệ giữa các dẫn xuất, chúng tôi viết lại công thức ở trên thành:

$$
\frac{\mathrm{d}C}{\mathrm{d}s} = \frac{\mathrm{d}C}{\mathrm{d}z}\cdot \frac{\mathrm{d}z}{\mathrm{d}s} = \frac{\mathrm{d}C}{\mathrm{d}z}\cdot h'(s)
$$

Do đó, nếu chúng ta có một chuỗi các hàm đó trong mạng, chúng ta có thể nhân đôi bằng cách nhân với các đạo hàm của tất cả các hàm ${h}$ lần lượt cho đến hết.

Sẽ trực quan hơn khi nghĩ về nó dưới góc độ nhiễu loạn. Thúc đẩy $s$ bằng $\mathrm{d}s$ sẽ làm xáo trộn $z$ bằng cách:

$$\mathrm{d}z = \mathrm{d}s \cdot h'(s)$$

Điều này đến lượt nó sẽ làm nhiễu loạn $C$ bằng cách:

$$
\mathrm{d}C = \mathrm{d}z\cdot\frac{\mathrm{d}C}{\mathrm{d}z} = \mathrm{d}s\cdot h’(s)\cdot\frac{\mathrm{d}C}{\mathrm{d}z}
$$

Một lần nữa, chúng tôi kết thúc với cùng một công thức như hiển thị ở trên.

### Lan truyền ngược thông qua một tổng có trọng số

Đối với một mô-đun tuyến tính, chúng tôi thực hiện lan truyền ngược thông qua một tổng trọng số. Ở đây, chúng tôi xem toàn bộ mạng như một hộp đen ngoại trừ 3 kết nối đi từ biến ${z}$ đến một loạt các biến $s$.

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure6.png" alt="Figure6" style="zoom: 25%;" /></center> |
|        <center>Hình 7: Lan truyền ngược thông qua tổng trọng số</center>|

Lần này nhiễu loạn là một tổng trọng số. $Z$ ảnh hưởng đến một số biến. Thúc đẩy $z$ bằng $\mathrm{d}z$ sẽ làm xáo trộn $s[0]$, $s[1]$ và $s[2]$ bằng cách:

$$ \mathrm{d}s[0]=w[0]\cdot \mathrm{d}z $$

$$ \mathrm{d}s[1]=w[1]\cdot \mathrm{d}z $$

$$ \mathrm{d}s[2]=w[2]\cdot\mathrm{d}z $$

Điều này sẽ làm xáo trộn $C$ bằng cách:

$$ \mathrm{d}C = \mathrm{d}s[0]\cdot \frac{\mathrm{d}C}{\mathrm{d}s[0]}+\mathrm{d}s[1]\cdot \frac{\mathrm{d}C}{\mathrm{d}s[1]}+\mathrm{d}s[2]\cdot\frac{\mathrm{d}C}{\mathrm{d}s[2]} $$

Do đó, $C$ sẽ thay đổi theo tổng của 3 biến thể:

$$ \frac{\mathrm{d}C}{\mathrm{d}z} = \frac{\mathrm{d}C}{\mathrm{d}s[0]}\cdot w[0]+\frac{\mathrm{d}C}{\mathrm{d}s[1]}\cdot w[1]+\frac{\mathrm{d}C}{\mathrm{d}s[2]}\cdot w[2] $$

## [Triển khai PyTorch của mạng nơ-ron và một thuật toán backprop tổng quát](https://www.youtube.com/watch?v=d9vdh3b787Y&t=2288s)

### Sơ đồ khối của mạng nơ-ron truyền thống

- Khối tuyến tính $s_{k+1}=w_kz_k$
- Khối phi tuyến tính $z_k=h(s_k)$

<center><img src="{{site.baseurl}}/images/week02/02-1/Figure 7.png" alt="Figure 7" style="zoom: 33%;" /></center>

$w_k$: ma trận $z_k$: vector $h$: ứng dụng của hàm vô hướng ${h}$ cho mọi thành phần. Đây là mạng nơ-ron 3 lớp với các cặp hàm tuyến tính và phi tuyến tính, mặc dù hầu hết các mạng nơ-ron hiện đại không có sự phân tách tuyến tính và phi tuyến tính rõ ràng như vậy và phức tạp hơn.

### Triển khai PyTorch

```python
import torch
from torch import nn
image = torch.randn(3, 10, 20)
d0 = image.nelement()

class mynet(nn.Module):
    def __init__(self, d0, d1, d2, d3):
        super().__init__()
        self.m0 = nn.Linear(d0, d1)
        self.m1 = nn.Linear(d1, d2)
        self.m2 = nn.Linear(d2, d3)

    def forward(self,x):
        z0 = x.view(-1)  # flatten input tensor
        s1 = self.m0(z0)
        z1 = torch.relu(s1)
        s2 = self.m1(z1)
        z2 = torch.relu(s2)
        s3 = self.m2(z2)
        return s3
model = mynet(d0, 60, 40, 10)
out = model(image)
```

- Chúng ta có thể triển khai mạng thần kinh với các lớp hướng đối tượng trong PyTorch. Đầu tiên, chúng ta xác định một lớp cho mạng nơ-ron và khởi tạo các lớp tuyến tính trong hàm tạo bằng cách sử dụng lớp `nn.Linear` được xác định trước . Các lớp tuyến tính phải là các đối tượng riêng biệt vì mỗi lớp chứa một véc-tơ tham số. Các lớp `nn.Linear` cũng cho biết thêm các véc-tơ bias ngầm. Sau đó, chúng tôi xác định một hàm chuyển tiếp về cách tính toán kết quả đầu ra với hàm $\text{torch.relu}$ làm kích hoạt phi tuyến. Chúng ta không phải khởi tạo các hàm relu riêng biệt vì chúng không có tham số.

- Chúng ta không cần phải tự mình tính toán độ dốc vì PyTorch biết cách truyền ngược và tính toán độ dốc cho hàm `forward`.

### Backprop qua mô-đun chức năng

Bây giờ chúng tôi trình bày một hình thức lan truyền ngược tổng quát hơn.

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure9.png" alt="Figure9" style="zoom:33%;" /></center> |
|    <center>Hình 8: Lan truyền ngược thông qua một mô-đun chức năng</center>|

- Sử dụng quy tắc chuỗi cho các hàm vector
  $$
   z_g : [d_g\times 1]
  $$

  $$
   z_f:[d_f\times 1]
  $$

  $$
  \frac{\partial c}{\partial{z_f}}=\frac{\partial c}{\partial{z_g}}\frac{\partial {z_g}}{\partial{z_f}}
  $$

  $$
  [1\times d_f]= [1\times d_g]\times[d_g\times d_f]
  $$

Đây là công thức cơ bản cho $\frac{\partial c}{\partial{z_f}}$ bằng cách sử dụng quy tắc chuỗi. Lưu ý rằng độ dốc của một hàm vô hướng đối với một véc-tơ là một véc-tơ có cùng kích thước với véc-tơ mà bạn phân biệt. Để làm cho các ký hiệu nhất quán, nó là một véc-tơ hàng thay vì một véc-tơ cột.

- Ma trận Jacobian
  
  $$
  \left(\frac{\partial{z_g}}{\partial {z_f}}\right)_{ij}=\frac{(\partial {z_g})_i}{(\partial {z_f})_j}
  $$
  
Chúng ta cần $\frac{\partial {z_g}}{\partial {z_f}}$ (các mục nhập ma trận Jacobian) để tính toán gradient của hàm cost đối với $z_f$ cho gradient của hàm cost đối với $z_g$. Mỗi mục nhập $ij$ bằng đạo hàm riêng của thành phần thứ $i$ của vectơ đầu ra đối với thành phần thứ $j$ của vectơ đầu vào.

Nếu chúng ta có một loạt các mô-đun, chúng tôi tiếp tục nhân ma trận Jacobian của tất cả các mô-đun xuống và chúng tôi nhận được độ dốc w.r.t của tất cả các biến bên trong.

### Backprop thông qua một đồ thị nhiều giai đoạn

Hãy xem xét một khối nhiều mô-đun trong một mạng nơ-ron như trong Hình 9.
  
  | <center><img src="{{site.baseurl}}/images/week02/02-1/Figure10.png" alt="Figure10" style="zoom:33%;" /></center> |
|         <center>Hình 9: Backprop thông qua đồ thị nhiều giai đoạn</center>|

Đối với thuật toán backprop, chúng ta cần hai bộ độ dốc - một bộ liên quan đến các trạng thái (mỗi mô-đun của mạng) và một bộ liên quan đến trọng số (tất cả các tham số trong một mô-đun cụ thể). Vì vậy, chúng tôi có hai ma trận Jacobian được liên kết với mỗi mô-đun. Một lần nữa chúng ta có thể sử dụng quy tắc chuỗi cho backprop.

- Sử dụng quy tắc chuỗi cho các hàm véc-tơ

$$
  \frac{\partial c}{\partial {z_k}}=\frac{\partial c}{\partial {z_{k+1}}}\frac{\partial {z_{k+1}}}{\partial {z_k}}=\frac{\partial c}{\partial {z_{k+1}}}\frac{\partial f_k(z_k,w_k)}{\partial {z_k}}
  $$

  $$
  \frac{\partial c}{\partial {w_k}}=\frac{\partial c}{\partial {z_{k+1}}}\frac{\partial {z_{k+1}}}{\partial {w_k}}=\frac{\partial c}{\partial {z_{k+1}}}\frac{\partial f_k(z_k,w_k)}{\partial {w_k}}
  $$
  
- Hai ma trận Jacobian cho mô-đun

  - Một đối với $z[k]$
  - Một đối với $w[k]$

