---
lang-ref: ch.02-1
lecturer: Yann LeCun
title: Giới thiệu Gradient Descent và Backpropagation Algorithm
authors: Amartya Prasad, Dongning Fang, Yuxin Tang, Sahana Upadhya
date: 3 Feb 2020
translator: Huynh Nguyen
lang: vi
translator-date: 15 Apr 2020
---

## [Thuật toán tối ưu hóa Gradient Descent](https://www.youtube.com/watch?v=d9vdh3b787Y&t=29s)

### Các mô hình tham số

$$
\bar{y} = G(x,w)
$$

Các mô hình tham số chỉ đơn giản là các hàm phụ thuộc vào các đầu vào và các tham số có thể đào tạo được. Không có sự khác biệt giữa hai mẫu, ngoại trừ việc các thông số có thể đào tạo được chia sẻ trên các mẫu đào tạo trong khi đầu vào thay đổi theo từng mẫu. Trong hầu hết các khuôn khổ học sâu, các tham số là ẩn, nghĩa là chúng không được chuyển đổi khai hàm được gọi ra. Nói cách khác chúng được lưu bên trong hàm, ít nhất là một trong các phiên bản hướng đối tượng của các mô hình.
Mô hình tham số (hàm) nhận một đầu vào, có một véc-tơ tham số và tạo ra một đầu ra. Trong học giám sát, đầu ra này đi vào hàm chi phí (cost function)($C(y,\bar{y}$)) so sánh đầu ra thực (${y}$) với đầu ra của mô hình ($\bar{y}$). Đồ thị tính toán mô hình này được thế hiện trong hình 01.

| <center><img src="{{site.baseurl}}/images/week02/02-1/Figure1.jpg" alt="Figure1" style="zoom: 33%;" /></center> |
| <center>Hình 1: Biểu diễn đồ thị tính toán của mô hình tham số </center>|

Ví dụ của các hàm tham số:

Mô hình hồi quy tuyến tính - Tổng trọng số thành phần  của các véc-tơ đầu vào:

$$
\bar{y} = \sum_i w_i x_i, C(y,\bar{y}) = \Vert y - \bar{y}\Vert^2
$$

Hàng xóm láng giềng (Nearest Neighbour) - Có một đầu vào $\vect{x}$ va một ma trận trọng số $\matr{W}$ với mỗi hàng của ma trận được lập chỉ mục bởi $k$. Đầu ra là giá trị của $k$ tương chứng với hàng $\matr{W}$ gần nhất với $\vect{x}$.

$$
\bar{y} = \underset{k}{\arg\min} \Vert x - w_{k,.} \Vert^2
$$

Các mô hình tham số cũng có liên quan đến các hàm phức tạp.

#### Ký hiệu sơ đồ khối cho đồ thị tính toán

- Các biến (tensor, scala, continuous, discrete)
  - <img src="{{site.baseurl}}/images/week02/02-1/x.PNG" alt="x" style="zoom:50%;" /> là một đầu vào được quan sát cho hệ thống.
  - <img src="{{site.baseurl}}/images/week02/02-1/y.PNG" alt="y" style="zoom:50%;" /> là một biến tính toán được tạo ra bởi một hàm xác định.

- Hàm xác định

<img src="{{site.baseurl}}/images/week02/02-1/deterministic_function.PNG" alt="deterministic_function" style="zoom:50%;" />

  - Dùng để biểu diễn các hàm chi phí.
  - Nó có một biến tham số (${w}$).
  - Mặt tròn cho biết hướng dễ tính toán. Trong sơ đồ trên, việc tính ${\bar{y}}$ từ ${x}$ dễ dàng hơn so với cách khác.

- Hàm có giá trị vô hướng - Scala

<img src="{{site.baseurl}}/images/week02/02-1/scalar-valued.PNG" alt="scalar-valued" style="zoom:50%;" />

  - Dùng để biểu diễn các hàm chi phí.
  - Có đầu ra vô hướng.
  - Sử dụng nhiều đầu vào và đầu ra một giá trị duy nhất (thường là khoảng các giữa các đầu vào).

#### Hàm mất mát

Hàm mất mát là một hàm được giảm thiểu trong quá trình đào tạo. Có hai loại mất mát:

1) Mất mát mỗi mẫu

$$
 L(x,y,w) = C(y, G(x,w))
$$

2) Mất mát trung bình

Đối với bất kỳ bộ mẫu nào:

$$S = \lbrace(x[p],y[p]) \mid p \in \lbrace 0, \cdots, P-1 \rbrace \rbrace$$

Khoản mất mát trung bình trên bộ $S$ được chia ra bởi:

$$L(S,w) = \frac{1}{P} \sum_{(x,y)} L(x,y,w)$$

| <center><img src="{{site.baseurl}}/images/week02/02-1/Average_Loss.png" alt="Average_Loss" style="zoom:33%;" /></center> |
| <center>Hình 2: Đồ thị tính toán cho mô hình có mất mát trung bình</center>|

Trong các mô hình học giám sát tiêu chuẩn, mất mát (trên mỗi mẫu) chỉ đơn giản là đầu ra của hàm chi phí. Máy học chủ yếu là tối ưu hóa các hàm (thường là giảm thiểu chúng). Nó cũng có thể liên quan đến việc tìm Nash Equilibria giữa hai hàm như với GAN. Điều này được thực hiện bằng cách sử dụng các phương pháp dựa trên Gradient, mặc dù không nhất thiết phải là Gradient Descent.

### Gradient

**Phương pháp dựa trên Gradient** là một phương pháp/ thuật toán tìm cực tiểu của một hàm, giả sử rằng người ta dễ dàng tính toán gradient của một hàm. Nó được giả định rằng hàm là liên tục và có thể phân biệt hầu hết ở mọi nơi (nó không phải khác biệt ở mọi nơi).

**Trực giác Gradient Descent** - Hãy tưởng tượng bạn đang ở trên núi vào giữa đêm đầy sương mù. Bạn phải đi xuống ngôi làng gần đó nhất với tầm nhìn hạn chế, bạn nhìn xung quanh vùng lân cận của mình để tìm hướng đi xuống dốc nhất và thực hiện một bước theo hướng đó.

**Các phương pháp khác nhau của Gradient Descent**
- Quy tắc cập nhật Gradient đầy đủ (batch-hàng loạt)

 $$
 w \leftarrow w - \eta \frac{\partial L(S,w)}{\partial w}
 $$
  
- Đối với SGD (Stochastic Gradient  Descent), quy tắc cập nhật trở thành:

Chọn $p \in \lbrace 0, \cdots, P-1 \rbrace$, sau đó cập nhật

$$
w \leftarrow w - \eta \frac{\partial L(x[p], y[p],w)}{\partial w}
$$

Trong đó:

${w}$ đại diện cho thông số cần tối ưu hóa.
$\eta$ ở đây là một hằng số, nhưng trong các thuật toán phức tạp hơn, nó có thể là một ma trận.

Nếu đó là một ma trận bán xác định dương, chúng ta sẽ vẫn di chuyển xuoongss dốc nhưng không nhất thiết phải đi theo hướng dốc xuống nhất. Trên thực tế, hướng xuống dốc nhất có thể không phải lúc nào cũng là hướng chúng ta muốn di chuyển.

Nếu một hàm không thể phân biệt đượ, tức là nó có một lỗ hoặc một cầu thang giống như hoặc bằng phẳng, trong đó gradient không cung cấp cho bạn bất kỳ thông tin nào, người ta phải sử dụng các phương pháp khác - được gọi là Phương thức thứ tự 0 hoặc Phương thức không có gradient. Học sâu là tất cả phương pháp dự trên gradient.

Tuy nhiên, Học tăng cường (RL - Reinforcement Learning) liên quan đến **ước tính độ dốc** mà không có dạng rõ ràng cho độ dốc. Một ví dụ là một Robot học cách đi xe đạp, thỉnh thoảng Robot bị ngã. Hàm mục tiêu đo thời gian chiếc xe đạp đứng vững mà không bị ngã. Thật không may, không có gradient cho hàm mục tiêu. Robot cần thử những cái khác nhau.

Hầu hết thời gian, hàm chi phí RL không thể phân biệt được nhưng mang tính toán đầu ra dựa trên gradient. Đây là sự khác biệt chính giữa học giám sát và học tăng cường. Với cái sau, hàm chi phí $C$ không thể phân biệt được. Trong thực tế nó hoàn toàn không biết. Nó chỉ trả về một đầu ra khi các đầu vào được cung cấp cho nó, giống như một hộp đen. Điều này làm cho nó không hiệu quả cao và là mộ trong những nhược điểm của RL - đặc biệt là khi vector tham số có chiều cao (có nghĩa là một không gian giải pháp không lồ để tìm kiếm, khiến cho nó khó tìm thấy nơi để di chuyển).

Một kỹ thuật rất phổ biến trong RL là phương pháp Actor Critic. Phương pháp Actor Critic về cơ bản bao gồm một mô-đun C được biết trước, có thể đào tạo được. Người ta có thể đào tạo mô-đun C, có thể phân biệt được để gần đúng với hàm chi phí/ hàm reward. Reward là một chi phí tiêu cực, giống như một hình phạt hơn. Đó là một cách để cho hàm chi phí có thể phân biệt được hoặc ít nhất là xấp xỉ nó bằng bằng một hàm có thể phân biệt để người ta nhân rộng.
