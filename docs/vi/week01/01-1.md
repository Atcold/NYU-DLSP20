---
lang-ref: ch.01-1
lecturer: Yann LeCun
title: Động lực của học sâu, lịch sử và cảm hứng của nó
authors: Yunya Wang, SunJoo Park, Mark Estudillo, Justin Mae
date: 27 Jan 2020
translator: Huynh Nguyen
lang: vi
translator-date: 01 Oct 2020
---


## [Nội dung](https://www.youtube.com/watch?v=0bMe_vCZo30&t=217s)

- Kiến thức cơ bản của học có giám sát (Supervised Learning), mạng thần kinh (Neural Nets) và học sâu (Deep Learning)
- Lan truyền ngược và các thành phần kiến trúc
- Mạng lưới thần kinh tích chập và các ứng dụng của nó
- Các kiến trúc học sâu
- Thủ thuật quy định hóa/ Thủ thuật tối ưu hóa/ Hiểu cách hoạt động của Học sâu
- Mô hình dưa trên năng lượng
- Học giám sát và hơn thế nữa


## Cảm hứng của học sâu và lịch sử của nó

Ở cấp độ khái niệm, học sâu được truyền từ bộ não người, nhưng không phải tất cả các chi tiết của bộ não người điều có liên quan. Để so sánh, máy bay được lấy cảm hứng từ chim. Nguyên lý bay thì giống nhau, nhưng các chi tiết thì hoàn toàn khác nhau.

Lịch sử của học sâu được quay trở lại từ một lĩnh vực đã được đổi tên là điều khiển học. Nó bắt đầu bởi McCulloch và Pitts vào những năm 1940. Họ đã đưa ra ý tưởng rằng các nơ-ron những đơn vị ngưỡng có trạng thái bật và tắt. Bạn có thể xây dựng mạch Boolean bằng cách kết nối các nơ-ron với nhau và tiến hành suy luận logic với các nơ-ron đó. Bộ não người về cơ bản là một cổ máy suy luận logic bởi vì các tế bào thần kinh là một hệ nhị phân.Các tế bào thần kinh tính toán tổng trọng số của các đầu vào so sánh tổng trọng số đó với ngưỡng của nó. Nó sẽ bật nếu nó ở trên ngưỡng và tắt nếu ở dưới ngưỡng, đó là cái nhìn đơn giảng về cách mạng lưới thần kinh hoạt động.

Năm 1947, Donald Hebb có ý tưởng rằng các tế bào thần kinh trong não hoạt động bằng cách điều chỉnh độ bền của các kết nối giữa các nơ-ron với nhau. Đây được gọi là siêu học (hyper learning, trong đó nếu hai tế bào thần kinh được kích hoạt cùng nhau, thì kết nối liên kết giữa chúng sẽ tăng lên; nếu chúng không được kích hoạt bằng nhau, thì kết nối liên kết giữa chúng sẽ giảm xuống.

Sau đó vào năm 1948, điều khiển học được Norbert Wiener đề xuất, ý tưởng rằng bằng cách có các hệ thống với cảm biến và cơ cấu chấp hành, bạn có một vòng phản hồi và một hệ thống tự điều chỉnh. Các quy luật của cơ chế phản hồi của ô tô đều xuất phát từ công việc này.

Năm 1957, Frank Rosenblatt đề xuất Perceptron, là một thuật toán học sửa đổi trọng số của các mạng nơ-ron rất đơn giản.

Nhìn chung, ý tưởng cố gắng tạo ra những cỗ máy trí tuệ bằng cách mô phỏng rất nhiều tế bào thần kinh ra đời vào những năm 1940, phát triển vào những năm 1950 và hoàn toàn chết vào cuối những năm 1960. Những lý do chính khiến lĩnh vực này chết dần vào năm 1960 là:

- Các nhà nghiên cứu đã sử dụng các tế bào thần kinh có dạng nhị phân (binary). Tuy nhiên, cách để lan truyền ngược (backpropagation) hoạt động là sử dụng các chức năng kích hoạt (activation functions) liên tục. Vào thời điểm đó, các nhà nghiên cứu không có ý tưởng sử dụng các tế bào thần kinh liên tục và họ cũng không nghĩ rằng họ có thể đào tạo với độ dốc (gradient) vì các tế bào thần kinh nhị phân không khác biệt.

- Với các tế bào thần kinh liên tục, người ta sẽ phải nhân kích hoạt của một tế bào thần kinh với một trọng số để có được một phần đóng góp vào tổng trọng số. Tuy nhiên, trước năm 1980, phép nhân hai số, đặc biệt là các số thập phân, rất chậm. Điều này dẫn đến một động cơ khác để tránh sử dụng các tế bào thần kinh liên tục.

Học dâu lại thành công trở lại vào 1985 với sự xuất hiện của việc lan truyền ngược. Năm 1995, lĩnh vực này lại chết một lần nữa và cộng đồng máy học (machine learning) từ bỏ ý tưởng về mạng lưới thần kinh. Năm 2010, mọi người bắt đầu sử dụng mạng nơ-ron trong nhận dạng giọng nói với sự cải thiện hiệu xuất rất lớn và sau đó nó được triển khai rộng rãi trong lĩnh vực thương mại. Năm 2013, thị giác máy tính bắt đầu chuyển sang mạng nơ-ron. Năm 2016, quá trình chuyển đổi tương tự cũng xảy ra trong xử lý ngôn ngữ tự nhiên. Chẳng bao lâu nữa, các cuộc cách mạng tương tự sẽ xảy ra trong lĩnh vực robot, điều khiển và nhiều lĩnh vực khác.

### Học giám sát

$90\%$ of deep learning applications use supervised learning. Supervised learning is a process by which, you collect a bunch of pairs of inputs and outputs, and the inputs are feed into a machine to learn the correct output. When the output is correct, you don't do anything. If the output is wrong, you tweak the parameter of the machine and correct the output toward the one you want. The trick here is how you figure out which direction and how much you tweak the parameter and this goes back to gradient calculation and backpropagation.

Supervised learning stems from Perceptron and Adaline. The Adaline is based on the same architecture with weighted inputs; when it is above the threshold, it turns on and below the threshold, it turns off. The Perceptron is a 2-layer neuron net where the second layer is trainable and the first layer is fixed. Most of the time, the first layer is determined randomly and that's what they call associative layers.


## [History of Pattern Recognition and introduction to Gradient Descent](https://www.youtube.com/watch?v=0bMe_vCZo30&t=1461s)

The foregoing is the conceptual basis of pattern recognition before deep learning developed. The standard model of pattern recognition consists of feature extractor and trainable classifier. Input goes into the feature extractor, extracting relevant useful characteristics of inputs such as detecting an eye when the purpose is recognizing the face. Then, the vector of features is fed to the trainable classifier for computing weighted sum and comparing it with the threshold. Here, a trainable classifier could be a perceptron or single neural network. The problem is feature extractor should be engineered by hand. Which means, pattern recognition/computer vision focus on feature extractor considering how to design it for a particular problem, not much devoted to a trainable classifier.

After the emergence and development of deep learning, the 2-stage process changed to the sequences of modules. Each module has tunable parameters and nonlinearity. Then, stack them making multiple layers. This is why it is called “deep learning”. The reason why using nonlinearity rather than linearity is that two linear layers could be one linear layer since the composition of two linear is linear.

The simplest multi-layer architecture with tunable parameters and nonlinearity could be: the input is represented as a vector such as an image or audio. This input is multiplied by the weight matrix whose coefficient is a tunable parameter. Then, every component of the result vector is passed through a nonlinear function such as ReLU. Repeating this process, it becomes a basic neural network. The reason why it is called a neural network is that this architecture calculates the weighted sum of components of input by corresponding rows of a matrix.

Back to the point of supervised learning, we are comparing the resulting output with target output then optimize the objective function which is the loss, computing a distance/penalty/divergence between the result and target. Then, average this cost function over the training set. This is the goal we want to minimize. In other words, we want to find the value of the parameters that minimize this average.

The method of how to find it is computing gradient. For example, if we are lost in a smooth mountain at foggy night and want to go to the village in the valley. One way could be turning around and seeing which way the steepest way is to go down then take a small step down. The direction is (negative) gradient. With the assumption that the valley is convex, we could reach the valley.

The more efficient way is called Stochastic Gradient Descent (SGD). Since we want to minimize average loss over the training set, we take one sample or small group of samples and calculate the error, then use gradient descent. Then, we take a new sample and get a new value for the error, then get the gradient which is a different direction normally. Two of the main reasons for using SGD are that it helps a model to converge fast empirically if the training set is very large and it enables better generalization, which means getting similar performance on various sets of data.


### [Computing gradients by backpropagation](https://www.youtube.com/watch?v=0bMe_vCZo30&t=2336s)

Computing gradients by backpropagation is a practical application of the chain rule. The backpropagation equation for the input gradients is as follows:

$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{x}_{i - 1}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial \boldsymbol{x}_i}{\partial \boldsymbol{x}_{i - 1}} \\
\frac{\partial C}{\partial \boldsymbol{x}_{i - 1}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial f_i(\boldsymbol{x}_{i - 1}, \boldsymbol{w}_i)}{\partial \boldsymbol{x}_{i - 1}}
\end{aligned}
$$

The backpropagation equation for the weight gradients is as follows:

$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{w}_{i}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial \boldsymbol{x}_i}{\partial \boldsymbol{w}_{i}} \\
\frac{\partial C}{\partial \boldsymbol{w}_{i}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial f_i(\boldsymbol{x}_{i - 1}, \boldsymbol{w}_i)}{\partial \boldsymbol{w}_{i}}
\end{aligned}
$$

Note that instead of scalar inputs, they will be vector inputs. More generally, multi-dimensional inputs. Backpropagation allows you to compute the derivative of the difference of the output you want and the output you get (which is the value of the objective function) with respect to any value inside the network. Finally, backpropagation is essential as it applies to multiple layers.

It is important to consider how to interpret inputs. For example, an image of 256$$\times$$256 would require a 200,000 valued matrix. These would be huge matrices that the neural network layers will need to handle. It would be impractical to utilize such matrices. Therefore, it is important to make hypothesis of the structure of the matrix.


## Hierarchical representation of the Visual Cortex

Experiments by Fukushima gave us an understanding of how our brain interprets the input to our eyes. In summary, it was discovered that neurons in front of our retina compress the input (known as contrast normalization) and the signal travels from our eyes to our brain. After this, the image gets processed in stages and certain neurons get activated for certain categories. Hence, the visual cortex does pattern recognition in a hierarchical manner.

Experiments in which researchers poked electrodes in specific areas of the visual cortex, specifically the V1 area made researchers realize that certain neurons react to motifs that appear in a very small area in a visual field and similarly with neighbouring neurons and neighbouring areas in the visual field. Additionally, neurons that react to the same visual field, react to different types of edges in an organized manner (*e.g.* vertical or horizontal edges). It is also important to note that there's also the idea that the visual process is essentially a feed forward process. Hence, somehow fast recognition can be done without some recurrent connections.
