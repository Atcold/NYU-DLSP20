---
lang-ref: ch.08
title: Week 8
authors: Vishwaesh Rajiv, Wenjun Qu, Xulai Jiang, Shuya Zhao
date: 23 Mar 2020
lang: ja
translation-date: 28 Nov 2020
translator: Jesmer Wong
---

<!-- ## Lecture part A -->
## レクチャーパートA

<!-- In this section, we focused on the introduction of contrastive methods in Energy-Based Models in several aspects. First, we discuss the advantage brought by applying contrastive methods in self-supervised learning. Second, we discussed the architecture of denoising autoencoders and their weakness in image reconstruction tasks. We also talked about other contrastive methods, like contrastive divergence and persistent contrastive divergence. -->

このセクションでは、いくつかの側面でのエネルギーベースモデル（EBM）のコントラスティブな方法の紹介を中心に行いました。
まずは、自己教師あり学習にコントラスティブな方法を適用するその利点について説明しました。次に、デノイジングオートエンコーダのアーキテクチャと、画像再構成タスクにおけるそれらの弱点について説明しました。また、コントラスティブダイバージェンスや持続的なコントラスティブダイバージェンスのような他のコントラスティブな方法についても説明しました。


<!-- ## Lecture part B -->
## レクチャーパートB

<!-- In this section, we discussed regularized latent variable EBMs in detail covering concepts of conditional and unconditional versions of these models. We then discussed the algorithms of ISTA, FISTA and LISTA and look at examples of sparse coding and filters learned from convolutional sparse encoders. Finally we talked about Variational Auto-Encoders and the underlying concepts involved. -->

このセクションでは、正則化された潜在変数つきのEBMについて、とくに条件付きバージョンと条件なしバージョンのモデルの概念を詳しく説明しました。次に、ISTA、FISTA、およびLISTAのアルゴリズムについて説明し、畳み込みスパースエンコーダーから学習したスパースコーディングとフィルターの例を見ていきました。最後に、変分オートエンコーダーとそれに関連する基本的な概念について説明しました。


<!-- ## Practicum -->
## 演習

<!-- In this section, we discussed a specific type of generative model called Variational Autoencoders and compared their functionalities and advantages over Classic Autoencoders. We explored the objective function of VAE in detail, understanding how it enforced some structure in the latent space. 
Finally, we implemented and trained a VAE on the MNIST dataset and used it to generate new samples. -->

このセクションでは、変分オートエンコーダー（VAE）とばれるある特定のタイプの生成モデルについて説明し、この機能と従来のオートエンコーダーに対する利点を比較しました。VAEの目的関数を詳細に理解し、どうやって潜在空間がある構造を持つように強制するのかを理解しました。最後に、MNISTデータセットでVAEを訓練し、それを使用して新しいサンプルを生成しました。

