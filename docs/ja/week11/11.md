---
lang-ref: ch.11
title: Week 11
lang: ja
translation-date: 6 Dec 2020
translator: Shiro Takagi
---

<!-- ## Lecture part A -->
## レクチャーパート A

<!-- In this section, we discussed about the common activation functions in Pytorch. In particular, we compared activations with kink(s) versus smooth activations - the former is preferred in a deep neural network as the latter might suffer with gradient vanishing problem. We then learned about the common loss functions in Pytorch. -->
このセクションでは、Pytorchにおける一般的な活性化関数について議論しました。特に、キンクを伴う活性化関数と滑らかな活性化関数を比較しました。後者が勾配消失問題を抱えているので、前者の方が深層ニューラルネットワークの学習でば好まれています。次に、Pytorchにおける一般的な損失関数について学びました。

<!-- ## Lecture part B -->
## レクチャーパート B

<!-- In this section, we continued to learn about loss functions - in particular, margin-based losses and their applications. We then discussed how to design a good loss function for EBMs as well as examples of well-known EBM loss functions. We gave particular attention to margin-based loss function here, as well as explaining the idea of "most offending incorrect answer. -->
このセクションでは、損失関数、特にマージンベースの損失とその応用について学びました。続いて、EBMに適した損失関数の設計方法と、よく知られているEBMの損失関数の例について説明しました。ここでは特にマージンベースの損失関数に注目し、「最も問題となる不正解」の考え方を説明しました。

<!-- ## Practicum -->
## 演習

<!-- This practicum proposed effective policy learning for driving in dense traffic. We trained multiple policies by unrolling a learned model of the real world dynamics by optimizing different cost functions. The idea is to minimize the uncertainty in the model's prediction by introducing a cost term that represents the model's divergence from the states it is trained on.   -->
本実習では、渋滞している道路の中での運転のための効果的な方策の学習方法を提案しました。異なるコスト関数を最適化して学習した実世界のダイナミクスのモデルを展開することで、複数の方策を学習しました。モデルの訓練された状態からのダイバージェンスを表すコスト項を導入することで、モデルの予測の不確実性を最小化するというアイデアによるものでした。 
