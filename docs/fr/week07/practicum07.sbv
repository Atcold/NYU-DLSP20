0:00:00.030,0:00:03.920
Donc les fondements de l‚Äôapprentissage profond.

0:00:03.920,0:00:09.080
Encore moi. N‚Äôh√©sitez pas √† m‚Äôinterrompre comme d‚Äôhabitude. Cela sera le dernier cours que nous aurons en pr√©sentiel.

0:00:09.080,0:00:12.750
Nous avons une tr√®s mauvaise situation, surtout en Italie.

0:00:12.750,0:00:16.529
Des gens meurent, il n‚Äôy a plus de lits dans les h√¥pitaux ni de m√©decins.

0:00:16.529,0:00:21.449
Les m√©decins travaillent 24 heures sur 24, 7 jours sur 7, et ils rentrent chez eux

0:00:21.449,0:00:25.260
et infectent leur propre famille. C‚Äôest donc une situation vraiment mauvaise en ce moment

0:00:25.260,0:00:30.810
et il semble que nous serons dans une situation semblable ici dans deux semaines.

0:00:30.810,0:00:38.129
Lavez-vous les mains. Essayez de ne pas aller dans des endroits tr√®s fr√©quent√©s. Restez en bonne sant√©.

0:00:38.129,0:00:42.950
Commen√ßons le cours. Apprentissage autosupervis√© / non supervis√©.

0:00:46.789,0:00:50.520
Les capacit√©s des mod√®les g√©n√©rateurs. Donc je vais vous donner des bonbons

0:00:50.520,0:00:54.870
de sorte que cela vous donne faim et que je puisse vous nourrir avec la premi√®re partie

0:00:54.870,0:00:58.199
de cette le√ßon. Cette le√ßon va √™tre divis√©e en deux parties. La premi√®re aujourd'hui

0:00:58.199,0:01:06.360
l‚Äôautre sera en ligne via Zoom. Levez la main ceux qui pense que l‚Äôimage

0:01:06.360,0:01:13.250
de gauche est r√©elle. Ok. Maintenant, levez la main ceux qui pense que la

0:01:18.299,0:01:29.970
la photo de droite est r√©elle. Ok. Qui pense que les deux sont r√©els ? Qui

0:01:29.970,0:01:37.290
pense que celle-l√† est fausse ? Qui pense que celle-l√† est fausse ? Qui pense que

0:01:37.290,0:01:44.299
les deux sont fausses ? Ok. Vous avez raison. Ces deux images ont √©t√© g√©n√©r√©es par

0:01:44.299,0:01:51.210
un mod√®le que nous avons entra√Æn√©s. En faites, cette personne, Karras, a entra√Æn√©. Donc si vous allez sur le

0:01:51.210,0:01:57.060
site web ¬´ this person does not exist ¬ª, vous pouvez trouver plusieurs tr√®s bons exemples

0:01:57.060,0:02:02.310
de personnes n‚Äôexistant pas. Si vous continuez √† cliquer parfois vous allez

0:02:02.310,0:02:06.780
trouver une personne avec un trou dans le visage, c‚Äôest alors tr√®s facile de

0:02:06.780,0:02:13.130
reconna√Ætre qu'il ne s‚Äôagit pas d'une personne r√©elle. Mais sinon toutes les autres

0:02:13.130,0:02:27.730
ont l'air assez r√©elles. Vous pouvez remarquer qu'elles ont de tr√®s belles dents, de tr√®s belles joues‚Ä¶ Je ne sais pas trop comment vous appelez √ßa en anglais.

0:02:25.730,0:02:29.990
Cependant vous pouvez clairement dire ici si vous v√©rifiez l‚Äôarri√®re-plan

0:02:29.990,0:02:34.000
que le r√©seau ne produit pas un arri√®re-plan tr√®s pr√©cis bien que les visages semblent tr√®s bons.

0:02:34.000,0:02:40.130
Pourquoi √ßa ? Car le r√©seau a eu comme entr√©e de nombreux √©chantillons de faces.

0:02:40.130,0:02:45.770
Et la chose qui n‚Äôest pas constante, c‚Äôest le fond. L‚Äôarri√®re-plan

0:02:45.770,0:02:49.880
est variable ici et donc vous ne pouvez pas apprendre tous les fonds 

0:02:49.880,0:02:01.520
possibles. Le fond ressemble √† un truc bizarre car il est beaucoup plus variable que les apparences de visages possibles.

0:03:01.520,0:03:07.370
Etant donn√© un visage humain, de combien de fa√ßons pouvez-vous le d√©former ?

0:03:07.370,0:03:12.230
Combien de degr√©s de libert√© un visage a-t-il ?

0:03:12.230,0:03:19.790
Vous connaissez la r√©ponse, nous avons d√©j√† couvert ce sujet en classe. [Etudiante]

0:03:19.790,0:03:27.490
Elle a dit huit. [Etudiant] 1050 ? Ah 50. C‚Äôest correct.

0:03:27.490,0:03:32.480
Vous avez environ une cinquantaine de muscles plus la rotation, les inclinaisons, etc.

0:03:32.480,0:03:37.820
Toutes ces possibilit√©s‚Ä¶ C'est juste une surface en 50 dimensions.

0:03:37.820,0:03:42.230
Tout le reste ne compte pas car √† l‚Äôext√©rieure de la surface. 

0:03:42.230,0:03:50.310
Cette image est de plusieurs m√©gapixels donc chaque point vit dans cet immense espace dimensionnel bien que toutes les variations

0:03:50.330,0:03:55.740
possibles sont limit√©es √† un sous-espace. Donc c‚Äôest la surface de donn√©es. 

0:03:55.740,0:04:02.270
Consultez le site web. Ok donc nous avons ici un tr√®s mignon chien

0:04:02.270,0:04:10.910
et de l'autre c√¥t√© un oiseau moins mignon. D√©sol√© ouais. Si vous faites une interpolation 

0:04:10.910,0:04:15.860
lin√©aire entre le chien et l'oiseau, qu‚Äôattendez-vous √† voir au milieu ?

0:04:15.860,0:04:21.760
Je vais √©teindre la lumi√®re et la rallumerez plus tard.

0:04:21.760,0:04:28.129
[Etudiant] R√©p√©tez. Une image floue. Que voulez-vous dire ?

0:04:28.129,0:04:32.440
Qu'esp√©rez-vous obtenir ici √† peu pr√®s ?

0:04:33.879,0:04:45.590
Vous pouvez r√©pondre. Donc je vais faire 100% de celui-l√† + 0%. 90% de celui-l√†

0:04:45.590,0:04:50.659
+10%. 80% de celui-l√† + 20% celui-ci. Donc qu'est-ce que tu seras vu ici ?

0:04:50.659,0:04:56.300
Vous devriez deviner. Vous √™tes moins que d'habitude, donc vous devez vraiment 

0:04:56.300,0:05:01.500
parler plus qu‚Äôhabituellement. [Etudiant] Un √©cureuil volant ? Non. Donc vous avez un chien

0:05:03.710,0:05:07.699
et un oiseau. Si je fais une interpolation lin√©aire de ces deux images dans

0:05:07.699,0:05:16.789
un espace de pixels qu'obtenez-vous ? [Etudiant] R√©p√©tez. [Etudiant] Oui, une superposition.

0:05:16.789,0:05:20.090
Vous obtenez quelque chose qui ressemble √† ceci. Une superposition

0:05:20.090,0:05:24.770
de la premi√®re image avec la deuxi√®me image. Alors revenons ici et faisons

0:05:24.770,0:05:28.849
plut√¥t une interpolation dans l'espace latent du r√©seau. Donc j‚Äôentre ces

0:05:28.849,0:05:33.620
deux images, j'obtiens les deux repr√©sentations de ces couches cach√©es.

0:05:33.620,0:05:37.490
Je fais une interpolation lin√©aire entre les couches cach√©es et ensuite je fais le d√©codage.

0:05:37.490,0:05:46.909
Qu‚Äôattendez-vous √† voir ici ? Vous devez encore me r√©pondre. [Etudiant]

0:05:46.909,0:05:53.090
Criez. [Etudiant] Le fond est toujours en d√©sordre mais que sera le sujet ? 

0:05:53.090,0:06:00.440
[Etudiant] Bien donc vous allez commencer √† voir un chien oiseau puis un 

0:06:00.440,0:06:08.960
oiseau chien. Un oiseau chien et un chien oiseau.

0:06:08.960,0:06:13.819
C‚Äôest un r√©seau qui a fait √ßa.

0:06:13.819,0:06:18.169
C‚Äôest atroce, un blasph√®me. Vous devriez regarder Fullmetal Alchemist.

0:06:18.169,0:06:23.960
L‚Äô√©pisode o√π le p√®re prend sa fille et le chien et fait quelque chose de

0:06:23.960,0:06:35.699
similaire. C'√©tait tr√®s int√©ressant. Si vous regardez les animes, voyez Brotherhood qui est la deuxi√®me adaptation. [Etudiant]

0:06:35.689,0:06:40.430
Je ne sais pas car c'est beaucoup de vert. Donc je suppose qu'il s'en est d√©barrass√©. Je ne sais pas.

0:06:40.430,0:06:44.189
Oui je ne sais pas. Bonne question et bons yeux.

0:06:44.189,0:06:49.169
Laissez-moi vous en montrer d'autres provenant de l'article de Brock.

0:06:49.169,0:06:58.490
Sur la premi√®re ligne, vous avez une petite version de ces images et nous partons de quelque chose qui ressemble √† un

0:06:58.490,0:07:04.879
requin ou une raie manta, puis ce truc ressemble √† un ¬´ polypus ¬ª‚Ä¶ comment

0:07:04.879,0:07:11.599
appelez-vous √ßa en anglais ? [Etudiant] Une pieuvre ? Quelque chose comme une pieuvre.

0:07:11.599,0:07:16.039
La pieuvre devient comme un singe puis ressemble √† un chien. Donc vous

0:07:16.039,0:07:20.629
pouvez voir le requin devenir une pieuvre qui devient un singe qui devient un chien.

0:07:20.629,0:07:24.529
C‚Äôest int√©ressant la fa√ßon dont on peut changer de race en ayant seulement les deux derniers

0:07:24.529,0:07:28.340
points fixes puis vous vous promenez dans l'espace latent. Vous en avez un 

0:07:28.340,0:07:33.969
autre ici. Vous allez d‚Äôun chien vers un oiseau. Donc encore une fois vous avez un genre d‚Äô√©cureuil oiseau ou

0:07:33.969,0:07:38.539
peu importe, puis vous avez un oiseau et de l'autre c√¥t√© vous avez un chien.

0:07:38.539,0:07:45.440
Dans celui-ci vous avez cet animal qui sent. Comment vous appelez √ßa ? [Etudiant] Une moufette [skunk en anglais] Merci.

0:07:45.440,0:07:50.900
Oh c‚Äôest de l√† l‚Äôexpression ¬´ you smell like a skunk ¬ª. C‚Äôest la m√™me chose.

0:07:50.900,0:07:55.159
Donc si vous avez une moufette ici et vous arrivez √† un chien. Cela ressemble en fait √†

0:07:55.159,0:08:03.319
beaucoup de chiens diff√©rents apr√®s cette chose. Puis enfin, on a un oiseau transformer en mouche.

0:08:03.319,0:08:08.419
Je pense que ce sont des exemples assez impressionnants. Cela devrait vous donner faim de telle sorte que

0:08:08.419,0:08:19.310
je puisse vous nourrir avec la deuxi√®me partie du cours. [Etudiant] Vous avez cette image

0:08:19.310,0:08:22.430
d'un c√¥t√©, vous avez cette image de l'autre. Vous obtenez les ench√¢ssements 

0:08:22.430,0:08:25.699
et faites une interpolation des ench√¢ssements. Vous pouvez regarder le papier

0:08:25.699,0:08:30.439
pour plus de d√©tails. Il s'agit ici de vous montrer que la diff√©rence

0:08:30.439,0:08:35.120
entre l'interpolation dans l'espace des pixels et l'espace latent.

0:08:35.120,0:08:43.090
Donc l'espace latent capture la s√©mantique de base d'une image. Donc vous

0:08:43.090,0:08:48.250
passez de l'espace des pixels, qui n'est pas vraiment compatible avec nos

0:08:48.250,0:08:54.790
outils pour cr√©er un espace mieux adapt√© √©tant la repr√©sentation cach√©e

0:08:54.790,0:08:59.050
interne des donn√©es du r√©seau. L√† encore, il s'agit juste de vous donner

0:08:59.050,0:09:04.660
de l'app√©tit. Je ne suis pas formel du tout ici. Qu‚Äôavons-nous ensuite ?

0:09:04.660,0:09:08.720
Vous pouvez zoomer sur les chiens. Vous pouvez d√©placer sur X, sur Y. 

0:09:08.720,0:09:13.870
Vous pouvez changer la luminosit√©. Ce qui est int√©ressant ici, c'est que lorsque vous changez

0:09:13.870,0:09:18.610
la luminosit√©, vous passer du jour √† la nuit ou de la nuit au jour car c‚Äôest

0:09:18.610,0:09:23.770
√† cela que ressemble le changement de luminosit√© le plus normal dans les images.

0:09:23.770,0:09:26.830
Chaque fois que vous changez de luminosit√©, vous changez en fait l'heure de la journ√©e.

0:09:26.830,0:09:31.510
Vous avez aussi les rotations 2D ou 3D. C‚Äôest tr√®s int√©ressant car cela signifie que

0:09:31.510,0:09:36.190
le r√©seau a d'une mani√®re ou d'une autre, une repr√©sentation interne du monde 3D.

0:09:36.190,0:09:41.800
C'est quelque chose que Yann a mentionn√© hier. Si vous vous d√©placez un peu

0:09:41.800,0:09:52.120
vous voyez ce genre de parallaxe. La fa√ßon la plus simple d'exprimer ce ph√©nom√®ne est de dire qu‚Äôil y a un monde en 3D. [Etudiant]

0:09:52.120,0:10:02.430
Donc dans ce cas, ils ont entra√Æn√© le r√©seau afin de pouvoir g√©rer

0:10:02.430,0:10:08.710
une transformation sp√©cifique. Il faut que j‚Äôajoute la r√©f√©rence de ce papier.

0:10:08.710,0:10:16.210
Encore une fois, je vous donne juste quelques bonbons pour les yeux, je ne

0:10:16.210,0:10:21.220
vais pas vous donner plus de choses formelles pour le moment. Dans ce cas 

0:10:21.220,0:10:29.590
que j‚Äôaime beaucoup, vous pouvez obtenir la version anim√©e de votre photo.

0:10:29.590,0:10:34.430
Essayer √ßa, mais pas avec du hentai. Nous ne voulons pas faire ces choses. [rires]

0:10:34.430,0:10:38.590
Ok donc certains d'entre vous connaissent ces choses. Int√©ressant. [rires] 

0:10:38.590,0:10:44.470
Ce qui ne connaissent pas. C‚Äôest ok, oubliez tout √ßa.

0:10:44.470,0:10:54.139
Voici d'autres trucs qui sont plut√¥t cool. Vous pouvez passer d‚Äôune image en basse r√©solution √† haute r√©solution.

0:10:54.459,0:10:58.449
Voici un autre exemple mais c'est bien s√ªr c‚Äôest noir sur blanc

0:10:58.449,0:11:01.839
donc c'est beaucoup plus facile de faire ce genre de choses et c'est la m√™me chose pour les z√®bres.

0:11:01.839,0:11:05.230
Il s'agit d'une technique d'apprentissage pr√©alable, donc ils utilisaient 

0:11:05.230,0:11:09.879
un mod√®le hi√©rarchique. N√©anmoins, cela fonctionne assez bien. 

0:11:09.879,0:11:16.209
Quelques ann√©es plus tard Garcia vous donne‚Ä¶ c'est comme

0:11:16.209,0:11:20.619
cr√©er des √©chantillons par interpolation lin√©aire.

0:11:20.619,0:11:24.879
La troisi√®me image est celle g√©n√©r√©e par le r√©seau neuronal et

0:11:24.879,0:11:29.679
la derni√®re est en fait l'image r√©elle. A la troisi√®me ligne, vous pouvez voir clairement que

0:11:29.679,0:11:39.759
l'homme asiatique est devenu europ√©en. Pourquoi √ßa ? [Etudiant] Les biais. Correct.

0:11:39.759,0:11:43.899
Le r√©seau a vu beaucoup de personnes blanches et donc le moyen le plus simple 

0:11:43.899,0:11:49.929
de reconstruire les caract√©ristiques d‚Äôun visage inconnu et de se brancher 

0:11:49.929,0:11:55.299
sur un visage de personne blanche. Cette dame a l'air d'avoir un accident vasculaire c√©r√©bral

0:11:55.299,0:12:00.910
car nous n'avons pas beaucoup d‚Äôimages de vues de c√¥t√©. Cette dame a

0:12:00.910,0:12:05.740
chang√© de sexe en bas. Cet homme semble avoir eu un accident car l√† encore,

0:12:05.740,0:12:10.869
nous n'avons pas beaucoup d‚Äôimages de personnes avec des lunettes dans l'ensemble de donn√©es.

0:12:10.869,0:12:15.369
Donc le r√©seau a vu une chose tr√®s sombre et a sorti quelqu'un

0:12:15.369,0:12:22.240
venant de se faire frapper tr√®s fort, Mais encore une fois, c'est tr√®s vieux.

0:12:22.240,0:12:26.290
Cela date d‚Äôil y a quatre ans. C‚Äô√©taient les premiers r√©sultats. Cela vous

0:12:26.290,0:12:32.079
permet de tirer parti des donn√©es r√©elles afin de combler les trous.

0:12:32.079,0:12:36.360
Les trous sont en fait des d√©tails r√©els. Nous avons de tr√®s tr√®s nombreux

0:12:36.360,0:12:40.509
nouveaux r√©sultats r√©cents, mais c‚Äô√©taient les r√©sultats pionniers.

0:12:40.509,0:12:47.230
Un de plus. Ici vous bloquez le visage avec un carr√© gris et vous

0:12:47.230,0:12:52.820
demandez ensuite au r√©seau de reconstruire le visage pour qu'il vous donne

0:12:52.820,0:12:57.680
le plus beau point. Donc vous prenez une image qui reste sur 

0:12:57.680,0:13:03.950
la surface d‚Äôentra√Ænement. Vous mettez un patch sur le visage. Ce patch fera s'√©loigner 

0:13:03.950,0:13:08.210
l'image de la surface d‚Äôentra√Ænement. Puis vous pouvez faire par exemple une descente de gradient

0:13:08.210,0:13:13.430
dans cet espace √©nerg√©tique de telle sorte que l'on puisse trouver le point le plus proche,

0:13:13.430,0:13:17.570
le point ayant l‚Äô√©nergie la plus faible associ√©e √† cette image initiale sp√©cifique.

0:13:17.570,0:13:21.110
Donc vous obtenez une image, vous la perturbez, la rendant √©loign√©e de la

0:13:21.110,0:13:24.650
surface d‚Äôentra√Ænement. Puis vous pouvez alors faire une descente de gradient

0:13:24.650,0:13:29.710
dans le paysage √©nerg√©tique de telle sorte que vous puissiez choisir 

0:13:29.710,0:13:33.860
l'√©chantillon le plus proche sur la surface d‚Äôentra√Ænement. C'est ce que Yann

0:13:33.860,0:13:38.090
a dit hier √† propos des mod√®les √† base d'√©nergie. Lorsque vous apprenez

0:13:38.090,0:13:41.780
une √©nergie vous pouvez r√©ellement l‚Äôutiliser pour faire de l'inf√©rence. Pour faire de l'inf√©rence

0:13:41.780,0:13:45.740
il faut en fait minimiser l'√©nergie. Donc la minimisation de l'√©nergie 

0:13:45.740,0:13:49.560
signifie l'inf√©rence. Pas l‚Äôentra√Ænement. L‚Äôentra√Ænement c‚Äôest autre chose.

0:13:49.560,0:13:52.850
Nous couvrirons plus en d√©tail les mod√®les √† base d'√©nergie dans les cours

0:13:52.850,0:13:58.010
suivants. Ici vous avez d'autres exemples, dont l'un utilise un auto-encodeur variationnel [VAE dans la suite].

0:13:58.010,0:14:04.460
et un autre utilisant un GAN [voir practinum 09]. Il s'agit d'un exemple

0:14:04.460,0:14:10.520
de Reed. C'est fou car vous pouvez passer de la description en anglais au

0:14:10.520,0:14:15.980
dessin de ce que la description en anglais d√©crit. Donc vous partez d'une s√©quence

0:14:15.980,0:14:20.600
vers un vecteur qui est comme le concept. Puis √† partir du concept vous

0:14:20.600,0:14:24.850
utilisez un d√©codeur. C'est donc un r√©seau g√©n√©ratif qui va d√©coder votre sortie sp√©cifique.

0:14:24.850,0:14:33.800
C'√©tait √† peu pr√®s tout pour les bonbons pour les yeux. Cela devrait vous

0:14:33.800,0:14:39.400
avoir donn√© faim pour la deuxi√®me partie de la classe. Vous avez faim ? 

0:14:39.400,0:14:48.230
[Etudiants] Oui, je n'ai pas d√Æn√© non plus. Donc les auto-encodeurs [A-E dans la suite].

0:14:48.230,0:14:51.470
Qu'est-ce que ces choses ? Apprentissage non supervis√©. C'est donc le premier mod√®le

0:14:51.470,0:14:55.760
dans lequel nous allons plonger pour voir comment nous pouvons entra√Æner un r√©seau

0:14:55.760,0:15:03.440
sans cibles ou √©tiquettes. Que sont les cibles ? Quelle est la diff√©rence 

0:15:03.440,0:15:09.860
entre cible et √©tiquette ? [Etudiant] Vous savez d√©j√† tout. Quelqu'un d'autre. [Etudiant]

0:15:09.860,0:15:18.480
Pr√©diction signifie ? [Etudiant] Les deux sont en fait des annotations.

0:15:18.480,0:15:25.080
[Etudiant] Merci. Les √©tiquettes sont cat√©goriques. Vous pouvez √©tiqueter

0:15:25.080,0:15:29.970
les choses : ceci est une chaise, ceci une table, √ßa une porte. Les cibles

0:15:29.970,0:15:37.230
sont la cible. Donc nous allons observer comment nous pouvons entra√Æner

0:15:37.230,0:15:43.590
ce mod√®le sans avoir r√©ellement d'objectifs ou d'√©tiquettes. C'est donc le

0:15:43.590,0:15:48.690
premier r√©seau qui est l'architecture avec laquelle nous allons jouer. 

0:15:48.690,0:15:53.370
C‚Äôest tr√®s similaire √† ce que nous avons observ√© jusqu'√† pr√©sent, mais la grande diff√©rence est que nous partons

0:15:53.370,0:15:58.200
du fond rose et nous savons d√©j√† pourquoi. On arrive √† la couche cach√©e interm√©diaire en vert,

0:15:58.200,0:16:05.340
puis allez en haut vers‚Ä¶ l‚Äôentr√©e. La sortie du r√©seau va donc √™tre

0:16:05.340,0:16:09.510
la pr√©diction de l'entr√©e. Il y a aussi d‚Äôautre type de repr√©sentation.

0:16:09.510,0:16:17.880
Ce sont les √©quations. Les couches cach√©es vont √™tre la rotation et l‚Äô√©crasement de mon entr√©e.

0:16:17.880,0:16:22.830
La sortie est la version √©cras√©e de la rotation de la couche cach√©e

0:16:22.830,0:16:27.450
o√π rotation signifie transformations affines. Nous avons quelques

0:16:27.450,0:16:32.480
dimensionnalit√©s. Donc on tire vers d mais x et xÃÇ vivent dans ‚Ñù‚Åø.

0:16:32.480,0:16:40.580
La deuxi√®me partie est notre r√©seau g√©n√©ratif. Celui qui va de h √† xÃÇ. Cela va √™tre mon r√©seau g√©n√©rateur.

0:16:40.580,0:16:44.850
Ici vous avez un diagramme diff√©rent qui fait essentiellement la m√™me chose 

0:16:44.850,0:16:48.840
et que certaines personnes pr√©f√®rent o√π les transformations se trouvent

0:16:48.840,0:16:53.550
dans des bo√Ætes. Donc vous avez des gens qui disent que c'est un r√©seau neural √† deux couches

0:16:53.550,0:17:01.680
bien que nous savons qu'il s'agit d'un r√©seau neural √†‚Ä¶ Combien de couches

0:17:01.680,0:17:08.580
a ce r√©seau de neurones ? [Etudiant] Trois couches fantastique. C‚Äôest ma convention.

0:17:08.580,0:17:14.070
Si vous utilisez la notation de Yann, alors nous avons aussi‚Ä¶ Oh attendez. Vous pouvez 

0:17:14.070,0:17:17.620
avoir aussi des poids l√©gers pour essayer de reproduire une ACP

0:17:17.620,0:17:24.970
bien que vous n'ayez pas de garanties sur l'ordre des diff√©rents bases.

0:17:24.970,0:17:34.690
Mais si nous utilisons la notation de Yann, nous allons aussi ajouter ce genre de petits projectiles qui repr√©sentent la transformation.

0:17:34.690,0:17:41.100
Donc pourquoi utilisons-nous des auto-encodeurs ? Quel est l'int√©r√™t de

0:17:41.100,0:17:51.940
pr√©voir l‚Äôentr√©e ? Disons que j'utilise une matrice identit√©. Je fournis 

0:17:51.940,0:17:56.170
une entr√©e qui est un vecteur. Je multiplie la matrice identit√© par mon 

0:17:56.170,0:18:04.720
Vecteur. Je re√ßois le m√™me vecteur. C‚Äôest l‚Äôauto-encodeur. Donc vous

0:18:04.720,0:18:18.760
obtenez la m√™me chose qu‚Äôen entr√©e. Pourquoi diable faisons-nous cela ? [Etudiant] Vous n'avez pas l'entr√©e

0:18:18.760,0:18:22.750
quand vous pr√©disez mais je peux juste apprendre la matrice d'identit√©.

0:18:22.750,0:18:26.750
J'ai une matrice d'identit√©. J‚Äôai mis quelque chose dedans et je sors quelque chose.

0:18:26.750,0:18:31.630
J'ai mis quelque chose dedans, je mets quelque chose dehors. La m√™me chose en entr√©e qu‚Äôen sortie.  

0:18:31.630,0:18:36.040
La chose la plus triviale √† apprendre pour un r√©seau est la matrice identit√©.

0:18:36.040,0:18:40.870
La chose que je mets √† l'int√©rieur en ressort. C'est ainsi que nous nous entra√Ænons ce truc.

0:18:40.870,0:18:53.020
[Etudiant] R√©p√©tez. [Etudiant] Si d est moins ? OK il y a un premier point.

0:18:53.020,0:19:00.400
Donc si nous avons une‚Ä¶ Si vous avez une dimension interm√©diaire d inf√©rieure √† n

0:19:00.400,0:19:05.830
nous pouvons commencer √† voir √† quoi peut servir ce truc. Par exemple il

0:19:05.830,0:19:09.429
peut √™tre utilis√© pour la compression. Donc si j'ai une repr√©sentation interm√©diaire

0:19:09.429,0:19:13.900
qui prend moins de place que ma repr√©sentation d'entr√©e, je peux utiliser l‚Äôencodeur 

0:19:13.900,0:19:18.940
comme un compresseur. Puis j'ai ma repr√©sentation cach√©e, mon code adressant

0:19:18.940,0:19:23.350
quelle entr√©e sp√©cifique il s‚Äôagit. Et cela prend moins de place. Je peux

0:19:23.350,0:19:31.090
m‚Äôen servir comme compresseur d'images par exemple. C'√©tait mon id√©e initiale pour les AEs.

0:19:31.090,0:19:36.960
Mais ce n'est qu'un type d‚Äôapplications. Ce n‚Äôest pas la fa√ßon correcte de penser √† ce mod√®le.

0:19:36.960,0:19:44.760
Une t√¢che de l‚ÄôAE est donc de reconstruire les donn√©es qui vivent sur la

0:19:44.760,0:19:51.970
surface de donn√©es. Donc nous avons une surface de donn√©es, nous obtenons quelques points de donn√©es et

0:19:51.970,0:19:57.070
j'utilise ces points pour l‚Äôentra√Ænement de mon syst√®me. J'aimerais que mon AE soit capable

0:19:57.070,0:20:01.600
de ne reconstruire sur les donn√©es que les choses qui vivent sur la surface

0:20:01.600,0:20:06.160
des donn√©es. Donc c'est la t√¢che des AEs.

0:20:06.160,0:20:10.480
Seulement reconstruire un petit sous-ensemble‚Ä¶ et je perds mon micro‚Ä¶

0:20:10.480,0:20:16.230
Une seconde. Je devrais‚Ä¶ Ok c‚Äôest trop court.

0:20:16.230,0:20:26.140
Nous devrions seulement pouvoir reconstruire un petit ensemble d'entr√©es possibles. Cela devient int√©ressant

0:20:26.140,0:20:31.300
car si vous ne pouvez reconstruire qu'un petit ensemble d'entr√©es alors

0:20:31.300,0:20:36.400
vous ne pouvez pas reconstruire des choses qui sont au loin. Par exemple

0:20:36.400,0:20:44.110
je vous ai montr√© des photos avec une bo√Æte grise sur le visage.

0:20:44.110,0:20:48.370
Donc je prends mon point et l‚Äô√©loigne de ma surface d‚Äôentra√Ænement.

0:20:48.370,0:20:52.780
Si j'essaie de le reconstruire et que le r√©seau ne peut reconstruire que les choses qui sont sur

0:20:52.780,0:20:57.670
la surface, il reconstruira quelque chose qui est ici. Et qui n'a pas ce

0:20:57.670,0:21:04.030
patch sur le visage. Vous voyez ou pas ? Donc si vous √™tes seulement contraint √†

0:21:04.030,0:21:08.140
reconstituer les choses qui ont √©t√© observ√©es pendant l‚Äôentra√Ænent, toute variation

0:21:08.140,0:21:14.850
que vous appliquez aux nouvelles entr√©es plus tard au moment o√π vous utilisez ce r√©seau, va √™tre supprim√©.

0:21:14.850,0:21:25.110
Car le r√©seau sera insensible √† ce genre de perturbations. Voyons √ßa un peu plus de d√©tails. Est-ce clair jusqu'√† pr√©sent ?

0:21:25.110,0:21:33.340
Oui ? Non ? Ok. Alors voyons les pertes de reconstruction que nous pouvons utiliser.

0:21:33.340,0:21:42.640
La premi√®re la perte classique que nous avons pour l'ensemble des donn√©es est la moyenne de mes pertes par √©chantillon.

0:21:42.640,0:21:55.720
Il y a deux pertes par √©chantillon. La premi√®re est l'entropie crois√©e binaire qui est tr√®s p√©nalisante si vous faites une erreur.

0:21:55.720,0:22:04.090
Donc la sortie, les objectifs sont 0 ou 1. Donc j'ai une distribution cat√©gorielle.

0:22:04.090,0:22:08.410
Puis votre sortie va √™tre quelque chose qui vit aussi entre 0 et 1.

0:22:08.410,0:22:12.280
Donc vous avez une fonction non lin√©aire de type sigmo√Øde √† la fin puis

0:22:12.280,0:22:17.380
vous essayez de minimiser ce type ici. Autrement si vous avez de vraies valeurs

0:22:17.380,0:22:22.900
d‚Äôentr√©es et sorties qui sont par exemple des images en couleur, vous 

0:22:22.900,0:22:37.030
pouvez vouloir utiliser la MSC. Donc comme quelqu'un, votre ami, l‚Äôa mentionn√© avant, c'est assez √©vident 

0:22:37.030,0:22:41.409
de penser √† une couche cach√©e sous-compl√®te. Une couche cach√©e sous-compl√®te

0:22:41.409,0:22:48.280
a une dimensionnalit√© inf√©rieure √† la taille de l'entr√©e.

0:22:48.280,0:22:54.400
Dans ce cas, le r√©seau ne peut peut-√™tre pas copier ou utiliser la matrice d'identit√© car vous

0:22:54.400,0:23:01.539
avez une repr√©sentation interm√©diaire qui est plus petite et vous devez ensuite √©tendre celle-l√† pour revenir √† la dimension initiale.

0:23:01.539,0:23:06.309
Vous pouvez utiliser un AE avec couche cach√©e sous-compl√®te pour faire de la compression par exemple.

0:23:06.309,0:23:12.070
C‚Äôest assez standard. Cela fait sens jusqu'√† pr√©sent ? Ok donc nous jouerons 

0:23:12.070,0:23:17.380
avec cela dans une seconde avec un notebook. N√©anmoins je dirai que j'aime 

0:23:17.380,0:23:24.880
celui-l√† encore plus. Et vous allez me dire pourquoi. Vous avez 

0:23:24.880,0:23:34.440
tous les ingr√©dients. C‚Äôest la sixi√®me ou septi√®me semaine‚Ä¶ La septi√®me.

0:23:34.450,0:23:41.730
Pourquoi je veux une repr√©sentation interm√©diaire plus importante ?

0:23:41.730,0:24:31.870
[Etudiant] Tout le monde l‚Äôa entendu ? Non. C‚Äôest la bonne intuition. R√©p√©tez √ßa juste plus fort. [Etudiant]

0:24:31.870,0:24:37.520
Nous avons toujours dit que plus on va dans la repr√©sentation interm√©diaire, 

0:24:37.520,0:24:42.049
plus l‚Äôoptimisation est facile. Donc, bien que les informations sont

0:24:42.049,0:24:47.000
contenues dans la premi√®re couche et dans la couche cach√©e ce sera la m√™me.

0:24:47.000,0:24:51.620
Je ne peux pas ajouter d'informations. Mais c'est beaucoup plus facile maintenant 

0:24:51.620,0:24:57.919
pour le r√©seau de jouer avec une repr√©sentation qui a plus de dimensions.

0:24:57.919,0:25:01.820
Nous pouvons maintenant simplement apprendre la matrice d'identit√© et 

0:25:01.820,0:25:06.409
copier tout. Vous copiez le premier gars dans le premier endroit puis

0:25:06.409,0:25:09.740
le deuxi√®me type que vous copiez ici, le troisi√®me que vous copiez ici. 

0:25:09.740,0:25:13.480
Vous copiez tout √† travers. Vous n'avez rien appris, que l'identit√©.

0:25:13.480,0:25:19.549
Nous devons appliquer d'autres types de contraintes pour l'information.

0:25:19.549,0:25:29.330
Nous devons donc introduire un goulot d'√©tranglement en mati√®re d'information. Bien que nous √©largissions la

0:25:29.330,0:25:33.500
repr√©sentation interm√©diaire, nous devons contraindre la repr√©sentation, 

0:25:33.500,0:25:40.640
limiter les configurations possibles que la couche cach√©e peut prendre en compte.

0:25:40.640,0:25:45.110
La couche d‚Äôentr√©e peut prendre autant de configurations que vous le souhaitez. La couche cach√©e ne doit

0:25:45.110,0:25:49.360
contenir que la configuration possible que la surface des donn√©es 

0:25:49.360,0:25:53.630
d‚Äôentra√Ænement peut avoir. Donc l'entr√©e peut √™tre tout ce que vous voulez

0:25:53.630,0:25:58.549
mais vous ne pouvez-vous entra√Æner qu'avec des donn√©es qui se trouvent sur la surface de donn√©es.

0:25:58.549,0:26:03.270
Donc la couche cach√©e doit seulement pouvoir mod√©liser, capturer les 

0:26:03.270,0:26:11.970
variabilit√©s dans les donn√©es d‚Äôentra√Ænement et √™tre insensible √† tout ce qui est en dehors. Donc nous pouvons avoir une reconstruction

0:26:11.970,0:26:18.240
s√©lective d'un sous-ensemble du tr√®s grand espace d‚Äôentr√©e. Etes-vous avec moi ?

0:26:18.240,0:26:28.230
Oui ? Non ? [Etudiant] Nous allons voir maintenant comment √©viter le surentra√Ænement.

0:26:28.230,0:26:33.210
Il y a donc plusieurs fa√ßons de proc√©der pour faire fonctionner la chose

0:26:33.210,0:26:37.800
√† droite mais pouvez avoir la m√™me justification pour le type √† gauche.

0:26:37.800,0:26:48.900
Donc disons que j'ai un d√©codeur super g√©nial. Mon encodeur pourrait juste mettre toutes mes donn√©es d‚Äôentra√Ænement comme :

0:26:48.900,0:26:52.830
premi√®re donn√©e d‚Äôentra√Ænement pour le premier point. Deuxi√®me donn√©e d‚Äôentra√Ænement pour le deuxi√®me point.

0:26:52.830,0:26:57.510
Troisi√®me donn√©e d‚Äôentra√Ænement pour le troisi√®me point. Donc je peux associer chacun de

0:26:57.510,0:27:02.760
mes donn√©es de d‚Äôentra√Ænement √† un nombre : 1, 2, 3, 4, 5, peu importe.

0:27:02.760,0:27:06.390
Puis vous avez le d√©codeur qui a m√©moris√© tous les points d‚Äôentra√Ænement.

0:27:06.390,0:27:11.400
Il suffit alors de sortir le point d‚Äôentra√Ænement que vous souhaitez de ce s√©lecteur.

0:27:11.400,0:27:16.190
Donc vous n'avez peut-√™tre besoin que d'une seule boule ici, un seul neurone

0:27:16.190,0:27:20.820
dans la couche cach√©e afin d'avoir un r√©seau qui ne surentra√Æne pas. 

0:27:20.820,0:27:23.280
Tant que le d√©codeur et l'encodeur sont tr√®s puissants.

0:27:23.280,0:27:27.360
Donc le point que votre coll√®gue a mentionn√© : comment √©viter le surentra√Ænement ?

0:27:27.360,0:27:33.270
Cette chose peu surentra√Æner aussi. Cette chose va surentra√Æner √† moins

0:27:33.270,0:27:37.890
d‚Äô√™tre prudent sur la fa√ßon dont nous concevons ces choses.

0:27:37.890,0:27:46.770
Il existe diff√©rentes m√©thodes : les m√©thodes contrastives, les m√©thodes r√©gularis√©es et les m√©thodes architecturales. 

0:27:46.770,0:27:51.460
Nous avons vu hier des choses. Nous allons couvrir quelques-unes d'entre elles 

0:27:51.460,0:27:57.560
et avons 20 minutes pour √ßa. Oui ? [Etudiant] C‚Äôest la diapositive suivante.

0:28:05.650,0:28:12.520
Auto-encodeur d√©bruiteur. Comment √ßa marche ? Je prends 

0:28:12.520,0:28:22.210
mon entr√©e en rose. Je l'√©loigne de mon point original. Donc voici ma surface de donn√©es.

0:28:22.210,0:28:26.530
Chacun de ces points est un √©chantillon pour l‚Äôentra√Ænement.

0:28:26.530,0:28:32.890
Je prends mon point et le d√©place al√©atoirement.

0:28:32.890,0:28:37.810
Maintenant je force le r√©seau √† reconstruire ce point initial. 
	
0:28:37.810,0:28:42.730
Ceci est donc un auto-encodeur d√©bruiteur [DAE dans la suite d‚Äôapr√®s le sigle anglais].

0:28:42.730,0:28:46.800
Vous prenez un point de votre surface d‚Äôentra√Ænement, vous l‚Äô√©loignez puis

0:28:46.800,0:28:52.780
vous forcez le r√©seau √† le ramener ici. Je prends le m√™me point, 

0:28:52.780,0:28:56.200
je l‚Äô√©loigne dans l'autre direction et je le remets ici. Je prends le m√™me

0:28:56.200,0:29:02.400
point, je l‚Äô√©loigne dans une autre direction et je le remets ici. Ok alors qu'est-ce que nous apprenons ?

0:29:02.400,0:29:07.030
Nous apprendrons un champ vectoriel qui ram√®ne tout √† ce point.

0:29:07.030,0:29:12.550
Puis je commence √† me d√©placer dans ma surface d‚Äôentra√Ænement et j'ai

0:29:12.550,0:29:17.020
tous ces genre de champs vectoriels pointant vers l‚Äô√©chantillon

0:29:17.020,0:29:21.790
d‚Äôentra√Ænement. Si vous avez un √©chantillon d‚Äôentra√Ænement ici et un

0:29:21.790,0:29:25.690
autre ici, ce gars va essayer d'attirer ici. L‚Äôautre va essayer d‚Äôattirer l√†.

0:29:25.690,0:29:41.070
Donc les choses qui sont sur la surface restent l√†. Les choses √† l'ext√©rieur de la surface vont s'effondrer vers la surface. Des questions ?

0:29:41.110,0:29:47.640
Il y a une mise en garde [Alfredo demande la prononciation du mot ¬´ caveat ¬ª]

0:29:47.640,0:29:52.630
Merci. Nous supposons que nous injectons la m√™me distribution de bruit

0:29:52.630,0:29:57.850
que nous allons observer dans la r√©alit√©. De cette fa√ßon, nous pouvons apprendre

0:29:57.850,0:30:06.070
comment redresser de mani√®re robuste. Donc si nous supposons que nous avons acc√®s au type de perturbations que nous allons observer plus tard lors

0:30:06.070,0:30:10.240
de l‚Äôinf√©rence, nous pouvons entra√Æner le mod√®le √† √™tre insensible √† ces 

0:30:10.240,0:30:15.090
types de perturbations et c'est une tr√®s grande supposition.

0:30:15.090,0:30:21.880
Oh belle image. Donc voici mes donn√©es d‚Äôentra√Ænement. Mes points roses.

0:30:21.880,0:30:30.570
Je vais √©teindre les lumi√®res. Donc ici j‚Äôai mes points roses

0:30:30.570,0:30:36.160
qui vous semblent blancs. J'ai aussi les points orange qui sont

0:30:36.160,0:30:40.690
les points d√©plac√©s. Donc ils sont originaires de ces points ici puis

0:30:40.690,0:30:44.260
je les d√©place dans toutes ces directions diff√©rentes. Ensuite j‚Äôentra√Æne

0:30:44.260,0:30:49.150
pour ramener tous ces points oranges aux points de d√©part initiaux.

0:30:49.150,0:30:55.240
Voici donc la sortie du r√©seau. J'entre ce nuage de points orange dans

0:30:55.240,0:31:00.160
le r√©seau. J‚Äôentra√Æne mon r√©seau √† sortir les points sur la spirale

0:31:00.160,0:31:04.390
et ces points bleus sont les reconstructions du r√©seau.

0:31:04.390,0:31:09.130
Donc si les points sont d√©j√† sur la surface, ils ne bougent pas.

0:31:09.130,0:31:15.040
Si les points sont √©loign√©s de la surface, ils bougent beaucoup.

0:31:15.040,0:31:20.380
Je peux mesurer de combien ils ont boug√© et c‚Äôest l‚Äô√©nergie. A quel point c'est cool ?

0:31:20.380,0:31:25.480
Ok peut-√™tre que vous n'avez pas encore compris. Donc dans ce cas pour √™tre un peu

0:31:25.480,0:31:31.730
plus minutieux, j'envoie toutes les combinaisons x,y possibles de ce plan √† l'int√©rieur de mon r√©seau.

0:31:31.730,0:31:35.410
Donc ici vous avez cette ligne car tout ce coin √† gauche en bas

0:31:35.410,0:31:40.270
a √©t√© √©cras√© ici. Vous pouvez voir ici que les points sont assez √©pars et

0:31:40.270,0:31:44.050
il y en a un tr√®s tr√®s grand nombre qui occupent dens√©ment la surface.

0:31:44.050,0:31:49.900
Cependant, il y a quelques points ici. Donc ceci vous montre en couleur

0:31:49.900,0:31:55.570
quelle est la distance que ces points ont parcourue. Donc les points ici 

0:31:55.570,0:32:00.390
dans le coin en bas √† gauche ont voyag√© d‚Äôune unit√© et sont arriv√©s ici.

0:32:00.390,0:32:07.300
Les points par ici ont voyag√© de 0,9 quelque chose et sont descendus ici.

0:32:07.300,0:32:15.970
Les points sur cette deuxi√®me branche sont all√©s nulle part. Pourquoi √ßa ?

0:32:15.970,0:32:20.760
Ils sont attir√©s √† la fois par les deux points de ce c√¥t√© et

0:32:20.760,0:32:26.430
de ce c√¥t√©, en moyenne pendant l‚Äôentra√Ænement. N√©anmoins si vous

0:32:26.430,0:32:30.180
oubliez d‚Äôavoir des choses qui se ¬´ curlent ¬ª sur elles-m√™mes, tout tombe ici.

0:32:30.180,0:32:38.940
Devinez quoi, je peux mettre les points qui viennent de bouger un peu

0:32:38.940,0:32:43.740
√† l'int√©rieur de l'AE et je peux continuer √† faire cela un peu

0:32:43.740,0:32:49.680
jusqu'√† ce que ces points s'effondrent au niveau de la surface.

0:32:49.680,0:32:55.500
Ou je peux faire quelque chose de cool. Je suis cool mais il y a un truc. Que fais-je ici ?

0:32:55.500,0:33:00.120
C'est mon DAE qui me permet d'arriver au point initial d‚Äôo√π commence

0:33:00.120,0:33:03.870
mon d√©placement. Donc j'ai obtenu mon point de d√©part, j‚Äôai d√©plac√©

0:33:03.870,0:33:08.450
et ensuite forc√© le r√©seau √† revenir au point initial.

0:33:08.450,0:33:15.570
Que s'est-il pass√© ici ? Comment ai-je pu r√©parer √ßa ? Comment pouvez-vous r√©parer cette cr√™te ici,

0:33:15.570,0:33:27.150
cette r√©gion sombre ? Des suppositions ? [Etudiant] Vous pouvez les envoyer au hasard ou‚Ä¶ [Etudiant] Attendez quelqu'un

0:33:27.150,0:33:32.280
la haut √† droite veut parler [Etudiant] Pousser vers l‚Äôext√©rieur. Comment je pousser vers l'ext√©rieur ? Oh ok le pousser vers le haut serait aussi

0:33:32.280,0:33:34.950
tr√®s bien. Donc j'essaie aussi de pousser vers le haut tout ce qui

0:33:34.950,0:33:38.720
n'est pas sur la surface. Cela n‚Äôa pas tout √† fait fonctionn√©. C‚Äôest un hack.

0:33:42.960,0:33:48.000
Ce n'est pas √©l√©gant. Ce n‚Äôest pas faisable dans un espace en grandes dimensions. Donc ce que j'ai

0:33:48.000,0:33:52.920
fait ici, c‚Äôest de faire tomber le point vers le plus proche de la surface.

0:33:52.920,0:33:57.000
J'ai donc fait une recherche exhaustive du point le plus proche de la surface et j'ai

0:33:57.000,0:34:01.230
forc√© mon r√©seau √† ce que mes points tombent toujours sur le point le plus proche

0:34:01.230,0:34:04.860
bien qu'elles puissent √™tre g√©n√©r√©es √† partir d'un autre point initial. 

0:34:04.860,0:34:09.900
Donc si ce point par ici est initialement originaire d'ici, il tombera 

0:34:09.900,0:34:21.310
toujours dans cette direction. Seuls quelques points, l√† dans le milieu, ne tomberont nulle part. [Etudiant]

0:34:24.210,0:34:31.060
Dans plus de dimensions tout est √©loign√©s. Donc cela ne fonctionne pas tout √† fait.

0:34:31.060,0:34:34.330
Nous n‚Äôavons pas encore vu le notebook. Je vous montrerais √ßa la prochaine 

0:34:34.330,0:34:41.050
fois ou quand on pourra. [Etudiant] Oui dans ce cas, j‚Äôai un DAE et ai

0:34:41.050,0:34:45.730
obtenu que le point d√©plac√© tombe sur le point le plus proche de la surface.

0:34:45.730,0:34:50.679
J'ai donc fait une recherche exhaustive. C'est simple car j'ai 150 points

0:34:50.679,0:34:57.730
ici mais c'est un hack. Vous ne pouvez pas faire cela en pratique. Mais

0:34:57.730,0:35:02.080
Peu importe, c‚Äôest pour d√©velopper une sorte de compr√©hension de √ßa.

0:35:02.080,0:35:06.280
C‚Äôestt quelque chose que Yann aime beaucoup mais je ne suis pas encore en mesure de le faire fonctionner.

0:35:06.280,0:35:13.720
Je suppose que je ne suis pas encore assez intelligent. Dans ce cas, c‚Äôest un AE r√©gularis√©.

0:35:13.720,0:35:20.859
Ici j‚Äôai un terme de co√ªt de r√©gularisation L1 sur ma repr√©sentation cach√©e. Donc je force mon

0:35:20.859,0:35:25.630
r√©seau pour trouver des repr√©sentations cach√©es qui sont courtes et

0:35:25.630,0:35:30.369
de quelques dimensions. Donc si j'ai une r√©gularisation L1 de ma

0:35:30.369,0:35:36.640
repr√©sentation cach√©e, je n'aurai que quelques √©l√©ments actifs √† un moment donn√©.

0:35:36.640,0:35:40.630
Le probl√®me est que si vous mettez tous ces autres √©l√©ments √† 0, vous avez

0:35:40.630,0:35:45.070
des gradients nuls √† r√©tropropager. Donc vous pouvez utiliser √† la place des r√©tropropagations de cible et

0:35:45.070,0:35:52.580
d'autres jolies choses mais je travaille toujours sur ce sujet. Donc je n'ai aucune id√©e de comment faire fonctionner √ßa.

0:35:52.580,0:35:59.859
Le point est qu‚Äôil s'agit du terme de r√©gularisation. Donc la p√©nalit√© L1, sur la repr√©sentation cach√©e. Cette zone sombre ici

0:35:59.859,0:36:05.589
devrait en fait s'√©tendre tout autour. A nouveau, c'est tr√®s difficile pour le moment pour moi

0:36:05.589,0:36:09.339
de le faire fonctionner. Je ne dis pas que c'est impossible mais simplement que je suis

0:36:09.339,0:36:14.619
pas assez malin. Auto-encodeur contrastif [CAE dans la suite]. Nous verrons juste apr√®s le notebook.

0:36:14.619,0:36:28.710
Laissez-moi rallumer la lumi√®re‚Ä¶ ou peut-√™tre pas. Je ne sais pas. Devrais-je ? J‚Äôai l‚Äôobscurit√©. Ok, peu importe.

0:36:28.940,0:36:37.800
De retour sur la cam√©ra üòâ. A nouveau, la surface de donn√©es des points d‚Äôentra√Ænement. 

0:36:37.800,0:36:46.260
Que fait le CAE ? ce truc ici, est simplement le terme de reconstruction plus cette chose ici. Qu'est-ce que c'est ?

0:36:46.260,0:36:54.540
Le gradient de ma repr√©sentation cach√©e par rapport √† l‚Äôentr√©e, norme carr√©e

0:36:54.540,0:36:59.609
de la perte globale. Donc ma perte globale essaiera de minimiser la

0:36:59.609,0:37:05.430
variation de ma couche cach√©e en fonction des variations de l'entr√©e.

0:37:05.430,0:37:09.630
Donc nous voulons avoir une repr√©sentation pour l'entr√©e qui ne change pas tant que cela

0:37:09.630,0:37:16.980
quand je tortille mon entr√©e. Donc ce CAE rend essentiellement insensible‚Ä¶

0:37:16.980,0:37:23.880
D√©sol√©‚Ä¶ insensible √† la reconstruction, p√©nalise l‚Äôinsensibilit√©

0:37:23.880,0:37:35.400
aux directions de reconstruction. Donc vous pouvez reconstruire les choses sur la surface mais cela rendra par ailleurs insensible √† toute

0:37:35.400,0:37:39.830
autre direction possible. Donc nous n'avons pas d'hypoth√®se sur la

0:37:39.830,0:37:43.589
perturbation que j'applique. Je suis juste insensible √† tout mais ensuite

0:37:43.589,0:37:49.980
j‚Äôai encore beaucoup de points ici. Donc vous devez minimiser la reconstruction quand

0:37:49.980,0:38:02.099
je fournis des √©chantillons diff√©rents. Donc la fl√®che verte : ¬´ p√©nalis√©e et insensible ¬ª et l‚Äôorange : ¬´ p√©nalis√©e ¬ª.

0:38:02.099,0:38:06.050
Et finalement‚Ä¶ ok il reste dix minutes.

0:38:06.050,0:38:13.440
Enfin, qu'est-ce que fais l‚ÄôAE ? Comme vous pouvez le voir, je peux utiliser tr√®s bien matplotlib.

0:38:13.440,0:38:21.210
Nous avons ici la surface d‚Äôentra√Ænement qui est une chose unique se 

0:38:21.210,0:38:27.750
d√©pla√ßant dans trois dimensions. Et ici j'ai tous ces points de donn√©es.

0:38:27.750,0:38:38.730
Donc le x vit sur cet ensemble de donn√©es, dans ‚Ñù‚Åø. Ce qu'un AE doit faire 

0:38:38.730,0:38:44.500
c'est essentiellement d'allonger cette boucle dans une direction.

0:38:44.500,0:38:48.850
Donc vous avez l√† votre z qui dans ce cas s'appelle l'espace latent.

0:38:48.850,0:38:53.170
Donc vous obtenez le premier l√† et ensuite le second.

0:38:53.170,0:39:02.590
Le fait est : comment puis-je passer de √ßa √† √ßa ? Je sais que si je suis

0:39:02.590,0:39:06.730
dans ce premier lieu je peux retourner √† ce lieu. Je sais que si je suis

0:39:06.730,0:39:11.800
ici, je peux retourner l√†. Je ne suis pas tout √† fait s√ªr de ce qui se passe ici.

0:39:11.800,0:39:18.670
Je n'ai que des √©chantillons d‚Äôentra√Ænement. Donc je n'ai que la correspondance

0:39:18.670,0:39:24.580
entre des points dans l'espace d'entr√©e et des points dans l'espace latent. Je n'ai pas

0:39:24.580,0:39:29.140
de correspondance entre les r√©gions de l'espace d'entr√©e et les r√©gions de

0:39:29.140,0:39:37.320
l‚Äôespace latent. Donc vous savez seulement comment connecter l'entr√©e √†

0:39:37.320,0:39:41.770
des r√©gions dans l'espace latent et comment y revenir. Nous avons appris 

0:39:41.770,0:39:46.530
que l‚ÄôDAE prend l'entr√©e, la secoue et avons forc√© √† revenir au m√™me point.

0:39:46.530,0:39:50.170
Ensuite vous retournez √† d‚Äôautres endroits pour d√©finir un endroit.

0:39:50.170,0:39:58.300
Donc vous prenez celui-ci, vous le secouez, il ira toujours l√† puis revenez au bon endroit.

0:39:58.300,0:40:40:08.890
Pour le contrastif, pour l‚Äôentr√©e, vous essayez de p√©naliser chaque d√©hanchement de celui-ci lorsque vous d√©hanchez celui-l√†.

0:40:08.890,0:40:15.990
Ok, c‚Äôest le AEC. N√©anmoins comment puis-je commencer √† partir d'ici, bouger

0:40:15.990,0:40:21.400
et obtenir quelque chose qui ressemble √† une sortie d√©cente ? Si je traduis :

0:40:21.400,0:40:26.770
si j'ai un chien ici et un oiseau ici, l‚Äôespace latent,

0:40:26.770,0:40:33.070
si je me d√©place sur cette ligne, comment puis-je assurer que les choses sur cette

0:40:33.070,0:40:38.890
ligne ici ressembleront √† des transformations significatives ici ?

0:40:38.890,0:40:42.850
Nous ne savons pas. Nous savons seulement que cette image est li√©e √† ce point,

0:40:42.850,0:40:47.080
cette image est li√©e √† ce point. Nous n'avons pas connaissance sur

0:40:47.080,0:40:54.220
quel genre de comportement, sur comment se comporte cet espace

0:40:54.220,0:40:59.740
lorsque je me d√©place dans l‚Äôespace, comment √ßa se r√©percute ici. Donc nous ne savons pas comment ce d√©codeur,

0:40:59.740,0:41:05.410
qui va de l'espace latent √† l'espace d'entr√©e, se comporte quand nous ne sommes pas

0:41:05.410,0:41:10.150
exactement dans les points. Donc pour l'instant nous avons des points √† associer. La prochaine fois

0:41:10.150,0:41:15.910
nous allons observer, nous allons apprendre √† associer les r√©gions de l'espace d'entr√©e

0:41:15.910,0:41:21.700
avec des r√©gions de l'espace cach√©. Pour le moment nous allons seulement de point en point.

0:41:21.700,0:41:28.950
Donc le notebook pour les sept derni√®res minutes. Merci de rester avec moi.

0:41:28.950,0:41:55.65
Oui je bouge trop. Donc cd Work Github pDL, conda activate pDL, jn.

0:41:59.410,0:42:14.580
Donc le notebook ¬´ 10-autoencoder ¬ª. C'est invisible pour vous mais c'est le num√©ro dix. Donc je vais juste ex√©cuter des trucs.

0:42:15.900,0:42:24.339
Ok, d'accord, alors que faisons-nous ici ?

0:42:24.339,0:42:28.590
Vous voyez bien ? Oui. Plaignez-vous si vous ne voyez pas bien les choses. 

0:42:28.590,0:42:33.190
Je ne peux pas v√©rifier trop de choses. Donc nous importons certains trucs. Nous avons une routine de conversion d'image

0:42:33.190,0:42:42.130
qui consiste simplement √† ajouter +1 et √† multiplier par 0,5 car

0:42:42.130,0:42:47.109
quand je re√ßois mes donn√©es, j'essaie de les ramener √† une moyenne nulle

0:42:47.109,0:42:52.000
et j'ai aussi une fourchette de -0,5 √† +0,5. Donc c'est centr√©.

0:42:52.000,0:42:56.830
Pour r√©cup√©rer, j‚Äôadditionne 1 au lieu d'√™tre une moyenne nulle, cela va √†

0:42:56.830,0:43:07.640
une moyenne de 0,5 et ensuite j'ai‚Ä¶  Cela va de -1 √† +1. Puis j‚Äôajoute 1. Donc √ßa va de 0 √† 2 puis avec le fois 0,5, cela va de 0 √† 1.

0:43:07.640,0:43:13.720
C'est une routine d'affichage. Ok je vous montre que je soustrais

0:43:13.720,0:43:19.970
0,5 et je divise par 0,5 mes donn√©es. Ce sont les chiffres MNIST de Yann.

0:43:19.970,0:43:25.420
Ici, nous configurons le ¬´ device ¬ª pour faire tourner sur CPU ou GPU.

0:43:25.420,0:43:31.040
Ici, nous avons des images qui sont les chiffres que nous avons vu lorsque nous avons entra√Æn√©s les

0:43:31.040,0:43:36.320
ConvNets. Elles sont de taille 28 par 28 pixels et dans ce cas je vais

0:43:36.320,0:43:41.510
cr√©er un AE qui a une couche cach√©e interm√©diaire √† 30 dimensions.

0:43:41.510,0:43:48.980
Donc on passe de 784 √† 30 et puis on revient √† 784.

0:43:48.980,0:43:53.500
Donc c‚Äôest mon mod√®le d‚ÄôAE. Juste une couche lin√©aire, une transformation affine

0:43:53.500,0:43:58.610
de 28¬≤ √† d. Puis tangente hyperbolique. Et ensuite j'ai le d√©codeur qui est 

0:43:58.610,0:44:03.280
mon mod√®le g√©n√©ratif partant de l'espace cach√©, l'espace latent, qui est d

0:44:03.280,0:44:08.360
vers 28¬≤. Puis j'ai de nouveau une tangente hyperbolique pour limiter ma

0:44:08.360,0:44:15.470
sortie entre -1 et +1. Ma phase arri√®re est simplement envoy√© par le biais

0:44:15.470,0:44:19.850
de l‚Äôencodeur et du d√©codeur. Donc je cr√©√© mon mod√®le puis mon crit√®re

0:44:19.850,0:44:26.090
qui est la perte MSE. Puis le taux d'apprentissage et Adam.

0:44:26.090,0:44:29.930
Donc c‚Äôest la partie entra√Ænement. Je fais 20 √©poques. 

0:44:29.930,0:44:35.330
La premi√®re partie va √™tre l'envoi des images √† travers le mod√®le.

0:44:35.330,0:44:48.83
C‚Äôest l‚Äô√©tape 1. L‚Äô√©tape 2 va √™tre le calcul de la perte qui est la ligne num√©ro 15. Le troisi√®me point va nettoyer le gradient sinon on accumule.

0:44:48.830,0:44:53.600
C‚Äôest la ligne 17. Puis on fait de la r√©tropropagation,

0:44:53.600,0:44:57.230
le calcul de la d√©riv√©e partielle ou de la perte finale par rapport aux poids.

0:44:57.230,0:45:02.420
C‚Äôest la ligne 18. Enfin nous faisons un pas en arri√®re dans la direction‚Ä¶

0:45:02.420,0:45:07.970
C‚Äôest la direction du gradient, et vous reculez. Je parle beaucoup car

0:45:07.970,0:45:13.790
l'ordinateur fait l'entra√Ænement. Donc vous pouvez voir ici que nous avons 

0:45:13.790,0:45:23.150
fait 20 √©poques et laissez-moi vous montrer √† quoi ils ressemblent.

0:45:23.150,0:45:28.430
Ce sont les reconstructions de mon r√©seau. Ce sont les sorties du r√©seau

0:45:28.430,0:45:32.480
√©tant donn√© que nous les compressons dans cette repr√©sentation interm√©diaire 

0:45:32.480,0:45:39.980
√† 30 dimensions. Je vais vous montrer les vrais dans une seconde. Laissez-moi changer celui-ci en un DAE. Donc ici je cr√©e un module 

0:45:39.980,0:45:45.500
de dropout qui √©teint les neurones au hasard. Je cr√©e mon masque de bruit

0:45:45.500,0:45:50.090
puis je cr√©e mes mauvaises images qui multiplient ces images par ce masque 

0:45:50.090,0:45:56.510
binaire. Puis j'envoie au r√©seau ces mauvaises images, les images alt√©r√©es,

0:45:56.510,0:46:01.010
et je r√©-entra√Æne ce truc. Nous aimons aussi arriver √† 500 dimensions, donc

0:46:01.010,0:46:06.560
c‚Äôest une couche cach√©e sur-compl√®te et ensuite nous nous entra√Ænons.

0:46:06.560,0:46:14.780
Et c'est l‚Äôentra√Ænement. Alors r√©capitulons la diff√©rence l‚Äôentra√Ænement

0:46:14.780,0:46:19.040
pr√©c√©dent et l‚Äôentra√Ænement actuel. Donc nous avons vu qu‚Äôavant,

0:46:19.040,0:46:24.590
nous utilisions juste un AE sous-complet. Donc nous √©tions

0:46:24.590,0:46:30.220
pass√©s de 784 dimensions en entr√©e √† une couche cach√©e de 30 dimensions. 

0:46:30.220,0:46:36.980
Maintenant nous utilisons un AE sur-complet. J‚Äôutilise 500 ici, ce qui est moins que 784.

0:46:36.980,0:46:46.160
Donc une bonne question serait de savoir pourquoi 500 dimensions ?

0:46:46.160,0:46:51.230
Pourquoi un AE avec des couches cach√©es de dimensions 500 est consid√©r√© ou

0:46:51.230,0:46:56.090
peut √™tre consid√©r√© comme sur-complet ? Pensez au nombre de pixels qui sont

0:46:56.090,0:47:01.130
en moyenne noir par exemple dans ces images. Donc nous avons d√©j√† ex√©cut√© cette partie.

0:47:01.130,0:47:06.500
Donc passons √† l‚Äôentra√Ænement. Comment l‚Äôentra√Ænement change-t-il ?

0:47:06.500,0:47:12.500
J'ai un masque de dropout ici qui me permet d‚Äôintroduire quelques

0:47:12.500,0:47:17.660
perturbations sur les images originales. Puis j'ai mon bruit qui est

0:47:17.660,0:47:22.619
simplement en appliquant un masque de dropout sur un vecteur ¬´ ones ¬ª.

0:47:22.619,0:47:27.479
Cela va √™tre utile pour des visualisations ult√©rieures. Puis je cr√©e mes mauvaises images,

0:47:27.479,0:47:32.009
les images perturb√©es qui sont simplement la multiplication de mes images

0:47:32.009,0:47:38.429
par ce bruit. Si nous n'avions pas de neurones en moins, le bruit serait

0:47:38.429,0:47:42.799
juste ¬´ ones ¬ª et vous obtenez 1 fois l'image. Donc vous avez la m√™me image.

0:47:42.799,0:47:47.640
Sinon, lorsque les neurones sont mis √† 0 avec le dropout, l'image est

0:47:47.640,0:47:52.410
multipli√©e par 0 pour des valeurs sp√©cifiques de pixels. Donc l‚Äôimage se 

0:47:52.410,0:47:59.569
retrouve avec des points noirs. Puis je rentre ces mauvaises images dans mon mod√®le.

0:47:59.569,0:48:06.739
Puis le crit√®re est la distance entre la sortie et l'image originale.

0:48:06.739,0:48:16.650
Donc avant, ici nous entrions les images perturb√©es √† l'int√©rieur du mod√®le, donc ce sont des points qui sont en dehors 

0:48:16.650,0:48:21.390
de la surface d‚Äôentra√Ænement mais ensuite je force √† aller au point original.

0:48:21.390,0:48:25.140
Donc vous avez le point d'origine, vous le perturbez donc l‚Äô√©loignez, 

0:48:25.140,0:48:28.919
puis vous forcez le r√©seau √† ce qu‚Äôil sorte celui-ci. Donc il essaie de

0:48:28.919,0:48:35.159
contraster tout type de perturbation qui arrive √† ce point initial.

0:48:35.159,0:48:40.499
Tout le reste est identique : ¬´ zero_grad ¬ª, ¬´ backward ¬ª, ¬´ step ¬ª et l‚Äôentrainement.

0:48:40.499,0:48:47.130
Nous pouvons v√©rifier √† quoi ressemble cette reconstruction et si je regarde

0:48:47.130,0:48:52.679
l'it√©ration pr√©c√©dente, ils ont l'air beaucoup plus propres car nous 

0:48:52.679,0:48:58.799
utilisons une couche cach√©e beaucoup plus grande. Mais avant nous ne pouvions pas utiliser 

0:48:58.799,0:49:01.999
une couche cach√©e car cela aurait surentra√Æn√©. Si vous essayiez de

0:49:01.999,0:49:05.669
reconstruire des choses qui sont toujours au m√™me point, vous pouvez simplement les copier.

0:49:05.669,0:49:09.569
Dans ce cas, vous ne pouvez pas copier car l'entr√©e n'est pas ce point mais

0:49:09.569,0:49:13.799
est en fait le point d√©plac√©. Vous apprenez donc un champ vectoriel qui

0:49:13.799,0:49:20.039
vous ram√®ne √† la position initiale sur la surface d‚Äôentra√Ænement.

0:49:20.039,0:49:28.890
Descendons et visualisons les filtres pr√©c√©dents que je ne vous ai pas montr√©s. Donc ce sont les filtres de l‚ÄôAE

0:49:28.890,0:49:37.850
avec une couche cach√©e sous-compl√®te. Donc vous pouvez voir ici qu‚Äôil y a des motifs dans la zone centrale de ces filtres.

0:49:37.850,0:49:43.280
Donc ce sont les filtres qui sont simplement mes lignes de mes m√©triques W

0:49:43.280,0:49:48.640
qui ont √©t√© remodel√©s en une image que je peux visualiser.

0:49:48.640,0:49:52.400
Dans ce cas, dans ce notebook, nous n'utilisons aucun ConvNet.

0:49:52.400,0:49:59.210
Nous n'utilisons que les images qui ont √©t√© enroul√©es dans un vecteur, et compar√©es, multipli√©es

0:49:59.210,0:50:05.420
comme le produit scalaire contre les vecteurs, de ma matrice.

0:50:05.420,0:50:09.200
Donc les lignes de ma matrice ont √©t√© remodel√©es de mani√®re √† ce que vous puissiez

0:50:09.200,0:50:13.430
donner un sens √† ce qu'elles repr√©sentent. Ici par exemple il semble y avoir

0:50:13.430,0:50:18.470	
comme un d√©tecteur d‚Äôune boucle sup√©rieure. Pas un d√©tecteur car c‚Äôest violet,

0:50:18.470,0:50:24.320
donc, les sorties seraient n√©gatives. Vous avez ici comme un 0, ici quelque 

0:50:24.320,0:50:34.130
chose qui ressemble √† un 8 ou un 3. Et vous avez ce genre de noyau ici qui n'a pratiquement rien appris ou‚Ä¶

0:50:34.130,0:50:39.320
C‚Äôest le seul qui n'a pas appris grand-chose. Vous pouvez remarquer que 

0:50:39.320,0:50:43.490
tous ces points en dehors de la r√©gion o√π le num√©ro apparait ou des choses

0:50:43.490,0:50:47.150
Int√©ressantes apparaissent sont multipli√©s par une constante.

0:50:47.150,0:50:52.150
Car c‚Äôest en dehors d'un chiffre et donc les choses ne changent pas.

0:50:52.150,0:51:03.109
Ces noyaux bruyants, en moyenne, produisent un score de 0. Donc le r√©seau

0:51:03.109,0:51:08.300
ne se soucie pas de donner une valeur particuli√®re √† ces points/pixels

0:51:08.300,0:51:19.300
car √† nouveau, en moyenne, ils ne contribuent pas au score final. Que se passe t‚Äôil maintenant ? Quand nous entrons

0:51:19.300,0:51:27.440
les donn√©es qui ont une quantit√© variable de pixels mis √† 0, ces points

0:51:27.440,0:51:32.930
comptent √† pr√©sent car la valeur de l'image n'est plus continue.

0:51:32.930,0:51:39.590
Donc si je vous montre les nouveaux noyaux. A quel point est-ce cool ?

0:51:39.590,0:51:47.450
C‚Äôest compl√®tement diff√©rent. Ici vous avez encore un certain motif mais dans la majorit√© de ces noyaux,

0:51:47.450,0:51:51.150
si vous ne consid√©riez pas ceux qui n'a rien appris comme celui-ci,

0:51:51.150,0:51:59.700
les noyaux ont appris une sorte de filtre de bord sp√©cifique ou des caract√©ristiques sp√©cifiques de forme,

0:51:59.700,0:52:07.110
des filtres de forme. Tous les pixels ext√©rieurs ont maintenant √©t√© mis √† 

0:52:07.110,0:52:11.940
0 ou √† une valeur qui est uniforme car, encore une fois, les images 

0:52:11.940,0:52:17.250
d'entr√©e ne sont plus constantes dans les zones hors des chiffres.

0:52:17.250,0:52:26.540
Donc les valeurs des pixels‚Ä¶ les valeurs du noyau dans ces r√©gions sp√©cifiques comptent d√©sormais. C'est une grande diff√©rence.

0:52:26.540,0:52:34.050
Encore une fois, cette carte ici, ce noyau n'a rien appris.

0:52:34.050,0:52:44.369
Comparons maintenant notre DAE avec les algorithmes de l‚Äô√©tat de l‚Äôart pour le d√©bruitage d‚Äôimages. Donc nous allons

0:52:44.369,0:52:55.650
importer certaines fonctions de la librairie opencv : les algorithmes de Navier-Stokes et Telea. Donc importons les et

0:52:55.650,0:53:01.530
voyons √† quoi ils ressemblent. Donc la premi√®re image est l'image bruit√©e. Celles que nous avons g√©n√©r√©e

0:53:01.530,0:53:05.630
avant sont celles o√π nous avons fait du dropout sur certaines

0:53:05.630,0:53:11.700
valeurs pour les mettre √† 0. Donc dans ce cas le jaune est 1 et le violet 0.

0:53:11.700,0:53:22.859
La deuxi√®me partie est les mauvaises images, ce qui signifie que le violet est ‚Äì 1, le jaune + 1 et le vert 0.

0:53:22.859,0:53:28.460
Donc tous ces points noirs, les points violets de la premi√®re rang√©e, sont 

0:53:28.460,0:53:32.940
ici repr√©sent√©s en vert. Ce sont donc les valeurs qui sont mises √† 0, les

0:53:32.940,0:53:40.650
valeurs masqu√©es. Nous avons les images originales et les reconstructions 

0:53:40.650,0:53:46.230
de notre AE qui semble raisonnablement bon si vous pensez au fait que la 

0:53:46.230,0:53:51.390
moiti√© des pixels est manquante. Donc seule la moiti√© des pixels sont

0:53:51.390,0:54:00.119
fourni au r√©seau, puis le r√©seau reconstruit ce √† quoi ressemble l'image originale, plus ou moins. Cool cool.

0:54:00.119,0:54:06.510
Voyons maintenant ce que les algorithmes de l‚Äô√©tat de l‚Äôart produisent.

0:54:06.510,0:54:13.130
Donc nous pouvons commencer par Telea puis Navier-Stokes. Donc voici Telea

0:54:13.130,0:54:19.730
et ceci est Navier-Stokes. Comme vous pouvez le constater ici, la qualit√© de 

0:54:19.730,0:54:25.640
notre mod√®le est clairement sup√©rieure en termes de qualit√©.

0:54:25.640,0:54:30.360
N√©anmoins remarquez que ce mod√®le fonctionne juste pour ce genre de

0:54:30.360,0:54:33.660
perturbation sp√©cifique que nous avons introduite et appris √†

0:54:33.660,0:54:41.070
contrecarrer. Donc encore une fois l‚ÄôAE que nous avons entra√Æn√© en une

0:54:41.070,0:54:45.270
minute fonctionne bien mieux que les algorithmes de vision par ordinateur 

0:54:45.270,0:54:51.660
de pointe lorsque les donn√©es sont disponibles. Donc je pense que c'est tout

0:54:51.660,0:54:55.500
pour aujourd'hui. Merci de m'avoir √©cout√©, abonnez-vous √† ma cha√Æne et cliquez

0:54:55.500,0:55:03.500
sur la cloche des notifications si vous souhaitez avoir des informations sur les derni√®res vid√©os et suivez-moi sur Twitter. Paix. Bye bye.
