---
lang: fr
lang-ref: ch.10
title: Semaine 10
translation-date: 10 Aug 2020
translator: Loïck Bourdois
---

<!--
## Lecture part A

In this section, we understand the motivation behind Self-Supervised Learning (SSL), define what it is and see some of its applications in NLP and Computer Vision. We understand how pretext tasks aid with SSL and see some example pretext tasks in images, videos and videos with sound. Finally, we try to get an intuition behind the representation learned by pretext tasks.
-->


## Conférence partie A

Dans cette section, nous voyons la motivation qui sous-tend l’autoapprentissage supervisé (SSL en anglais). Nous le définissons et voyons certaines de ses applications en NLP et en vision par ordinateur. Nous comprenons comment les tâches de prétexte en SSL et voyons quelques exemples de tâches de prétexte en images, vidéos et vidéos avec son. Enfin, nous essayons d'avoir une intuition derrière la représentation apprise par les tâches de prétexte.

<!--
## Lecture part B

In this section, we discuss the shortcomings of pretext tasks, define characteristics that make a good pretrained feature, and how we can achieve this using Clustering and Contrastive Learning. We then learn about ClusterFit, its steps and performance. We further dive into a specific simple framework for Contrastive Learning known as PIRL. We discuss its working as well as its evaluation in different contexts.
-->

## Conférence partie B

Dans cette section, nous discutons des lacunes des tâches de prétexte, nous définissons les éléments qui font une bonne caractéristique pré-entraînée, et comment nous pouvons y parvenir en utilisant le clustering et l'apprentissage contrastif. Nous en apprenons ensuite davantage sur le ClusterFit, ses étapes et ses performances. Nous nous plongeons ensuite dans un cadre simple et spécifique pour l'apprentissage contrastif, connu sous le nom de PIRL. Nous discutons de son fonctionnement ainsi que de son évaluation dans différents contextes.

<!--
## Practicum


During this week's practicum, we explore the [Truck Backer-Upper](http://neuro.bstu.by/ai/To-dom/My_research/Papers-2.1-done/RL-sparce-reward/9/Ref/truckbackerupper.pdf) (Nguyen & Widrow, '90).
This problem shows how to solve an non-linear control problem using neural networks.
We learn a model of a truck's kinematics, and optimize a controller through this learned model, finding that the controller is able to learn complex behaviors through purely observational data.
-->

## Pratique
Nous explorons le [Truck Backer-Upper](http://neuro.bstu.by/ai/To-dom/My_research/Papers-2.1-done/RL-sparce-reward/9/Ref/truckbackerupper.pdf) (Nguyen & Widrow, '90).
Ce problème montre comment résoudre un problème de contrôle non-linéaire en utilisant des réseaux de neurones.
Nous apprenons un modèle de la cinématique d'un camion, et nous optimisons un contrôleur grâce à ce modèle appris, en constatant que le contrôleur est capable d'apprendre des comportements complexes grâce à des données purement observationnelles.





