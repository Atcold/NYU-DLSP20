---
lang: fr
lang-ref: ch.09
title: Semaine 9
translation-date: 09 Aug 2020
translator: Loïck Bourdois
---

<!--
## Lecture part A

We discussed discriminative recurrent sparse auto-encoders and group sparsity. The main idea was how to combine sparse coding with discriminative training. We went through how to structure a network with a recurrent autoencoder similar to LISTA and a decoder. Then we discussed how to use group sparsity to extract invariant features.
-->


## Conférence partie A

Nous discutons des auto-encodeurs discriminants récurrents épars et de l’éparsité de groupe. L'idée principale est de savoir comment combiner un codage épars avec un entraînement discriminant. Nous examinons comment structurer un réseau avec un auto-encodeur récurrent similaire à LISTA et un décodeur. Nous discutons ensuite de la manière d'utiliser la rareté des groupes pour extraire les caractéristiques invariantes.

<!--
## Lecture part B

In this section, we talked about the World Models for autonomous control including the neural network architecture and training schema. Then, we discussed the difference between World Models and Reinforcement Learning (RL). Finally, we studied Generative Adversarial Networks (GANs) in terms of energy-based model with the contrastive method.
-->

## Conférence partie B

Dans cette section, nous parlons des modèles du monde (world models) pour le contrôle autonome, y compris l'architecture du réseau neuronal et le schéma d’entraînement. Ensuite, nous discutons de la différence entre les modèles du monde et l'apprentissage par renforcement (RL). Enfin, nous étudions les Generative Adversarial Networks (GANs) en termes d’EBM avec la méthode contrastive.

<!--
## Practicum


During this week's practicum, we explored Generative Adversarial Networks (GANs) and how they can produce realistic generative models. We then compared GANs with VAEs from week 8 to highlight key differences between two networks. Next, we discussed several model limitations of GANs. Finally, we looked at the source code for the PyTorch example Deep Convolutional Generative Adversarial Networks (DCGAN).
-->

## Pratique
Nous explorons les Generative Adversarial Networks (GANs) et la manière dont ils peuvent produire des modèles générateurs réalistes. Nous comparons ensuite les GAN avec les VAE de la semaine 8 pour mettre en évidence les principales différences entre deux réseaux. Ensuite, nous discutons de plusieurs limites des GANs. Enfin, nous examinons le code source de l'exemple « PyTorch Deep Convolutional Generative Adversarial Networks (DCGAN) ».




