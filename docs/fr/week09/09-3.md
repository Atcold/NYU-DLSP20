---
lang: fr
lang-ref: ch.09-3
title: Réseaux génératifs antagonistes
lecturer: Alfredo Canziani
authors: William Huang, Kunal Gadkar, Gaomin Wu, Lin Ye
date: 31 Mar 2020
translation-date: 19 Aug 2020
translator: Loïck Bourdois
---

<!--
## [Introduction to generative adversarial networks (GANs)](https://www.youtube.com/watch?v=xYc11zyZ26M&t=57s)

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANArchitecture.png" height="400px" /><br>
<b>Fig. 1</b>: GAN Architecture
</center>

GANs are a type of neural network used for unsupervised machine learning. They are comprised of two adversarial modules: _generator_ and _cost_ networks. These modules compete with each other such that the _cost_ network tries to filter fake examples while the _generator_ tries to trick this filter by creating realistic examples $\vect{\hat{x}}$. Through this competition, the model learns a generator that creates realistic data. They can be used in tasks such as future predictions or for generating images after being trained on a particular dataset.

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANMapping.png" height="400px" /><br>
<b>Fig. 2</b>: GAN Mapping from Random Variable
</center>

GANs are examples of energy based models (EBMs). As such, the cost network is trained to produce low costs for inputs closer to the true data distribution denoted by the pink $\vect{x}$ in Fig. 2. Data from other distributions, like the blue $\vect{\hat{x}}$ in Fig. 2, should have high cost. A mean squared error (MSE) loss is typically used to calculate the cost network's performance. It is worth noting that the cost function outputs a positive scalar value within a specified range *i.e.*$\text{cost} : \mathbb{R}^n \rightarrow \mathbb{R}^+ \cup \{0\}$). This is unlike a classic discriminator which uses discrete classification for its outputs.

Meanwhile, the generator network ($\text{generator} : \mathcal{Z} \rightarrow \mathbb{R}^n$) is trained to improve its mapping of random variable $\vect{z}$ to realistic generated data $\vect{\hat{x}}$ to trick the cost network. The generator is trained with respect to the cost network's output, trying to minimize the energy of $\vect{\hat{x}}$. We denote this energy as $C(G(\vect{z}))$, where $C(\cdot)$ is the cost network and $G(\cdot)$ is the generator network.

The training of the cost network is based on minimizing the MSE loss, while the training of the generator network is through minimizing the cost network, using gradients of $C(\vect{\hat{x}})$ with respect to $\vect{\hat{x}}$.

To ensure that high cost is assigned to points outside the data manifold and low cost is assigned to points within it, the loss function for the cost network $\mathcal{L}\_{C}$ is $C(x)+[m-C(G(\vect{z}))]^+$ for some positive margin $m$. Minimizing $\mathcal{L}\_{C}$ requires that $C(\vect{x}) \rightarrow 0$ and $C(G(\vect{z})) \rightarrow m$. The loss for the generator $\mathcal{L}\_{G}$ is simply $C(G(\vect{z}))$, which encourages the generator to ensure that $C(G(\vect{z})) \rightarrow 0$. However, this does create instability as $0 \leftarrow C(G(\vect{z})) \rightarrow m$.
-->

## [Introduction aux generative adversarial networks (GANs)](https://www.youtube.com/watch?v=xYc11zyZ26M&t=57s)

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANArchitecture.png" height="400px" /><br>
<b>Figure 1</b> : Architecture d’un GAN
</center>

Les GAN sont un type de réseau neuronal utilisé pour l'apprentissage machine non supervisé. Ils sont composés de deux modules contradictoires : les réseaux _générateur_ et  _coût_. Ces modules se font concurrence de telle sorte que le réseau _coût_ tente de filtrer les faux exemples tandis que le _générateur_ tente de tromper ce filtre en créant des exemples réalistes $\vect{\hat{x}}$. Grâce à cette compétition, le modèle apprend un générateur qui crée des données réalistes. Ces données peuvent être utilisées dans des tâches telles que les prédictions ou pour générer des images après avoir été entraîné sur un ensemble de données particulier.

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANMapping.png" height="400px" /><br>
<b>Figure 2</b> : Cartographie d’un GAN à partir d'une variable aléatoire
</center>

Les GAN sont des exemples de modèles à base d’énergie (EBM). En tant que tel, le réseau _coût_ est entraîné à produire des coûts faibles pour des intrants plus proches de la distribution réelle des données, désignée par le $\vect{x}$ rose dans la figure 2. Les données provenant d'autres distributions, comme le $\vect{\hat{x}}$ bleu de la figure 2, devraient avoir un coût élevé. Une perte d'erreur quadratique moyenne (EQM) est généralement utilisée pour calculer la performance du réseau de coût. Il convient de noter que la fonction de coût produit une valeur scalaire positive dans une plage spécifiée *c’est-à-dire* $\text{cost} : \mathbb{R}^n \rightarrow  \mathbb{R}^+ \cup \{0\}$). Ceci est différent d'un discriminateur classique qui utilise une classification discrète pour ses sorties.

Pendant ce temps, le réseau générateur ($\text{generator} : \mathcal{Z} \rightarrow \mathbb{R}^n$) est entraîné à améliorer la correspondance de la variable aléatoire $\vect{z}$ aux données réalistes générées $\vect{\hat{x}}$ pour tromper le réseau de coût. Le générateur est entraîné d’après la sortie du réseau de coût, en essayant de minimiser l'énergie de $\vect{\hat{x}}$. Nous désignons cette énergie par $C(G(\vect{z}))$, où $C(\cdot)$ est le réseau de coût et $G(\cdot)$ est le réseau du générateur.

L’entraînement du réseau de coût est basée sur la minimisation de la perte MSE, tandis que l’entraînement du réseau de générateur est basée sur la minimisation du réseau de coût, en utilisant des gradients de $C(\vect{\hat{x}})$ par rapport à $\vect{\hat{x}}$.

Pour garantir que le coût élevé est attribué aux points situés à l'extérieur du collecteur de données et que le coût faible est attribué aux points situés à l'intérieur de celui-ci, la fonction de perte pour le réseau de coût $\mathcal{L}\_{C}$ est de $C(x)+[m-C(G(\vect{z}))]^+$ pour une certaine marge positive $m$. Pour minimiser $\mathcal{L}\_{C}$, il faut que $C(\vect{x}) \rightarrow  0$ et $C(G(\vect{z}) \rightarrow m$. La perte pour le générateur $\mathcal{L}\_{G}$ est simplement $C(G(\vect{z}))$, ce qui encourage le générateur à s'assurer que $C(G(\vect{z}) \\N- Flèche droite 0$. Cependant, cela crée une instabilité car 0$ \leftarrow C(G(\vect{z})) \rightarrow m$.

<!--
## [Difference between GANs and VAEs](https://www.youtube.com/watch?v=xYc11zyZ26M&t=1844s)

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANvsVAEArchitecture.png" height="400px" /><br>
<b>Fig. 3</b>: VAE (left) *vs.* GAN (right) - Architectural design
</center>

Compared to Variational Auto-Encoders (VAEs) from week 8, GANs create generators slightly differently. Recall, VAEs map inputs $\vect{x}$ to a latent space $\mathcal{Z}$ with an _encoder_ and then map from $\mathcal{Z}$ back to the data space with a _decoder_ to get $\vect{\hat{x}}$. They then use the reconstruction loss to push $\vect{x}$ and $\vect{\hat{x}}$ to be similar. GANs, on the other hand, train through an adversarial setting with the generator and cost networks competing as described above. These networks are successively trained through backpropagation through gradient based methods. Comparison of this architectural difference can be seen in Fig. 3.

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANvsVAEMapping.jpg" height="250px" /><br>
<b>Fig. 4</b>: VAE (left) *vs.* GAN (right) - Mapping from Random Sample $\vect{z}$
</center>

GANs also differ from VAEs through how they produce and use $\vect{z}$. GANs start by sampling $\vect{z}$, similar to the latent space in a VAE. They then use a generative network to map $\vect{z}$ to $\vect{\hat{x}}$. This $\vect{\hat{x}}$ is then sent through a discriminator/cost network to evaluate how "real" it is. One of the main differences from VAE and GAN is that **we do not need to measure a direct relationship (*i.e.* reconstruction loss) between the output of the generative network $\vect{\hat{x}}$ and real data $\vect{x}$.** Instead, we force $\vect{\hat{x}}$ to be similar to $\vect{x}$ by training the generator to produce $\vect{\hat{x}}$ such that the discriminator/cost network produces scores that are similar to those of real data $\vect{x}$, or more "real".
-->

## [Différence entre les GAN et les VAE](https://www.youtube.com/watch?v=xYc11zyZ26M&t=1844s)

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANvsVAEArchitecture.png" height="400px" /><br>
<b>Figure 3</b> : VAE (gauche) *vs.* GAN (droite) - Conception architecturale
</center>

Par rapport aux VAE de la semaine 8, les GAN créent des générateurs légèrement différents. Rappelons que les VAE « mappent » les entrées $\vect{x}$ vers un espace latent $\mathcal{Z}$ avec un _encodeur_ puis « mappent » de $\mathcal{Z}$ vers l'espace de données avec un _décodeur_ pour obtenir $\vect{\hat{x}}$. Ils utilisent ensuite la perte de reconstruction pour pousser $\vect{x}$ et $\vect{\hat{x}}$ à être similaires. Les GAN, en revanche, s'entraînent dans un cadre contradictoire avec le générateur et les réseaux de coûts en concurrence comme décrit ci-dessus. Ces réseaux sont successivement entraînés par rétropropagation au moyen de méthodes basées sur le gradient. Une comparaison de cette différence architecturale est présentée à la figure 3.

<center>
<img src="{{site.baseurl}}/images/week09/09-3/GANvsVAEMapping.jpg" height="250px" /><br>
<b>Fig. 4</b> : VAE (gauche) *vs.* GAN (droite) - Cartographie à partir d'un échantillon aléatoire $\vect{z}$
</center>

Les GAN diffèrent également des VAE par la façon dont ils produisent et utilisent les $vect{z}$. Les GAN commencent par échantillonner $\vect{z}$, comme l'espace latent dans un VAE. Ils utilisent ensuite un réseau génératif pour mettre en correspondance $\vect{z}$ avec $\vect{\hat{x}}$. Ce $\vect{\hat{x}}$ est ensuite envoyé à travers un réseau discriminateur/coûts pour évaluer son caractère "réel". Une des principales différences entre la VAE et le GAN est que **nous n'avons pas besoin de mesurer une relation directe (*c'est-à-dire* la perte de reconstruction) entre la sortie du réseau générateur $\vect{\hat{x}}$ et les données réelles $\vect{x}$. ** Au lieu de cela, nous forçons $\vect{\hat{x}}$ à être similaire à $\vect{x}$ en entraînant le générateur à produire $\vect{\hat{x}}$ de telle sorte que le réseau discriminateur/coûts produise des scores similaires à ceux des données réelles $\vect{x}$, ou plus "réels".

<!--
## Major pitfalls in GANs

While GANs can be powerful for building generators, they have some major pitfalls.
-->

## Les principaux pièges avec les GANs

Si les GANs peuvent être puissants pour la construction de générateurs, ils présentent quelques pièges majeurs.

<!--
### 1. Unstable convergence

As the generator improves with training, the discriminator performance gets worse because the discriminator can no longer easily tell the difference between real and fake data. If the generator is perfect, then the manifold of the real and fake data will lie on top of each other and the discriminator will create many misclassifications.

This poses a problem for convergence of the GAN: the discriminator feedback gets less meaningful over time. If the GAN continues training past the point when the discriminator is giving completely random feedback, then the generator starts to train on junk feedback and its quality may collapse. [Refer to [training convergence in GANs](https://developers.google.com/machine-learning/gan/training)]

As a result of this adversarial nature between the generator and discriminator there is an unstable equilibrium point rather than an equilibrium.
-->

### 1. Convergence instable

Au fur et à mesure que le générateur s'améliore avec l'entraînement, les performances du discriminateur se détériorent car celui-ci ne peut plus faire facilement la différence entre les données réelles et les fausses. Si le générateur est parfait, les données réelles et fausses se superposeront et le discriminateur créera de nombreuses erreurs de classification.

Cela pose un problème pour la convergence du GAN : le retour d'information du discriminateur devient moins significatif avec le temps. Si le GAN continue à s'entraîner au-delà du moment où le discriminateur donne un retour d'information complètement aléatoire, alors le générateur commence à s'entraîner sur le retour d'information indésirable et sa qualité peut s'effondrer. Voir [la convergence de l’entraînement dans les GAN](https://developers.google.com/machine-learning/gan/training)

En raison de cette nature contradictoire entre le générateur et le discriminateur, il existe un point d'équilibre instable plutôt qu'un équilibre.

<!--
### 2. Vanishing gradient

Let's consider using the binary cross entropy loss for a GAN:

$$
\mathcal{L} = \mathbb{E}_\boldsymbol{x}[\log(D(\boldsymbol{x}))] + \mathbb{E}_\boldsymbol{\hat{x}}[\log(1-D(\boldsymbol{\hat{x}}))] \text{.}
$$

As the discriminator becomes more confident, $D(\vect{x})$ gets closer to $1$ and $D(\vect{\hat{x}})$ gets closer to $0$. This confidence moves the outputs of the cost network into flatter regions where the gradients become more saturated. These flatter regions provide small, vanishing gradients that hinder the generator network's training. Thus, when training a GAN, you want to make sure that the cost gradually increases as you become more confident.
-->

### 2. Disparition du gradient

Envisageons d'utiliser la perte binaire d'entropie croisée pour un GAN :

$$
\mathcal{L} = \mathbb{E}_\boldsymbol{x} [\log(D(\boldsymbol{x}))] + \mathbb{E}_\boldsymbol{\hat{x}} [\log(1-D(\boldsymbol{\hat{x}})] \text{.}
$$

Au fur et à mesure que le discriminateur devient plus confiant, $D(\vect{x})$ se rapproche de $1$ et $D(\vect{\hat{x}})$ se rapproche de $0$. Cette confiance déplace les sorties du réseau de coûts vers des régions plus plates où les gradients sont plus saturés. Ces régions plus plates présentent de petits gradients qui disparaissent et qui entravent l'entraînement du réseau de générateurs. Ainsi, lorsque vous entraînez un GAN, vous voulez vous assurer que le coût augmente progressivement à mesure que vous devenez plus confiant.

<!--
### 3. Mode collapse

 If a generator maps all $\vect{z}$'s from the sampler to a **single** $\vect{\hat{x}}$ that can fool the discriminator, then the generator will produce **only** that $\vect{\hat{x}}$. Eventually, the discriminator will learn to detect *specifically* this fake input. As a result, the generator simply finds the next most plausible $\vect{\hat{x}}$ and the cycle continues. Consequently, the discriminator gets trapped in local minima while cycling through fake $\vect{\hat{x}}$'s. A possible solution to this issue is to enforce some penalty to the generator for always giving the same output given different inputs.
-->

### 3. Effondrement des modes

 Si un générateur fait correspondre tous les $\vect{z}$ de l'échantillonneur à un **simple** $\vect{\hat{x}}$ qui peut tromper le discriminateur, alors le générateur produira **seulement** ce $\vect{\hat{x}}$. Finalement, le discriminateur apprendra à détecter *spécifiquement* cette fausse entrée. En conséquence, le générateur trouve simplement le $\vect{\hat{x}}$ suivant le plus plausible et le cycle continue. Par conséquent, le discriminateur se retrouve piégé dans les minima locaux pendant qu'il passe en revue les faux $\vect{\hat{x}}$. Une solution possible à ce problème est d'imposer une pénalité au générateur pour avoir toujours donné la même sortie avec des entrées différentes.

<!--
## [Deep Convolutional Generative Adversarial Network (DCGAN) source code](https://www.youtube.com/watch?v=xYc11zyZ26M&t=2911s)

The source code of the example can be found [here](https://github.com/pytorch/examples/blob/master/dcgan/main.py).
-->

## [Code source du Deep Convolutional Generative Adversarial Network (DCGAN)](https://www.youtube.com/watch?v=xYc11zyZ26M&t=2911s)

Le code source de l'exemple peut être trouvé [ici](https://github.com/pytorch/examples/blob/master/dcgan/main.py).

<!--
### Generator

1. The generator upsamples the input using several `nn.ConvTranspose2d` modules separated with `nn.BatchNorm2d` and `nn.ReLU`.
2. At the end of the sequential, the network uses `nn.Tanh()` to squash outputs to $(-1,1)$.
3. The input random vector has size $nz$. The output has size $nc \times 64 \times 64$, where $nc$ is the number of channels.

```python
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        output = self.main(input)
        return output
```
-->

### Générateur

1. Le générateur suréchantillonne l'entrée en utilisant plusieurs modules `nn.ConvTranspose2d` séparés par `nn.BatchNorm2d` et `nn.ReLU`.
2. A la fin de la séquence, le réseau utilise `nn.Tanh()` pour écraser les sorties à $(-1,1)$.
3. Le vecteur aléatoire d'entrée a la taille $nz$. La sortie a la taille $nc \times 64 \times 64$, où $nc$ est le nombre de canaux.

```python
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        output = self.main(input)
        return output
```


<!--
### Discriminator

1. It is important to use `nn.LeakyReLU` as the activation function to avoid killing the gradients in negative regions. Without these gradients, the generator will not receive updates.
2. At the end of the sequential, the discriminator uses `nn.Sigmoid()` to classify the input.

```python
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        output = self.main(input)
        return output.view(-1, 1).squeeze(1)
```

These two classes are initialized as `netG` and `netD`.
-->

### Discriminateur

1. Il est important d'utiliser `nn.LeakyReLU` comme fonction d'activation pour éviter de tuer les gradients dans les régions négatives. Sans ces gradients, le générateur ne recevra pas de mises à jour.
2. A la fin de la séquence, le discriminateur utilise `nn.Sigmoid()` pour classer l'entrée.

```python
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        output = self.main(input)
        return output.view(-1, 1).squeeze(1)
```
Ces deux classes sont initialisées comme `netG` et `netD`.

<!--
### Loss function for GAN

We use Binary Cross Entropy (BCE) between target and output.

```python
criterion = nn.BCELoss()
```
-->

### Fonction de perte pour le GAN

Nous utilisons l'entropie croisée binaire (BCE) entre la cible et la sortie.

```python
criterion = nn.BCELoss()
```


<!--
### Setup

We set up `fixed_noise` of size `opt.batchSize` and length of random vector `nz`. We also create labels for real data and generated (fake) data called `real_label` and `fake_label`, respectively.

```python
fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)
real_label = 1
fake_label = 0
```

Then we set up optimizers for discriminator and generator networks.

```python
optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
```
-->

### Configuration

Nous mettons en place un `fixed_noise` de taille `opt.batchSize` et de longueur de vecteur aléatoire `nz`. Nous créons également des labels pour les données réelles et les données générées (fausses) appelées respectivement `real_label` et `fake_label`.

```python
fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)
real_label = 1
fake_label = 0
```

Ensuite, nous mettons en place des optimiseurs pour les réseaux discriminateurs et générateurs.

```python
optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
```

<!--
### Training

Each epoch of training is divided into two steps.

**Step 1** is to update the discriminator network. This is done in two parts. First, we feed the discriminator real data coming from `dataloaders`, compute the loss between the output and `real_label`, and then accumulate gradients with backpropagation. Second, we feed the discriminator data generated by the generator network using the `fixed_noise`, compute the loss between the output and `fake_label`, and then accumulate the gradient. Finally, we use the accumulated gradients to update the parameters for the discriminator network.

Note that we detach the fake data to stop gradients from propagating to the generator while we train the discriminator.

Also note that we only need to call `zero_grad()` once in the beginning to clear the gradients so the gradients from both the real and fake data can be used for the update. The two `.backward()` calls accumulate these gradients. We finally only need one call of `optimizerD.step()` to update the parameters.

```python
# train with real
netD.zero_grad()
real_cpu = data[0].to(device)
batch_size = real_cpu.size(0)
label = torch.full((batch_size,), real_label, device=device)

output = netD(real_cpu)
errD_real = criterion(output, label)
errD_real.backward()
D_x = output.mean().item()

# train with fake
noise = torch.randn(batch_size, nz, 1, 1, device=device)
fake = netG(noise)
label.fill_(fake_label)
output = netD(fake.detach())
errD_fake = criterion(output, label)
errD_fake.backward()
D_G_z1 = output.mean().item()
errD = errD_real + errD_fake
optimizerD.step()
```

**Step 2** is to update the Generator network. This time, we feed the discriminator the fake data, but compute the loss with the `real_label`! The purpose of doing this is to train the generator to make realistic $\vect{\hat{x}}$'s.

```python
netG.zero_grad()
label.fill_(real_label)  # fake labels are real for generator cost
output = netD(fake)
errG = criterion(output, label)
errG.backward()
D_G_z2 = output.mean().item()
optimizerG.step()
```
-->

### Entraînement
Chaque époque d'entraînement est divisée en deux étapes.
**L'étape 1** consiste à mettre à jour le réseau des discriminateurs. Elle se fait en deux parties. Tout d'abord, on alimente le discriminateur en données réelles provenant des `dataloaders`, on calcule la perte entre la sortie et le `real_label`, puis on accumule des gradients avec la rétropropagation. Deuxièmement, nous alimentons le discriminateur en données générées par le réseau de générateurs en utilisant le `fixed_noise`, nous calculons la perte entre la sortie et le `fake_label`, et ensuite nous accumulons le gradient. Enfin, nous utilisons les gradients accumulés pour mettre à jour les paramètres du réseau du discriminateur.
Notez que nous détachons les fausses données pour empêcher les gradients de se propager vers le générateur pendant que nous entraînons le discriminateur.
Notez également que nous n'avons besoin d'appeler `zero_grad()` qu'une seule fois au début pour effacer les gradients afin que les gradients des données réelles et fausses puissent être utilisés pour la mise à jour. Les deux appels `.backward()` accumulent ces gradients. Nous n'avons finalement besoin que d'un seul appel de `optimizerD.step()` pour mettre à jour les paramètres.

```python
# train with real
netD.zero_grad()
real_cpu = data[0].to(device)
batch_size = real_cpu.size(0)
label = torch.full((batch_size,), real_label, device=device)

output = netD(real_cpu)
errD_real = criterion(output, label)
errD_real.backward()
D_x = output.mean().item()

# train with fake
noise = torch.randn(batch_size, nz, 1, 1, device=device)
fake = netG(noise)
label.fill_(fake_label)
output = netD(fake.detach())
errD_fake = criterion(output, label)
errD_fake.backward()
D_G_z1 = output.mean().item()
errD = errD_real + errD_fake
optimizerD.step()
```
**L'étape 2** consiste à mettre à jour le réseau générateur. Cette fois, nous alimentons le discriminateur en fausses données, mais nous calculons la perte avec le `real_label` ! Le but de cette opération est d'entraîner le générateur à faire des ${\vect{\hat{x}}$ réalistes.
```python
netG.zero_grad()
label.fill_(real_label)  # fake labels are real for generator cost
output = netD(fake)
errG = criterion(output, label)
errG.backward()
D_G_z2 = output.mean().item()
optimizerG.step()
```

