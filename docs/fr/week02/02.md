---
lang: fr
lang-ref: ch.02
title: Semaine 2
translation-date: 02 Aug 2020
translator: Loïck Bourdois
---

<!--
## Lecture part A

We start by understanding what parametrised models are and then discuss what a loss function is. We then look at Gradient-based methods and how it's used in the backpropagation algorithm in a traditional neural network. We conclude this section by learning how to implement a neural network in PyTorch followed by a discussion on a more generalized form of backpropagation.
-->


## Conférence partie A

Nous commençons par comprendre ce que sont les modèles paramétrés, puis nous discutons de ce qu'est une fonction de perte. Nous examinons ensuite les méthodes basées sur les gradients et leur utilisation dans l'algorithme de rétropropagation d'un réseau neuronal traditionnel. Nous concluons cette section en apprenant comment mettre en œuvre un réseau de neurones dans PyTorch, puis nous discutons d'une forme plus généralisée de rétropropagation.

<!--
## Lecture part B

We begin with a concrete example of backpropagation and discuss the dimensions of Jacobian matrices. We then look at various basic neural net modules and compute their gradients, followed by a brief discussion on softmax and logsoftmax. The other topic of discussion in this part is Practical Tricks for backpropagation.
-->

## Conférence partie B

Nous commençons par un exemple concret de rétropropagation et discutons des dimensions des matrices jacobiennes. Nous examinons ensuite divers modules de base des réseaux de neurones et calculons leurs gradients, puis nous discutons brièvement de softmax et de logsoftmax. L'autre sujet de discussion dans cette partie est celui des astuces pratiques pour la rétropropagation.

<!--
## Practicum

We give a brief introduction to supervised learning using artificial neural networks. We expound on the problem formulation and conventions of data used to train these networks. We also discuss how to train a neural network for multi class classification, and how to perform inference once the network is trained.
-->

## Pratique

Nous présentons brièvement l'apprentissage supervisé à l'aide de réseaux neuronaux artificiels. Nous exposons la formulation du problème et les conventions des données utilisées pour entraîner ces réseaux. Nous discutons également de la manière d’entraîner un réseau neuronal pour la classification multi-classes, et de la manière d'effectuer l'inférence une fois le réseau entraîné.

