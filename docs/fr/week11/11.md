---
lang: fr
lang-ref: ch.11
title: Semaine 11
translation-date: 11 Aug 2020
translator: Loïck Bourdois
---

<!--
## Lecture part A

In this section, we discussed about the common activation functions in Pytorch. In particular, we compared activations with kink(s) versus smooth activations - the former is preferred in a deep neural network as the latter might suffer with gradient vanishing problem. We then learned about the common loss functions in Pytorch.
-->


## Conférence partie A

Dans cette section, nous discutons des fonctions d'activation communes à Pytorch. En particulier, nous comparons les activations avec coude(s) par rapport aux activations lisses. La première est préférée dans un réseau neuronal profond car la seconde pourrait souffrir d'un problème de disparition du gradient. Nous découvrons ensuite les fonctions de perte communes à Pytorch.


<!--
## Lecture part B


In this section, we continued to learn about loss functions - in particular, margin-based losses and their applications. We then discussed how to design a good loss function for EBMs as well as examples of well-known EBM loss functions. We gave particular attention to margin-based loss function here, as well as explaining the idea of "most offending incorrect answer.
-->

## Conférence partie B

Dans cette section, nous continuons de nous informer sur les fonctions de perte - en particulier, les pertes basées sur la marge et leurs applications. Nous discutons ensuite de la manière de concevoir une bonne fonction de perte pour les EBMs ainsi que des exemples de fonctions de perte bien connues des EBMs. Nous accordons une attention particulière à la fonction de perte basée sur la marge, tout en expliquant l'idée de "réponse incorrecte la plus offensante".

<!--
## Practicum


This practicum proposed effective policy learning for driving in dense traffic. We trained multiple policies by unrolling a learned model of the real world dynamics by optimizing different cost functions. The idea is to minimize the uncertainty in the model's prediction by introducing a cost term that represents the model's divergence from the states it is trained on. 
-->

## Pratique
Nous proposons un apprentissage efficace pour la conduite dans un trafic dense. Nous entraînons de multiples politiques en déroulant un modèle appris de la dynamique du monde réel en optimisant différentes fonctions de coût. L'idée est de minimiser l'incertitude dans les prévisions du modèle en introduisant un terme de coût qui représente la divergence du modèle par rapport aux états sur lesquels il est entraîné.




