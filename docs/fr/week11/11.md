---
lang: fr
lang-ref: ch.11
title: Semaine 11
translation-date: 11 Aug 2020
translator: Loïck Bourdois
---

<!--
## Lecture part A

In this section, we discussed about the common activation functions in Pytorch. In particular, we compared activations with kink(s) versus smooth activations - the former is preferred in a deep neural network as the latter might suffer with gradient vanishing problem. We then learned about the common loss functions in Pytorch.
-->


## Cours magistral partie A

Dans cette section, nous discutons des fonctions d'activation communes dans PyTorch. En particulier, nous comparons les fonctions d'activation avec coude(s) par rapport aux fonctions d'activation lisses. La première est préférée dans un réseau neuronal profond car la seconde pourrait souffrir d'un problème de disparition du gradient. Nous découvrons ensuite les fonctions de perte communes dans PyTorch.


<!--
## Lecture part B


In this section, we continued to learn about loss functions - in particular, margin-based losses and their applications. We then discussed how to design a good loss function for EBMs as well as examples of well-known EBM loss functions. We gave particular attention to margin-based loss function here, as well as explaining the idea of "most offending incorrect answer.
-->

## Cours magistral partie B

Dans cette section, nous continuons d'aborder les fonctions de perte en particulier celles basées sur une marge et leurs applications. Nous discutons ensuite de la manière de concevoir une bonne fonction de perte pour les EBMs ainsi que des exemples de fonctions de perte bien connues des EBMs. Nous accordons une attention particulière à la fonction de perte basée sur une marge, tout en expliquant l'idée de réponse incorrecte la plus offensante.

<!--
## Practicum


This practicum proposed effective policy learning for driving in dense traffic. We trained multiple policies by unrolling a learned model of the real world dynamics by optimizing different cost functions. The idea is to minimize the uncertainty in the model's prediction by introducing a cost term that represents the model's divergence from the states it is trained on. 
-->

## Travaux dirigés
Nous proposons un apprentissage d'une politique dans le cadre d'une conduite dans un trafic dense. Nous entraînons de multiples politiques en déroulant un modèle appris de la dynamique du monde réel en optimisant différentes fonctions de coût. L'idée est de minimiser l'incertitude dans les prédictions du modèle en introduisant un terme de coût qui représente la divergence du modèle par rapport aux états sur lesquels il est entraîné.

