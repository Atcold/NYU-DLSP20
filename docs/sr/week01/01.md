---
lang: sr
lang-ref: ch.01
title: 1. Nedelja
translation-date: 13 Dec 2020
translator: Ema Pajić
---


## Lekcija, deo A

<!-- We discuss the motivation behind deep learning. We begin with the history and inspiration of deep learning. Then we discuss the history of pattern recognition and introduce gradient descent and its computation by backpropagation. Finally, we discuss the hierarchical representation of the visual cortex.
-->
Objašnjavamo motivaciju iza dubokog učenja. Počinjemo sa istorijom i inspiracijom za nastanak dubokog učenja. Zatim diskutujemo istoriju prepoznavanja oblika i uvodimo gradijentni spust i njegovo računanje propagacijom unazad. Na kraju, diskutujemo hijerarhijsku reprezentaciju vizualnog korteksa. 


## Lekcija, deo B

<!-- We first discuss the evolution of CNNs, from Fukushima to LeCun to AlexNet. We then discuss some applications of CNN's, such as image segmentation, autonomous vehicles, and medical image analysis. We discuss the hierarchical nature of deep networks and the attributes of deep networks that make them advantageous. We conclude with a discussion of generating and learning features/representations.
-->
Prvo ćemo pričati o evoluciji konvolucionih neuronskih mreža (CNN), od Fukušime i LeCun-a do AlexNet-a. Zatim ćemo videti neke primene konvolucionih neuronskih mreža kao što je segmentacija slike, autonomna vozila i analiza medicinskih slika. Na kraju objašnjavamo hijerarhijsku prirodu dubokih neuronskih mreža i svojstva koja ih čine povoljnim. Završavamo pričom o generisanju i učenju obeležja / reprezentacija.


## Praktikum

<!-- We discuss the motivation for applying transformations to data points visualized in space. We talk about Linear Algebra and the application of linear and non-linear transformations. We discuss the use of visualization to understand the function and effects of these transformations. We walk through examples in a Jupyter Notebook and conclude with a discussion of functions represented by neural networks.
-->
Prvo ćemo pričati o motivaciji za primenu transformacija na podatke vizualizovane u prostoru, zatim o linearnoj algebri i primeni linearnih i nelinearnih transformacija. Razmatramo upotrebu vizualizacije za razumevanje funkcije i efekte ovih transformacija. Prolazimo kroz primere u Jupyter Notebook-u i zaključujemo diskusijom o funkciji koju reprezentuje neuronska mreža.
