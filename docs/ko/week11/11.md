---
lang-ref: ch.11
title: 11주차
lang: ko
translation-date: 01 Aug 2020
translator: Jinwoo Oh
---


## 이론 part A

<!-- In this section, we discussed about the common activation functions in Pytorch. In particular, we compared activations with kink(s) versus smooth activations - the former is preferred in a deep neural network as the latter might suffer with gradient vanishing problem. We then learned about the common loss functions in Pytorch. -->

Part A에서는 파이토치<sup>PyTorch</sup>에서 주로 쓰이는 활성화 함수에 대해 논의하였다. 특히, 꺾인<sup>Kinks</sup> 활성화와 부드러운<sup>Smooth</sup> 활성화를 비교하였다. 부드러운 활성화는 경사 소실 문제<sup>Gradient Vanishing Problem</sup>를 보이기 때문에, 심층 신경망에서는 꺾인 활성화가 선호된다. 이어, 파이토치에서 주로 쓰이는 손실 함수<sup>Loss Function</sup>에 대해 배웠다.


## 이론 part B

<!-- In this section, we continued to learn about loss functions - in particular, margin-based losses and their applications. We then discussed how to design a good loss function for EBMs as well as examples of well-known EBM loss functions. We gave particular attention to margin-based loss function here, as well as explaining the idea of “most offending incorrect answer. -->

이 섹션에서는 손실 함수들, 특히 마진 기반 손실 함수<sup>Margin-based Loss</sup>와 이들의 응용에 대해 배웠다. 그 다음, EBM<sup>Energy-Based Model: 에너지 기반 모델</sup>에서 "좋은" 손실 함수를 설계하는 방법과 잘 알려져 있는 예시에 대해 논의하였다. 여기서는 마진 기반 손실 함수에 대해 집중적으로 보며 "가장 문제가 되는 오답"<sup>most offending incorrect answer</sup>(즉, 모든 오답 중 가장 낮은 에너지를 가진 오답)의 개념에 대해 설명을 하였다.


## 실습

<!-- This practicum proposed effective policy learning for driving in dense traffic. We trained multiple policies by unrolling a learned model of the real world dynamics by optimizing different cost functions. The idea is to minimize the uncertainty in the model’s prediction by introducing a cost term that represents the model’s divergence from the states it is trained on.-->

실습에서는 교통량이 많은 상황에서 효과적으로 운전하기 위한 정책 학습<sup>Policy Learning</sup> 방법을 제안하였다. 다양한 비용 함수를 최적화함으로써 현실의 역학 관계가 학습된 모델을 펼쳐<sup>unrolling: Backpropagation through time</sup> 여러 정책을 훈련시켰다. 이 아이디어는 훈련된 상태와 모델간의 차이를 나타내는 비용<sup>Cost</sup>이라는 개념을 도입하여 모델의 예측에 있어서 불확실성을 최소화 한다는 것이다.
