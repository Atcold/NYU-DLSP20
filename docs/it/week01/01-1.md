---
lang-ref: ch.01-1
title: Motivation of Deep Learning, and Its History and Inspiration
authors: Yunya Wang, SunJoo Park, Mark Estudillo, Justin Mae
date: 27 Jan 2020
translation-date: 1 Apr 2020
translator: Nantas Nardelli
---


## [Programma del corso](https://www.youtube.com/watch?v=0bMe_vCZo30&t=217s)

- Basi di apprendimento supervisionato (Supervised Learning), reti neurali
  (Neural Networks), apprendimento profondo (Deep Learning)
- Retropropagazione (Backpropagation), e componenti architetturali
- La rete neurale convoluzionale (CNN, Convolutional Neural Network) e le sue applicazioni
- Altre architetture per l'apprendimento profondo
- Trucchi per la regolarizazione / ottimizazione / comprensione su come
  l'apprendimento profondo funziona
- Modelli a energia
- Apprendimento auto-supervisionato e oltre


## L'ispirazione dietro all'apprendimento profondo e la sua storia

A un livello concettuale, l'apprendimento profondo è ispirato dal cervello, ma
non tutti i dettagli del cervello sono pertinenti. Nello stesso modo, ad
esempio, gli aeroplani furono inspirati dagli uccelli: i principi dietro al volo
sono gli stessi, ma i dettagli sono diversi.

La storia dell'apprendimento profondo risale a una materia ora chiamata
cibernetica. Tutto è iniziato negli anni '40 con McCulloch e Pitts. Loro
arrivarono all'idea che i neuroni sono delle unità con valori di soglia e uno
stato, attivato o disattivato). Si potrebbe costruire un circuito booleano
connettendo dei neuroni tra di loro e conducendo un processo di inferenza logica
con questi neuroni. Il cervello è sostanzialmente un processore d'inferenza
logica, poiché i neuroni sono binari. Ogni neurone calcola una somma pesata
degli ingressi, paragonando questa somma al valore di soglia. Il neurone si
attiva se questo valore è sopra la soglia, e si disattiva se è sotto. Il che è
una visione semplicizzata di come funzionano le reti neurali.

Nel 1947, Donald Hebb ebbe l'idea che i neuroni nel cervello imparano attraverso
la modifica della forza delle connessioni tra i neuroni. Questo processo si
chiama iper-apprendimento, cioè dove due neuroni che sparano insieme avranno la
loro connessione rafforzata, mentre due neuroni che non sparano insieme
l'avranno indebolita.

Nel 1949, Norbert Wiener propose i sistemi cibernetici, cioè sistemi che, avendo
sensori e attuatori, creano un ciclo di feedback (retroazione) e un sistema
auto-regolatore. Le regole dei meccanismi di feedback nell'automobile moderano
fuoriescono tutte da questo lavoro.

Nel 1957 Frank Rosenblatt propose il percettrone (Perceptron), un algoritmo di
apprendimento che modifica i pesi di reti neurali semplici.

Complessivamente, quest'idea di provare a costrurire processori intelletuali
andando a simulare molti neuroni nacque negli anni '40, decollò negli anni '50,
e morì nel fine anni '60. Le ragioni principali della morte di questo campo
furono:

- Il fatto che i ricercatori avevano usato neuroni che erano binari, senza
  individuare il fatto che, per funzionare, la retropropagazione ha bisogno di
  funzioni di attivazione che sono continue. In quel momento, i ricercatori non
  ebbero l'idea di usare neuroni continui, and non pensarono che si potesse
  addestrare i neuroni con i gradienti, poiché i neuroni binari non sono
  differenziabili.
- Usando neuroni continui, si potrebbe aver moltiplicato l'attivazione di un
  neurone con un peso per contribuire alla somma pesata. Però, prima degli anni
  '80, la moltiplicazione di due numeri, specialmente se numeri in virgola
  mobile, era particolarmente lenta. Questo risultò in un altro incentivo per
  evitare l'uso dei neuroni continui.

L'apprendimento profondo prese piede di nuovo nel 1985 con l'avvento della
retropropagazione. Nel 1995, il campo morì di nuovo, e la comunità scientifica
dell'apprendimento autonomo abbandonò l'idea delle reti neurali.
Nei primi anni del 2010, alcune persone iniziarono a usare reti neurali per il
riconoscimento vocale (Speec Processing), con miglioramenti enormi in termini di prestazioni,
vedendo presto un uso globale in campi commerciali. Nel 2013, il campo della
visione artificiale (Computer Vision) iniziò a passare all'utilizzo delle reti neurali. Nel 2016,
la stessa cosa accadde nel campo dell'elaborazione del linguaggio naturale
(Natural Language Processing). Presto, simili rivoluzioni andranno ad accadere
in robotica, controllo, e molti altri campi.


### Apprendimento supervisionato
Il $90%$ delle applicazioni dell'apprendimento profondo usa l'apprendimento
supervisionato. L'apprendimento supervisionato e' un processo attraverso il
quale uno va ad aggregare un po' di coppie di input (dati d'ingresso) / output
(prodotti di uscita), e mettere questi input dentro un processore che impara gli
output corretti. Quando gli output sono corretti, non si fa niente. Quando sono
sbagliati, uno va a sistemare i parametri del processore, correggendo l'output
verso quello che si vuole. Il trucco qua è come capire quanto correggere il
valore e quale direzione (aritmetica) usare per modificare il parametro. Questa
va a finire nel calcolo dei gradienti e della retropropagazione.

L'apprendimento supervisionato arriva dal percettrone e il modello ADALINE.
ADALINE è basato sulla stessa architettura della somma pesata degli ingressi.
Quando questa somma è sopra la soglia, il modello si attiva, mentre sotto la
soglia si disattiva.
Il percettrone è una rete neurale a due strati dove il secondo strato può essere
addestrato, mentre il primo è fisso. Nella maggior parte dei casi, il primo
strato è determinato a caso, il che viene chiamato strato associativo.


## [La storia del riconoscimento di pattern, e l'introduzione della discesa del gradiente](https://www.youtube.com/watch?v=0bMe_vCZo30&t=1461s)

Il testo successivo forma la base concettuale del riconoscimento di patter prima
che l'apprendimento profondo nacque. Il modello standard del riconoscimento di
pattern consiste in modelli classificatori che possono essere addestrati, e
nell'estrazione delle caratteristiche dei dati. L'input viene passato attraverso
un estrattore di caratteristiche, estraendo caratteristiche dell'input che sono
pertinenti e utili per esempio a rilevare un occhio quando lo scopo è quello di
rilevare una faccia.
Poi, questo vettore di caratteristiche è mandato dentro a un classificatore
addestrabile per calcolare la somma pesata, confrontandola con una soglia. In
questo caso, il classificatore addestrabile potrebbe essere un percettrone, o
una reter neurale singola. Il problema è che l'estrattore delle caratteristiche
deve essere ingegnerizzato a mano, il che significa che il riconoscimento di
pattern e la visione artificiale vanno così a concentrarsi su estrattori di
caratteristiche che vengono progettati per risolvere particolari problemi,
invece di svilupparne tali che possono essere usati su classificatori
addestrabili generali.

Dopo l'emergenza e lo sviluppo dell'apprendimento profondo, questi processo a 2
stadi cambiò in una sequenza di moduli. Ogni modulo ha dei parametri che possono
essere aggiustati, e delle nonlinearità. L'utilizzo di molteplici strati insieme
è la ragione per il quale la materia si chiama apprendimento "profondo". La
ragione per il quale si utilizzazono non-linearità invece che linearità si può
ritrovare riflettendo sul fatto che due strati lineari possono diventare uno strato
lineare visto che la composizione di due funzioni lineari è lineare.

L'architettura a molteplici strati più semplice con parametri aggiustabili e
non-linearità potrebbe essere così: l'input è rappresentato da un vettore
come un immagine o un pezzo d'audio. L'input è moltiplicato da una matrice di
pesi il quale coefficente è un parametro aggiustabile. Poi ogni componente del
vettore risultante viene passato attraverso una funzione non-lineare come la
ReLU. Ripetendo questo processo, il tutto divento una rete neurale di base. La
ragione per il quale viene chiamata rete neurale è che l'architettura calcola la
somma pesata dei componenti del vettore di entrata per le file correspondenti
alle righe di una matrice.

Tornando all'apprendimento supervisionato, stiamo confrontando l'output
risultante con il valore obiettivo che ottimizza la funzione obiettiva, che sta
calcolando la distanza / penalità / divergenza tra il risultato e l'obiettivo,
facendo la media di questo funzione di costo su tutto il set di addestramento.
Questa è la meta che vogliamo minimizzare. In altre parole, vogliamo trovare il
valore dei parametri che minimizza questa media.

Il metodo per trovare questo valore è il calcolo dei gradienti. Per esempio, se
siamo persi in una montagna regolare (o liscia) in una notte nebbiosa, e
vogliamo andare al villaggio che si trova a valle, una maniera potrbbe essere
girarsi intorno per trovare la via più ripida per andare giù, e fare il passo
più piccolo possibile. Questa direzione è il gradiente (negativo). Assumendo che
la valle sia convessa, potremmo raggiungere il villaggio.

La maniera più efficiente per fare questo si chiama discesa stocastica del
gradiente (SGD, Stochastic Gradient Descent). Visto che voglia minimizzare la
perdita media su tutto il set di apprendimento, possiamo prendere un campione, o
un piccolo gruppo di campioni, e calcolare l'errore, per poi usare la discesa
del gradiente. Quindi prendiamo un nuovo campione, calcoliamo un nuovo valore di
errore, e arriviamo a un gradiente che normalmente ci dà una direzione diversa.
Due delle principali ragioni dietro l'utilizzo di SGD è che aiuta il modello a
convergere velocemente dal punto di vista empirico se il set di apprendimento è
molto largo, con l'aggiunta che ti fornisce miglior generalizzazione, il che
significa avere prestazioni simili su diversi set di dati.


### [Calcolare gradienti usando la retropropagazione](https://www.youtube.com/watch?v=0bMe_vCZo30&t=2336s)

Il calcolo dei gradienti con la retropropagazione è un'applicazione pratica
della regola della catena. L'equazione della retropropagazione per i gradienti
dell'input è la seguente:

$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{x}_{i - 1}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial \boldsymbol{x}_i}{\partial \boldsymbol{x}_{i - 1}} \\
\frac{\partial C}{\partial \boldsymbol{x}_{i - 1}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial f_i(\boldsymbol{x}_{i - 1}, \boldsymbol{w}_i)}{\partial \boldsymbol{x}_{i - 1}}
\end{aligned}
$$

Mentre l'equazione per i gradienti dei pesi è la seguente:

$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{w}_{i}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial \boldsymbol{x}_i}{\partial \boldsymbol{w}_{i}} \\
\frac{\partial C}{\partial \boldsymbol{w}_{i}} &= \frac{\partial C}{\partial \boldsymbol{x}_i}\frac{\partial f_i(\boldsymbol{x}_{i - 1}, \boldsymbol{w}_i)}{\partial \boldsymbol{w}_{i}}
\end{aligned}
$$

Nota bene che invece di usare input di numeri scalari, questi sono input
vettoriali o, più generalmente, input multidimensionali.
La retropropagazione permette di calcolare la derivativa della differenza
dell'output che vuoi and dell'output prodotto (che è il valore della funzione
obiettivo) rispetto a qualsiasi valore dentro alla rete. La retropropagazione è
essenziale, visto che può essere usata su molteplici strati.

È importante considerare come interpretare gli input. Per esempio, un'immagine
di $$256\times256$$ ha bisogno di una matrice con 200,000 valori. Queste sono
matrici enormi che la rete neurale dovrà andare a gestire. Non sarebbe pratico
utilizzare questo tipo di matrici, quindi è importante fare delle ipotesi
riguardo la struttura della matrice.


## Rappresentazioni gerachice della corteccia visiva

Gli esperimenti di Fukushima ci hanno permesso di capire come il nostro cervello
interpreta il segnale che viene dai nostri occhi. In sintesi, fu scoperto che i
neuroni di fronte alla retina comprimono il segnale (il quale processo si chiama
normalizzazione del contrasto), e che questo segnale viaggia dagli occhi al
cervello. Dopo, l'immagine viene elaborata per fasi e alcuni neuroni vengono
attivati a seconda di determinate categorie. Quindi, la corteccia visiva usa il
riconoscimento di pattern in modo gerarchico.

Alcuni esperimenti nei quali ricercatori hanno colipto gli elettrodi in aree
specifiche della corteccia visiva, più precisamente l'area V1, fece realizzare a
questi che determinati neuroni reagiscono per motivi che appaiono in un area
molto piccola del campo visivo, reagendo allo stesso modo con neuroni vicini nel
campo visivo.
Per di più, neuroni che reagiscono nello stesso campo visivo, reagiscono a
diversi tipi di bordi in maniera organizzata (per esempio per bordi verticali, o
orizzontali). 
È anche importante sottolineare come esista un'idea che il processovisivo sia
sostanzialmente un processo feed-forward. Quindi, in qualche modo, il processo
di riconoscimento rapido può essere fatto senza connessioni ricorrenti.
