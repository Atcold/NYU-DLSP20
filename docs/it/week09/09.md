---
lang: it
lang-ref: ch.09
title: Settimana 9
translation-date: 24 May 2020
translator: Marco Zullich
---

## Lezione parte A

<!-- ## Lecture part A -->

Discutiamo degli *autoencoder* discriminativi ricorrenti sparsi e della sparsità di gruppo. L'idea di base è la combinazione della codificazione sparsa coll'addestramento discriminativo. Approfondiamo la strutturazione di una rete con *autoencoder* ricorrente simile a LISTA e con un decodificatore. Dopodiché, discutiamo su come usare la sparsità di gruppo ai fini dell'estrazione di caratteristiche invarianti.

<!-- We discussed discriminative recurrent sparse auto-encoders and group sparsity. The main idea was how to combine sparse coding with discriminative training. We went through how to structure a network with a recurrent autoencoder similar to LISTA and a decoder. Then we discussed how to use group sparsity to extract invariant features. -->

## Lezione parte B

<!-- ## Lecture part B -->

In questa sezione, parliamo dei *World Models* per controllo autonomo, incluse le archietture delle reti neurali e gli schemi di addestramento. Dopodiché, discutiamo della differenza fra i *World Models* e l'apprendimento per rinforzo (RL, *Reinforcement Learning*). Infine, studiamo le reti generative avversarie (GAN, *Generative Adversarial Network*, anche conosciuta in italiano come *rete antagonista generativa*) come modelli basati sull'energia con metodo contrastivo.

<!-- In this section, we talked about the World Models for autonomous control including the neural network architecture and training schema. Then, we discussed the difference between World Models and Reinforcement Learning (RL). Finally, we studied Generative Adversarial Networks (GANs) in terms of energy-based model with the contrastive method. -->

## Pratica

<!-- ## Practicum -->

Durante la pratica di questa settimana, esploriamo le GAN e come possono produrre modelli generativi realistici. Dopodiché compariamo le GAN con i VAE di cui alla settimana 8 per evidenziare differenze chiave fra le due reti. Dopodiché, discutiamo di numerose limitazioni del modello delle GAN. Infine, diamo un'occhiata al codice sorgente per l'esempio di Pytorch sulle reti generative avversarie convoluzionali profonde (DCGAN, *Deep Convolutional* GAN).

<!-- During this week's practicum, we explored Generative Adversarial Networks (GANs) and how they can produce realistic generative models. We then compared GANs with VAEs from week 8 to highlight key differences between two networks. Next, we discussed several model limitations of GANs. Finally, we looked at the source code for the PyTorch example Deep Convolutional Generative Adversarial Networks (DCGAN). -->
