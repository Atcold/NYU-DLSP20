---
lang: it
lang-ref: ch.09
title: Settimana 9
translation-date: 24 May 2020
translator: Marco Zullich
---

## Lezione parte A

<!-- ## Lecture part A -->

Discutiamo degli *autoencoder* discriminativi ricorrenti sparsi e della sparsità di gruppo. L'idea di base è la combinazione della codificazione sparsa con l'addestramento discriminativo. Approfondiamo la strutturazione di una rete con *autoencoder* ricorrente simile a LISTA e con un decodificatore. Dopodiché, discutiamo su come usare la sparsità di gruppo ai fini dell'estrazione di caratteristiche invarianti.

<!-- We discussed discriminative recurrent sparse auto-encoders and group sparsity. The main idea was how to combine sparse coding with discriminative training. We went through how to structure a network with a recurrent autoencoder similar to LISTA and a decoder. Then we discussed how to use group sparsity to extract invariant features. -->

## Lezione parte B

<!-- ## Lecture part B -->

In questa sezione, parliamo dei modelli della realtà (*world models*) per controllo autonomo, incluse le architetture delle reti neurali e gli schemi di addestramento. Dopodiché, discutiamo della differenza fra i modelli della realtà e l'apprendimento per rinforzo (*Reinforcement Learning, RL*). Infine, studiamo le reti generative avversarie (*Generative Adversarial Network, GAN*, anche conosciuta in italiano come "rete antagonista generativa") come modelli basati sull'energia con metodo contrastivo.

<!-- In this section, we talked about the World Models for autonomous control including the neural network architecture and training schema. Then, we discussed the difference between World Models and Reinforcement Learning (RL). Finally, we studied Generative Adversarial Networks (GANs) in terms of energy-based model with the contrastive method. -->

## Pratica

<!-- ## Practicum -->

Durante la pratica di questa settimana, esploriamo le _GAN_ e come possono produrre modelli generativi realistici. Dopodiché compariamo le _GAN_ con gli autoencoder variazionale (_variational autoencoder, VAE_) presentati nella settimana 8 per evidenziare le differenze chiave fra le due reti. Dopodiché, discutiamo di numerose limitazioni del modello delle _GAN_. Infine, andiamo a vedere il codice sorgente (_source code_) per l'esempio di Pytorch sulle reti generative avversarie convoluzionali profonde (*Deep Convolutional GAN, DCGAN*).

<!-- During this week's practicum, we explored Generative Adversarial Networks (GANs) and how they can produce realistic generative models. We then compared GANs with VAEs from week 8 to highlight key differences between two networks. Next, we discussed several model limitations of GANs. Finally, we looked at the source code for the PyTorch example Deep Convolutional Generative Adversarial Networks (DCGAN). -->
