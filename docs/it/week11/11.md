---
lang: it
lang-ref: ch.11
title: Settimana 11
translation-date: 15 Aug 2020
translator: Francesca Guiso
---

## Lezione parte A
<!-- ## Lecture part A -->

In questa sezione, abbiamo discusso di alcune funzioni di attivazione comuni di PyTorch. In particolare, abbiamo messo a confronto due tipi di funzioni di attivazione: non-differenziabili (es. con punti angolosi) e differenziabili (lisce). Le prime sono preferibili per le reti neurali profonde poiché le seconde potrebbero essere soggette al problema dello svanimento del gradiente (_vanishing gradient problem_). Poi, abbiamo discusso delle funzioni di perdita comuni di PyTorch.
<!-- In this section, we discussed about the common activation functions in Pytorch. In particular, we compared activations with kink(s) versus smooth activations - the former is preferred in a deep neural network as the latter might suffer with gradient vanishing problem. We then learned about the common loss functions in Pytorch. -->

## Lezione parte B
<!-- ## Lecture part B -->

In questa sezione, abbiamo continuato la discussione sulle funzioni di perdita - in particolare le funzioni di perdita a margine (*margin-based loss functions*) e le loro applicazioni. Abbiamo poi discusso come concepire una funzione di perdita adeguata ai modelli ad energia (*energy-based models, EBM*) e abbiamo visto degli esempi ben noti di funzioni di perdita per gli EBM. Abbiamo dato particolare attenzione alle funzioni di perdita a margine e al concetto di "errore più grave".
<!-- In this section, we continued to learn about loss functions - in particular, margin-based losses and their applications. We then discussed how to design a good loss function for EBMs as well as examples of well-known EBM loss functions. We gave particular attention to margin-based loss function here, as well as explaining the idea of "most offending incorrect answer. -->

## Pratica
<!-- ## Practicum -->

Questa pratica propone una politica di apprendimento efficace per la guida nel traffico denso. Abbiamo addestrato diverse politiche, "srotolando" un modello addestrato sulla realtà, tramite l'ottimizzazione di diverse funzioni di costo (*cost functions*). L'idea è di introdurre un termine di costo che rappresenta la "distanza" del modello dagli stati su cui è stato addestrato, minimizzandone così l'incertezza nelle previsioni.
<!-- This practicum proposed effective policy learning for driving in dense traffic. We trained multiple policies by unrolling a learned model of the real world dynamics by optimizing different cost functions. The idea is to minimize the uncertainty in the model's prediction by introducing a cost term that represents the model's divergence from the states it is trained on.   -->
