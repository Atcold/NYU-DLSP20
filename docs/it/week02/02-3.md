---
lang-ref: ch.02-3
lang: it
title: Reti Neurali Artificiali (ANNs)
authors:
date: 4 February 2020
translation-date: 30 Mar 2020
translator: Yuri Gardinazzi
typora-root-url: 02-3
---

## [Apprendimento supervisionato per la classificazione](https://www.youtube.com/watch?v=WAn6lip5oWk&t=150s)

* Considera **Fig. 1(a)** sotto. I punti in questo grafico si trovano sui rami della spirale, e vivono in $\R^2$. Ogni colore rappresenta una classe. IL numero di classi uniche è $K = 3$. Questo è rappresentato matematicamente da **Eqn. 1(a)**.

* **Fig. 1(b)** Mostra una spirale simile, con agguinto del rumore gaussiano. Questo è rappresentato matematicamente da **Eqn. 1(b)**.

  In entrambi i casi i punti non sono linearmente separabili.

  <center>
  <table border="0">
    <td>
      <center>
    <img src="{{site.baseurl}}/images/week02/02-3/clean-spiral.png" width="350px" /><br>
       <b>Fig. 1(a)</b> "Clean" 2D spiral
       </center>
      </td>
      <td>
      <center>
      <img src="{{site.baseurl}}/images/week02/02-3/noisy-spiral.png" width="350px" /><br>
       <b>Fig. 1(b)</b> "Noisy" 2D spiral
       </center>
      </td>
  </table>
  </center>


$$
X_{k}(t)=t\left(\begin{array}{c}{\sin \left[\frac{2 \pi}{K}(2 t+k-1)\right]} \\ {\cos \left[\frac{2 \pi}{K}(2 t+k-1)\right]}\end{array}\right) \\
0 \leq t \leq 1, \quad k=1, ..., K
$$

  <center><b>Eqn. 1(a)</b> </center>

$$
  X_{k}(t)=t\left(\begin{array}{c}{\sin \left[\frac{2 \pi}{K}(2 t+k-1 +\mathcal{N}\left(0, \sigma^{2}\right))\right]} \\ {\cos \left[\frac{2 \pi}{K}(2 t+k-1 +\mathcal{N}\left(0, \sigma^{2}\right))\right]}\end{array}\right)\\0 \leq t \leq 1, \quad k=1, ..., K
$$

<center><b>Eqn. 1(b)</b></center>

Cosa vuol dire eseguire una  **classificazione**? Si consideri il caso della **regressione logistica**. Se applicassimo la regressione logistica per classificare questi dati, creerebbe un insieme di **piani lineari** (confini delle decisioni) nel tentativo di separare i dati nelle classi. Il problema di questa soluzione è che in ogni regione ci sono punti che appartengono a diverse classi. I rami della spirale incrociano i confini lineari (linear decision boundaries). Questa **non** è una buona soluzione!

**Come lo sistemiamo?** Trasformiamo il spazio in input in modo che i dati siano forzati a essere linearmente separabili. Nel corso dell'allenamento della rete neurale faremo questo, I confini impareranno ad adattarsi alla distribuzione dei dati d'allenamento.

**Nota:** Una rete neurale è sempre rappresentata dal **basso all'alto**. Il primo strato è in basso, e l'ultimo è in alto. QUesto perché concettualmente i dati in input sono caratteristiche a basso livello per qualsiasi compito che vuole svolgere la rete neurale. Come i dati attrasversano **verso l'alto** la rete ogni strato successivo estrae caratteristiche di livello più alto.


## Dati d'allenamento

La scorsa settimana, abbiamo visto che una rete neurale appena inizializzata trasforma il suo input in modo arbitrario. Questa trasformazione, tuttavia, non è **(inizialmente)** di valido aiuto nell'risolvere i suoi obiettivi. Esploriamo come, usando i dati, possiamo forzare la trasformazione per avere qualche informazione rilevante per il compito da svolgere. I dati seguenti sono utilizzati per l'allenamento di una rete.

* $\vect{X}$ rappresenta i dati in input, una matrice di dimensione $m$ (Numero dei dati d'allenamento) x $n$ (Dimensione di ogni punto in input). Nel caso dei dati delle figure  **1(a)** e **1(b)**, $n = 2$.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/training-data.png" width="600px" /><br>
<b>Fig. 2</b> Dati d'allenamento
</center>

* Vettore $\vect{c}$ e matrice $\boldsymbol{Y}$ rappresentano insieme le classi per ognuno dei punti $m$. Nell'esempio sopra ci sono $3$ classi distinte.

  * $c_i \in \lbrace 1, 2, \cdots, K \rbrace$, e $\vect{c} \in \R^m$. Tuttavia, potremmo non usare $\vect{c}$ come dati d'allenamento. Se usiamo etichette per le classi numeriche $c_i \in \lbrace 1, 2, \cdots, K \rbrace$, la rete potrebbe dedurre un ordine delle classi che non è rappresentativo della distribuzione dei dati.
  * Per aggirare questo problema, usiamo una **codifica one-hot** (one-hot encoding). Per ogni etichetta $c_i$, un vettore di zeri $K$ dimensionale $\vect{y}^{(i)}$ viene creato, che ha il $c_i$-th elemento settato a 1 $1$ (guarda **Fig. 3** sotto).

<center>
<img src="{{site.baseurl}}/images/week02/02-3/one-hot.png" width="250px" /><br>
<b>Fig. 3</b> Codifica one-hot
</center>

  * Tuttavia, $\boldsymbol Y \in \R^{m \times K}$. Questa matrice può essere pensata come se avesse una sorta di massa probabilistica, che è totalmente concentrata in uno dei $$K$$ punti.


## Fully (FC) connected layers / Strati completamente connessi

Ora daremo un'occhiata a una rete completamente connessa (FC), e come funziona.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/FC-net.png" height="250px" /><br>
<b>Fig. 4</b> Rete completamente connessa
</center>

Si consideri la rete mostra sopra nella **Fig. 4**. Il dato in input,$\boldsymbol x$, è soggetto a una trasformazione affine definita da $ \boldsymbol W_h$, seguita da una trasformazione non lineare.
IL risultato di questa trasformazione non lineare è denotato da $\boldsymbol h$, rappresentando un output **nascosto** , i.e. uno che non è **visto** dall'esterno della rete. Questo è seguito da un'altra trasformazione affine ($\boldsymbol W_y), seguita da un'altra trasformazione non lineare. Questo produce l'output finale $\boldsymbol{ \hat{y}} $. Questa rete può essere rappresentata matematicamente dalle equazioni in  **Eqn. 2** sotto. $$f$$ e $$g$$ are sono entrambi non lineari.

$$
\begin{aligned}
&\boldsymbol h=f\left(\boldsymbol{W}_{h} \boldsymbol x+ \boldsymbol b_{h}\right)\\
&\boldsymbol{\hat{y}}=g\left(\boldsymbol{W}_{y} \boldsymbol h+ \boldsymbol b_{y}\right)
\end{aligned}
$$

<center><b>Eqn. 2</b> Matematica dietro una rete FC</center>

Una rete neurale basilare come quella mostrata sopra è semplicemente un insieme di coppie successive, con ogni coppia che è una trasformazione affine seguita da una operazione non lineare (schiacciamento (squashing)). Le funzioni non lineari usate di frequente sono ReLu, Sigma (Sigmoud), tangente iperbolica e Softmax

La rete mostrata sopra è una rete a 3 strati:

 1. neurone input
 2. neurone nascosto
 3. neurone output

Tuttavia, una rete neurale a $3$ strati neural network ha $2$ trasformazioni affini. Questo può esse estrapolato da una rete a $n$ strati.

Ora spostiamoci su un caso più complicato.

Facciamo un caso con 3 strati nascosti, completamente connesso in ogni strato. Un illustrazione può essere trovat nella **Fig. 5**

<center>
<img src="{{site.baseurl}}/images/week02/02-3/pre-inference4layers.png" /><br>
<b>Fig. 5</b> Rete neurale con 3 strati nascosti.
</center>

Si consideri il neruone $j$ nel secondo strato. La sua funzione d'attivazione è:

$$
a^{(2)}_j = f(\boldsymbol w^{(j)} \boldsymbol x + b_j) = f\Big( \big(\sum_{i=1}^n w_i^{(j)} x_i\big) +b_j ) \Big)
$$

Dvve $\vect{w}^{(j)}$ è la $j$-esima riga di $\vect{W}^{(1)}$.

Nota che l'attivazione dello strato di input in questo caso è l'identità. Gli strati nascosti possono avere funzioni d'attivazione come ReLU, tangente iperbolica, Sigma (sigmoid), soft (Arg)max, ecc.

L'attivazione dell'ultimo laye in generale dipenderebbe dal caso d'uso, come spiegato in questo [this](https://piazza.com/class/k5spqaanqk51ks?cid=36) Piazza post.


## Rete neurale (inferenza)

Ripensiamo alla rete a 3 strati (input, nascosto, output) ancora, come si vede nella **Fig. 6**.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/2-layer-inference.png" height="250px"/><br>
<b>Fig. 6</b> Rete neurale a tre strati
</center>

A che tipo di funzioni stiamo guardando?

$$
\boldsymbol {\hat{y}} = \boldsymbol{\hat{y}(x)}, \boldsymbol{\hat{y}}: \mathbb{R}^n \rightarrow \mathbb{R}^K, \boldsymbol{x} \mapsto \boldsymbol{\hat{y}}
$$

Tuttavia, è utile visualizzare che c'è uno strato nascosto, e la mappatura (mapping) può essere espansa come:


$$
\boldsymbol{\hat{y}}: \mathbb{R}^{n} \rightarrow \mathbb{R}^d \rightarrow \mathbb{R}^K, d \gg n, K
$$

Come dovrebbe apparire un esempio di configurazione per i casi sopra? In questo caso, uno ha dimensione di input due ($n=2$), il singolo stratto nascosto potrebbe avere dimensione di 1000 ($d = 1000$), e noi abbiamo 3 classi ($C=3$). Ci sono buone ragioni pratiche per non avere così tanti neuroni in uno strato nascosto, cos' avrebbe senso divire il signolo strato nascosto in 3 con 10 neuroni ciascuno ($1000 \rightarrow 10 \times 10 \times 10$).


## [Rete neurale (allenamento I)](https://www.youtube.com/watch?v=WAn6lip5oWk&t=822s)

A cosa dovrebbe assomigliare il tipico allenamento? È utile formulare questa domanda nella terminologia standard di perdite (losses).

Prima, reintroduciamo la soft (arg)max ed esplicitiamo che è una funzione d'attivazione comune per l'ultimo strato, quando si usa una perdita negativa simil-log, in casi di predizione di più classi.
Come constatato dal Professore LeCUn nella lezione, questo perché si ottengono gradienti migliori rispetto all'usare Sigma e perdita quadratica (square loss). IN aggiunta, l'ultimo layer sarà pronto per essere normalizzato (la somma di tutti i neuroni nell'ultimo layer viene 1), in un modo che è migliore per i metodi gradiente rispetto alla normalizzazione (dividere per la norma).

La soft (arg)max  darà logit nell'ultimo strato che assomiglieranno a questo:
The soft (arg)max will give you logits in the last layer that look like this:

$$
\text{soft{(arg)}max}(\boldsymbol{l})[c] = \frac{ \exp(\boldsymbol{l}[c])}   {\sum^K_{k=1} \exp(\boldsymbol{l}[k])}  \in (0, 1)
$$

È importante norae che l'insieme non è chiuso perché la funzione esponenziale è strettamente positiva per natura.

Dato un insieme di predizioni $\matr{\hat{Y}}$, la perdita sarà:


$$
\mathcal{L}(\boldsymbol{\hat{Y}}, \boldsymbol{c}) = \frac{1}{m} \sum_{i=1}^m \ell(\boldsymbol{\hat{y}_i}, c_i), \quad
\ell(\boldsymbol{\hat{y}}, c) = -\log(\boldsymbol{\hat{y}}[c])
$$

Qui c denota la classe integer, non la rappresentazione della codifica one-hot

Facciamo due esempi, uno dove l'esempio è correttamente classificato, e uno dove non lo è.


Diciamo

$$
\boldsymbol{x}, c = 1 \Rightarrow \boldsymbol{y} =
{\footnotesize\begin{pmatrix}
1 \\
0 \\
0
\end{pmatrix}}
$$

Qual è l'istanza di perdità più corretta?

Per il caso di una *quasi perfetta predizione* ($\sim$ means *circa*):

$$
\hat{\boldsymbol{y}}(\boldsymbol{x}) =
{\footnotesize\begin{pmatrix} \sim 1 \\ \sim 0 \\ \sim 0 \end{pmatrix}}
 \Rightarrow \ell \left(
{\footnotesize\begin{pmatrix} \sim 1 \\ \sim 0 \\ \sim 0 \end{pmatrix}}
, 1\right) \rightarrow 0^{+}
$$

Per il caso di una *q*uasi totalmente sbagliata*:

$$ \hat{\boldsymbol{y}}(\boldsymbol{x}) =
{\footnotesize\begin{pmatrix} \sim 0 \\ \sim 1 \\ \sim 0 \end{pmatrix}}
\Rightarrow \ell \left(
{\footnotesize\begin{pmatrix} \sim 0 \\ \sim 1 \\ \sim 0 \end{pmatrix}}
, 1\right) \rightarrow +\infty  $$

Nota negli esempi sopra, $\sim 0 \rightarrow 0^{+}$ e $\sim 1 \rightarrow 1^{-}$. Perché questo? Prendi un minuti per pensarci.

**Nota**:  è importante sapere che se usi `CrossEntropyLoss`, avrai `LogSoftMax` e un comportamento simil-log `NLLLoss` uniti insieme, quindi non farlo due volte!

## [Rete neurale (allenamento II)](https://www.youtube.com/watch?v=WAn6lip5oWk&t=2188s)

Per l'allenamento, aggregriamo tutti i parametri allenabili -- matrici peso e bias -- in una collezione che chiamiamo  $\mathbf{\Theta} = \lbrace\boldsymbol{W_h, b_h, W_y, b_y} \rbrace$.
Questo ci permette di scrivere la funzione obiettivo o di perdita come:

$$
J \left( \mathbf{\Theta} \right) = \mathcal{L} \left( \boldsymbol{\hat{Y}} \left( \mathbf{\Theta} \right), \boldsymbol c \right) \in \mathbb{R}^{+}
$$

Questo fa si che la funzione di perdita dipenda dall'output della rete
$\boldsymbol {\hat{Y}} \left( \mathbf{\Theta} \right)$, cosicché possiamo trasformarlo in un problema di ottimizzazione.

Una semplice illustrazione di come funziona può essere vista nella
**Fig. 7**, dove $J(\vartheta)$, è la funzione che dobbiamo minimizzare, ha solo un parametro scalare $\vartheta$.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/1-GD.png" style="zoom: 60%; background-color:#DCDCDC;" /><br>
<b>Fig. 7</b> Ottimizzazione di una funzione attraverso la discesa del gradiente.
</center>

Prendiamo un punto di inizializzazione casuale $\vartheta_0$ -- con associata una funzione di perdita $J(\vartheta_0)$. Possiamo calcolare la derivata calcolata nel punto  $J'(\vartheta_0) = \frac{\text{d} J(\vartheta)}{\text{d} \vartheta} (\vartheta_0)$. In questo caso, la pendenza della derivata è positiva. quindi dobbiamo fare un passo nel gradiente discendente più ripido. In questo caso è $-\frac{\text{d} J(\vartheta)}{\text{d} \vartheta}(\vartheta_0)$.

La ripetizione iterativa di questo processo è conosciuta come discesa del gradiente. I metodi Gradiente sono gli strumenti principali per allenare una rete neurale.

Per poter calcolare i gradienti necessari, dobbiamo utilizzare la retropropagazione

$$ \frac{\partial \, J(\mathbf{\Theta})}{\partial \, \boldsymbol{W_y}} = \frac{\partial \, J(\mathbf{\Theta})}{\partial \, \boldsymbol{\hat{y}}} \; \frac{\partial \, \boldsymbol{\hat{y}}}{\partial \, \boldsymbol{W_y}} \quad \quad \quad  \frac{\partial \, J(\mathbf{\Theta})}{\partial \, \boldsymbol{W_h}} = \frac{\partial \, J(\mathbf{\Theta})}{\partial \, \boldsymbol{\hat{y}}} \; \frac{\partial \, \boldsymbol{\hat{y}}}{\partial \, \boldsymbol h} \;\frac{\partial \, \boldsymbol h}{\partial \, \boldsymbol{W_h}} $$


## Classificazione spirale - Jupyter notebook

Il notebook jupyer può essere trovato [qui](https://github.com/Atcold/pytorch-Deep-Learning-Minicourse/blob/master/04-spiral_classification.ipynb). Per lanciare il notebook, assicurati di aver l'ambiente `the dl-minicourse`installato come specificato in [README.md](https://github.com/Atcold/pytorch-Deep-Learning-Minicourse/blob/master/README.md).

La spiegazione di come usare `torch.device()` può essere trovata nelle [note dell'ultima settimana](https://atcold.github.io/pytorch-Deep-Learning-Minicourse/en/week01/01-3/).

Come prima, andremo a lavorare coi punti in $\mathbb{R}^2$ con 3 diverse categorie - in red, yellow and blue - come si può vedere nella **Fig. 8**.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/2-data.png" style="zoom: 50%; background-color:#DCDCDC;" /><br>
<b>Fig. 8</b> Classificazione della spirale - dati.
</center>

`nn.Sequential()` è un container, che passa i moduli al costruttori cosicché sono aggiunti; `nn.linear()` non è quel che sembra perché applica una trasformazione **affine** ai dati che gli arrivano: $\boldsymbol y = \boldsymbol W \boldsymbol x + \boldsymbol b$. Per più informazioni guarda [PyTorch documentation](https://pytorch.org/docs/stable/nn.html).

Ricorda, una trasformazione affine può essere 5 cose: rotazione, riflessione, traslazione, ridimensionamento (scaling) e taglio (shearing)

Come si può vedere nella**Fig. 9**, dove provando a separare i dati della spirale con confini lineari - usando solo i moduli `nn.linear()`, senza non linearità tra loro - il miglior risultato che possiamo avere è un accuratezza del 50%.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/3-linear.png" style="zoom: 60%; background-color:#DCDCDC;" /><br>
<b>Fig. 9</b> Confini di decisione lineari(Linear decision boundaries).
</center>

Quando andiamo da un modello lineare a uno con due moduli `nn.linear()` e un `nn.ReLU()` tra loro, l'accuratezza arriva fino al 95%. Questo perché i confini diventano non lineari e si adattano molto meglio alla forma della spirale formata dai dati, come si può vedere nella **Fig. 10**.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/4-non-linear.png" style="zoom: 64%; background-color:#DCDCDC;" /><br>
    <b>Fig. 10</b> Confini decisionali non lineari.
</center>

Un esempio di un problema di regressione che non può essere risolto correttamente con una regressione lineare, ma può essere risolto facilmente con la stessa struttura della rete può essere visto in [questo notebook](https://github.com/Atcold/pytorch-Deep-Learning-Minicourse/blob/master/05-regression.ipynb) e **Fig. 11**, che mostra 10 diverse reti, dove 5 hanno una  funzione di collegamento `nn.ReLU()` e 5 hanno una `nn.Tanh()`. Il primo è una funzione lineare a tratti, mentre la seconda è una regressione continua e liscia.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/5-nn-reg.png" style="zoom: 64%; background-color:#DCDCDC;" /><br>
<b>Fig. 11</b>: 10 Reti neurali, con la loro varianza e deviazione standard.<br>
Sinistra: Cinque reti <code>ReLU</code>. Destra: Cinque reti <code>tanh</code>.
</center>

Le linee gialle e verdi mostrano la deviazione standard e la varianza per le reti, Usando queste è utile per qualcosa di simile a un "intervallo di confidenza" - dato che  le funzioni danno una singola predizione per output- Usando insieme la predizione della varianza ci permette di stimare l'incertezza di una predizione che è stata fatta. L'importanza di questo può essere visto nella **Fig. 12**, dove abbiamo esteso le funzione di decisione al di fuori dell'intervallo di allenamento e queste tendono verso +\infty, -\infty$.

<center>
<img src="{{site.baseurl}}/images/week02/02-3/6-nn-confidence.png" style="zoom: 64%; background-color:#DCDCDC;" /><br>
<b>Fig. 12</b> Rete neurale,con varianza e deviazione standard, fuori dall'intervallo di allenamento.<br>
Sinistra: Cinque reti <code>ReLU</code>. Destra: Five reti <code>tanh</code>.
</center>

Per allenare ogni Rete Neurale usando Pytoch, hai bisogno di 5 fondamentali passi nel ciclo di allenamento :

1. `output = model(input)` è il passo avanti del modello, che prende l'input e genera l'output.
2. `J = loss(output, target <or> label)` prende l'output del modello e calcola la perdita dell'allenamento rispetto all'obiettivo o classe vera.
3. `model.zero_grad()` pulisce i calcoli del gradiente, cosicché non saranno accumulati al passo successivo.
4. `J.backward()` effettua una retropropagazione e accumulazione: Calcola $\nabla_\texttt{x} J$ per ogni variabile $\texttt{x}$ per la quale è specificato `requires_grad=True`. Questi sono accumulati nel gradiente di ogni variabile: $\texttt{x.grad} \gets \texttt{x.grad} +  \nabla_\texttt{x} J$.
5. `optimiser.step()` effettua uno step in discesa gradiente: $\vartheta \gets \vartheta - \eta\, \nabla_\vartheta J$.

Quando si allena una NN, è molto probabile che avrai bisogno di questi 5 step nell'ordine in cui sono stati presentati.

