---
lang-ref: ch.10
lang: it
title: Settimana 10
translator: Marco Zullich
translation-date: 10 Jul 2020
---


## Lezione parte A

In questa sezione, comprendiamo la motivazione dietro all'apprendimento auto-supervisionato (*Self-Supervised Learning*, SSL), definiamo che cos'è e ne vediamo delle applicazioni nell'NLP (elaborazione del linguaggio naturale, *Natural Language Processing*) e nella visione artificiale. Comprendiamo inoltre come i *c.d.* *compiti di pretesto* (*pretext tasks*) aiutino l'SSL e ne osserviamo alcuni esempi in immagini, video e video con audio. Infine, proviamo a ottenere un'intuizione dietro alla rappresentazione imparata dai compiti di pretesto.

<!-- In this section, we understand the motivation behind Self-Supervised Learning (SSL), define what it is and see some of its applications in NLP and Computer Vision. We understand how pretext tasks aid with SSL and see some example pretext tasks in images, videos and videos with sound. Finally, we try to get an intuition behind the representation learned by pretext tasks. -->


## Lezione parte B

In questa sezione, discutiamo dei limiti dei compiti di pretesto, definiamo le caratteristiche che distinguono una buona caratteristica pre-addestrata e come possiamo ottenerle utilizzando metodi di *clustering* ("raggruppamento") e apprendimento contrastivo (*Contrastive Learning*). Parliamo inoltre di *ClusterFit*, del suo funzionamento e delle sue performance. Andiamo più nel dettaglio vedendo un *framework* specifico ma semplice per l'apprendimento contrastivo conosciuto come PIRL. Discutiamo del suo funzionamento e della sua valutazione in contesti disparati.

<!-- In this section, we discuss the shortcomings of pretext tasks, define characteristics that make a good pretrained feature, and how we can achieve this using Clustering and Contrastive Learning. We then learn about ClusterFit, its steps and performance. We further dive into a specific simple framework for Contrastive Learning known as PIRL. We discuss its working as well as its evaluation in different contexts. -->

## Pratica

<!-- ## Practicum -->

Durante la parte pratica di questa settimana, esploriamo un controllore per la retromarcia di un camion ([*truck backer-upper*] (http://neuro.bstu.by/ai/To-dom/My_research/Papers-2.1-done/RL-sparce-reward/9/Ref/truckbackerupper.pdf)) (Nguyen & Widrow, '90).
Questo capitolo illustra come risolvere un problema di controllo non-lineare.
Apprendiamo un modello della cinematica di un camion e ottimizziamo un controllore tramite questo modello appreso, trovando che il controllore è capace di imparare comportamenti complessi a partire puramente dai dati osservati.

<!-- During this week's practicum, we explore the [Truck Backer-Upper](http://neuro.bstu.by/ai/To-dom/My_research/Papers-2.1-done/RL-sparce-reward/9/Ref/truckbackerupper.pdf) (Nguyen & Widrow, '90). -->
<!-- This problem shows how to solve an non-linear control problem using neural networks.
We learn a model of a truck's kinematics, and optimize a controller through this learned model, finding that the controller is able to learn complex behaviors through purely observational data. -->
